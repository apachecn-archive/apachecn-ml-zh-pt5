

# 第十二章。下一步是什么？

通过这本书，我们了解了集成学习，并探索了它在许多场景中的应用。在介绍性章节中，我们查看了不同的示例、数据集和模型，发现没有一个模型或技术比其他模型或技术表现得更好。这意味着我们在处理这个问题时，应该一直保持警惕，因此分析师必须非常谨慎地进行。从各种模型中选择最佳模型的方法意味着我们拒绝所有性能略低于其他模型的模型，因此在追求*最佳*模型的过程中浪费了大量资源。

在[第 7 章](part0051_split_000.html#1GKCM1-2006c10fab20488594398dc4871637ee "Chapter 7. The General Ensemble Technique")、*通用集成技术*中，我们看到，如果我们有多个分类器，每个分类器都比随机猜测好，分类器的多数投票会提高性能。我们还看到，在分类器数量相当多的情况下，多数表决的总体准确性高于最准确的分类器。虽然多数投票工作在分类器是独立分类器的过于简化的假设上，但是*集成学习*的基础和重要性已经实现，并且前景看起来更加光明，因为我们确信有一个具有最高准确度的集成分类器。集成的分类器或模型被称为*基本分类器/学习器/模型*。如果所有的基础模型属于同一个模型家族，或者如果该家族是逻辑模型、神经网络、决策树或 SVM，那么我们将把它们分类为同质集成。如果基本模型属于两个或多个模型族，那么该集成被称为异类集成。

集成学习的一个基本方面在于*重采样技术*。在[第二章](part0018_split_000.html#H5A41-2006c10fab20488594398dc4871637ee "Chapter 2. Bootstrapping")、*自举*中介绍了刀切法和自举法，并针对不同类别的模型举例说明了这两种方法。刀切方法使用伪值，我们见证了它在一些复杂场景中的应用。伪值在机器学习领域中未被充分利用，并且它们在关系或感兴趣的参数相当复杂并且更灵活的方法是可能的情况下可能是有用的。伪值的概念也可以用在集合诊断中，并且可以创建*伪准确度*测量，其将给予集合中分类器的影响额外的准确度。Efron 和 Tibshirani (1990 年)讨论了获得 bootstrap 样本的不同方法。在我们在装袋和随机森林的步骤中获得的重样本中，我们遵循简单的替换抽取观察样本。从现有的 bootstrap 文献中获取不同的抽样方法是未来工作的一个潜在领域。

Bagging、random forest 和 boosting 是以决策树作为基本学习器的同构系综。本书中讨论的决策树可以被称为频繁方法或经典方法。决策树的贝叶斯实现在一种称为**贝叶斯加法回归树**的技术中是可用的。这个方法的 R 实现可以在位于[https://cran.r-project.org/web/packages/BART/index.html](https://cran.r-project.org/web/packages/BART/index.html)的 BART 包中获得。BART 的理论基础可在[https://arxiv.org/pdf/0806.3286.pdf](https://arxiv.org/pdf/0806.3286.pdf)获得。基于 BART 的同类系综的扩展需要以一种全面的方式进行。特别是，bagging 和 random forests 需要以 BART 为基础学习者进行扩展。

使用堆栈集成方法建立异构基础模型的集成模型。对于分类问题，我们可以预期加权投票比简单多数投票更有用。类似地，模型的加权预测预期比简单平均执行得更好。为测试基础模型相似性而提出的统计测试都是*经典*测试。贝叶斯协议措施有望给我们进一步的指导方针，这本书的作者现在知道这种评估是在集合多样性的背景下进行的。你可以在[https://www . crcpress . com/Bayesian-Methods-for-Measures-of-Agreement/broe meling/p/book/9781420083415](https://www.crcpress.com/Bayesian-Methods-for-Measures-of-Agreement/Broemeling/p/book/9781420083415)阅读 Broemeling (2009)以了解更多信息。此外，当涉及到大型数据集时，需要系统地开发生成一组独立模型的选项。

时间序列数据具有不同的结构，观测值的相关性意味着我们不能不经过适当的调整就直接应用集成方法。[第 11 章](part0076_split_000.html#28FAO1-2006c10fab20488594398dc4871637ee "Chapter 11. Ensembling Time Series Models")、*集合时间序列模型*，更详细地探讨了这个话题。最近，随机森林已经被开发用于时间序列数据。随机森林的实现可以在[https://pet olau . github . io/Ensemble-of-trees-for-forecasting-time-series/](https://petolau.github.io/Ensemble-of-trees-for-forecasting-time-series/)看到，如果你有兴趣，可以参考这个链接了解更多信息。

高维数据分析是另一个较新的话题，本书没有涉及。布尔曼和范德格尔(2011)的第 12 章(见[https://www.springer.com/in/book/9783642201912](https://www.springer.com/in/book/9783642201912))在这方面给出了有用的提示。为了增加数据，Schapire 和 Freund (2012)的论文(在 https://mitpress.mit.edu/books/boosting)是一笔真正的财富。周(2012)【https://www . crcpress . com/Ensemble-Methods-Foundations-and-Algorithms/Zhou/p/book/9781439830031)也是一本非常重要的关于集成方法的书，这本书得益于它的见解。Kuncheva (2004-14)(可在 https://online library . Wiley . com/doi/book/10.1002/9781118914564 找到)可能是第一本详述集成方法的书，它包含了许多关于集成诊断的其他细节。Dixit (2017)(位于[https://www . packtpub . com/big-data-and-business-intelligence/ensemble-machine-learning](https://www.packtpub.com/big-data-and-business-intelligence/ensemble-machine-learning))是另一个关于集成方法的最新标题，书中使用 Python 软件对这些方法进行了说明。

最后，读者应该始终保持对最近发展的连续跟踪。对于 R 实施，资源的最佳地点是[https://cran.r-project.org/web/views/MachineLearning.html](https://cran.r-project.org/web/views/MachineLearning.html)。

接下来，我们将看看重要期刊的列表。在这些杂志上，许多关于机器学习的发展和讨论正在发生，因此集成学习也是如此。这些日志如下:

*   学研学刊([http://www.jmlr.org/](http://www.jmlr.org/)
*   IEEE 汇刊模式分析与机器智能([https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34)
*   模式识别字母([https://www . journals . Elsevier . com/pattern-Recognition-Letters](https://www.journals.elsevier.com/pattern-recognition-letters))
*   机器学习([https://www.springer.com/computer/ai/journal/10994](https://www.springer.com/computer/ai/journal/10994)
*   神经计算([https://www.journals.elsevier.com/neurocomputing](https://www.journals.elsevier.com/neurocomputing))
*   最后，但同样重要的是(尽管这不是一本期刊)[https://www.packtpub.com/tech/Machine-Learning](https://www.packtpub.com/tech/Machine-Learning)

如果你觉得这本书有用，我们应该在下一版再见！