# 九、优化 ML 模型

在本章中，您将了解两种可用于发现数据集最佳模型的技术。您将从探索 AzureML SDK 的 **HyperDrive** 包开始。这个包允许你通过调整模型暴露的参数来微调模型的性能，这个过程也被称为**超参数调整**。然后您将探索 AzureML SDK 的**自动化 ML** ( **AutoML** )包，它允许您通过代码自动化模型选择、训练和优化过程。

在本章中，我们将讨论以下主要话题:

*   使用超驱动进行超参数调谐
*   用代码运行 AutoML 实验

# 技术要求

您需要访问 Azure 订阅。在该订阅中，您将需要一个`packt-azureml-rg`。你将需要一个`Contributor`或者`Owner`T3，如 [*第二章*](B16777_02_Final_VK_ePub.xhtml#_idTextAnchor026) 、*部署 Azure 机器学习工作区资源*中所述。

你还需要对 **Python** 语言有一个基本的了解。代码片段面向 Python 版或更高版本。你还应该熟悉在 AzureML Studio 中使用笔记本的体验，这在 [*第八章*](B16777_08_Final_VK_ePub.xhtml#_idTextAnchor117) ，*用 Python 代码做实验*中有所涉及。

本章假设您已经在 AzureML 工作区中注册了 **scikit-learn** 糖尿病数据集，并且已经创建了一个名为 **cpu-sm-cluster** 的计算集群，如*定义数据存储*、*处理数据集*以及 [*第 7 章*](B16777_07_Final_VK_ePub.xhtml#_idTextAnchor102) 、*azure ml Python SDK*中的*处理计算目标*部分所述。

你可以在 GitHub 的网址[http://bit.ly/dp100-ch09](http://bit.ly/dp100-ch09)找到本章的所有笔记和代码片段。

# 使用 HyperDrive 调节超参数

在 [*第 8 章*](B16777_08_Final_VK_ePub.xhtml#_idTextAnchor117) ，*用 Python 代码*做实验，你训练了一个接受`alpha`参数的`LassoLars`模型。为了避免过度适应训练数据集，`LassoLars`模型使用了一种称为`alpha`的技术，参数指定了这个惩罚项有多重要，这直接影响了训练结果。影响训练过程的参数被称为是位于`scikit-learn`库中的`DecisionTreeClassifier`类，你可以通过`max_depth`定义树的最大深度，它是一个整数。在同一个模型中，您可以通过给`max_leaf_nodes` **超参数**指定一个数值来控制叶节点的最大数量。

这些超参数控制决策树的大小，如图*图 9.1* 所示:

![Figure 9.1 – Decision tree hyperparameters
](img/B16777_09_001.jpg)

图 9.1–决策树超参数

**超参数调整**是为**超参数**寻找最优值的过程，该过程根据您用于训练的数据产生性能最佳的模型。为了能够评估每个**超参数**组合的性能，必须训练模型，并且必须评估性能指标。在 [*第八章*](B16777_08_Final_VK_ePub.xhtml#_idTextAnchor117) 、*用 Python 代码*进行实验的糖尿病模型中，您使用**归一化均方根误差** ( **NRMSE** )度量来评估模型。

AzureML SDK 提供了`HyperDriveConfig`类，它允许你执行`HyperDriveConfig`是你在 [*第 8 章*](B16777_08_Final_VK_ePub.xhtml#_idTextAnchor117) 、*中使用的`ScriptRunConfig`类的包装，用 Python 代码做实验*。这意味着您需要在`run_config`参数中传递您想要用来训练您的模型的`ScriptRunConfig`。您还需要指定您的代码正在记录的指标，以及您对该指标的目标是什么。在糖尿病案例中，您试图最小化您在第 8 章 、*使用 Python 代码*中看到的`submit`方法。显示端到端流程的伪代码如下，其中的`script`变量引用了定义您将使用哪个训练脚本的`ScriptRunConfig`对象:

```
hd_config = HyperDriveConfig(
             run_config=script,
             primary_metric_name="nrmse",
             primary_metric_goal=PrimaryMetricGoal.MINIMIZE
             ,…)
experiment = Experiment(ws, "chapter09-hyperdrive")
hyperdrive_run = experiment.submit(hd_config)
```

除了`ScriptRunConfig`，你还需要通过`HyperDriveConfig`才会使用。**超参数**可以接受离散值或连续值:

*   离散值的典型例子是整数或字符串值。例如，`activation`中的`selu`为，`relu`为，**为整流线性单元** ( **ReLU** )。
*   连续值的一个典型例子是浮点值。您一直在训练的`LassoLars`模型中的`alpha`参数是一个接受浮点值的**超参数**。

当你在探索可能的`azureml.train.hyperdrive.parameter_expressions`模块时。

在离散`choice`函数的情况下，它允许你指定选项列表`activation` **超参数**你之前用下面的脚本看到:

```
choice('selu','relu')
```

该脚本将尝试`selu`和`relu`激活函数，同时寻找最佳模型。

重要说明

如果你对神经网络感兴趣，你可能需要更好地理解这些激活功能。有一些很棒的书可以帮助你开始学习神经网络设计。对于 DP-100 考试，你不需要这些知识。

注意，即使在连续的`alpha` `LassoLars`模型的情况下，你仍然可以使用`choice`方法来定义离散值进行探索。例如，下面对`choice`的使用相当于你在 [*第 8 章*](B16777_08_Final_VK_ePub.xhtml#_idTextAnchor117)*中的*跟踪模型演化*部分所做的用 Python 代码*做实验:

```
choice(0.001, 0.01, 0.1, 0.25, 0.5)
```

您还可以定义您在探索搜索空间时将获得的样本的概率分布。例如，如果您想为所有值提供均等的机会，您将使用均匀分布。另一方面，您可以使用正态分布将搜索区域集中在搜索空间的中心。AzureML SDK 提供了一些你可以使用的方法，比如`uniform(low, high)`、`loguniform(low, high)`、`normal(μ,σ)`和`lognormal(μ, σ)`。您可以对离散值使用带`q`前缀的等价物，例如`quniform(low, high, q)`、`qloguniform(low, high, q)`、`qnormal(μ, σ, q)`和`qlognormal(μ, σ`、`, q)`，其中`q`参数是将连续值转换为离散值的量化因子。

在本书的 GitHub 页面上，您可以找到绘制 1000 个样本的代码，这些样本是用这些函数的分布生成的。结果见*图 9.2* :

![Figure 9.2 – Advanced discrete and continuous hyperparameter value distributions. Sample values are ordered. The x axis shows the ordered value's index number
](img/B16777_09_002.jpg)

图 9.2-高级离散和连续超参数值分布。样本值已排序。x 轴显示排序值的索引号

重要说明

在*图 9.2* 中，在`loguniform`和`lognormal`图中，量化因子为 1 的离散函数的线与连续函数的线重叠。因此，你只能看到两条线。

一旦定义了搜索空间，您需要指定用于选择每个`azureml.train.hyperdrive`模块的采样策略:

*   `choice` method you saw above. The Azure ML SDK will search all possible **hyperparameter** combinations of those discrete values. Imagine that you wanted to explore the following four parameter combinations:
    *   a=0.01，b=10
    *   a=0.01，b=100
    *   a=0.5，b=10
    *   a=0.5，b=100

    以下代码片段定义了这四种组合的搜索空间:

    ```
    from azureml.train.hyperdrive import GridParameterSampling
    from azureml.train.hyperdrive import choice
    param_sampling = GridParameterSampling( {
            "a": choice(0.01, 0.5),
            "b": choice(10, 100)
        }
    )
    ```

*   `RandomParameterSampling`阶级。它允许您从可用选项中随机选择**超参数**值。它支持离散和连续的**超参数**。
*   接下来你会读到。它支持离散和连续的**超参数**。

让我们将迄今为止你所学到的一切付诸行动:

1.  导航到 AzureML Studio web 界面的**作者** | **笔记本**部分。
2.  创建一个名为`chapter09`的文件夹。
3.  您需要在`training.py`脚本中创建一个`diabetes-training`文件夹。该脚本与 [*第 8 章*](B16777_08_Final_VK_ePub.xhtml#_idTextAnchor117) 、*试验 Python 代码*中使用的脚本相同，在*部分将代码移动到 Python 脚本文件*。你可以从那里复制内容。最终的**文件**树如图*图 9.3* 所示。
4.  Create a notebook named **chapter09.ipynb** within the **chapter09** folder. *Figure 9.3* shows what the final **Files** tree will look like:![Figure 9.3 – The Files tree structure that contains the code and the chapter09 notebook
    ](img/B16777_09_003.jpg)

    图 9.3-包含代码和第 09 章笔记本的文件树结构

5.  Add the following initialization code in the first cell:

    ```
    from azureml.core import (
        Workspace, Environment
    )
    from azureml.core.conda_dependencies import \
         CondaDependencies 
    import sklearn
    ws = Workspace.from_config()
    diabetes_env = Environment(name=»diabetes-training-env»)
    diabetes_env.python.conda_dependencies = \
         CondaDependencies.create(
          conda_packages=[
              f"scikit-learn=={sklearn.__version__}"],
          pip_packages=["azureml-defaults",
                        "azureml-dataprep[pandas]"])
    target = ws.compute_targets['cpu-sm-cluster'] 
    ```

    这是一个类似于你在 [*第八章*](B16777_08_Final_VK_ePub.xhtml#_idTextAnchor117) 、*试验 Python 代码*中使用的代码。唯一的区别是您使用的是`create`方法，而不是一个一个地添加包。

6.  In a new cell, define the `ScriptRunConfig` object that will execute the `training.py` script:

    ```
    from azureml.core import ScriptRunConfig
    script = ScriptRunConfig(
        source_directory='diabetes-training',
        script='training.py',
        environment=diabetes_env,
        compute_target=target
    )
    ```

    这个`ScriptRunConfig`对象与您在 [*第 8 章*](B16777_08_Final_VK_ePub.xhtml#_idTextAnchor117) 、*使用 Python 代码*的*在计算集群上训练糖尿病模型*部分中创建的对象几乎相同。唯一的区别是您没有传递`arguments`参数。特别是，你不要指定`--alpha`参数。您将在下一步中配置的`HyperDriveConfig`对象将自动追加该参数。

7.  Add and execute the following code in a new cell:

    ```
    from azureml.train.hyperdrive import HyperDriveConfig
    from azureml.train.hyperdrive import (
       RandomParameterSampling, uniform, PrimaryMetricGoal
    )
    param_sampling = RandomParameterSampling({
            'alpha': uniform(0.00001, 0.1),
        }
    )
    hd_config = HyperDriveConfig(
                   run_config=script,                          
                   hyperparameter_sampling=param_sampling,
                   primary_metric_name="nrmse", 
                   primary_metric_goal=                   
                              PrimaryMetricGoal.MINIMIZE,
                   max_total_runs=20,
                   max_concurrent_runs=4)
    ```

    在这段代码中，您定义了一个`RandomParameterSampling`方法来探索均匀分布的值，范围从 0.00001 到 0.1，用于将被传递到您在*步骤 3* 中创建的训练脚本的`alpha`参数。这个训练脚本接受`--alpha`参数，然后将其传递给`alpha` `LassoLars`模型。

    您将这个`RandomParameterSampling`配置分配给`HyperDriveConfig`的`hyperparameter_sampling`参数。

    您还配置了`HyperDriveConfig`的`run_config`属性，以使用您在*步骤 6* 中定义的`ScriptRunConfig`对象。注意，`RandomParameterSampling`类将传递脚本所需的`alpha`参数。

    然后您定义生产的模型将使用`primary_metric_name`参数评估。您还指定您正在尝试最小化该值(参数`primary_metric_goal`，因为它是您想要最小化的误差。

    最后两个参数，`max_total_runs`和`max_concurrent_runs`，控制着你在寻找最佳模型时愿意投入的资源。`max_total_runs`参数控制实验运行的最大数量。这可以是 1 到 1，000 次运行。这是一个必需参数。`max_concurrent_runs`可选参数，控制运行的最大并发量。在这种情况下，您定义了 *4* ，这意味着在`ScriptRunConfig`中将只提供四个节点。这意味着集群仍将有一个未配置的节点，因为它最多可以扩展到五个节点，正如您在第 7 章 [*的*使用计算目标*一节中定义的那样*](B16777_07_Final_VK_ePub.xhtml#_idTextAnchor102)，*azure ml Python SDK*。还有一个可选参数可用于限制搜索最佳`max_duration_minutes`参数的时间，您在上面的示例中没有指定该参数，该参数定义了运行**超参数调整**过程的最大持续时间(分钟)。超时后，所有后续计划运行将自动取消。

8.  In a new cell, add the following code:

    ```
    from azureml.core import Experiment
    experiment = Experiment(ws, "chapter09-hyperdrive")
    hyperdrive_run = experiment.submit(hd_config)
    hyperdrive_run.wait_for_completion(show_output=True)
    ```

    在这段代码中，您提交的要在`hyperdrive_run`变量下执行的`HyperDriveConfig`是`HyperDriveRun`的一个实例，它继承自普通的`Run`类。

9.  You can review the results of the process in the Studio web UI. Navigate to the `alpha` hyperparameter. You can visually explore the effect the various values of the `alpha` parameter have regarding the `alpha` value of `HyperDriveRun` (**Run 1**).

    重要说明

    在您的执行中，运行编号可能会有所不同。每次执行单元时，都会创建一个新的运行编号，从之前的编号继续。因此，如果您执行包含 20 个子运行的 hyperdrive 运行代码，则最后一个子运行将是运行 21。下一次执行相同的代码时，hyperdrive 运行将从运行 22 开始，最后一个子级将是运行 42。本节中提到的运行编号是各个图中显示的编号，观察到差异是正常的，尤其是如果您必须重新运行几个细胞。

10.  Navigate to the **Outputs + logs** tab of the completed **Run 1** run. You will notice that there is a single file under the **azureml-logs** folder named **hyperdrive.txt**, as shown in *Figure 9.5*:![Figure 9.5 – Log file in HyperDriveRun, picking up the first four jobs from 
    the hyperparameter space that will be executed in parallel
    ](img/B16777_09_005.jpg)

    图 9.5–HyperDriveRun 中的日志文件，从将要并行执行的超参数空间中选取前四个作业

    该文件包含计划完成超参数调整过程的所有作业。实际运行日志和存储的模型存储在子运行中。如果您需要调试代码问题，您必须打开其中一个来查看脚本错误。

11.  您还可以获得最佳模型的运行，相应的`get_best_run_by_primary_metric`方法检索`HyperDriveRun`的最佳运行，该运行由`hyperdrive_run`变量引用。从那里，您可以读取`Run`对象的`get_metrics`方法，并且您可以使用`get_details`方法获得执行的细节。在这些细节中，有一个`runDefinition`对象包含一个`arguments`列表，如图*图 9.6* 所示:

![Figure 9.6 – Demystifying the best_run.get_details()['runDefinition']['arguments'] code
](img/B16777_09_006.jpg)

图 9.6–揭开 best _ run . get _ details()[' run definition '][' arguments ']代码的神秘面纱

在本节中，您看到了如何运行一个**超参数调整**过程来为您的模型的**超参数**找到最佳值。在下一节中，您将看到如何通过使用提前终止策略来优化搜索最佳价值的时间。

## 使用提前终止政策

`HyperDriveConfig`构造函数的参数之一是`policy`参数。该参数接受一个`EarlyTerminationPolicy`对象，该对象定义了可以提前终止运行的策略。默认情况下，这个参数有一个`None`值，这意味着将使用`NoTerminationPolicy`类，允许每次运行执行到完成。

为了能够使用提前终止策略，您的脚本必须在每次运行期间执行多次迭代。

在**文件**视图中，添加一个名为**离职-政策-训练**的文件夹，并在其中添加一个 **training.py** 文件，如图*图 9.7* 所示:

![Figure 9.7 – Adding a training script that performs multiple epochs
](img/B16777_09_007.jpg)

图 9.7–添加执行多个时期的训练脚本

在训练脚本中添加以下代码:

```
from azureml.core.run import Run
import argparse
import time
parser = argparse.ArgumentParser()
parser.add_argument("--a", type=int, dest="a", help="The alpha parameter")
parser.add_argument("--b", type=int, dest="b", help="The beta parameter")
args = parser.parse_args()
if (args.a > 2):
    args.a = 0
run = Run.get_context()
def fake_train(run, a, b):
    time.sleep(5)
    metric = a + b
    run.log("fake_metric", metric)
for epoch in range(20):
    fake_train(run, args.a * epoch, args.b)
```

脚本获得两个参数`a`和`b`，然后调用`fake_train`方法 20 次。在数据科学文献中，人们将这 20 次称为 20 个**时期**，这些是整个训练数据集的训练周期。

在每个历元中，`a`参数乘以迭代次数，迭代次数是从 *0* 一直到 *19* 的整数值，调用`fake_train`方法。`fake_train`方法休眠 5 秒钟以模拟训练过程，然后将修改后的`a`值添加到`b`参数中。结果记录在`fake_metric`指标中。

此外，在*的第 8 行*中，代码检查传递给脚本的`a`参数。如果大于 *2* ，则变为值 *0* 。这意味着，当`a`值增加到值 *2* 时，您正在训练的假模型将表现得更好，然后其性能将下降，如图*图 9.8* 所示。

注意，您不需要读取任何数据集，因此，您不需要引用`Workspace`。这就是为什么上面代码中的*第 10 行*不需要检查这是否是一个`_OfflineRun`对象，就像你在 [*第 8 章*](B16777_08_Final_VK_ePub.xhtml#_idTextAnchor117) 、*试验 Python 代码*中的*移动代码 to Python 脚本文件*一节所做的那样。

如果您要运行`HyperDriveConfig`，对在 *1* 和 *4* 之间的所有值进行网格搜索，以获得各时期的`fake_metric`演变。在图的右侧上，您可以看到`fake_metric`如何受到`a`和`b`T5 的各种值的影响，其性能优于使用`a`参数 *3* 和 *4* 训练的模型，关于`fake_metric`:

![Figure 9.8 – Hyperparameter tuning without early termination policy
](img/B16777_09_008.jpg)

图 9.8–无提前终止策略的超参数调整

理想情况下，您希望减少等待所有运行完成的时间。`EarlyTerminationPolicy`允许您监控正在运行的作业，如果与其他作业相比，它们的性能很差，请提前取消它们。产生的输出将类似于图 9.9 中的输出，其中您可以看到一些作业在到达第二十个报告间隔之前被终止(该图从 0 开始计数)，从而节省了时间和计算资源:

![Figure 9.9 – Hyperparameter tuning with aggressive early termination policy
](img/B16777_09_009.jpg)

图 9.9–积极提前终止策略下的超参数调整

AzureML SDK 为提供了一些内置的`EarlyTerminationPolicy`实现，位于`azureml.train.hyperdrive`模块中:

*   `NoTerminationPolicy`:这个是允许所有运行完成的默认停止策略。
*   `MedianStoppingPolicy`:中位数停止策略计算所有运行的运行平均值。然后，它会取消那些最佳性能比运行平均值的中值差的运行。您可以将此策略视为将每次运行的性能与之前运行的平均性能进行比较。这个策略的好处在于，它考虑了到目前为止发生的所有运行，而不仅仅是将当前运行与到目前为止的最佳运行进行比较。该特征允许中间停止策略避免陷入局部最优值。
*   `BanditPolicy`:bandit 策略计算当前运行和最佳运行之间的距离，然后基于一些松弛标准终止它。您可以定义最佳运行的绝对距离(`slack_amount`参数)或最大允许比率(`slack_factor`参数)。
*   `TruncationSelectionPolicy`:截断选择策略是最激进的策略，它取消了在主要度量上性能排名最低的运行的一定百分比(`truncation_percentage`参数)。当对相对年轻的运行进行排序时，在早期的迭代中，该策略将它们与较老的运行的同等迭代性能进行比较。因此，该策略通过考虑随着训练时间的推移模型性能的提高来努力实现运行排序的公平性。

所有策略都有两个可选参数:

*   `evaluation_interva` l:应用策略的频率。
*   `delay_evaluation`:此将第一个策略评估延迟指定的时间间隔，为年轻运行提供达到成熟状态的时间。

让我们使用最推荐的策略对您在上面创建的脚本进行超参数调优，`MedianStoppingPolicy`:

1.  转到将在超参数调整过程中使用的`ScriptRunConfig`对象。
2.  In a new cell, add the following code:

    ```
    from azureml.train.hyperdrive import (
        GridParameterSampling,    
        choice,
        MedianStoppingPolicy,
        HyperDriveConfig,
        PrimaryMetricGoal
    )
    param_sampling = GridParameterSampling(
        {
            "a": choice(1, 2, 3, 4),
            "b": choice(1, 2, 3, 4),
        }
    )
    early_termination_policy = MedianStoppingPolicy(
        evaluation_interval=1, delay_evaluation=5
    )
    hd_config = HyperDriveConfig(
        policy=early_termination_policy,
        run_config=script,
        hyperparameter_sampling=param_sampling,
        primary_metric_name="fake_metric",
        primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,
        max_total_runs=50,
        max_concurrent_runs=4
    )
    ```

    这个`HyperDriveConfig`对象使用`MedianStoppingPolicy`作为它的策略参数来评估第一次 *5 次*迭代后的所有运行，并将每次迭代的结果与运行平均值的中值进行比较。

3.  In a new cell, add the following code to start the execution of the `HyperDriveConfig` object you defined in *step 2*:

    ```
    experiment = Experiment(ws, "chapter09-hyperdrive")
    hyperdrive_run = experiment.submit(hd_config)
    hyperdrive_run.wait_for_completion(show_output=True)
    ```

    *图 9.10* 显示了这次`HyperDriveRun`运行的结果，16 个任务中只有 8 个提前终止:

![Figure 9.10 – Hyperparameter tuning with median stopping early termination policy
](img/B16777_09_010.jpg)

图 9.10–采用中位数停止提前终止策略的超参数调整

重要说明

在上面的代码中，`max_total_runs`参数的值为 50。这是可能发生的子运行数量的上限。在本例中，您只有 16 种组合。这意味着实验将只运行 16 次，然后它将停止，因为整个搜索区域已经被搜索。如果您想让`max_total_runs`参数生效，您应该指定一个小于 16 的值。

到目前为止，您已经看到了如何根据现有的数据优化特定的模型。在下一节中，您将看到如何通过 SDK 搜索运行 AutoML 实验的最佳模型，类似于您在 [*第 5 章*](B16777_05_Final_VK_ePub.xhtml#_idTextAnchor072)*中所做的，通过 studio 用户界面让机器进行模型训练*。

# 用代码运行 AutoML 实验

到目前为止，在本章的中，您正在微调一个`LassoLars`模型，执行一个超参数调整过程来根据训练数据确定`alpha`参数的最佳值。在本节中，您将使用 AzureML SDK 中的 **AutoML** 为您的训练数据集自动选择数据预处理、模型和超参数设置的最佳组合。

配置一个`AutoMLConfig`对象。您需要定义您想要投资的**任务类型**、**指标**、**训练数据**和**计算预算**。该过程的输出是一个模型列表，您可以从中选择最佳运行以及与该运行相关的最佳模型，如图*图 9.11* 所示:

![Figure 9.11 – AutoML process
](img/B16777_09_011.jpg)

图 9.11–AutoML 流程

根据你试图建模的问题类型，你必须选择`task`参数，选择`classification`、`regression`或`forecasting`，如图*图 9.12* 所示:

![Figure 9.12 – AutoML task types, algorithms, and supported metrics
](img/B16777_09_012.jpg)

图 9.12–AutoML 任务类型、算法和支持的指标

*图 9.12* 只显示了 AzureML SDK 支持的算法的子集。`azureml.train.automl.constants.SupportedModels`包包含了`classification`、`regression`和`forecasting`类，它们列出了所有支持的算法作为属性。因为预测只是回归的一个更专门化的版本，所以回归的所有算法都可以使用。AutoML 支持一些额外的、更专业的预测算法，比如非常流行的 ARIMA 技术或脸书的预言家算法。

`primary_metric`参数决定了优化模型训练过程中使用的指标。回归和预测的指标是相同的。分类算法使用不同的度量标准，如图 9.12 所示。

训练数据可以在`training_data`参数中提供，或者以熊猫`Dataset`对象的格式。训练数据以表格形式显示，包括`target`栏。您定义想要预测的列的名称，传递`label_column_name`参数。默认情况下，AutoML 将使用该数据集对生成的模型进行定型和验证。如果数据集超过 20，000 行，数据集将被拆分，保留 10%用于验证。如果数据集小于 20，000 行，则使用交叉验证。如果您想指定从`training_data`创建多少个折叠，您可以使用`n_cross_validations`参数。另一种方法是提供`validation_size`参数，它是训练数据的百分比(值 *0.0* 到 *1.0* ),用作验证。如果您想要手动将数据分割成训练和验证数据，那么您可以将您的验证数据分配给`validation_data`参数，就像您将在本节后面所做的那样。

**计算预算**是你愿意花在从你的训练数据中寻找最佳机器学习模型的金额。它由三部分组成:

*   **计算集群的节点类型**:您的计算集群类型的功能越多，运行 AutoML 作业时每秒的成本就越大。这是您在创建计算群集时配置的设置，除非您创建新的群集，否则此时无法更改。
*   `max_concurrent_iterations`参数使用计算集群拥有的最大节点数。这将允许您运行并行迭代，但是增加了成本。默认情况下，该参数为 *1* ，一次只允许一次迭代。
*   `experiment_timeout_hours`参数或者您可以定义`experiment_exit_score`参数，该参数定义要达到的分数，然后停止进一步探索。限制计算支出的另一种方法是限制要探索的不同算法和参数组合的数量。默认情况下，AutoML 将探索 1000 种组合，您可以通过指定`iterations`参数来限制它。

既然你已经探索了你需要在`AutoMLConfig`对象中配置的所有选项，导航到你的`chapter09.ipynb`笔记本，添加一个新的单元格，并键入以下代码:

```
from azureml.core import Workspace, Dataset
from azureml.train.automl import AutoMLConfig
ws = Workspace.from_config()
compute_target = ws.compute_targets["cpu-sm-cluster"]
diabetes_dataset = Dataset.get_by_name(workspace=ws, name='diabetes')
train_ds,validate_ds = diabetes_dataset.random_split(percentage=0.8, seed=1337)
experiment_config = AutoMLConfig(
    task = "regression",
    primary_metric = 'normalized_root_mean_squared_error',
    training_data = train_ds,
    label_column_name = "target",
    validation_data = validate_ds,
    compute_target = compute_target,
    experiment_timeout_hours = 0.25,
    iterations = 4
)
```

在这段代码中，您获得了对工作区、您的计算集群和`diabetes`数据集的引用，您将数据集分为训练数据集和验证数据集。然后创建一个`AutoMLConfig`对象，由来处理`target`列。您还可以指定`validation_data`参数。

重要说明

您可以在`training_data`参数中传递整个数据集并跳过`validation_data`参数，而不是分割数据集。由于数据集仅包含 442 行，AutoML 会将训练数据集拆分为 10 个折叠，这将用于执行交叉验证技术。

然后，您定义用于该训练的`compute_target`实验，并通过允许实验运行一刻钟(`experiment_timeout_hours`参数)，即 15 分钟，并仅探索 4 个模型和参数组合(`iterations`参数)，来确定您的计算预算。在你的情况下，`iterations`参数可能是终止 **AutoML** 实验的原因。

重要说明

对于预测，除了之前定义的回归参数之外，您还需要指定`forecasting_parameters`。`ForecastingParameters`类有以下常用参数:

1) `time_column_name`:表示时间序列的时间维度的列。

2) `max_horizon`:以时间序列频率为单位的期望预测范围。这是默认的 *1* ，意味着你的模型将能够预测未来的单个时隙。该时间段是数据集使用的频率。如果您的数据集每小时有 1 行，并且您想要预测 7 天，`max_horizon`需要是 7 天 x 每天 24 个时段= 168。

到目前为止，您已经创建了`experiment_config`，它包含了您将要执行的 **AutoML** 实验的配置。添加一个新单元，并将以下代码添加到中，启动 AutoML 训练流程:

```
from azureml.core.experiment import Experiment
my_experiment = Experiment(ws, 'chapter09-automl-experiment')
run = my_experiment.submit(experiment_config, 
                           show_output=True)
```

`run`变量包含对使用`submit`方法创建的`AutoMLRun`对象的引用。几分钟后，该过程将完成。要获得当前的最佳运行和最佳模型，您可以使用`get_output()`方法，如下面的代码片段所示:

```
best_run, best_model = run.get_output()
```

或者，您可以使用相应的`Tuple`索引直接访问最佳运行和最佳模型，如下面的代码片段所示:

```
best_run = run.get_output()[0]
best_model = run.get_output()[1]
```

在每一个自动化机器学习实验中，你的数据都会被自动缩放或归一化，以帮助算法表现良好。这种数据转换正在成为训练模型的一部分。这意味着您的数据首先通过数据转换器，然后使用您无法直接看到的新要素名称对模型进行训练。你会在 [*第十章*](B16777_10_Final_VK_ePub.xhtml#_idTextAnchor147)*了解模型结果*中看到`sklearn.composeColumnTransformer`的例子。要查看嵌入在 AutoML 模型中的实际步骤，您可以使用生产模型的`steps`属性:

```
best_model.steps
```

第一步被命名为`datatransformer`，包含用于我们的`diabetes`数据集的估算值。这个步骤被命名为`datatransformer`,用于回归和分类任务。对于预测任务，这个步骤被命名为`timeseriestransformer`，它包含额外的基于日期的转换。要获得一个转换和工程特性名称的列表，您可以使用下面的代码片段:

```
print(best_model.named_steps['datatransformer'] \
                 .get_featurization_summary())
feature_names=best_model.named_steps['datatransformer'] \
                 .get_engineered_feature_names()
print("Engineered feature names:")
print(feature_names)
```

在本节中，您使用 **AutoML** 搜索了针对糖尿病回归问题的最佳模型。这总结了在给定特定数据集的情况下，可以优化机器学习模型的最常用方法。

# 总结

在本章中，您探索了优化特定模型以针对数据集执行良好操作的最常用方法，以及如何实现模型选择过程的自动化。您首先执行并行化的`HyperDriveConfig`类，以优化针对`diabetes`数据集训练的`LassoLars`模型的`alpha`参数。然后，您自动化了模型选择，使用 AutoML 来检测预测`diabetes`数据集的`target`列的算法和参数的最佳组合。

在下一章中，你将在这些知识的基础上学习如何使用 AzureML SDK 来解释模型结果。

# 问题

1.  You want to get the best model trained by an `model = run.get_output()[0]`

    b.`model = run.get_output()[1]`

    c.`model = run.get_outputs()[0]`

    d.`model = run.get_outputs()[1]`

2.  You want to run a forecasting `ForecastingParameters` class?

    a. *forecast_horizon = 5 * 1*

    b. *forecast_horizon = 5 * 24*

    c. *forecast_horizon = 5 * 12*

# 延伸阅读

本节提供了一个有用的 web 资源列表，可以帮助您增加 AzureML SDK 和本章中使用的各种代码片段的知识:

*   `HyperDriveConfig`类:[https://docs . Microsoft . com/en-us/python/API/azure ml-train-core/azure ml . train . hyperdrive . hyperdrive config？view=azure-ml-py](https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.hyperdriveconfig?view=azure-ml-py)
*   `AutoMLConfig`类:[https://docs . Microsoft . com/en-us/Python/API/azure ml-train-automl-client/azure ml . train . automl . automlconfig . automlconfig](https://docs.microsoft.com/en-us/Python/api/azureml-train-automl-client/azureml.train.automl.automlconfig.automlconfig)
*   自动化机器学习中的数据特征:[https://docs . Microsoft . com/en-us/azure/machine-learning/how-to-configure-auto-features](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-features)
*   自动训练预测模型:[https://docs . Microsoft . com/en-us/azure/machine-learning/how-to-auto-train-forecast](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-forecast)
*   对从 scikit-learn 库中加载的糖尿病数据集的引用:[https://sci kit-learn . org/stable/modules/generated/sk learn . datasets . load _ diabetes . html](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html)