# 五、让机器训练模型

在这一章中，你将创建你的第一个**自动化机器学习** ( **自动化 ML** 或 **AutoML** )实验。AutoML 是指尝试多种建模技术并选择模型的过程，该模型根据您指定的训练数据集产生最佳预测。首先，您将浏览作为 Azure Machine Learning Studio web 体验一部分的 AutoML 向导，并了解需要配置的不同选项。然后，您将学习如何监控 AutoML 实验的进度，以及如何将生产最好的模型作为 web 服务部署在一个 **Azure 容器实例** ( **ACI** )中，以便能够进行实时推理。

阅读这一章的最好方法是坐在电脑前，阅读你的这本书。通过一起使用你的 Azure 订阅和这本书，你可以开始你的 AutoML 之旅。

在本章中，我们将讨论以下主要话题:

*   配置 AutoML 实验
*   监控实验的执行
*   将最佳模型部署为 web 服务

# 技术要求

您需要访问 Azure 订阅。在该订阅中，您将需要一个`packt-azureml-rg`。你将需要一个`Contributor`或者`Owner`T3，如 [*第二章*](B16777_02_Final_VK_ePub.xhtml#_idTextAnchor026) 、*部署 Azure 机器学习工作区资源*中所述。

# 配置 AutoML 实验

如果您被要求训练一个模型来对数据集进行预测，您将需要做几件事情，包括标准化数据集，将其分成训练和验证数据，运行多个实验来了解哪个算法对数据集执行得最好，然后微调最佳模型。自动化机器学习通过完全自动化耗时的迭代任务来缩短这一过程。它允许所有用户，从普通 PC 用户到经验丰富的数据科学家，根据目标数据集构建多个机器学习模型，并根据您选择的指标选择性能最佳的模型。

该过程由以下步骤组成:

1.  **准备实验**:选择要用于训练的数据集，选择要预测的列，配置实验参数。这是您将在本节中读到的配置阶段。
2.  **数据护栏**:这是执行实验的第一步。它在所提供的训练数据集之上执行基本的数据防护。AutoML 尝试识别您的数据的潜在问题；例如，在您尝试预测的列中，所有定型数据必须具有相同的值。
3.  **训练多个模型**:训练数据标准化和算法的多个组合，以找到优化(最大化或最小化)期望指标的最佳模型。这个过程一直持续到满足退出标准之一，或者是时间约束，或者是指定的模型性能目标。
4.  **创建一个集合模型**:在这里，你训练一个模型，它结合了迄今为止最好的训练模型的结果，并产生一个潜在的改进推理。
5.  **选择最佳模型**:根据您指定的指标选择最佳模型。

Azure 机器学习提供了一个基于网络的向导，允许你配置这样的实验。在 [*第三章*](B16777_03_Final_VK_ePub.xhtml#_idTextAnchor045) 、 *Azure ML Studio组件*中，你探索了Azure ML Studio**\ web 体验。**

 **在本章中，您将创建一个 AutoML 分类模型来预测客户是否会流失。该模型将能够预测客户是否会继续成为忠实客户，或者他们是否会终止其有效的移动电话合同。您将使用一个虚构的电信公司的虚构数据集。该数据集为每个客户显示了他们与该公司合作的时间以及他们使用其有效订阅的时间。让我们开始吧:

1.  To start the AutoML experiment, you will need to open a browser and navigate to the Azure Machine Learning Studio. You will land on the home page, as shown in the following screenshot:![Figure 5.1 – Azure Machine Learning Studio home screen
    ](img/B16777_05_001.jpg)

    图 5.1–Azure ML Studio主屏幕

2.  On the Azure Machine Learning Studio home screen, navigate to the **Author** | **Automated ML** section by clicking the **Start now** button under **Automated ML**, as highlighted in the preceding screenshot. This will open the **Automated ML** home screen, as shown here:![Figure 5.2 – The Automated ML home screen
    ](img/B16777_05_002.jpg)

    图 5.2–自动化 ML 主屏幕

    在这个主页屏幕上，您可以找到最近执行的自动化 ML 实验。由于这是您第一次使用这个工作区，您应该不会在这里找到任何运行列表。

3.  通过按下**新的自动化 ML 运行**按钮，您将启动**创建新的自动化 ML** 向导，如下所示:

![Figure 5.3 – Starting the Automated ML wizard
](img/B16777_05_003.jpg)

图 5.3–启动自动化 ML 向导

在向导的第一个步骤中，名为**选择数据集**，您可以选择一个现有的数据集或者创建一个新的数据集。从该列表中，您将能够看到您在第 4 章 、*配置工作空间*中注册的两个数据集。你将不需要那些数据集。在下一节中，您将学习如何创建一个新的数据集，用于您将要执行的自动化 ML 实验。

## 注册数据集

在**自动化 ML** 向导的选择数据集步骤中，您可以注册一个新的数据集用于 AutoML 实验。按照以下步骤注册虚构的客户流失数据集:

1.  点击屏幕顶部的**创建数据集**。
2.  从出现的下拉菜单中选择 web 文件中的**。这将启动**从 web 文件创建数据集**向导，如下图所示。**
3.  On the first page of the wizard (`churn-dataset`.

    c) `Tabular`。这是一个不能更改的选项，因为 AutoML 目前只支持表格数据集。

    d) `Dataset to train a model that predicts customer churn`:

    ![Figure 5.4 – Basic info when creating a dataset from web files
    ](img/B16777_05_004.jpg)

    图 5.4–从 web 文件创建数据集时的基本信息

4.  Once you've filled everything in, press **Next**. It will take a while to download and parse the file. The wizard will move to the **Settings and preview** screen:![Figure 5.5 – The Settings and preview screen of the Create dataset from web files wizard
    ](img/B16777_05_005.jpg)

    图 5.5–从 web 文件创建数据集向导的设置和预览屏幕

5.  The steps shown in the preceding screenshot provide important information for the demo dataset. The file format of the sample file is automatically detected to be the **Parquet** file format. You can modify the selection if needed.

    演示数据集由七列组成:

    *   **ld** 是一个连续记录号，它不是原始拼花文件的一部分。Auto ML 生成此序列号，让您可以验证在预览窗口中看到的数据。该列将不属于注册的数据集。
    *   **id** 是一个字符串，唯一标识数据集中的每个客户。
    *   **customer _ tension**是一个整数值，它告诉我们每个客户在这个虚构的电信公司工作了多长时间。该值表示月。
    *   **product _ tension**是一个整数值，它告诉我们客户拥有当前活动订阅的时间。它是以月来衡量的。
    *   **activity_last_6_month** 告诉我们客户在过去 6 个月中打电话的时间。
    *   **activity_last_12_month** 告诉我们客户在过去 12 个月中打电话的时间。
    *   **churned** is a flag that informs us whether the customer renewed the subscription or terminated the active contract. This is the column you will be trying to predict.

        从这个虚构的数据集中，与您尝试构建的分类模型最相关的特征是**客户 _ 任期**、**产品 _ 任期**、**活动 _ 最后 _ 6 _ 月**和**活动 _ 最后 _ 12 _ 月**。被搅动的**列是您试图构建的模型的**目标**。 **id** 列允许您将模型的预测与可能流失的实际客户联系起来。**

6.  按下`Date`作为一个列的类型，您将能够选择这个列是否是一个时间戳，将把数据集标记为一个时间序列。`Date`作为列的类型。这允许您定义用于解析特定列的日期模式。例如，您可以使用`%Y-%m-%d`来指定日期以年-月-日的格式存储。
7.  Once you've finished exploring the wizard's **Schema** screen, press **Next**. The wizard's **Confirm details** screen provides you with an overview of the new dataset you want to register in your workspace, as shown here:![Figure 5.7 – The Confirm details page 
    ](img/B16777_05_007.jpg)

    图 5.7–确认详细信息页面

    该屏幕总结了您在第 4 章 、*配置工作区*的 [*章节的*使用数据集*中读到的数据集信息。如果您选择**在创建后分析该数据集**复选框，您可以选择一个计算目标来生成新创建的数据集的分析。您不需要为此数据集生成配置文件，因为它只有 6，720 行，Azure ML 会自动为您提供完整的配置文件。*](B16777_04_Final_VK_ePub.xhtml#_idTextAnchor053)

8.  点击**创建**按钮完成向导。

现在您已经注册了`churn-dataset`，您可以继续使用 AutoML 向导，在这里您将选择新注册的数据集，配置实验参数，并启动 AutoML 过程，这是您将在下一节中执行的操作。

## 返回 AutoML 向导

现在您已经创建了`churn-dataset`和，您可以继续使用 AutoML 向导。该向导包含三个步骤，如下图所示:

![Figure 5.8 – AutoML wizard steps 
](img/B16777_05_008.jpg)

图 5.8–AutoML 向导步骤

让我们从步骤开始！

1.  As the first step, select `churn-dataset`, which you created in the previous section, *Registering the dataset*, and click **Next**, as shown here:![Figure 5.9 – The Select dataset step of the Create a new Automated ML run wizard
    ](img/B16777_05_009.jpg)

    图 5.9–创建新的自动化 ML 运行向导的选择数据集步骤

2.  在`churn-automl-experiment`栏中为`churned`。根据目标列的类型，向导将自动为此列选择最佳任务，您将在向导的下一步中看到这一点。
3.  `gpu-cluster`这里，您在 [*第四章*](B16777_04_Final_VK_ePub.xhtml#_idTextAnchor053)*配置工作区*的*计算集群*部分创建的。如果您的工作区中没有注册的集群，您可以使用一个计算实例，也可以通过单击`gpu-cluster`来启动专用向导。默认情况下，免费试用订阅不允许您提供 GPU 计算。对于这个实验，您可以选择基于 CPU 的集群，而不是基于 GPU 的集群。
4.  配置完运行详情后，点击**下一步**按钮。
5.  The next page of the wizard is the **Select task and settings** page, as shown here:![Figure 5.11 – The Create a new Automated ML run wizard – Select task type
    ](img/B16777_05_011.jpg)

    图 5.11–创建新的自动化 ML 运行向导–选择任务类型

    在此步骤中，您可以配置以下内容:

    a) **选择任务类型** : AutoML 目前支持三种类型的任务:

    *   **分类**:产生的模型可以预测一条记录所属的类别。一个类别可以是任何东西，比如 yes 或 no **Boolean** 值或者蓝色、绿色或黄色值。在我们的案例中，您试图预测客户是否会流失，这可以用是或否来回答。
    *   **回归**:当你想预测一个数值时，使用回归模型，比如一套公寓的价格或者糖尿病的发病率。我们将在 [*第八章*](B16777_08_Final_VK_ePub.xhtml#_idTextAnchor117) 、*用 Python 代码做实验*中看到这一点。
    *   **时间序列预测**:你通常使用这种类型的模型来预测时间序列值，如股票价格，同时考虑价值随时间的变化。这种类型的模型是回归模型之上的特殊化。这意味着可以使用所有的回归模型，但也有一些更专业的算法，如脸书的 **Prophet** 算法或**自回归综合移动平均法** ( **ARIMA** )技术。

    根据您选择的目标列，向导将自动猜测您正在尝试执行的任务。在我们的例子中，它选择了**分类**。

    b) **查看附加配置设置**:根据您选择的任务类型，您可以配置各种设置，包括用于评估模型的目标指标和终止搜索最佳模型的退出标准。根据任务的类型，该向导页面上的选项会有所不同。您可以在下图中看到其中的一些选项。您将在第五步中访问向导的这一部分:

    ![Figure 5.12 – Configuration settings depending on the selected task type.
    ](img/B16777_05_012.jpg)

    图 5.12–取决于所选任务类型的配置设置。

    c) **查看特征设置**:这允许您配置关于的各种操作，模型将使用这些操作进行预测。在此部分中，您可以排除诸如行唯一 ID 或不相关信息之类的功能，以加快定型过程并减小最终模型的大小。您还可以指定每个要素的类型和插补函数，插补函数会处理数据集中缺失的值。你将在*步骤 6* 中访问向导的这一部分。

6.  大多数情况下点击`auto`，除非你有理由修改它。默认情况下，如果少于 1，000 行，则使用 10 重交叉验证；如果多于 1，000 行且少于 20，000 行，则使用 3 重交叉验证；如果多于 20，000 行，则数据集被拆分为 90%的定型数据和 10%的验证数据。
7.  `0.5`，也就是半小时或者 30 分钟。您可以保留其余选项，如前面的屏幕截图所示。点击**保存**，返回到*步骤 4* 中看到的向导的**选择任务类型**页面。
8.  By clicking on **View featurization settings**, the **Featurization** screen will open, as shown here:![Figure 5.14 – The Featurization view on the create AutoML wizard
    ](img/B16777_05_014.jpg)

    图 5.14–创建 AutoML 向导的特征视图

    在此屏幕上，您可以定义影响训练流程数据准备阶段的操作。可以配置以下选项:

    *   **Included** :您可以排除算法不应该考虑的列。不能排除目标列。
    *   **特征类型**:默认情况下选择**自动**值，自动检测数据集中每一列的类型。可以是以下类型之一:**数字**、**日期时间**、**分类**、**分类散列**或**文本**。如果需要，您可以手动将列配置为可用类型之一。
    *   **Impute with**: If you have missing values in your dataset, this option will do in-place imputation based on the selected methodology. The options you can choose from are **Auto**, which is the default one, **Most frequent**, and **Fill with constant**. Especially for **Numeric** features, you can also use the **Mean** or the **Median** imputation strategy.

        重要说明

        假设您有一个产品 ID 特性，它明确提到了每个客户注册的订阅产品。该特征将具有数值，例如 1，055 和 1，060。该特征可能会意外地被标记为数字特征，即使它是分类特征。如果训练数据集中缺少值，自动方法可能会使用平均产品 ID 估算缺少的值，这没有任何意义。AutoML 足够聪明，能够理解如果一个数字特征只有几个重复的唯一值，这个特征可能是分类的，但你可以通过将它们标记为关于**特征类型**的**分类**来明确地帮助机器学习模型。

9.  在该向导页面上，您应该排除 **id** 功能。 **id** 特性提供了实际客户是谁的信息。它不提供任何与分类问题相关的信息，因此应该排除它以节省计算资源。点击**保存**返回到您在*步骤 4* 中看到的向导的**选择任务类型**页面。

点击**完成**，如图*图 5.11* 所示，您可以完成 AutoML 实验的配置，运行将自动开始。浏览器会将您重定向到 AutoML run execution 页面，该页面允许您监控 AutoML 训练过程并查看训练结果。您将在下一部分探索该页面。

# 监控实验的执行

在上一节*配置自动化 ML 实验*中，您提交了一个要在远程计算集群上执行的 AutoML 实验。提交作业后，浏览器会将您重定向到如下页面:

![Figure 5.15 – Running a new Automated ML run for the first time since the run finished
](img/B16777_05_015.jpg)

图 5.15–运行完成后首次运行新的自动化 ML 运行

在页面的顶部，自动生成实验运行的名称。在前面的截图中，它被称为`AutoML_05558d1d-c8ab-48a5-b652-4d47dc102d29`。通过单击铅笔图标，您可以编辑这个名称，使它更容易记住。把名字改成`my-first-experiment-run`。在运行名称的正下方，您可以点击以下命令之一:

*   **刷新**:刷新页面提供的信息。在进行实验时，您可以获得最新、最棒的信息。
*   **生成笔记本**:这将创建一个笔记本，其中包含使用 Azure ML SDK 运行相同实验所需的所有 Python 代码。通过第八章 、*使用 Python 代码*中的代码，你将了解更多关于运行 AutoML 实验所需的代码。
*   **Cancel**: This will cancel the current run. This option is only available if the experiment is still running.

    重要说明

    取消跑步时，可能需要一段时间才能取消。通过点击**刷新**按钮，您可以检查取消过程的进度。

*   **删除**:删除选中的运行。仅当运行已被取消或已完成执行时，它才被启用。

“运行实验”页面提供了许多关于整个过程的信息，并使用选项卡进行组织。默认情况下，您从名为 **Details** 的选项卡开始。在该选项卡中，您会发现以下重要信息:

*   On the **Properties** box, which is located on the left of the preceding screenshot, the most important information is located in the following fields:

    a) **状态**，描述当前运行的状态。这可以是正在运行、已取消、出错或已完成。

    b) **计算目标**是运行执行的地方。

    c) **Raw JSON** 是一个链接，允许您以机器可读的格式查看当前运行的所有配置信息。

*   在右侧的**运行总结**框中，您会发现**任务类型**，这是您正在训练的模型的类型。点击**查看配置设置**，可以获得当前实验的配置参数汇总。
*   **描述**框允许您记录您在当前实验中评估的假设。通过点击铅笔图标，您可以添加您的实验运行的描述，该信息将允许您回忆您在该实验中寻找什么以及结果是什么。

运行页面的第二页签名为**数据护栏**。此选项卡为您提供实验中使用的数据集的详细定性和定量信息。根据任务类型，您将执行不同类型的验证。如果一切正常，每个验证的状态为**通过**，如果数据集有问题需要解决，则为**失败**，如果 AutoML 发现数据集有问题并为您修复，则为**完成**。在 **Done** 案例中，您可以通过点击 **+View additional details** 按钮查看数据集中已修复内容的附加信息。

第三个选项卡称为**模型**，包含了 AutoML 到目前为止已经训练过的所有模型的列表，如图*图 5.16* 所示。指标得分最高的型号将列在顶部。该表显示了**算法名称**、特定模型的解释结果(如果可用的话)(**解释**)、模型的得分(**准确性**，在这种情况下)、用于训练模型的数据的百分比(**采样**，以及关于模型何时被训练以及花费了多长时间的信息(**创建了**和**持续时间**列)。如果从列表中选择一个模型，将会启用以下三个命令:

*   **Deploy** 启动所选模型的部署，您将在下一节中了解到。
*   `model.pkl`，包括实际训练好的模型和执行推理所需的所有支持文件。
*   **解释模型**启动**解释**向导，您需要选择一个**计算集群**来计算特定模型的模型解释。默认情况下，AutoML 将解释最佳模型，但是您可能希望解释其他模型来比较它们。一旦计算出解释，您可以通过点击**解释**栏中的**查看解释**来查看它们。这将打开所选模型的**解释**选项卡，该选项卡已填充报告。您将在第 10 章 、*了解模型结果*中了解更多关于模型可解释性的内容。

主页上的第四个标签名为**输出+日志**，在一个简单的文件浏览器中显示特定运行的输出和日志。这些日志是整个 AutoML 进程的日志。如果您想要查看特定模型训练过程的日志，您需要从**模型**选项卡中选择模型，然后访问该子运行的**输出+日志**部分。此选项卡中的文件资源管理器允许您浏览左侧的文件夹结构。如果您选择一个文件，其内容将显示在右侧。

到目前为止，您已经成功训练了几个模型，并找到了预测客户是否会流失的最佳模型。在下一节中，您将学习如何通过几次点击来操作这个模型。

# 将最佳模型部署为 web 服务

在前面的部分中，您浏览了 run experiment 页面，同时查看了与运行执行和探索结果相关的信息，它们是经过训练的模型。在本节中，我们将重新访问**模型**选项卡，并开始将最佳模型部署为 web 服务，以便能够进行实时推理。导航到跑步的详细信息页面，如图*图 5.15* 所示。让我们开始吧:

1.  Click on the **Models** tab. You should see a page similar to the one shown here:![Figure 5.16 – The Models tab as a starting point for deploying a model
    ](img/B16777_05_016.jpg)

    图 5.16–模型选项卡作为部署模型的起点

2.  In this list, you can select any model you want to deploy. Select the row with the best model, as shown in the preceding screenshot. Click the **Deploy** command at the top of the list. The **Deploy a model** dialog will appear, as shown here:![Figure 5.17 – The Deploy a model dialogue
    ](img/B16777_05_017.jpg)

    图 5.17–部署模型对话框

3.  在`myfirstmlwebservice`中。
4.  **计算类型**:有两种类型可供选择:
    *   **Azure Kubernetes Cluster**(**AKS**):当您想要为生产工作负载部署模型并并行处理多个请求时，应该选择这个选项。如果您想要保护终端，此选项允许基于密钥和基于令牌的身份验证。它还支持使用**现场可编程门阵列**(**FPGA**)进行更快的模型推理。在这种情况下，您还需要指定您想要部署模型的 AKS 集群的 **Compute name** 属性。该列表应包含您可能在第 4 章 、*配置工作空间*中注册的所有推理集群。
    *   **Azure 容器实例**:如果你计划进行功能测试或者你想要为开发环境部署一个模型，你可以将 web 服务作为一个单独的 Azure 容器实例来部署。这种计算类型更便宜，但它不可扩展，并且仅支持基于密钥的身份验证。对于这本书，您可以选择这个类型来部署模型。
5.  By pressing **Deploy**, you can start deploying the model.

    在浏览器的右上角，将出现一个弹出窗口，如下图所示，让您知道您的模型已经开始部署:

    ![Figure 5.18 – Endpoint deployment window – deployment InProgress
    ](img/B16777_05_018.jpg)

    图 5.18–端点部署窗口–部署进行中

6.  The pop-up window will quickly disappear, but you can revisit it by clicking on the notification **bell** icon in the top-right corner, as shown here:![Figure 5.19 – Azure Machine Learning Studio taskbar in the top-right corner
    ](img/B16777_05_019.jpg)

    图 5.19-右上角的 Azure Machine Learning Studio 任务栏

7.  The model will take a couple of minutes to deploy. By looking at your notifications, you can check the progress of your deployment. If the notification turns green, as shown in the following screenshot, then the deployment is completed:![Figure 5.20 – Endpoint deployment window – deployment Completed
    ](img/B16777_05_020.jpg)

    图 5.20–端点部署窗口–部署完成

8.  By clicking on the **Deploy details** link in the notification, your browser will redirect you to the endpoint page of the deployed model, as shown here:![Figure 5.21 – Endpoint page of the deployed model
    ](img/B16777_05_021.jpg)

    图 5.21–已部署模型的端点页面

    重要说明

    有多种方法可以到达模型的端点页面。例如，你可以通过 Azure ML Studio 中的**资产** | **端点**菜单查看所有已发布端点的列表。要进入同一页面，请选择要检查的端点。

    部署模型的端点页面与运行实验页面具有类似的基于选项卡的结构。第一个选项卡叫做 **Details** ，提供关于模型部署的信息。其中，最重要的位于前面截图中的**属性**框中。它们如下:

    *   **服务 ID** 是您在部署向导的*步骤 3* 中指定的服务的名称。
    *   **部署状态**提供已经部署或者将要部署的模型的状态。端点可以有五种状态。你可以在本章的*延伸阅读*部分找到更多关于状态和潜在问题的信息。
    *   Rest 端点是一个链接，您可以将其复制到应用的代码中，以便通过 REST API 调用部署的模型。
9.  The second tab is called **Test** and allows you to test the deployed model. By default, you get the **Fields** mode, which is a form containing all the inputs your model is expecting, as shown here:![Figure 5.22 – The endpoint page of the deployed model
    ](img/B16777_05_022.jpg)

    图 5.22–已部署模型的端点页面

10.  If you want to perform a mini-batch inference, meaning that you want to send multiple records at once, you can switch to **CSV** from the top-right corner. In that mode, you can copy the contents of a CSV file into the text box that will appear and hit the **Test** button.

    在任一模式下，一旦点击 **Test** 按钮，输入数据将被提交给 REST API 并提供结果。

11.  端点页面的第三页签叫做`swagger.json`，是端点中自动生成的。这个文件描述了 REST APIs 的预期输入和输出，通常被 web 开发人员用来提供关于他们生产的 REST 端点的文档。
12.  最后， **Deployment logs** 选项卡显示了模型部署的详细日志。您可以使用此选项卡解决潜在的部署问题。

恭喜！您已经成功部署了自己的实时端点，可以推断客户是否会流失！在下一节中，您将了解在部署您的模型时创建的工件。

## 了解模型的部署

在前面的小节中，您部署了一个模型作为 REST 端点。在本节中，您将了解幕后发生了什么，并发现在该过程中生成的工件。

您从 AutoML 过程已经训练的模型列表开始。在该列表中，您选择了一个模型并点击了 **Deploy** 命令。通过这样做，您在 Azure ML 工作区中注册了所选的模型，一旦完成，流程将继续部署端点，如下图所示:

![Figure 5.23 – From AutoML model list to endpoint deployment
](img/B16777_05_023.jpg)

图 5.23–从 AutoML 模型列表到端点部署

模型注册在 Azure ML 工作空间中创建一个版本化的记录，允许您跟踪哪些数据集被用来训练特定的模型以及特定的模型被部署在哪里。你将在 [*第十二章*](B16777_12_Final_VK_ePub.xhtml#_idTextAnchor171) 、*用代码*操作化模型中了解更多关于模型注册的内容。让我们来看看:

1.  To see this model registration, in Azure ML Studio, navigate to **Assets** | **Models**. You will end up on the **Model List** page, as shown here:![Figure 5.24 – The Model List page
    ](img/B16777_05_024.jpg)

    图 5.24–型号列表页面

    **模型列表**页面列出了 Azure ML 工作空间中所有注册的模型。这些是工作区正在跟踪的模型。每个型号都有一个独特的名称。你可以拥有同一个模型的多个版本，当你试图用相同的名字注册一个模型时，这种事情会自动发生。模型列表允许您选择一个模型并对其执行各种操作，例如删除和部署它。

    重要说明

    只有当注册的模型没有被任何端点使用时，才能删除该模型。

2.  By clicking on the **Name** property of a model, you will end up on the details page of the selected registered model, as shown here:![Figure 5.25 – Registered model details page
    ](img/B16777_05_025.jpg)

    图 5.25–注册型号详细信息页面

    在这里，您可以获得关于模型的一般细节，比如哪个运行训练了特定的模型，使用了什么框架，以及这个运行注册的实验名称。注意，由于这个模型是使用 AutoML 训练的，所以框架是通用的 AutoML 框架。在 [*第十二章*](B16777_12_Final_VK_ePub.xhtml#_idTextAnchor171) 、*用代码*操作化模型中，您将能够注册您自己的模型，并指定您用来训练模型的框架。

    在的**工件**选项卡中，你会发现 **model.pkl** 文件，其中包含了训练好的模型。在**解释**和**公平性**选项卡中，您可以查看可解释性结果，如果它们是为特定模型生成的。您将在第 10 章 、*了解模型结果*中了解更多关于模型可解释性的内容。在**数据集**选项卡中，您可以看到您在配置 AutoML 实验时使用的数据集的特定版本的引用。这允许您在用于定型的数据集和您已部署的模型之间具有沿袭关系。

3.  Once the model has been registered, the deployment wizard creates an endpoint. Back in Azure ML Studio, click on the **Assets** | **Endpoint** menu item. This will bring you to the **Endpoints** page shown here:![Figure 5.26 – The Endpoints page
    ](img/B16777_05_026.jpg)

    图 5.26–端点页面

    此列表显示您从该 Azure ML 工作区部署的所有实时端点。您将注意到 **myfirstmlwebservice** 端点，它是您在前一节中在中部署的。通过点击它的名称，您将到达端点的页面，如图 5.21 中的*所示。*

4.  Behind the scenes, this endpoint is a container instance that was deployed in the `packt-azureml-rg`, right next to your Azure ML workspace resource. Navigate to the Azure portal and open the `packt-azureml-rg`. You should have resources similar to the ones shown here:![Figure 5.27 – The resources in the packt-azureml-rg resource group of the Azure portal
    ](img/B16777_05_027.jpg)

    图 5.27–Azure 门户的 packt-azureml-rg 资源组中的资源

5.  Here, you will see that a **Container instance** has been deployed named **myfirstmllwebservice-<random id>**, which is the name of the endpoint you saw in *Figure 5.26*. This is the engine that is hosting the REST API you deployed in the previous section.

    重要说明

    永远不要直接从资源组中删除 Azure ML 工作空间工件。这将在您的工作区中留下孤立的注册，例如指向已删除的容器实例的端点。

在本节中，您看到了当您从 AutoML 部署一个模型时，在幕后发生了什么。在下一节中，您将删除您部署的端点，以避免在您不需要的实时端点上花钱。

## 清理模型部署

在本节中，您将清理已部署的模型。您应该删除不打算使用的模型的部署。否则，您将为未使用的已配置资源付费。

导航到 Azure ML Studio。点击`myfirstmlwebservice`端点并点击**删除**命令。点击弹出窗口中的**删除**，确认您想要删除该端点:

![Figure 5.28 – Delete real-time endpoint pop-up window
](img/B16777_05_028.jpg)

图 5.28–删除实时端点弹出窗口

确认之后，您在 Azure 门户中看到的端点和容器实例将被删除。如果你愿意，你可以通过访问`packt-azureml-rg` **资源组**来验证这一点。

# 总结

在本章中，您学习了如何配置 AutoML 流程来发现能够预测客户是否会流失的最佳模型。首先，您使用 Azure Machine Learning Studio web experience 的 AutoML 向导来配置实验。然后，您在 studio 界面的**实验**部分监控运行的执行。训练完成后，您查看了已训练的模型，并看到了已存储的关于最佳模型的信息。然后，您在 Azure 容器实例中部署了该机器学习模型，并测试了实时端点是否执行了所请求的推理。最后，您删除了部署以避免在您的 Azure 订阅中产生成本。

在下一章中，您将通过查看设计器继续探索 Azure Machine Learning Studio 体验的无代码/低代码方面，该设计器允许您以图形方式设计训练管道并操作化生成的模型。

# 问题

您需要训练一个分类模型，但在 AutoML 过程中只考虑线性模型。在 Azure Machine Learning Studio 体验中，以下哪一项允许您这样做？

a)将除线性算法以外的所有算法添加到被阻止的算法列表中。

b)将退出标准选项设置为度量分数阈值。

c)禁用自动特征化选项。

d)禁用分类任务上的深度学习选项。

# 延伸阅读

本节提供了其他内容作为有用的网络资源:

*   关于 AutoML 的基本概念:
*   [https://docs . Microsoft . com/azure/machine-learning/concept-automated-ml](https://docs.microsoft.com/en-us/azure/machine-learning/concept-automated-ml)。
*   深入探讨如何使用 AutoML:[https://docs . Microsoft . com/azure/machine-learning/how-to-use-automated-ml-for-ml-models](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-automated-ml-for-ml-models)。
*   sklearn 中的交叉验证:[https://sci kit-learn . org/stable/modules/cross _ validation . html](https://scikit-learn.org/stable/modules/cross_validation.html)。
*   了解端点的服务状态:[https://docs . Microsoft . com/azure/machine-learning/how-to-deploy-and-where？tabs = azcli #了解服务状态](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where?tabs=azcli#understanding-service-state)。
*   从`swagger.json`文件生成客户端 SDK:[https://swagger.io/tools/swagger-codegen/](https://swagger.io/tools/swagger-codegen/)。**