<html><head/><body>

  
    <title>Unknown</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  


  <div><h1 class="header-title">超参数优化</h1>
                
            
            
                
<p class="mce-root">auto-sklearn 库使用<strong class="calibre7">贝叶斯优化</strong>来调整<strong class="calibre7">机器学习</strong> ( <strong class="calibre7"> ML </strong>)管道的超参数。你将学习贝叶斯优化的内部工作原理，但是让我们先回顾一下数学优化的基础。</p>
<p class="mce-root">简单地说，优化就是选择最佳值来最小化或最大化给定的函数。如果我们的目标是最小化，那么一个函数被称为<strong class="calibre7">损失函数</strong>或<strong class="calibre7">成本函数</strong>。如果你试图最大化它，那么它被称为<strong class="calibre7">效用函数</strong>或<strong class="calibre7">适应函数</strong>。例如，当您构建 ML 模型时，损失函数有助于您在训练阶段最小化预测误差。</p>
<p class="mce-root">当你从一个更广的角度来看这整个过程时，有许多可变因素在起作用。</p>
<p class="mce-root">首先，你可以用一个系统来决定问题的类型，比如无监督、有监督、半监督或强化学习问题。您可以根据数据大小和复杂性决定硬件和软件配置。然后你可以选择合适的语言或库在你的实验中使用。从一组可用的转换器和估算器中，您可以选择其中的一个子集用于训练、验证和测试阶段。</p>
<p class="mce-root">所有这些都可以被称为<strong class="calibre7">配置参数</strong>来为开发 ML 流水线设置场景。</p>
<p class="mce-root">第二，在训练阶段，变换器和估计器有它们自己的参数要计算，例如线性模型中的系数，或者用于创建多项式和交互特征的次数参数。</p>
<p class="mce-root">例如，ML 算法通常分为参数算法和非参数算法。如果一个算法有固定数量的参数，这意味着函数形式是已知的，那么它是参数化的；如果不是，那么它被称为<strong class="calibre7">非参数</strong>，你的数据将塑造函数的形式。</p>
<p class="mce-root">第三，除了参数之外，你需要在训练开始之前设置超参数，以指导变压器和估计器参数的估计。</p>
<p class="mce-root">超参数尤其重要，因为您的管道的性能将取决于它们，并且由于有许多超参数，每个超参数可以取一系列值，您很快就会意识到这是一个优化问题。</p>
<p class="mce-root">给定超参数和它们可以取值的范围，也就是您的搜索空间，您如何高效地找到性能最佳的 ML 管道？实际上，表现最好的 ML 管道是具有最佳交叉验证分数的管道。</p>
<p class="mce-root">本章将涵盖以下主题:</p>
<ul class="calibre13">
<li class="calibre14">ML 实验的配置空间</li>
<li class="calibre14">ML 模型参数和超参数</li>
<li class="calibre14">什么是热启动，它如何帮助参数优化</li>
<li class="calibre14">基于贝叶斯的超参数调整</li>
<li class="calibre14">一个示例系统</li>
</ul>


            

            
        
    </div>



  




  
    <title>Unknown</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  


  <div><h1 class="header-title">技术要求</h1>
                
            
            
                
<p class="mce-root">您可以在本书的资源库的<kbd class="calibre16">Chapter 05</kbd>文件夹中找到所有代码示例。</p>


            

            
        
    </div>



  




  
    <title>Unknown</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  


  <div><h1 class="header-title">超参数</h1>
                
            
            
                
<p class="mce-root">为了更好地理解这一过程，您将从具有 3 个全局最小值的 Branin 函数开始:</p>
<div><img class="fm-editor-equation29" src="img/66d8edba-9c1a-48f4-afac-f3ba0980e350.png" width="4220" height="250"/></div>
<p class="mce-root">以下代码片段向您展示了 Branin 函数的最小化:</p>
<pre class="calibre21">import numpy as np<br class="calibre2"/><br class="calibre2"/>def branin(x):<br class="calibre2"/><br class="calibre2"/>    # Branin function has 2 dimensions and it has 3 global mimima<br class="calibre2"/>    x1 = x[0]<br class="calibre2"/>    x2 = x[1]<br class="calibre2"/><br class="calibre2"/>    # Global minimum is f(x*)=0.397887 at points (-pi, 12.275), (pi,2.275) and (9.42478, 2.475)<br class="calibre2"/><br class="calibre2"/>    # Recommended values of a, b, c, r, s and t for Branin function<br class="calibre2"/>    a = 1<br class="calibre2"/>    b = 5.1 / (4 * np.pi**2)<br class="calibre2"/>    c = 5. / np.pi<br class="calibre2"/>    r = 6.<br class="calibre2"/>    s = 10.<br class="calibre2"/>    t = 1 / (8 * np.pi)<br class="calibre2"/><br class="calibre2"/>    # Calculating separate parts of the function first for verbosity<br class="calibre2"/>    p1 = a * (x2 - (b * x1**2) + (c * x1) - r)**2<br class="calibre2"/>    p2 = s * (1-t) * np.cos(x1)<br class="calibre2"/>    p3 = s<br class="calibre2"/><br class="calibre2"/>    # Calculating result<br class="calibre2"/>    ret = p1 + p2 + p3<br class="calibre2"/><br class="calibre2"/>    return ret<br class="calibre2"/><br class="calibre2"/># minimize function from scipy.optimize will minimize a scalar function with one or more variables<br class="calibre2"/>from scipy.optimize import minimize<br class="calibre2"/><br class="calibre2"/>x = [5.6, 3.2]<br class="calibre2"/><br class="calibre2"/>res = minimize(branin, x)<br class="calibre2"/><br class="calibre2"/>print(res)<br class="calibre2"/><br class="calibre2"/></pre>
<p class="mce-root">执行前面的代码片段将产生以下输出:</p>
<pre class="calibre21">fun: 0.3978873577297417<br class="calibre2"/>hess_inv: array([[0.10409341, -0.0808961],<br class="calibre2"/>[-0.0808961, 0.56160622]])<br class="calibre2"/>jac: array([3.57627869e-07, -1.19209290e-07])<br class="calibre2"/>message: 'Optimization terminated successfully.'<br class="calibre2"/>nfev: 36<br class="calibre2"/>nit: 5<br class="calibre2"/>njev: 9<br class="calibre2"/>status: 0<br class="calibre2"/>success: True<br class="calibre2"/>x: array([3.14159268, 2.27499994])</pre>
<p class="mce-root">优化被成功终止，并且可以在 Branin 函数的(<kbd class="calibre16">3.14159268</kbd>，<kbd class="calibre16">2.27499994</kbd>)处找到全局最小值。有很多解算器可以用来解决你的优化问题，比如<strong class="calibre7"> BFGS </strong>、<strong class="calibre7"> L-BFGS-B </strong>和<strong class="calibre7"> SLSQP </strong>，这些解算器会有不同的特性，比如一致性和复杂性。通过示例进行练习将使您熟悉其中一些示例，并为进一步探索打开空间。</p>
<p class="mce-root">让我们回顾一下最大似然问题的优化基础。下面的公式显示了大多数 ML 问题归结为什么:</p>
<div><img class="fm-editor-equation30" src="img/5c114d28-f788-4cce-aedd-af03dd888c3a.png" width="3890" height="610"/></div>
<p class="mce-root">在这个方程中，你有损失函数和正则项来防止过度拟合。用<em class="calibre17"> w </em>表示的权重是您在训练过程中试图学习的内容，这些是前面提到的学习算法的参数。除了这些参数，你一般还需要定义超参数，比如学习速率和提前停止条件，这些都会影响学习行为。</p>
<p class="mce-root">你也注意到损失函数中的<em class="calibre17"> α </em>和<em class="calibre17"> β </em>了吗？这些都是你在训练之前需要设置的参数，也是超参数。</p>
<p class="mce-root">超参数帮助您在模型偏差和模型方差之间保持健康的平衡。</p>
<p class="mce-root">让我们来看看<kbd class="calibre16">sklearn</kbd>中估算器参数的一个简单例子:</p>
<pre class="calibre21">from sklearn.linear_model import LogisticRegression<br class="calibre2"/><br class="calibre2"/>log_reg = LogisticRegression()<br class="calibre2"/>log_reg.get_params()</pre>
<p class="mce-root">输出将如下所示:</p>
<pre class="calibre21">{'C': 1.0,<br class="calibre2"/> 'class_weight': None,<br class="calibre2"/> 'dual': False,<br class="calibre2"/> 'fit_intercept': True,<br class="calibre2"/> 'intercept_scaling': 1,<br class="calibre2"/> 'max_iter': 100,<br class="calibre2"/> 'multi_class': 'ovr',<br class="calibre2"/> 'n_jobs': 1,<br class="calibre2"/> 'penalty': 'l2',<br class="calibre2"/> 'random_state': None,<br class="calibre2"/> 'solver': 'liblinear',<br class="calibre2"/> 'tol': 0.0001,<br class="calibre2"/> 'verbose': 0,<br class="calibre2"/> 'warm_start': False}</pre>
<p class="mce-root">这里有 14 个超参数，如果你考虑可能的组合，你会意识到搜索空间有多大。您的目标是从所有超参数集中获得最佳交叉验证分数。</p>
<p class="mce-root"><kbd class="calibre16">LogisticRegression</kbd>的重要超参数之一是<kbd class="calibre16">C</kbd>，它控制正则化的强度。值反过来影响正则化强度，这意味着较高的值表示较弱的正则化。</p>
<p class="mce-root">即使您是正在使用的算法的专家，正确设置超参数也是实验性的，并且是从业者的主观经验。您需要找到比您的启发式方法更好的方法来找到接近最优或最优的超参数集。</p>
<p class="mce-root">例如，您可以使用<kbd class="calibre16">GridSearchCV</kbd>或<kbd class="calibre16">RandomizedSearchCV</kbd>在<kbd class="calibre16">sklearn</kbd>中搜索超参数空间:</p>
<ul class="calibre13">
<li class="calibre14"><kbd class="calibre16">GridSearchCV</kbd>根据给定的超参数及其取值范围生成候选集。假设您有以下参数网格:</li>
</ul>
<pre class="calibre79"># Hyperparameters<br class="calibre2"/>param_grid = [ {'C': [0.001, 0.01, 0.1, 1, 10, 20, 50, 100],<br class="calibre2"/>                'penalty': ['l1', 'l2']} ]</pre>
<p class="calibre91">然后<kbd class="calibre16">GridSearhCV</kbd>将生成以下参数:</p>
<pre class="calibre79">'params': [{'C': 0.001, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 0.001, 'penalty': 'l2'},<br class="calibre2"/>  {'C': 0.01, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 0.01, 'penalty': 'l2'},<br class="calibre2"/>  {'C': 0.1, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 0.1, 'penalty': 'l2'},<br class="calibre2"/>  {'C': 1, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 1, 'penalty': 'l2'},<br class="calibre2"/>  {'C': 10, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 10, 'penalty': 'l2'},<br class="calibre2"/>  {'C': 20, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 20, 'penalty': 'l2'},<br class="calibre2"/>  {'C': 50, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 50, 'penalty': 'l2'},<br class="calibre2"/>  {'C': 100, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 100, 'penalty': 'l2'}]</pre>
<p class="calibre91">它将执行彻底的搜索以找到最佳的交叉验证分数。</p>
<ul class="calibre13">
<li class="calibre14"><kbd class="calibre16">RandomizedSearchCV</kbd>执行搜索的方式与<kbd class="calibre16">GridSearchCV</kbd>不同。它不是彻底搜索超参数空间，而是从指定的分布中采样参数设置。您应该按照以下方式构建参数网格:</li>
</ul>
<pre class="calibre79"># Hyperparameters<br class="calibre2"/>param_grid = {'C': sp_randint(1, 100),<br class="calibre2"/>                'penalty': ['l1', 'l2']}</pre>
<p class="calibre91">你注意到<kbd class="calibre16">sp_randint</kbd>了吗？它将允许<kbd class="calibre16">RandomizedSearchCV</kbd>从均匀分布中抽取随机变量，参数将创建如下:</p>
<pre class="calibre79">'params': [{'C': 6, 'penalty': 'l2'},<br class="calibre2"/>  {'C': 97, 'penalty': 'l2'},<br class="calibre2"/>  {'C': 92, 'penalty': 'l2'},<br class="calibre2"/>  {'C': 62, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 63, 'penalty': 'l2'},<br class="calibre2"/>  {'C': 5, 'penalty': 'l2'},<br class="calibre2"/>  {'C': 7, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 45, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 77, 'penalty': 'l2'},<br class="calibre2"/>  {'C': 12, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 72, 'penalty': 'l2'},<br class="calibre2"/>  {'C': 28, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 7, 'penalty': 'l2'},<br class="calibre2"/>  {'C': 65, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 32, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 84, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 27, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 12, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 21, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 65, 'penalty': 'l1'}],</pre>
<p class="mce-root">让我们看一个用法的例子，对于<kbd class="calibre16">GridSearchCV</kbd>和<kbd class="calibre16">RandomizedSearchCV</kbd>。</p>
<pre>GridSearchCV:</pre>
<pre class="calibre21">from sklearn.linear_model import LogisticRegression<br class="calibre2"/><br class="calibre2"/>log_reg = LogisticRegression()<br class="calibre2"/><br class="calibre2"/># Hyperparameters<br class="calibre2"/>param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 20, 50, 100],<br class="calibre2"/>                'penalty': ['l1', 'l2']}<br class="calibre2"/><br class="calibre2"/>from sklearn.model_selection import GridSearchCV<br class="calibre2"/><br class="calibre2"/>n_folds = 5<br class="calibre2"/>estimator = GridSearchCV(log_reg,param_grid, cv=n_folds)<br class="calibre2"/><br class="calibre2"/>from sklearn import datasets<br class="calibre2"/>iris = datasets.load_iris()<br class="calibre2"/>X = iris.data<br class="calibre2"/>Y = iris.target<br class="calibre2"/><br class="calibre2"/>estimator.fit(X, Y)</pre>
<p class="mce-root">您将看到以下输出:</p>
<pre class="calibre21">GridSearchCV(cv=5, error_score='raise',<br class="calibre2"/>       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,<br class="calibre2"/>          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,<br class="calibre2"/>          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,<br class="calibre2"/>          verbose=0, warm_start=False),<br class="calibre2"/>       fit_params=None, iid=True, n_jobs=1,<br class="calibre2"/>       param_grid=[{'C': [0.001, 0.01, 0.1, 1, 10, 20, 50, 100], 'penalty': ['l1', 'l2']}],<br class="calibre2"/>       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,<br class="calibre2"/>       scoring=None, verbose=0)</pre>
<p class="mce-root">训练完成后，您可以看到性能最佳的估计器设置:</p>
<pre class="calibre21">estimator.best_estimator_</pre>
<p class="mce-root">上述代码将生成以下输出:</p>
<pre class="calibre21">LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,<br class="calibre2"/>intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,<br class="calibre2"/>penalty='l1', random_state=None, solver='liblinear', tol=0.0001,<br class="calibre2"/>verbose=0, warm_start=False)</pre>
<p class="mce-root">你也可以看到最好的分数:</p>
<pre class="calibre21">estimator.best_score_</pre>
<p class="mce-root">输出如下:</p>
<pre class="calibre21">0.98</pre>
<p class="mce-root">您也可以通过检查<kbd class="calibre16">cv_results_</kbd>来查看所有结果:</p>
<pre class="calibre21">estimator.cv_results_</pre>
<p class="mce-root">这将为您提供每次训练的各种指标:</p>
<pre class="calibre21">{'mean_fit_time': array([0.00039144, 0.00042701, 0.00036378, 0.00043044, 0.00145531,<br class="calibre2"/>        0.00046387, 0.00670047, 0.00056334, 0.00890565, 0.00064907,<br class="calibre2"/>        0.00916181, 0.00063758, 0.01110044, 0.00076027, 0.01196856,<br class="calibre2"/>        0.00084472]),<br class="calibre2"/> 'mean_score_time': array([0.00017729, 0.00018134, 0.00016704, 0.00016623, 0.00017071,<br class="calibre2"/>        0.00016556, 0.00024438, 0.00017123, 0.00020232, 0.00018559,<br class="calibre2"/>        0.00020504, 0.00016532, 0.00024428, 0.00019045, 0.00023465,<br class="calibre2"/>        0.00023274]),<br class="calibre2"/> 'mean_test_score': array([0.33333333, 0.40666667, 0.33333333, 0.66666667, 0.77333333,<br class="calibre2"/>        0.82 , 0.96 , 0.96 , 0.98 , 0.96666667,<br class="calibre2"/>        0.96666667, 0.96666667, 0.96666667, 0.97333333, 0.96 ,<br class="calibre2"/>        0.98 ]),<br class="calibre2"/> 'mean_train_score': array([0.33333333, 0.40166667, 0.33333333, 0.66666667, 0.775 ,<br class="calibre2"/>        0.83166667, 0.96333333, 0.96333333, 0.97333333, 0.97333333,<br class="calibre2"/>        0.97333333, 0.97666667, 0.975 , 0.97833333, 0.975 ,<br class="calibre2"/>        0.98 ]),<br class="calibre2"/> 'param_C': masked_array(data=[0.001, 0.001, 0.01, 0.01, 0.1, 0.1, 1, 1, 10, 10, 20,<br class="calibre2"/>                    20, 50, 50, 100, 100],<br class="calibre2"/>              mask=[False, False, False, False, False, False, False, False,<br class="calibre2"/>                    False, False, False, False, False, False, False, False],<br class="calibre2"/>        fill_value='?',<br class="calibre2"/>             dtype=object),<br class="calibre2"/> 'param_penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',<br class="calibre2"/>                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2'],<br class="calibre2"/>              mask=[False, False, False, False, False, False, False, False,<br class="calibre2"/>                    False, False, False, False, False, False, False, False],<br class="calibre2"/>        fill_value='?',<br class="calibre2"/>             dtype=object),<br class="calibre2"/> 'params': [{'C': 0.001, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 0.001, 'penalty': 'l2'},<br class="calibre2"/>  {'C': 0.01, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 0.01, 'penalty': 'l2'},<br class="calibre2"/>  {'C': 0.1, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 0.1, 'penalty': 'l2'},<br class="calibre2"/>  {'C': 1, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 1, 'penalty': 'l2'},<br class="calibre2"/>  {'C': 10, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 10, 'penalty': 'l2'},<br class="calibre2"/>  {'C': 20, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 20, 'penalty': 'l2'},<br class="calibre2"/>  {'C': 50, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 50, 'penalty': 'l2'},<br class="calibre2"/>  {'C': 100, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 100, 'penalty': 'l2'}],<br class="calibre2"/> 'rank_test_score': array([15, 14, 15, 13, 12, 11, 8, 8, 1, 4, 4, 4, 4, 3, 8, 1],<br class="calibre2"/>       dtype=int32),<br class="calibre2"/> 'split0_test_score': array([0.33333333, 0.36666667, 0.33333333, 0.66666667, 0.7 ,<br class="calibre2"/>        0.76666667, 1. , 1. , 1. , 1. ,<br class="calibre2"/>        1. , 1. , 1. , 1. , 0.96666667,<br class="calibre2"/>        1. ]),<br class="calibre2"/> 'split0_train_score': array([0.33333333, 0.41666667, 0.33333333, 0.66666667, 0.775 ,<br class="calibre2"/>        0.825 , 0.95 , 0.95 , 0.95 , 0.96666667,<br class="calibre2"/>        0.95 , 0.975 , 0.95833333, 0.975 , 0.95833333,<br class="calibre2"/>        0.975 ]),<br class="calibre2"/> 'split1_test_score': array([0.33333333, 0.46666667, 0.33333333, 0.66666667, 0.8 ,<br class="calibre2"/>        0.86666667, 0.96666667, 0.96666667, 1. , 1. ,<br class="calibre2"/>        0.96666667, 1. , 0.96666667, 1. , 0.96666667,<br class="calibre2"/>        1. ]),<br class="calibre2"/> 'split1_train_score': array([0.33333333, 0.35833333, 0.33333333, 0.66666667, 0.775 ,<br class="calibre2"/>        0.825 , 0.95833333, 0.96666667, 0.975 , 0.96666667,<br class="calibre2"/>        0.975 , 0.975 , 0.975 , 0.975 , 0.975 ,<br class="calibre2"/>        0.975 ]),<br class="calibre2"/> 'split2_test_score': array([0.33333333, 0.36666667, 0.33333333, 0.66666667, 0.8 ,<br class="calibre2"/>        0.83333333, 0.93333333, 0.93333333, 0.96666667, 0.93333333,<br class="calibre2"/>        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,<br class="calibre2"/>        0.96666667]),<br class="calibre2"/> 'split2_train_score': array([0.33333333, 0.41666667, 0.33333333, 0.66666667, 0.76666667,<br class="calibre2"/>        0.83333333, 0.96666667, 0.96666667, 0.975 , 0.975 ,<br class="calibre2"/>        0.975 , 0.98333333, 0.975 , 0.98333333, 0.975 ,<br class="calibre2"/>        0.98333333]),<br class="calibre2"/> 'split3_test_score': array([0.33333333, 0.46666667, 0.33333333, 0.66666667, 0.8 ,<br class="calibre2"/>        0.83333333, 0.9 , 0.9 , 0.93333333, 0.9 ,<br class="calibre2"/>        0.93333333, 0.9 , 0.93333333, 0.93333333, 0.93333333,<br class="calibre2"/>        0.93333333]),<br class="calibre2"/> 'split3_train_score': array([0.33333333, 0.39166667, 0.33333333, 0.66666667, 0.775 ,<br class="calibre2"/>        0.84166667, 0.975 , 0.975 , 0.99166667, 0.98333333,<br class="calibre2"/>        0.99166667, 0.98333333, 0.99166667, 0.98333333, 0.99166667,<br class="calibre2"/>        0.99166667]),<br class="calibre2"/> 'split4_test_score': array([0.33333333, 0.36666667, 0.33333333, 0.66666667, 0.76666667,<br class="calibre2"/>        0.8 , 1. , 1. , 1. , 1. ,<br class="calibre2"/>        1. , 1. , 1. , 1. , 1. ,<br class="calibre2"/>        1. ]),<br class="calibre2"/> 'split4_train_score': array([0.33333333, 0.425 , 0.33333333, 0.66666667, 0.78333333,<br class="calibre2"/>        0.83333333, 0.96666667, 0.95833333, 0.975 , 0.975 ,<br class="calibre2"/>        0.975 , 0.96666667, 0.975 , 0.975 , 0.975 ,<br class="calibre2"/>        0.975 ]),<br class="calibre2"/> 'std_fit_time': array([7.66660734e-05, 3.32198455e-05, 1.98168153e-05, 6.91923414e-06,<br class="calibre2"/>        4.74922317e-04, 2.65661212e-05, 1.03221712e-03, 3.79795334e-05,<br class="calibre2"/>        1.86899641e-03, 8.53752397e-05, 1.93386463e-03, 2.95752073e-05,<br class="calibre2"/>        2.91377734e-03, 5.70420424e-05, 3.59721435e-03, 9.67829087e-05]),<br class="calibre2"/> 'std_score_time': array([1.28883712e-05, 2.39771817e-05, 4.81959487e-06, 2.47955322e-06,<br class="calibre2"/>        1.34236224e-05, 2.41545203e-06, 5.64869920e-05, 8.94803700e-06,<br class="calibre2"/>        4.10209125e-05, 3.35513820e-05, 3.04168290e-05, 2.87924369e-06,<br class="calibre2"/>        4.91685012e-05, 1.62987656e-05, 4.23611246e-05, 7.26868455e-05]),<br class="calibre2"/> 'std_test_score': array([0. , 0.04898979, 0. , 0. , 0.03887301,<br class="calibre2"/>        0.03399346, 0.03887301, 0.03887301, 0.02666667, 0.0421637 ,<br class="calibre2"/>        0.02981424, 0.0421637 , 0.02981424, 0.03265986, 0.02494438,<br class="calibre2"/>        0.02666667]),<br class="calibre2"/> 'std_train_score': array([0. , 0.02438123, 0. , 0. , 0.00527046,<br class="calibre2"/>        0.0062361 , 0.00849837, 0.00849837, 0.01333333, 0.0062361 ,<br class="calibre2"/>        0.01333333, 0.0062361 , 0.01054093, 0.00408248, 0.01054093,<br class="calibre2"/>        0.00666667])}</pre>
<p class="mce-root">让我们看看它是如何为<kbd class="calibre16">RandomizedSearchCV</kbd>工作的:</p>
<pre class="calibre21">from sklearn.model_selection import RandomizedSearchCV<br class="calibre2"/>from scipy.stats import randint as sp_randint<br class="calibre2"/><br class="calibre2"/># Hyperparameters<br class="calibre2"/>param_grid = {'C': sp_randint(1, 100),<br class="calibre2"/>                'penalty': ['l1', 'l2']}<br class="calibre2"/><br class="calibre2"/>n_iter_search = 20<br class="calibre2"/>n_folds = 5<br class="calibre2"/>estimator = RandomizedSearchCV(log_reg, param_distributions=param_grid, n_iter=n_iter_search, cv=n_folds)<br class="calibre2"/><br class="calibre2"/>estimator.fit(X, Y)</pre>
<p class="mce-root">前面的代码生成类似于<kbd class="calibre16">GridSearchCV</kbd>的输出:</p>
<pre class="calibre21">RandomizedSearchCV(cv=5, error_score='raise',<br class="calibre2"/>          estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,<br class="calibre2"/>          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,<br class="calibre2"/>          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,<br class="calibre2"/>          verbose=0, warm_start=False),<br class="calibre2"/>          fit_params=None, iid=True, n_iter=20, n_jobs=1,<br class="calibre2"/>          param_distributions={'C': &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x1176d4c88&gt;, 'penalty': ['l1', 'l2']},<br class="calibre2"/>          pre_dispatch='2*n_jobs', random_state=None, refit=True,<br class="calibre2"/>          return_train_score=True, scoring=None, verbose=0)</pre>
<p class="mce-root">再来看看<kbd class="calibre16">best_estimator_</kbd>:</p>
<pre class="calibre21">estimator.best_estimator_</pre>
<p class="mce-root">上述代码生成以下输出:</p>
<pre class="calibre21">LogisticRegression(C = 95, class_weight=None, dual=False, fit_intercept=True,<br class="calibre2"/>          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,<br class="calibre2"/>          penalty ='l2', random_state=None, solver='liblinear', tol=0.0001,<br class="calibre2"/>          verbose = 0, warm_start=False)</pre>
<p class="mce-root"><kbd class="calibre16">estimator.best_score_</kbd>显示如下输出:</p>
<pre class="calibre21">0.98</pre>
<p class="mce-root"><kbd class="calibre16">RandomizedSearchCV</kbd>具有相同的最佳得分，但这里需要注意的一点是，最佳性能评估器设置具有<kbd class="calibre16">C = 95</kbd>，这是一个很难找到的值，因为当手动构建参数网格时，人们通常会尝试取 10、100 或 1000 这样的整数。</p>
<p class="mce-root">您同样可以使用<kbd class="calibre16">estimator.cv_results_</kbd>检查交叉验证的结果:</p>
<pre class="calibre21">{'mean_fit_time': array([0.0091342 , 0.00065241, 0.00873041, 0.00068126, 0.00082703,<br class="calibre2"/>        0.01093817, 0.00067267, 0.00961967, 0.00883713, 0.00069351,<br class="calibre2"/>        0.01048965, 0.00068388, 0.01074204, 0.0090354 , 0.00983639,<br class="calibre2"/>        0.01081419, 0.01014266, 0.00067706, 0.01015086, 0.00067825]),<br class="calibre2"/> 'mean_score_time': array([0.00026116, 0.0001647 , 0.00020576, 0.00017738, 0.00022368,<br class="calibre2"/>        0.00023923, 0.00016236, 0.00017295, 0.00026078, 0.00021319,<br class="calibre2"/>        0.00028219, 0.00018024, 0.00027289, 0.00025878, 0.00020723,<br class="calibre2"/>        0.00020337, 0.00023756, 0.00017438, 0.00028505, 0.0001936 ]),<br class="calibre2"/> 'mean_test_score': array([0.96666667, 0.97333333, 0.97333333, 0.98 , 0.97333333,<br class="calibre2"/>        0.96666667, 0.97333333, 0.96666667, 0.98 , 0.97333333,<br class="calibre2"/>        0.96666667, 0.98 , 0.96666667, 0.96666667, 0.96666667,<br class="calibre2"/>        0.96666667, 0.96666667, 0.98 , 0.96666667, 0.96666667]),<br class="calibre2"/> 'mean_train_score': array([0.97333333, 0.97833333, 0.97333333, 0.98 , 0.97833333,<br class="calibre2"/>        0.975 , 0.97833333, 0.975 , 0.97333333, 0.97833333,<br class="calibre2"/>        0.975 , 0.98 , 0.975 , 0.97333333, 0.975 ,<br class="calibre2"/>        0.975 , 0.975 , 0.97833333, 0.975 , 0.97666667]),<br class="calibre2"/> 'param_C': masked_array(data=[20, 53, 5, 95, 50, 71, 41, 43, 8, 30, 70, 91, 53, 15,<br class="calibre2"/>                    35, 41, 56, 82, 90, 27],<br class="calibre2"/>              mask=[False, False, False, False, False, False, False, False,<br class="calibre2"/>                    False, False, False, False, False, False, False, False,<br class="calibre2"/>                    False, False, False, False],<br class="calibre2"/>        fill_value='?',<br class="calibre2"/>             dtype=object),<br class="calibre2"/> 'param_penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l2', 'l1', 'l2', 'l1', 'l1',<br class="calibre2"/>                    'l2', 'l1', 'l2', 'l1', 'l1', 'l1', 'l1', 'l1', 'l2',<br class="calibre2"/>                    'l1', 'l2'],<br class="calibre2"/>              mask=[False, False, False, False, False, False, False, False,<br class="calibre2"/>                    False, False, False, False, False, False, False, False,<br class="calibre2"/>                    False, False, False, False],<br class="calibre2"/>        fill_value='?',<br class="calibre2"/>             dtype=object),<br class="calibre2"/> 'params': [{'C': 20, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 53, 'penalty': 'l2'},<br class="calibre2"/>  {'C': 5, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 95, 'penalty': 'l2'},<br class="calibre2"/>  {'C': 50, 'penalty': 'l2'},<br class="calibre2"/>  {'C': 71, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 41, 'penalty': 'l2'},<br class="calibre2"/>  {'C': 43, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 8, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 30, 'penalty': 'l2'},<br class="calibre2"/>  {'C': 70, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 91, 'penalty': 'l2'},<br class="calibre2"/>  {'C': 53, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 15, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 35, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 41, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 56, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 82, 'penalty': 'l2'},<br class="calibre2"/>  {'C': 90, 'penalty': 'l1'},<br class="calibre2"/>  {'C': 27, 'penalty': 'l2'}],<br class="calibre2"/> 'rank_test_score': array([10, 5, 5, 1, 5, 10, 5, 10, 1, 5, 10, 1, 10, 10, 10, 10, 10,<br class="calibre2"/>         1, 10, 10], dtype=int32),<br class="calibre2"/> 'split0_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,<br class="calibre2"/>        1., 1., 1.]),<br class="calibre2"/> 'split0_train_score': array([0.95 , 0.975 , 0.95833333, 0.975 , 0.975,<br class="calibre2"/>        0.95833333, 0.975 , 0.95833333, 0.95833333, 0.975 ,<br class="calibre2"/>        0.95833333, 0.975 , 0.95833333, 0.95 , 0.95833333,<br class="calibre2"/>        0.95833333, 0.95833333, 0.975 , 0.95833333, 0.975 ]),<br class="calibre2"/> 'split1_test_score': array([0.96666667, 1. , 1. , 1. , 1. ,<br class="calibre2"/>        0.96666667, 1. , 0.96666667, 1. , 1. ,<br class="calibre2"/>        0.96666667, 1. , 0.96666667, 0.96666667, 0.96666667,<br class="calibre2"/>        0.96666667, 0.96666667, 1. , 0.96666667, 1. ]),<br class="calibre2"/> 'split1_train_score': array([0.975, 0.975, 0.975, 0.975, 0.975, 0.975, 0.975, 0.975, 0.975,<br class="calibre2"/>        0.975, 0.975, 0.975, 0.975, 0.975, 0.975, 0.975, 0.975, 0.975,<br class="calibre2"/>        0.975, 0.975]),<br class="calibre2"/> 'split2_test_score': array([0.93333333, 0.93333333, 0.93333333, 0.96666667, 0.93333333,<br class="calibre2"/>        0.93333333, 0.93333333, 0.93333333, 0.96666667, 0.93333333,<br class="calibre2"/>        0.93333333, 0.96666667, 0.93333333, 0.93333333, 0.93333333,<br class="calibre2"/>        0.93333333, 0.93333333, 0.96666667, 0.93333333, 0.93333333]),<br class="calibre2"/> 'split2_train_score': array([0.975 , 0.98333333, 0.975 , 0.98333333, 0.98333333,<br class="calibre2"/>        0.975 , 0.98333333, 0.975 , 0.975 , 0.98333333,<br class="calibre2"/>        0.975 , 0.98333333, 0.975 , 0.975 , 0.975 ,<br class="calibre2"/>        0.975 , 0.975 , 0.98333333, 0.975 , 0.98333333]),<br class="calibre2"/> 'split3_test_score': array([0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,<br class="calibre2"/>        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,<br class="calibre2"/>        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,<br class="calibre2"/>        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.9 ]),<br class="calibre2"/> 'split3_train_score': array([0.99166667, 0.98333333, 0.98333333, 0.99166667, 0.98333333,<br class="calibre2"/>        0.99166667, 0.98333333, 0.99166667, 0.98333333, 0.98333333,<br class="calibre2"/>        0.99166667, 0.99166667, 0.99166667, 0.99166667, 0.99166667,<br class="calibre2"/>        0.99166667, 0.99166667, 0.98333333, 0.99166667, 0.98333333]),<br class="calibre2"/> 'split4_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,<br class="calibre2"/>        1., 1., 1.]),<br class="calibre2"/> 'split4_train_score': array([0.975 , 0.975 , 0.975 , 0.975 , 0.975 ,<br class="calibre2"/>        0.975 , 0.975 , 0.975 , 0.975 , 0.975 ,<br class="calibre2"/>        0.975 , 0.975 , 0.975 , 0.975 , 0.975 ,<br class="calibre2"/>        0.975 , 0.975 , 0.975 , 0.975 , 0.96666667]),<br class="calibre2"/> 'std_fit_time': array([2.16497645e-03, 5.39653699e-05, 1.00355397e-03, 4.75298306e-05,<br class="calibre2"/>        9.75692490e-05, 2.63689357e-03, 7.04799517e-05, 2.52499464e-03,<br class="calibre2"/>        1.92020413e-03, 6.05031761e-05, 1.78589024e-03, 5.85074724e-05,<br class="calibre2"/>        2.28621528e-03, 2.19771432e-03, 1.96957384e-03, 3.06769107e-03,<br class="calibre2"/>        1.15194163e-03, 2.10475943e-05, 1.33958298e-03, 4.09795418e-05]),<br class="calibre2"/> 'std_score_time': array([4.62378644e-05, 1.66142000e-06, 3.40806829e-05, 1.73623737e-05,<br class="calibre2"/>        5.26490415e-05, 4.75790783e-05, 1.48510089e-06, 7.53432889e-06,<br class="calibre2"/>        3.86445261e-05, 8.16042958e-05, 4.98746594e-05, 1.93474877e-05,<br class="calibre2"/>        2.82650630e-05, 2.54787261e-05, 2.55031663e-05, 3.09080976e-05,<br class="calibre2"/>        2.99830109e-05, 7.89824294e-06, 2.02431836e-05, 4.25877252e-05]),<br class="calibre2"/> 'std_test_score': array([0.02981424, 0.03265986, 0.03265986, 0.02666667, 0.03265986,<br class="calibre2"/>        0.02981424, 0.03265986, 0.02981424, 0.02666667, 0.03265986,<br class="calibre2"/>        0.02981424, 0.02666667, 0.02981424, 0.02981424, 0.02981424,<br class="calibre2"/>        0.02981424, 0.02981424, 0.02666667, 0.02981424, 0.0421637 ]),<br class="calibre2"/> 'std_train_score': array([0.01333333, 0.00408248, 0.00816497, 0.00666667, 0.00408248,<br class="calibre2"/>        0.01054093, 0.00408248, 0.01054093, 0.00816497, 0.00408248,<br class="calibre2"/>        0.01054093, 0.00666667, 0.01054093, 0.01333333, 0.01054093,<br class="calibre2"/>        0.01054093, 0.01054093, 0.00408248, 0.01054093, 0.0062361 ])}</pre>
<p class="mce-root">交叉验证结果可能看起来很混乱，但您可以将它们导入到<kbd class="calibre16">pandas</kbd>数据框架中:</p>
<pre class="calibre21">import pandas as pd<br class="calibre2"/><br class="calibre2"/>df = pd.DataFrame(estimator.cv_results_)<br class="calibre2"/><br class="calibre2"/>df.head()</pre>
<p class="mce-root">我们可以看到如下几条记录:</p>
<pre class="calibre21">mean_fit_time mean_score_time mean_test_score mean_train_score param_C \<br class="calibre2"/>0 0.009134 0.000261 0.966667 0.973333 20 <br class="calibre2"/>1 0.000652 0.000165 0.973333 0.978333 53 <br class="calibre2"/>2 0.008730 0.000206 0.973333 0.973333 5 <br class="calibre2"/>3 0.000681 0.000177 0.980000 0.980000 95 <br class="calibre2"/>4 0.000827 0.000224 0.973333 0.978333 50 <br class="calibre2"/>  param_penalty params rank_test_score \<br class="calibre2"/>0 l1 {'C': 20, 'penalty': 'l1'} 10 <br class="calibre2"/>1 l2 {'C': 53, 'penalty': 'l2'} 5 <br class="calibre2"/>2 l1 {'C': 5, 'penalty': 'l1'} 5 <br class="calibre2"/>3 l2 {'C': 95, 'penalty': 'l2'} 1 <br class="calibre2"/>4 l2 {'C': 50, 'penalty': 'l2'} 5 <br class="calibre2"/>   split0_test_score split0_train_score ... split2_test_score \<br class="calibre2"/>0 1.0 0.950000 ... 0.933333 <br class="calibre2"/>1 1.0 0.975000 ... 0.933333 <br class="calibre2"/>2 1.0 0.958333 ... 0.933333 <br class="calibre2"/>3 1.0 0.975000 ... 0.966667 <br class="calibre2"/>4 1.0 0.975000 ... 0.933333 <br class="calibre2"/>   split2_train_score split3_test_score split3_train_score \<br class="calibre2"/>0 0.975000 0.933333 0.991667 <br class="calibre2"/>1 0.983333 0.933333 0.983333 <br class="calibre2"/>2 0.975000 0.933333 0.983333 <br class="calibre2"/>3 0.983333 0.933333 0.991667 <br class="calibre2"/>4 0.983333 0.933333 0.983333 <br class="calibre2"/>   split4_test_score split4_train_score std_fit_time std_score_time \<br class="calibre2"/>0 1.0 0.975 0.002165 0.000046 <br class="calibre2"/>1 1.0 0.975 0.000054 0.000002 <br class="calibre2"/>2 1.0 0.975 0.001004 0.000034 <br class="calibre2"/>3 1.0 0.975 0.000048 0.000017 <br class="calibre2"/>4 1.0 0.975 0.000098 0.000053 <br class="calibre2"/>   std_test_score std_train_score <br class="calibre2"/>0 0.029814 0.013333 <br class="calibre2"/>1 0.032660 0.004082 <br class="calibre2"/>2 0.032660 0.008165 <br class="calibre2"/>3 0.026667 0.006667 <br class="calibre2"/>4 0.032660 0.004082 <br class="calibre2"/>[5 rows x 22 columns]</pre>
<p class="mce-root">您可以过滤数据帧，看看<kbd class="calibre16">mean_test_score</kbd>在哪里最大:</p>
<pre class="calibre21">df[df['mean_test_score'] == df['mean_test_score'].max()]</pre>
<p class="mce-root">这将输出以下内容:</p>
<pre class="calibre21">    mean_fit_time mean_score_time mean_test_score mean_train_score param_C \<br class="calibre2"/>3 0.000681 0.000177 0.98 0.980000 95 <br class="calibre2"/>8 0.008837 0.000261 0.98 0.973333 8 <br class="calibre2"/>11 0.000684 0.000180 0.98 0.980000 91 <br class="calibre2"/>17 0.000677 0.000174 0.98 0.978333 82 <br class="calibre2"/>   param_penalty params rank_test_score \<br class="calibre2"/>3 l2 {'C': 95, 'penalty': 'l2'} 1 <br class="calibre2"/>8 l1 {'C': 8, 'penalty': 'l1'} 1 <br class="calibre2"/>11 l2 {'C': 91, 'penalty': 'l2'} 1 <br class="calibre2"/>17 l2 {'C': 82, 'penalty': 'l2'} 1 <br class="calibre2"/>    split0_test_score split0_train_score ... split2_test_score \<br class="calibre2"/>3 1.0 0.975000 ... 0.966667 <br class="calibre2"/>8 1.0 0.958333 ... 0.966667 <br class="calibre2"/>11 1.0 0.975000 ... 0.966667 <br class="calibre2"/>17 1.0 0.975000 ... 0.966667 <br class="calibre2"/>    split2_train_score split3_test_score split3_train_score \<br class="calibre2"/>3 0.983333 0.933333 0.991667 <br class="calibre2"/>8 0.975000 0.933333 0.983333 <br class="calibre2"/>11 0.983333 0.933333 0.991667 <br class="calibre2"/>17 0.983333 0.933333 0.983333 <br class="calibre2"/>    split4_test_score split4_train_score std_fit_time std_score_time \<br class="calibre2"/>3 1.0 0.975 0.000048 0.000017 <br class="calibre2"/>8 1.0 0.975 0.001920 0.000039 <br class="calibre2"/>11 1.0 0.975 0.000059 0.000019 <br class="calibre2"/>17 1.0 0.975 0.000021 0.000008 <br class="calibre2"/>    std_test_score std_train_score <br class="calibre2"/>3 0.026667 0.006667 <br class="calibre2"/>8 0.026667 0.008165 <br class="calibre2"/>11 0.026667 0.006667 <br class="calibre2"/>17 0.026667 0.004082 <br class="calibre2"/>[4 rows x 22 columns]</pre>
<p class="mce-root">作为练习，您可以使用以下超参数为<kbd class="calibre16">GradientBoostingClassifier</kbd>创建一个参数网格，以试验<kbd class="calibre16">GridSearchCV</kbd>和<kbd class="calibre16">RandomizedSearchCV</kbd>:</p>
<ul class="calibre13">
<li class="calibre14"><kbd class="calibre16">learning_rate</kbd>(默认值= 0.1)——提高学习率</li>
<li class="calibre14"><kbd class="calibre16">n_estimators</kbd>(默认值= 100)—适合的提升树的数量</li>
<li class="calibre14"><kbd class="calibre16">max_depth</kbd>(默认值= 3)—最大树深度</li>
</ul>


            

            
        
    </div>



  




  
    <title>Unknown</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  


  <div><h1 class="header-title">热启动</h1>
                
            
            
                
<p class="mce-root">就<strong class="calibre7">自动化 ML </strong> ( <strong class="calibre7"> AutoML </strong>)流水线而言，超参数搜索空间可以增长得非常快，并且在有限的时间和有限的资源下，穷举搜索变得不切实际。您需要更智能的方法来执行这项任务，尤其是如果您有一个大型数据集，并且有一个复杂的模型在其上工作。如果你发现自己处于这种情况，一个<kbd class="calibre16">GridSeachCV</kbd>实例穷举搜索是不可行的，或者在有限的时间内<kbd class="calibre16">RandomizedSearchCV</kbd>的随机参数抽取可能不会给你最好的结果。</p>
<p class="mce-root">热启动的基本思想是使用从以前的训练运行中获得的信息来确定下一次训练运行的更智能的起点。</p>
<p class="mce-root">例如，<kbd class="calibre16">LogisticRegression</kbd>有一个<kbd class="calibre16">warm_start</kbd>参数，默认设置为<kbd class="calibre16">False</kbd>。以下示例显示了第一次训练的时间，以及参数更新后设置为<kbd class="calibre16">False</kbd>的时间:</p>
<pre class="calibre21">from sklearn.linear_model import LogisticRegression<br class="calibre2"/><br class="calibre2"/>log_reg = LogisticRegression(C=10, tol=0.00001)<br class="calibre2"/><br class="calibre2"/>from sklearn import datasets<br class="calibre2"/>iris = datasets.load_iris()<br class="calibre2"/>X = iris.data<br class="calibre2"/>Y = iris.target<br class="calibre2"/><br class="calibre2"/>from time import time<br class="calibre2"/>start = time()<br class="calibre2"/>log_reg.fit(X, Y)<br class="calibre2"/>end = time()<br class="calibre2"/>print("Time: {}".format(end - start))<br class="calibre2"/># Time: 0.0009272098541259766<br class="calibre2"/><br class="calibre2"/>log_reg.set_params(C=20)<br class="calibre2"/># LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,<br class="calibre2"/># intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,<br class="calibre2"/># penalty='l2', random_state=None, solver='liblinear', tol=0.0001,<br class="calibre2"/># verbose=0, warm_start=False)<br class="calibre2"/><br class="calibre2"/>start = time()<br class="calibre2"/>log_reg.fit(X, Y)<br class="calibre2"/>end = time()<br class="calibre2"/>print("Time: {}".format(end - start))<br class="calibre2"/># Time: 0.0012941360473632812</pre>
<p class="mce-root"><kbd class="calibre16">LogisticRegression</kbd>的默认解算器是<kbd class="calibre16">liblinear</kbd>，它将在每次新拟合之前重新初始化权重，但其他解算器如<kbd class="calibre16">lbfgs</kbd>、<kbd class="calibre16">newton-cg</kbd>、<kbd class="calibre16">sag</kbd>和<kbd class="calibre16">saga</kbd>可以利用<kbd class="calibre16">warm_start</kbd>并通过使用来自先前拟合的信息来减少计算时间。</p>
<p class="mce-root">下面的代码片段向您展示了它在实践中是如何工作的一个小例子:</p>
<pre class="calibre21">log_reg = LogisticRegression(C=10, solver='sag', warm_start=True, max_iter=10000)<br class="calibre2"/><br class="calibre2"/>start = time()<br class="calibre2"/>log_reg.fit(X, Y)<br class="calibre2"/>end = time()<br class="calibre2"/>print("Time: {}".format(end - start))<br class="calibre2"/># Time: 0.043714046478271484<br class="calibre2"/><br class="calibre2"/>log_reg.set_params(C=20)<br class="calibre2"/><br class="calibre2"/>start = time()<br class="calibre2"/>log_reg.fit(X, Y)<br class="calibre2"/>end = time()<br class="calibre2"/>print("Time: {}".format(end - start))<br class="calibre2"/># Time: 0.020781755447387695</pre>


            

            
        
    </div>



  




  
    <title>Unknown</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  


  <div><h1 class="header-title">基于贝叶斯的超参数调整</h1>
                
            
            
                
<p class="mce-root">当涉及到基于模型的超参数调整时，有几种方法可以使用，这些方法在<strong class="calibre7">基于顺序模型的全局优化</strong> ( <strong class="calibre7"> SMBO </strong>)下集合在一起。</p>
<p class="mce-root">当您想到<kbd class="calibre16">GridSearchCV</kbd>或<kbd class="calibre16">RandomizedSearchCV</kbd>时，您可能会正确地认为它们交叉验证超参数的方式不太明智。两者都预先定义了要在训练期间验证的超参数集，并且没有被设计成从它们可能在训练期间获得的信息中受益。如果您可以找到一种方法，从基于模型性能的超参数验证的以前迭代中学习，那么您将会知道哪个超参数集可能在下一次迭代中提供更好的性能。</p>
<p class="mce-root">SMBO 方法源于这种推理，基于贝叶斯的超参数优化是这些方法之一。</p>
<p class="mce-root"><strong class="calibre7">基于序列模型的算法配置</strong> ( <strong class="calibre7"> SMAC </strong>)是一个很棒的库，它使用贝叶斯优化来配置给定 ML 算法的超参数，并且非常容易使用。</p>
<pre>branin function that you used at the beginning with SMAC:</pre>
<pre class="calibre21">from smac.facade.func_facade import fmin_smac<br class="calibre2"/><br class="calibre2"/>x, cost, _ = fmin_smac(func=branin, # function<br class="calibre2"/>                           x0=[3.2, 4.5], # default configuration<br class="calibre2"/>                           bounds=[(-5, 10), (0, 15)], # limits<br class="calibre2"/>                           maxfun=500, # maximum number of evaluations<br class="calibre2"/>                           rng=3) # random seed<br class="calibre2"/><br class="calibre2"/><br class="calibre2"/>print(x, cost)<br class="calibre2"/># [3.12848204 2.33810374] 0.4015064637498025</pre>


            

            
        
    </div>



  




  
    <title>Unknown</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  


  <div><h1 class="header-title">一个示例系统</h1>
                
            
            
                
<p class="mce-root">在本节中，您将编写一个包装器函数来优化 XGBoost 算法超参数，以提高对<kbd class="calibre16">Breast Cancer Wisconsin</kbd>数据集的性能:</p>
<pre class="calibre21"># Importing necessary libraries<br class="calibre2"/>import numpy as np<br class="calibre2"/>from xgboost import XGBClassifier<br class="calibre2"/>from sklearn import datasets<br class="calibre2"/>from sklearn.model_selection import cross_val_score<br class="calibre2"/><br class="calibre2"/># Importing ConfigSpace and different types of parameters<br class="calibre2"/>from smac.configspace import ConfigurationSpace<br class="calibre2"/>from ConfigSpace.hyperparameters import CategoricalHyperparameter, \<br class="calibre2"/>    UniformFloatHyperparameter, UniformIntegerHyperparameter<br class="calibre2"/>from ConfigSpace.conditions import InCondition<br class="calibre2"/><br class="calibre2"/># Import SMAC-utilities<br class="calibre2"/>from smac.tae.execute_func import ExecuteTAFuncDict<br class="calibre2"/>from smac.scenario.scenario import Scenario<br class="calibre2"/>from smac.facade.smac_facade import SMAC<br class="calibre2"/><br class="calibre2"/># Creating configuration space.<br class="calibre2"/># Configuration space will hold all of your hyperparameters<br class="calibre2"/>cs = ConfigurationSpace()<br class="calibre2"/><br class="calibre2"/># Defining hyperparameters and range of values that they can take<br class="calibre2"/>learning_rate = UniformFloatHyperparameter("learning_rate", 0.001, 0.1, default_value=0.1)<br class="calibre2"/>n_estimators = UniformIntegerHyperparameter("n_estimators", 100, 200, default_value=100)<br class="calibre2"/><br class="calibre2"/># Adding hyperparameters to configuration space<br class="calibre2"/>cs.add_hyperparameters([learning_rate, n_estimators])<br class="calibre2"/><br class="calibre2"/># Loading data set<br class="calibre2"/>wbc_dataset = datasets.load_breast_cancer()<br class="calibre2"/><br class="calibre2"/># Creating function to cross validate XGBoost classifier given the configuration space<br class="calibre2"/>def xgboost_from_cfg(cfg):<br class="calibre2"/>    """ Creates a XGBoost based on a configuration and evaluates it on the<br class="calibre2"/>    Wisconsin Breast Cancer-dataset using cross-validation.<br class="calibre2"/><br class="calibre2"/>    Parameters:<br class="calibre2"/>    -----------<br class="calibre2"/>    cfg: Configuration (ConfigSpace.ConfigurationSpace.Configuration)<br class="calibre2"/>        Configuration containing the parameters.<br class="calibre2"/>        Configurations are indexable!<br class="calibre2"/>    Returns:<br class="calibre2"/>    --------<br class="calibre2"/>    A crossvalidated mean score for the svm on the loaded data-set.<br class="calibre2"/>    """<br class="calibre2"/><br class="calibre2"/>    cfg = {k: cfg[k] for k in cfg if cfg[k]}<br class="calibre2"/><br class="calibre2"/>    clf = XGBClassifier(**cfg, eval_metric='auc', early_stopping_rounds=50, random_state=42)<br class="calibre2"/><br class="calibre2"/>    scores = cross_val_score(clf, wbc_dataset.data, wbc_dataset.target, cv=5)<br class="calibre2"/><br class="calibre2"/>    return 1 - np.mean(scores) # Minimize!<br class="calibre2"/><br class="calibre2"/><br class="calibre2"/># Creating Scenario object<br class="calibre2"/>scenario = Scenario({"run_obj": "quality",<br class="calibre2"/>                     "runcount-limit": 200, # maximum function evaluations<br class="calibre2"/>                     "cs": cs, # configuration space<br class="calibre2"/>                     "deterministic": "true"<br class="calibre2"/>                     })<br class="calibre2"/><br class="calibre2"/><br class="calibre2"/><br class="calibre2"/># SMAC object handles bayesian optimization loop<br class="calibre2"/>print("Please wait until optimization is finished")<br class="calibre2"/>smac = SMAC(scenario=scenario, rng=np.random.RandomState(42),<br class="calibre2"/>        tae_runner=xgboost_from_cfg)<br class="calibre2"/><br class="calibre2"/>incumbent = smac.optimize()<br class="calibre2"/><br class="calibre2"/># Let's see the best performing hyperparameter values<br class="calibre2"/>print(incumbent)<br class="calibre2"/># Configuration:<br class="calibre2"/># learning_rate, Value: 0.08815217130807515<br class="calibre2"/># n_estimators, Value: 196<br class="calibre2"/><br class="calibre2"/># You can see the errpr rate of optimized hyperparameters<br class="calibre2"/>inc_value = xgboost_from_cfg(incumbent)<br class="calibre2"/><br class="calibre2"/>print("Optimized Value: %.2f" % (inc_value))<br class="calibre2"/># 0.02</pre>
<p class="mce-root">太好了！现在您知道如何创建您的配置空间，添加您的超参数，并为每个参数定义取值范围。配置完成后，您已经看到了如何创建一个场景对象并使用 SMAC 来优化给定估计器的超参数。</p>
<p class="mce-root">您可以使用 SMAC 对象来获取运行历史，并查看每个配置的开销:</p>
<pre class="calibre21">param_1 = []<br class="calibre2"/>param_2 = []<br class="calibre2"/>costs = []<br class="calibre2"/><br class="calibre2"/>for k,v in smac.runhistory.config_ids.items():<br class="calibre2"/>    param_1.append(k._values['learning_rate'])<br class="calibre2"/>    param_2.append(k._values['n_estimators'])<br class="calibre2"/>    costs.append(smac.runhistory.cost_per_config[v])<br class="calibre2"/><br class="calibre2"/>print(len(param_1), len(param_2), len(costs))<br class="calibre2"/><br class="calibre2"/>import matplotlib.pyplot as plt<br class="calibre2"/>import matplotlib.cm as cm<br class="calibre2"/><br class="calibre2"/>sc = plt.scatter(param_1, param_2, c=costs)<br class="calibre2"/>plt.colorbar(sc)<br class="calibre2"/>plt.show()</pre>
<p class="mce-root">下图显示了<kbd class="calibre16">learning_rate</kbd>和<kbd class="calibre16">n_estimators</kbd>在优化过程中采用的不同值及其相关成本:</p>
<div><img src="img/e2c458fb-9951-4228-9b4d-b02b239d3035.png" width="911" height="704" class="calibre149"/></div>
<p class="mce-root">你可以看到最好的配置是<kbd class="calibre16">learning_rate</kbd>的大约 0.09 和<kbd class="calibre16">n_estimators</kbd>的大约 200。</p>


            

            
        
    </div>



  




  
    <title>Unknown</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  


  <div><h1 class="header-title">摘要</h1>
                
            
            
                
<p class="mce-root">在本章中，您学习了模型参数、超参数和配置空间。让我们快速回顾一下:</p>
<ul class="calibre13">
<li class="calibre14"><strong class="calibre3">模型参数</strong>:您可以将这些参数视为训练期间需要学习的参数</li>
<li class="calibre14"><strong class="calibre3">模型超参数</strong>:这些是您应该在训练开始前定义的参数</li>
<li class="calibre14"><strong class="calibre3">配置空间参数</strong>:这些参数是指用于托管您的实验的环境的任何其他参数</li>
</ul>
<p class="mce-root">已经向您介绍了常见的超参数优化方法，如网格搜索和随机搜索。网格搜索和随机化搜索不使用从先前的训练运行中产生的信息，这是基于贝叶斯的优化方法解决的缺点。</p>
<p class="mce-root">基于贝叶斯的优化方法利用先前训练运行的信息来决定下一次训练运行的超参数值，并以更智能的方式在超参数空间中导航。SMAC 是 auto-sklearn 用来优化给定估计器的超参数的工具，本章向您展示了如何在自己的 ML 管道中使用该方法。</p>


            

            
        
    </div>



  

</body></html>