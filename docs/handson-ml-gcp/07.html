<html><head/><body><html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Google Machine Learning APIs</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:c0dc9385-c68c-47e3-9ef8-4abf6976fdcb" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">谷歌机器学习 API</h1>

                

            

            

                

<p>如前一章所见，机器学习被广泛应用。然而，有一些应用程序很容易构建，而有一些很难构建，尤其是对于不太熟悉机器学习的用户来说。我们将在本章中讨论的一些应用程序属于难以构建的类别，因为为这些应用程序构建机器学习模型的过程是数据密集型、资源密集型的，并且需要该领域的大量知识。</p>

<p>在这一章中，我们将浏览谷歌提供的五个机器学习 API(截至 2018 年 3 月)。这些 API 旨在开箱即用，作为 RESTful APIs。对于下面提到的每个服务，我们将展示什么类型的应用程序可以从中受益，以及如何解释返回的结果:</p>

<ul>

<li>视觉具有标签检测、OCR、人脸检测和情感、标志和地标</li>

<li>语音意味着语音到文本</li>

<li>NLP 有实体、情感和位置</li>

<li>翻译</li>

<li>视频智能</li>

</ul>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Vision API</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:c0dc9385-c68c-47e3-9ef8-4abf6976fdcb" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">视觉 API</h1>

                

            

            

                

<p>Vision API 允许我们构建许多与 Vision 相关的应用程序:</p>

<ul>

<li>检测图像中的标签</li>

<li>检测图像中的文本</li>

<li>人脸检测</li>

<li>情绪检测</li>

<li>徽标检测</li>

<li>地标检测</li>

</ul>

<p class="mce-root">在我们开始使用上述方法构建应用程序之前，让我们以面部情绪检测为例，快速了解一下如何构建应用程序。</p>

<p>检测情绪的过程包括:</p>

<ol>

<li>收集大量的图像</li>

<li>用图像中可能表现的情感手工标记图像</li>

<li>训练一个<strong>卷积神经网络</strong> ( <strong> CNN </strong>)(将在以后的章节中讨论)根据输入的图像对情感进行分类</li>

</ol>

<p>虽然前面的步骤是大量资源密集型的(因为我们需要很多人来收集和手工标记图像)，但是有多种其他方法来获得面部情绪检测。我们不确定谷歌是如何收集和标记图像的，但我们现在将考虑谷歌为我们建立的 API，这样，如果我们想将图像分类为它们所代表的情感，我们就可以利用该 API。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Enabling the API</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:c0dc9385-c68c-47e3-9ef8-4abf6976fdcb" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">启用 API</h1>

                

            

            

                

<p>在我们开始构建应用程序之前，我们首先必须启用 API，如下所示:</p>

<ol>

<li>搜索 Google Cloud Vision API:</li>

</ol>

<div><img src="img/c0b69895-ef96-4500-836c-892128798f1b.png"/></div>

<ol start="2">

<li>启用 Google Cloud Vision API:</li>

</ol>

<div><img class="alignnone size-full wp-image-856 image-border" src="img/3f0fd833-0aba-4b4a-a7d6-da1cfd61f563.png" style=""/></div>

<ol start="3">

<li>一旦您点击 ENABLE，这个项目(也就是我的第一个项目)的 API 就会被启用，如前面的截图所示。</li>

<li>获取 API 的凭据:</li>

</ol>

<div><img class="alignnone size-full wp-image-857 image-border" src="img/8af83174-c263-4cab-843e-e61d707c8774.png" style=""/></div>

<ol start="5">

<li>单击创建凭据后，单击服务帐户密钥:</li>

</ol>

<div><img src="img/f0c5cd49-93fb-44db-aae9-12e910f22ad4.png" style=""/></div>

<ol start="6">

<li>单击新服务帐户:</li>

</ol>

<div><img class="alignnone size-full wp-image-863 image-border" src="img/e34a91c8-b9d0-4e6e-a48f-6d17ae69ff82.png" style=""/></div>

<ol start="7">

<li>输入服务帐户名称(在我的例子中是<kbd>kish-gcp</kbd>)并选择一个角色作为项目所有者:</li>

</ol>

<div><img src="img/9a1e919d-a00a-4897-9b8d-fe2001b1b8f8.png" style=""/></div>

<ol start="8">

<li>单击 Create 保存密钥的 JSON 文件。</li>

</ol>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Opening an instance</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:c0dc9385-c68c-47e3-9ef8-4abf6976fdcb" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">打开实例</h1>

                

            

            

                

<p>要打开一个实例，请单击虚拟机实例，如下图所示，然后单击激活 google cloud shell 图标:</p>

<div><img class="alignnone size-full wp-image-841 image-border" src="img/f8df15b9-f8a2-4a24-af2b-ec2d45251d15.png" style=""/></div>

<div><img class="alignnone size-full wp-image-840 image-border" src="img/2370fe86-0ccd-48aa-8185-38b28125c7b9.png" style=""/></div>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Creating an instance using Cloud Shell</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:c0dc9385-c68c-47e3-9ef8-4abf6976fdcb" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">使用云壳创建实例</h1>

                

            

            

                

<p>单击云壳图标后，我们创建一个实例，如下所示:</p>

<ol>

<li>通过指定以下代码创建一个实例:</li>

</ol>

<pre style="padding-left: 60px">datalab create --no-create-repository &lt;instance name&gt;</pre>

<ol start="2">

<li>在云 Shell 中，前面的代码如下所示:</li>

</ol>

<div><img class="alignnone size-full wp-image-865 image-border" src="img/7b24116c-0aa3-4f1f-9458-d605dbadc306.png" style=""/></div>

<ol start="3">

<li>输入所有提示的响应后，您需要将端口更改为<kbd>8081</kbd>以访问 Datalab，操作如下:</li>

</ol>

<div><img src="img/710044dc-2640-47d0-93b1-8ddbc07c34f8.png" style=""/></div>

<ol start="4">

<li>一旦你点击改变端口，你将得到如下窗口。进入<kbd>8081</kbd>，点击更改和预览，打开数据实验室:</li>

</ol>

<div><img src="img/a2160b6a-880a-4a66-8c76-313dd4705a96.png" style=""/></div>

<ol start="5">

<li>这将打开 Datalab，它的功能使我们能够编写所有类型的命令:<kbd>bash</kbd>、<kbd>bigquery</kbd>、<kbd>python</kbd>等等。</li>

</ol>

<p class="mce-root">既然已经设置了需求，让我们获取/安装 API 的需求:</p>

<ol>

<li>访问上一节中的 API 密钥，我们已经下载了所需的密钥。现在，让我们通过点击上传按钮将<kbd>.json</kbd>文件上传到数据实验室:</li>

</ol>

<div><img class="alignnone size-full wp-image-858 image-border" src="img/fba08f3a-b025-40eb-825f-6d338fcae55e.png" style=""/></div>

<ol start="2">

<li>一旦上传了<kbd>.json</kbd>文件，您应该能够从这里通过 Datalab 访问它:</li>

</ol>

<div><img src="img/e4a25f51-1121-4c68-a153-369213f94930.png" style=""/></div>

<ol start="3">

<li>打开笔记本；您可以通过单击“笔记本”选项卡在 Datalab 中打开笔记本，如下所示:</li>

</ol>

<div><img class="alignnone size-full wp-image-843 image-border" src="img/1c1dbb14-1143-4f17-a662-b9a1d269b821.png" style=""/></div>

<ol start="4">

<li>要安装<kbd>google-cloud</kbd>，打开笔记本后，将内核从 python2 改为 python3:</li>

</ol>

<div><img class="alignnone size-full wp-image-847 image-border" src="img/2c842bd5-f941-4f47-a91c-1a54681a9ff2.png" style=""/></div>

<ol start="5">

<li>安装<kbd>google-cloud</kbd>组件，如下所示:</li>

</ol>

<pre style="padding-left: 60px">%bash<br/>pip install google-cloud</pre>

<ol start="6">

<li>一旦安装了<kbd>google-cloud</kbd>，通过指定以下内容，确保先前上传的<kbd>.json</kbd>文件在当前 Python 环境中是可访问的:</li>

</ol>

<pre style="padding-left: 60px">import os<br/>os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "/content/datalab/google-<br/>api.json"</pre>

<ol start="7">

<li>为了上传感兴趣的图像，我们将考虑将文件从本地机器传输到 bucket，以及从 bucket 传输到 Datalab。</li>

</ol>

<ol start="8">

<li>在谷歌云中搜索<kbd>bucket</kbd>:</li>

</ol>

<div><img class="alignnone size-full wp-image-866 image-border" src="img/6337862a-a63e-4cf7-b6c8-6d66838c8e77.png" style=""/></div>

<ol start="9">

<li>现在，命名存储桶并创建它:</li>

</ol>

<div><img src="img/34631cf2-357f-435a-b990-77457e90d3fd.png" style=""/></div>

<ol start="10">

<li>点击上传<strong>文件</strong>将相关文件从本地机器上传到存储桶。</li>

</ol>

<div><img src="img/32220fa6-257a-444a-b7d2-1d24631e8a8f.jpg" style=""/></div>

<ol start="11">

<li>一旦文件上传到 bucket，就从 Datalab 获取它，如下所示:</li>

</ol>

<div><img src="img/4ebd04af-3b8c-499f-873f-b44a33315867.png" style=""/></div>

<ol start="12">

<li>现在，您应该注意到<kbd>11.jpg</kbd>在 Datalab 中是可访问的。</li>

</ol>

<p>既然要分析的图像在 Datalab 中是可访问的，那么让我们了解利用云视觉 API 来更好地理解图像的方法:</p>

<ol start="1">

<li>导入相关包:</li>

</ol>

<pre style="padding-left: 60px">from google.cloud import vision</pre>

<p style="padding-left: 60px">前面的代码片段确保 Vision 中可用的方法在当前会话中是可访问的。</p>

<ol start="2">

<li>调用对客户端图像执行 Google Cloud Vision API 检测任务(如人脸、地标、徽标、标签和文本检测)的服务— <kbd>ImageAnnotator</kbd>:</li>

</ol>

<pre style="padding-left: 60px">client = vision.ImageAnnotatorClient()</pre>

<ol start="3">

<li>验证图像是否按照预期上传:</li>

</ol>

<pre style="padding-left: 60px">import matplotlib.pyplot as plt<br/>import matplotlib.image as mpimg<br/>%matplotlib inline<br/>img=mpimg.imread('/content/datalab/11.jpg')<br/>plt.axis('off')<br/>plt.imshow(img)</pre>

<div><img src="img/eda014fe-a165-4cbb-b709-d7743b54d0f0.png" style=""/></div>

<ol start="4">

<li>调用<kbd>face_detection</kbd>方法获取图像的相关细节，如下所示:</li>

</ol>

<pre style="padding-left: 60px">response = client.face_detection({'source' : {'image_uri': "gs://kish-<br/>bucket/11.jpg"},})</pre>

<ol start="5">

<li>对图像注释的响应如下:</li>

</ol>

<div><img class="alignnone size-full wp-image-850 image-border" src="img/b1b03a99-5a4c-43b2-8d2a-60f8a586d63d.png" style=""/></div>

<div><img class="alignnone size-full wp-image-855 image-border" src="img/59629615-6973-44ba-9585-fbf796eba63e.png" style=""/></div>

<ol start="6">

<li>现在我们已经运行了我们的方法来检测图像中的人脸，让我们看看输出- <kbd>response</kbd>。如前所述，<kbd>response</kbd>的输出是一组属性:</li>

</ol>

<pre style="padding-left: 60px">response</pre>

<div><img class="alignnone size-full wp-image-852 image-border" src="img/f2c8d0a0-778a-421f-9a5a-e2e31d1f90e2.png" style=""/></div>

<p>以下是详细解释的几个要点:</p>

<ul>

<li><strong>包围多边形</strong>:包围多边形在脸的周围。边界框的坐标是原始图像的比例，如在<kbd>ImageParams</kbd>中返回的。计算边界框以根据人类的期望来框住面部。它基于地标结果。注意，如果只有部分面部出现在要注释的图像中，一个或多个<em> x </em>和/或<em> y </em>坐标可能不会在<kbd>BoundingPoly</kbd>中生成(多边形将是无界的)。</li>

<li><strong>人脸检测包围多边形</strong>:包围多边形<kbd>fd_bounding_poly</kbd>比<kbd>BoundingPoly</kbd>更紧密，只包围人脸的皮肤部分。通常，它用于从任何检测图像中可见皮肤数量的图像分析中消除面部。</li>

<li><strong>地标</strong>:检测到的人脸地标。</li>

</ul>

<p>在以下几点中有更多的术语需要解释:</p>

<ul>

<li><kbd>roll_angle</kbd>:滚动角度，表示脸部相对于图像顺时针/逆时针旋转的量。范围是[-180，180]。</li>

<li><kbd>pan_angle</kbd>:偏航角，表示相对于垂直于图像的垂直面，人脸指向的向左/向右的角度。范围是[-180，180]。</li>

<li><kbd>tilt_angle</kbd>:俯仰角，表示人脸指向的相对于图像水平面的上/下角度。范围是[-180，180]。</li>

<li><kbd>detection_confidence</kbd>:与检测相关的置信度。</li>

<li><kbd>landmarking_confidence</kbd>:与地标相关的置信度。</li>

<li><kbd>joy_likelihood</kbd>:与喜悦相关的可能性。</li>

<li><kbd>sorrow_likelihood</kbd>:与悲伤有关的可能性。</li>

<li><kbd>anger_likelihood</kbd>:与愤怒相关的可能性。</li>

<li><kbd>surprise_likelihood</kbd>:与惊喜相关的可能性。</li>

<li><kbd>under_exposed_likelihood</kbd>:与暴露相关的可能性。</li>

<li><kbd>blurred_likelihood</kbd>:与模糊相关的可能性。</li>

<li><kbd>headwear_likelihood</kbd>:与头饰关联的可能性。</li>

</ul>

<p>面部标志将进一步提供眼睛、鼻子、嘴唇、耳朵等的位置。</p>

<p>我们应该能够在识别出的人脸周围制作一个边界框。</p>

<p><kbd>face_annotations</kbd>的输出如下:</p>

<div><img src="img/e8b59b5a-4ea1-4e12-ba0b-a3c54a431b69.png" style=""/></div>

<p>从前面的代码中，我们应该能够理解边界框的坐标。在下面的代码中，我们计算边界框的起点，以及边界框相应的宽度和高度。计算完成后，我们将矩形叠加到原始图像上:</p>

<pre>import matplotlib.patches as patches<br/>import numpy as np<br/>fig,ax = plt.subplots(1)<br/><br/># Display the image<br/>ax.imshow(img)<br/><br/># Create a Rectangle patch<br/>x_width = np.abs(response.face_annotations[0].bounding_poly.vertices[1].x-<br/>  response.face_annotations[0].bounding_poly.vertices[0].x)<br/>y_height = np.abs(response.face_annotations[0].bounding_poly.vertices[1].y-<br/>  response.face_annotations[0].bounding_poly.vertices[3].y)<br/><br/>rect =<br/> patches.Rectangle((response.face_annotations[0].bounding_poly.vertices[0].x,<br/> response.face_annotations[0].bounding_poly.vertices[0].y),<br/>                         x_width,y_height,linewidth=5,edgecolor='y',facecolor='none')<br/><br/># Add the patch to the Axes<br/>ax.add_patch(rect)<br/>plt.axis('off')<br/>plt.show()</pre>

<p>上述代码的输出是脸部周围带有边框的图像，如下所示:</p>

<div><img class="alignnone size-full wp-image-846 image-border" src="img/1b10cd5c-cc20-4c35-9236-765efdb5b670.png" style=""/></div>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Label detection</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:c0dc9385-c68c-47e3-9ef8-4abf6976fdcb" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">标签检测</h1>

                

            

            

                

<p>在前面的代码片段中，我们使用了<kbd>face_detection</kbd>方法来获取各种坐标。</p>

<p>为了理解图像的标签，我们将使用<kbd>label_detection</kbd>方法代替<kbd>face_detection</kbd>，如下所示:</p>

<pre>response_label = client.label_detection({'source' : {'image_uri': "gs://kish-<br/>bucket/11.jpg"},})</pre>

<div><img src="img/202f4ad6-4b36-410b-aabe-88695abbd757.png" style=""/></div>

<p>标签检测的输出是标签的集合，以及与每个标签相关联的分数。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Text detection</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:c0dc9385-c68c-47e3-9ef8-4abf6976fdcb" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">文本检测</h1>

                

            

            

                

<p>使用<kbd>text_detection</kbd>方法可以识别图像中的文本，如下所示:</p>

<pre>response_text = client.text_detection({'source' : {'image_uri': "gs://kish-<br/>bucket/11.jpg"},})</pre>

<p><kbd>response_text</kbd>的输出如下:</p>

<div><img src="img/ad3a9fa3-3b57-4f05-a1d0-9136cc27f118.png" style=""/></div>

<p>注意，<kbd>text_detection</kbd>方法的输出是图像中出现的各种文本的边界框。</p>

<p>另外，请注意，<kbd>text_annotations</kbd>的描述提供了图像中检测到的文本。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Logo detection</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:c0dc9385-c68c-47e3-9ef8-4abf6976fdcb" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">徽标检测</h1>

                

            

            

                

<p>视觉服务还使我们能够通过使用<kbd>logo_detection</kbd>方法来识别图像中的徽标。</p>

<p>在下面的代码中，您可以看到我们能够通过传递图像位置的 URL 来检测到<kbd>wikipedia</kbd>的徽标，如下所示:</p>

<pre>response = client.logo_detection({'source' : {'image_uri':<br/>"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b3/Wikipedia-logo-v2-<br/>en.svg/135px-Wikipedia-logo-v2-en.svg.png"},})</pre>

<p><kbd>logo_detection</kbd>方法的输出如下:</p>

<div><img src="img/6b346970-15c3-4286-8f53-ac12b3f5753c.png" style=""/></div>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Landmark detection</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:c0dc9385-c68c-47e3-9ef8-4abf6976fdcb" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">地标检测</h1>

                

            

            

                

<p>注意，在前面的代码行中，我们已经在<kbd>logo_detection</kbd>方法中指定了图像位置的 URL，并且它产生了对预测的徽标的描述，以及与之相关联的置信度得分。</p>

<p>类似地，可以使用<kbd>landmark_detection</kbd>方法检测图像中的任何地标，如下所示:</p>

<pre>response = client.landmark_detection({'source' : {'image_uri': <br/> "https://upload.wikimedia.org/wikipedia/commons/thumb/1/1d/<br/>  Taj_Mahal_%28Edited%29.jpeg/250px-Taj_Mahal_%28Edited%29.jpeg"},})</pre>

<p><kbd>landmark_detection</kbd>方法的输出如下:</p>

<div><img src="img/a58efb19-07d8-4363-9f9c-37bb2458c7b1.png" style=""/></div>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Cloud Translation API</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:c0dc9385-c68c-47e3-9ef8-4abf6976fdcb" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">云翻译 API</h1>

                

            

            

                

<p>云翻译 API 提供了一个简单的编程接口，使用最先进的神经机器翻译将任意字符串翻译成任何支持的语言。翻译 API 响应速度非常快，因此网站和应用程序可以与翻译 API 集成，以便快速、动态地将源文本从源语言翻译成目标语言(例如，从法语翻译成英语)。对于源语言未知的情况，也可以使用语言检测。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Enabling the API</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:c0dc9385-c68c-47e3-9ef8-4abf6976fdcb" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">启用 API</h1>

                

            

            

                

<p>为了能够使用谷歌云翻译服务，我们需要启用，具体操作如下:</p>

<ol>

<li>要启用 Google Cloud 翻译 API，请在控制台中搜索 API:</li>

</ol>

<div><img class="alignnone size-full wp-image-854 image-border" src="img/b9192c37-46b7-4d04-a53a-9e9018296cb1.png" style=""/></div>

<ol start="2">

<li>启用谷歌云翻译 API:</li>

</ol>

<div><img class="alignnone size-full wp-image-844 image-border" src="img/c6f06a96-ad9e-4b17-9fd2-9dc7ffa6f099.png" style=""/></div>

<ol start="3">

<li>启用翻译 API 后，下一步是创建访问 API 的凭证。但是，请注意，如果您已经为一个 API 创建了凭证，它们可以用于任何其他 API。让我们继续使用云 Shell 初始化我们的实例:</li>

</ol>

<div><img class="alignnone size-full wp-image-849 image-border" src="img/5152c3b3-6194-4621-89c8-e542b9653cea.png" style=""/></div>

<ol start="4">

<li>一旦实例启动，我们将在端口<kbd>8081</kbd>上打开 Datalab。我们提供一个路径到文件<kbd>api-key</kbd>的位置，如下所示:</li>

</ol>

<pre style="padding-left: 60px">import os<br/>os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "/content/datalab/google-api.json"</pre>

<ol start="5">

<li>通过使用下面的语句导入<kbd>translate</kbd>的各种方法:</li>

</ol>

<pre style="padding-left: 60px">from google.cloud import translate</pre>

<ol start="6">

<li>创建一个<kbd>client</kbd>对象，该对象创建到云翻译服务的连接，如下所示:</li>

</ol>

<pre style="padding-left: 60px">client = translate.Client()</pre>

<p class="mce-root">谷歌云翻译 API 支持三种方法，分别是<kbd>get_languages()</kbd>、<kbd>detect_language()</kbd>和<kbd>translate()</kbd>:</p>

<ul>

<li><kbd>client.get_languages()</kbd>方法给出了所有可用语言的列表，以及它们的简写符号，如下所示:</li>

</ul>

<div><img src="img/fff7307a-0a48-4a08-ae02-46c9dffce6fc.png" style=""/></div>

<ul>

<li><kbd>client.detect_language()</kbd>方法检测编写文本的语言:</li>

</ul>

<div><img src="img/da018e49-6ab0-40a0-a710-b1c4db37929f.png"/></div>

<p style="padding-left: 60px">注意，在前面的方法中，我们给出了两个文本——一个是西班牙语的，另一个是英语的。前面的输出表示文本的语言，以及与语言检测相关联的置信度。</p>

<ul>

<li><kbd>client.translate()</kbd>方法检测源语言并将文本翻译成英语(默认情况下)，如下所示:</li>

</ul>

<div><img src="img/53851a88-716c-4b72-9094-fe2ff2ab68db.png"/></div>

<ul>

<li><kbd>client.translate()</kbd>方法还为我们提供了一个选项来指定文本需要翻译成的目标语言，如下所示:</li>

</ul>

<div><img src="img/76b2504a-a437-471b-ba5d-01d31127dfcd.png"/></div>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Natural Language API</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:c0dc9385-c68c-47e3-9ef8-4abf6976fdcb" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">自然语言 API</h1>

                

            

            

                

<p>谷歌云自然语言 API 通过在一个易于使用的 REST API 中提供强大的机器学习模型，揭示了文本的结构和意义。您可以使用它来提取文本文档、新闻文章或博客文章中提到的人、地点、事件等信息。你还可以用它来了解社交媒体上对你的产品的看法，或者从呼叫中心或消息应用程序中的客户对话中解析意图。您可以分析请求中上传的文本，或者将其与 Google 云存储上的文档存储相集成。</p>

<p>云自然语言 API 可以通过在控制台中搜索找到，如下所示:</p>

<div><img class="alignnone size-full wp-image-848 image-border" src="img/a3f55923-2eb1-4136-8ca5-83284d52ef7e.png" style=""/></div>

<p>在结果页面中启用了云自然语言 API:</p>

<div><img class="alignnone size-full wp-image-859 image-border" src="img/6e269f60-6e7e-421e-a5c1-d11aeb89a1af.png" style=""/></div>

<p class="mce-root">与翻译 API 类似，如果已经启用了至少一个 API，我们就不必为此 API 创建凭证。</p>

<p class="mce-root">自然语言处理可以用于提取与各种文本相关联的情感。</p>

<p class="mce-root">情感分析检查给定的文本，并识别文本中的主流情感观点，以确定作者的态度是积极的、消极的还是中立的。通过<kbd>analyzeSentiment</kbd>方法进行情感分析。</p>

<p class="mce-root">在下面的例子中，让我们了解如何识别语句的情感:</p>

<ol>

<li>导入相关包:</li>

</ol>

<pre style="padding-left: 60px">from google.cloud import language</pre>

<ol start="2">

<li>初始化对应于语言服务的类:</li>

</ol>

<pre style="padding-left: 60px">client = language.LanguageServiceClient()</pre>

<p>Google 自然语言 API 支持以下方法:</p>

<ul>

<li><kbd>analyzeEntities</kbd></li>

<li><kbd>analyzeSentiment</kbd></li>

<li><kbd>analyzeEntitySentiment</kbd></li>

<li><kbd>annotateText</kbd></li>

<li><kbd>classifyText</kbd></li>

</ul>

<p>每种方法都使用一个<kbd>Document</kbd>来表示文本。让我们在下面的例子中探索一下<kbd>analyzeSentiment</kbd>方法:</p>

<pre>text="this is a good text"<br/>from google.cloud.language_v1 import types<br/>document = types.Document(<br/>        content=text,<br/>        type='PLAIN_TEXT')<br/>sentiment = client.analyze_sentiment(document).document_sentiment<br/>sentiment.score</pre>

<p>注意，我们已经将输入文本转换成了一个<kbd>Document</kbd>类型，然后分析了文档的情感。</p>

<p>情感得分的输出反映了文本是正面的概率；分数越接近 1，陈述越积极。</p>

<p>类似地，可以传递一个 HTML 文件，如下所示:</p>

<div><img src="img/f48ffe89-6faa-4933-8c74-485e248c3fa1.png" style=""/></div>

<p>通过将内容更改为<kbd>gcs_content_uri</kbd>，存储在 Google Cloud bucket 中的文件也可以被引用，如下所示:</p>

<div><img class="alignnone size-full wp-image-842 image-border" src="img/2f8354ee-51fb-4f8e-a652-096019b87500.png" style=""/></div>

<p><kbd>analyze_entities()</kbd>方法在文本中查找命名实体(即专有名称)。这个方法返回一个<kbd>AnalyzeEntitiesResponse</kbd>:</p>

<pre>document = language.types.Document(content='Michelangelo Caravaggio, Italian    painter, is known for "The Calling of Saint Matthew".'<br/>                                   ,type='PLAIN_TEXT') <br/>response = client.analyze_entities(document=document)<br/><br/>for entity in response.entities:<br/>  print('name: {0}'.format(entity.name)) </pre>

<p>上述循环的输出是文档内容中存在的命名实体，如下所示:</p>

<div><img src="img/251c1f51-1758-40d2-b0e9-e1fc626ea55e.png" style=""/></div>

<p>我们还可以通过使用<kbd>analyze_syntax</kbd>方法提取给定文本中每个单词的词性，如下所示:</p>

<ol>

<li>将文档标记为构成文本的相应单词:</li>

</ol>

<pre style="padding-left: 60px">tokens = client.analyze_syntax(document).tokens<br/>tokens[0].text.content<br/># The preceding output is u'Michelangelo'</pre>

<ol start="2">

<li>然后可以提取<kbd>token</kbd>的词性，如下所示:</li>

</ol>

<pre style="padding-left: 60px">pos_tag = ('UNKNOWN', 'ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM','PRON', 'PRT', 'PUNCT', 'VERB', 'X', 'AFFIX')<br/>for token in tokens:print(u'{}: {}'.format(pos_tag[token.part_of_speech.tag],<br/>                               token.text.content))</pre>

<p>上述代码的输出是:</p>

<div><img src="img/9abf115f-6c7d-4ac1-b8ed-4ce4059c4b33.png" style=""/></div>

<p>请注意，大多数单词都被归类到正确的词类中。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Speech-to-text API</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:c0dc9385-c68c-47e3-9ef8-4abf6976fdcb" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">语音转文本 API</h1>

                

            

            

                

<p>Google Cloud Speech API 通过在一个易于使用的 API 中应用强大的神经网络模型，使开发人员能够将音频转换为文本。API 可以识别超过 110 种语言和变体。人们可以转录用户对着应用麦克风口述的文本，通过语音实现命令和控制，或者转录音频文件，等等。</p>

<p>要启用语音转文本 API，请在控制台中进行搜索，如下所示:</p>

<div><img class="alignnone size-full wp-image-853 image-border" src="img/7751f4e4-0b32-4450-a80c-d80227d2600f.png" style=""/></div>

<p>在生成的网页中，启用 API，如下所示:</p>

<div><img class="alignnone size-full wp-image-860 image-border" src="img/b74baeec-4435-4ffb-9edc-c72f0988558f.png" style=""/></div>

<p>与前面提到的 API 类似，为一个 API 获得的凭证可以为其他 Google APIs 复制。因此，我们不必为语音转文本 API 单独创建凭证。</p>

<p>启用 API 后，让我们启动云 Shell 和 Datalab，就像我们在前面几节中所做的那样。</p>

<p>在下面的代码中，我们将一个小音频文件转录成文本:</p>

<ol>

<li>导入相关的包和 API 密钥:</li>

</ol>

<pre style="padding-left: 60px">from google.cloud import speech<br/>import os<br/>os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "/content/datalab/google-api.json"<br/>from google.cloud.speech import enums<br/>from google.cloud.speech import types</pre>

<ol start="2">

<li>调用语音服务，如下所示:</li>

</ol>

<pre style="padding-left: 60px">client = speech.SpeechClient()</pre>

<ol start="3">

<li>我们可以指定要转换的音频，如下所示:</li>

</ol>

<pre style="padding-left: 60px">audio = types.RecognitionAudio(uri='gs://kish-bucket/how_are_you.flac')</pre>

<p>注意<strong>免费无损音频编解码器</strong> ( <strong> FLAC </strong>)。</p>

<p>使用位于 https://audio.online-convert.com/convert-to-flac 的<a xmlns:epub="http://www.idpf.org/2007/ops" href="https://audio.online-convert.com/convert-to-flac" target="_blank">的转换器可以将音频文件(<kbd xmlns:epub="http://www.idpf.org/2007/ops">.wav</kbd>)转换为<kbd xmlns:epub="http://www.idpf.org/2007/ops">.flac</kbd>文件。</a></p>

<p>该文件位于我们之前创建的 bucket 中。我们指定音频配置，如下所示:</p>

<pre>config = types.RecognitionConfig(<br/>encoding=enums.RecognitionConfig.AudioEncoding.FLAC,<br/>sample_rate_hertz=16000,<br/>language_code='en-US')</pre>

<p>通过传递<kbd>audio</kbd>内容以及指定的配置来获得响应:</p>

<pre>response = client.recognize(config, audio)</pre>

<p>现在可以访问结果，如下所示:</p>

<pre>for result in response.results: <br/>  print(result)</pre>

<p>这样的输出是:</p>

<div><img src="img/82460a32-f922-4b33-a502-babcfed47d56.png" style=""/></div>

<p>当输入音频文件是短(&lt; 1 分钟)持续时间的音频时，<kbd>recognize</kbd>方法起作用。</p>

<p>如果<kbd>audio</kbd>文件持续时间较长，要使用的方法是<kbd>long_running_recognize</kbd>:</p>

<pre>operation = client.long_running_recognize(config, audio)</pre>

<p>然后可以通过指定以下内容来访问<kbd>result</kbd>:</p>

<pre>response = operation.result(timeout=90)</pre>

<p>最后，可以通过打印响应结果来获得转录和置信度，就像前面所做的那样。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Video Intelligence API</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:c0dc9385-c68c-47e3-9ef8-4abf6976fdcb" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">视频智能 API</h1>

                

            

            

                

<p>云视频智能 API 通过一个易于使用的 REST API 提取元数据，使视频变得可搜索和可发现。你现在可以搜索目录中每个视频文件的每一个瞬间。它可以快速注释存储在谷歌云存储中的视频，并帮助您识别视频中的关键实体(名词)以及它们出现的时间。</p>

<p>可以按如下方式搜索和启用云视频智能 API:</p>

<div><img class="alignnone size-full wp-image-862 image-border" src="img/fd03c537-4531-4616-b22e-ce7363923d6a.png" style=""/></div>

<div><img class="alignnone size-full wp-image-861 image-border" src="img/5a9ffecc-7966-4fd5-9ae7-f5d114eb5a1e.png" style=""/></div>

<p>我们导入所需的包并将路径添加到<kbd>api-key</kbd>，如下所示:</p>

<pre>from google.cloud import videointelligence<br/>import os<br/>os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "/content/datalab/google-api.json"<br/>from google.cloud.speech import enums<br/>from google.cloud.speech import types</pre>

<p>方法<kbd>features</kbd>使我们能够指定我们想要在视频中检测的内容类型。可用的功能如下:</p>

<div><img src="img/54d48021-a4fb-496e-8b98-10cb80940baa.png" style=""/></div>

<p>让我们继续检测视频中我们感兴趣的标签:</p>

<pre>features = [videointelligence.enums.Feature.LABEL_DETECTION]</pre>

<p>我们指定视频的<kbd>config</kbd>和上下文，如下所示:</p>

<pre>mode = videointelligence.enums.LabelDetectionMode.SHOT_AND_FRAME_MODE<br/>config = videointelligence.types.LabelDetectionConfig(<br/>    label_detection_mode=mode)<br/>context = videointelligence.types.VideoContext(<br/>    label_detection_config=config)</pre>

<p>然后视频需要从云存储中传递，如下所示:</p>

<pre>path="gs://kish-bucket/Hemanvi_video.mp4"<br/>operation = video_client.annotate_video(<br/>        path, features=features, video_context=context)</pre>

<p><kbd>annotate_video</kbd>方法的结果访问如下:</p>

<pre>result = operation.result(timeout=90)</pre>

<p>视频的注释结果可从以下网址获得:</p>

<ul>

<li>视频段级别</li>

<li>视频镜头级别</li>

<li>框式水平仪</li>

</ul>

<p>在片段级别，循环查看各个片段标签注释后，可获得如下结果:</p>

<pre>segment_labels = result.annotation_results[0].segment_label_annotations<br/>for i, segment_label in enumerate(segment_labels):<br/>    print('Video label description: {}'.format(<br/>        segment_label.entity.description))<br/>    for category_entity in segment_label.category_entities:<br/>        print('\tLabel category description: {}'.format(<br/>            category_entity.description))<br/><br/>    for i, segment in enumerate(segment_label.segments):<br/>        start_time = (segment.segment.start_time_offset.seconds +<br/>                      segment.segment.start_time_offset.nanos / 1e9)<br/>        end_time = (segment.segment.end_time_offset.seconds +<br/>                    segment.segment.end_time_offset.nanos / 1e9)<br/>        positions = '{}s to {}s'.format(start_time, end_time)<br/>        confidence = segment.confidence<br/>        print('\tSegment {}: {}'.format(i, positions))<br/>        print('\tConfidence: {}'.format(confidence))<br/>    print('\n')</pre>

<p>上述代码的输出是:</p>

<div><img src="img/9f133d48-607a-4b76-90f0-abfa9876765b.png" style=""/></div>

<p>类似地，可以如下获得射击水平的结果:</p>

<pre>shot_labels = result.annotation_results[0].shot_label_annotations<br/>for i, shot_label in enumerate(shot_labels):<br/>    print('Shot label description: {}'.format(<br/>        shot_label.entity.description))<br/>    for category_entity in shot_label.category_entities:<br/>        print('\tLabel category description: {}'.format(<br/>            category_entity.description))<br/><br/>    for i, shot in enumerate(shot_label.segments):<br/>        start_time = (shot.segment.start_time_offset.seconds +<br/>                      shot.segment.start_time_offset.nanos / 1e9)<br/>        end_time = (shot.segment.end_time_offset.seconds +<br/>                    shot.segment.end_time_offset.nanos / 1e9)<br/>        positions = '{}s to {}s'.format(start_time, end_time)<br/>        confidence = shot.confidence<br/>        print('\tSegment {}: {}'.format(i, positions))<br/>        print('\tConfidence: {}'.format(confidence))<br/>    print('\n')</pre>

<p>前面几行代码的输出是:</p>

<div><img src="img/8670e457-6af0-4c19-b37d-e62ff23ad8a2.png" style=""/></div>

<p>最后，可以如下获得帧级别的结果:</p>

<pre>frame_labels = result.annotation_results[0].frame_label_annotations<br/>for i, frame_label in enumerate(frame_labels):<br/>    print('Frame label description: {}'.format(<br/>        frame_label.entity.description))<br/>    for category_entity in frame_label.category_entities:<br/>        print('\tLabel category description: {}'.format(<br/>            category_entity.description))<br/><br/>    # Each frame_label_annotation has many frames,<br/>    # here we print information only about the first frame.<br/>    frame = frame_label.frames[0]<br/>    time_offset = (frame.time_offset.seconds +<br/>                   frame.time_offset.nanos / 1e9)<br/>    print('\tFirst frame time offset: {}s'.format(time_offset))<br/>    print('\tFirst frame confidence: {}'.format(frame.confidence))<br/>    print('\n')</pre>

<p>前面几行代码的输出是:</p>

<div><img src="img/8a83da6e-44f2-4ad7-aa58-b6284fc4791d.png" style=""/></div>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Summary</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:c0dc9385-c68c-47e3-9ef8-4abf6976fdcb" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">摘要</h1>

                

            

            

                

<p>在本章中，我们介绍了 Google 提供的主要机器学习 API:视觉、翻译、NLP、语音和视频智能。我们已经了解了每个 API 中的各种方法如何使我们能够复制深度学习的结果，而不必从头开始编码。</p>

<p> </p>





            



            

        

    </body>



</html></body></html>