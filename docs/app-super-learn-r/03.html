<html><head/><body>


	
		<title>C12624_03_ePub_Final_SZ</title>
		
	
	
		<div><h1 id="_idParaDest-118"><em class="italics"> <a id="_idTextAnchor119"/>第三章:</em></h1>
		</div>
		<div><h1 id="_idParaDest-119"><a id="_idTextAnchor120"/>监督学习简介</h1>
		</div>
		<div><h2>学习目标</h2>
			<p>本章结束时，您将能够:</p>
			<ul>
				<li class="bullets">解释监督学习和机器学习工作流程</li>
				<li class="bullets">使用和探索北京 PM2.5 数据集</li>
				<li class="bullets">解释连续和分类因变量之间的区别</li>
				<li class="bullets">在 R 中实现基本的回归和分类算法</li>
				<li class="bullets">确定监督学习和其他类型的机器学习之间的主要区别</li>
				<li class="bullets">使用监督学习算法的评估指标</li>
				<li class="bullets">执行模型诊断，以避免有偏差的系数估计和较大的标准误差</li>
			</ul>
			<p>在这一章中，我们将介绍监督学习，并用真实世界的例子演示建立机器学习模型的工作流程。</p>
		</div>
		<div><h2 id="_idParaDest-120"><a id="_idTextAnchor121"/>简介</h2>
			<p>在前面的章节中，我们探索了 R 的一些包，例如<code>dplyr</code>、<code>plyr</code>、<code>lubridate</code>和<code>ggplot2</code>，在这些包中，我们讨论了在 R 中存储和处理数据的基础。后来，在探索性数据分析(EDA)中使用了相同的思想，以了解将数据分成更小部分的方法，从数据中提取见解，并探索其他方法来更好地理解数据，然后再尝试高级建模技术。</p>
			<p>在这一章中，我们将进一步介绍机器学习的思想。在为思考机器学习中的各种算法打下广泛基础的同时，我们将详细讨论监督学习。</p>
			<p>监督学习基于被领域专家很好标记的数据。为了从图像中对猫和狗进行分类，算法首先需要看到标记为猫和狗的图像，然后根据标签学习特征。大多数拥有大量历史数据的企业是从这些数据中获取知识财富的最大受益者。如果数据是干净的，并且注释良好，监督学习可以产生高精度的预测，这与其他机器学习算法不同，其他机器学习算法通常在开始时产生较大的误差。在没有正确标签的情况下，除了能够进行探索性分析和聚类之外，很难从数据中获得任何意义。</p>
			<p>解决现实世界问题的标准组件，如预测贷款违约(是/否)、工厂制造机器故障(是/否)、无人驾驶汽车中的物体检测(道路、汽车、信号)、预测股票市场价格(数字)是一组输入(特征)和给定输出(标签)，通常从历史数据中获得。当我们预测定量产出时，我们称之为<strong class="bold">回归</strong>，当我们预测定性产出时，我们称之为<strong class="bold">分类</strong>。</p>
			<h2 id="_idParaDest-121"><a id="_idTextAnchor122"/>北京 PM2.5 数据集汇总</h2>
			<p>在许多国家的城市和农村地区，主要污染物细颗粒物是许多人类健康风险的原因，也影响气候变化。特别是 PM2.5，定义为空气动力学直径小于 2.5 米的空气传播颗粒，是大气颗粒物的主要类别。各种研究已经将 PM2.5 与严重的健康问题联系起来，如心脏病发作和肺部疾病。本节中的表格显示了大气颗粒物的类型及其尺寸分布，单位为微米。</p>
			<p>在本章和其余章节中，我们将使用研究论文《评估北京的 PM2.5 污染:严重性、天气影响、亚太经合组织和冬季供暖》的作者发布的数据集，其中他们使用了在位于 116.47 E，39.95 N 的美国驻北京大使馆获得的每小时 PM2.5 读数，以及从 weather.nocrew.org 获得的在<strong class="bold">北京首都国际机场</strong>(<strong class="bold">【BCIA】</strong>)的每小时气象测量值。他们的研究声称首次将 PM2.5 和中国 PM2.5 污染的长期气象数据结合起来。下表描述了数据集中的属性:</p>
			<div><div><img src="img/C12624_03_01.jpg" alt="Figure 3.1: Attributes in Beijing's PM2.5 dataset.&#13;&#10;"/>
				</div>
			</div>
			<h6>图 3.1:北京 PM2.5 数据集中的属性。</h6>
			<h3 id="_idParaDest-122"><a id="_idTextAnchor123"/>练习 40:探索数据</h3>
			<p>在本练习中，我们将学习每个属性的样本值的数据结构，并使用<code>summary</code>函数。我们将看到数字变量的五个数字摘要统计。</p>
			<p>执行以下步骤来完成本练习:</p>
			<ol>
				<li>首先，使用以下命令将北京 PM2.5 数据集读入 PM25 DataFrame 对象:<pre>PM25 &lt;- read.csv("https://raw.githubusercontent.com/TrainingByPackt/Applied-Supervised-Learning-with-R/master/Lesson03/PRSA_data_2010.1.1-2014.12.31.csv")</pre></li>
				<li>Next, print the structure of data with sample values using the <code>str</code> command:<pre>str(PM25)</pre><p>前面命令的输出如下:</p><pre>'data.frame':	43824 obs. of  13 variables:
 $ No   : int  1 2 3 4 5 6 7 8 9 10 ...
 $ year : int  2010 2010 2010 2010 2010 2010 2010 2010 2010 2010 ...
 $ month: int  1 1 1 1 1 1 1 1 1 1 ...
 $ day  : int  1 1 1 1 1 1 1 1 1 1 ...
 $ hour : int  0 1 2 3 4 5 6 7 8 9 ...
 $ pm2.5: int  NA NA NA NA NA NA NA NA NA NA ...
 $ DEWP : int  -21 -21 -21 -21 -20 -19 -19 -19 -19 -20 ...
 $ TEMP : num  -11 -12 -11 -14 -12 -10 -9 -9 -9 -8 ...
 $ PRES : num  1021 1020 1019 1019 1018 ...
 $ cbwd : Factor w/ 4 levels "cv","NE","NW",..: 3 3 3 3 3 3 3 3 3 3 ...
 $ Iws  : num  1.79 4.92 6.71 9.84 12.97 ...
 $ Is   : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Ir   : int  0 0 0 0 0 0 0 0 0 0 ...</pre><h4>注意</h4><p class="callout">观察数据集包含<code>43824</code>观察值和 13 个属性。注意数据集包含 2010 年到 2014 年的数据。pm2.5、温度、压力、组合风向、累积风速、累积降雪小时数和累积降雨小时数的值在一天中的每个小时进行汇总。</p></li>
				<li>Now, let's show the summary statistics of the dataset:<pre>summary(PM25)</pre><p>输出如下所示:</p><pre>       No             year          month             day             hour           pm2.5       
 Min.   :    1   Min.   :2010   Min.   : 1.000   Min.   : 1.00   Min.   : 0.00   Min.   :  0.00  
 1st Qu.:10957   1st Qu.:2011   1st Qu.: 4.000   1st Qu.: 8.00   1st Qu.: 5.75   1st Qu.: 29.00  
 Median :21912   Median :2012   Median : 7.000   Median :16.00   Median :11.50   Median : 72.00  
 Mean   :21912   Mean   :2012   Mean   : 6.524   Mean   :15.73   Mean   :11.50   Mean   : 98.61  
 3rd Qu.:32868   3rd Qu.:2013   3rd Qu.:10.000   3rd Qu.:23.00   3rd Qu.:17.25   3rd Qu.:137.00  
 Max.   :43824   Max.   :2014   Max.   :12.000   Max.   :31.00   Max.   :23.00   Max.   :994.00  
                                                                                 NA's   :2067    
      DEWP              TEMP             PRES      cbwd            Iws               Is          
 Min.   :-40.000   Min.   :-19.00   Min.   : 991   cv: 9387   Min.   :  0.45   Min.   : 0.00000  
 1st Qu.:-10.000   1st Qu.:  2.00   1st Qu.:1008   NE: 4997   1st Qu.:  1.79   1st Qu.: 0.00000  
 Median :  2.000   Median : 14.00   Median :1016   NW:14150   Median :  5.37   Median : 0.00000  
 Mean   :  1.817   Mean   : 12.45   Mean   :1016   SE:15290   Mean   : 23.89   Mean   : 0.05273  
 3rd Qu.: 15.000   3rd Qu.: 23.00   3rd Qu.:1025              3rd Qu.: 21.91   3rd Qu.: 0.00000  
 Max.   : 28.000   Max.   : 42.00   Max.   :1046              Max.   :585.60   Max.   :27.00000  
                  
       Ir         
 Min.   : 0.0000  
 1st Qu.: 0.0000  
 Median : 0.0000  
 Mean   : 0.1949  
 3rd Qu.: 0.0000  
 Max.   :36.0000</pre></li>
			</ol>
			<p>下图是大气颗粒物尺寸分布(以微米为单位)的图示:</p>
			<div><div><img src="img/C12624_03_02.jpg" alt="Figure 3.2: Types and size distribution (in micrometers) of atmospheric particulate matter.&#13;&#10;"/>
				</div>
			</div>
			<h6>图 3.2:大气颗粒物的类型和尺寸分布(微米)。</h6>
			<h6>来源:https://en . Wikipedia . org/wiki/File:Airborne-particulate-size-chart . SVG</h6>
			<h4>注意</h4>
			<p class="callout">发表在<strong class="bold">胸科疾病杂志</strong> ( <strong class="bold"> JTD </strong>)上的文章《PM2.5 对人体呼吸系统的影响》的作者讨论了空气污染与呼吸系统疾病的关联。他们提供了一个全面的数据驱动的方法来解释导致这些呼吸系统疾病的因素。北京受到了特别关注，那里的研究人员对 PM2.5 上升的不利影响进行了广泛研究，并已成为世界各地各种气候变化论坛的主流讨论点。你可以在 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4740125/.的文章中找到更多的细节</p>
			<h2 id="_idParaDest-123"><a id="_idTextAnchor124"/>回归和分类问题</h2>
			<p>在我们的日常生活中，分类和回归问题随处可见。https://weather.com 下雨的可能性，我们的电子邮件被过滤到垃圾邮件邮箱和收件箱，我们的个人和家庭贷款被接受或拒绝，决定选择我们的下一个度假目的地，探索购买新房子的选择，获得短期和长期利益的投资决策，从亚马逊购买下一本书；这个清单还在继续。今天我们周围的世界越来越多地由帮助我们做出选择的算法来运行(这并不总是一件好事)。</p>
			<p>正如在<em class="italics">第二章</em>、<em class="italics">对数据的探索性分析</em>中所讨论的，我们将使用<strong class="bold">明托金字塔</strong>原理，称为<strong class="bold">情境-复杂-问题</strong> ( <strong class="bold"> SCQ </strong>)来定义我们的问题陈述。下表显示了 SCQ 解决北京 PM2.5 问题的方法:</p>
			<div><div><img src="img/C12624_03_03.jpg" alt="Figure 3.3: Applying SCQ on Beijing's PM2.5 problem.&#13;&#10;"/>
				</div>
			</div>
			<h6>图 3.3:SCQ 在北京 PM2.5 问题上的应用。</h6>
			<p>现在，在上表描述的 SCQ 构造中，我们可以进行简单的相关性分析，以确定影响 PM2.5 水平的因素，或者创建一个预测问题(预测是指找到一个从输入变量映射到输出的近似函数)，使用所有因素来估计 PM2.5 水平。为术语清晰起见，我们将因子称为输入变量。然后，PM2.5 成为因变量(通常称为输出变量)。因变量可以是分类变量，也可以是连续变量。</p>
			<p>例如，在将电子邮件分类成<strong class="bold">垃圾邮件</strong> / <strong class="bold">非垃圾邮件</strong>的问题中，因变量是分类变量。下表强调了回归和分类问题之间的一些关键差异:</p>
			<div><div><img src="img/C12624_03_04.jpg" alt="Figure 3.4: Difference between regression and classification problems.&#13;&#10;"/>
				</div>
			</div>
			<h6>图 3.4:回归和分类问题的区别。</h6>
			<h2 id="_idParaDest-124"><a id="_idTextAnchor125"/>机器学习工作流程</h2>
			<p>为了演示建立预测模型(机器学习或监督学习)的端到端过程，我们创建了一个易于理解的工作流。第一步是设计问题，然后获取和准备数据，这导致为训练和评估编写模型代码，最后部署模型。在本章的范围内，我们将把模型解释保持在最低限度，因为它将在第 4 章和第 5 章中再次详细讨论。</p>
			<p>下图描述了构建预测模型所需的工作流，从准备数据到部署模型:</p>
			<div><div><img src="img/C12624_03_05.jpg" alt="Figure 3.5: Machine learning workflow.&#13;&#10;"/>
				</div>
			</div>
			<h6>图 3.5:机器学习工作流程。</h6>
			<h3 id="_idParaDest-125"><a id="_idTextAnchor126"/>设计问题</h3>
			<p>一旦我们确定了工作的领域，就可以对问题的设计进行头脑风暴。其思路是首先将问题定义为回归或分类问题。一旦完成，我们就选择正确的目标变量，并识别特征。目标变量很重要，因为它决定了培训将如何进行。监督学习算法将目标变量保持在中心，同时试图从给定的特征集中找到模式。</p>
			<h3 id="_idParaDest-126"><a id="_idTextAnchor127"/>来源和准备数据</h3>
			<p>数据收集和准备是一项艰苦的工作，主要是在数据来源多样和众多的情况下。对于每个数据源，挑战是不同的，因此处理它所需的时间也不同。具有表格数据的数据源最容易处理，前提是它们不包含大量垃圾信息，而文本数据由于其自由流动的特性而最难清理。</p>
			<h3 id="_idParaDest-127"><a id="_idTextAnchor128"/>对模型进行编码</h3>
			<p>一旦数据准备就绪，我们就开始选择合适的模型。最常见的情况是，专家首先使用一个基线模型，使用输入特征和目标变量来衡量算法的预测能力。然后，人们可以直接尝试最先进的算法，或者决定采用试错法(尝试使用所有可能的模型)。一个人必须明白，模型没有对错之分，一切都取决于数据。编码时，数据随机分为训练和测试。编写代码是为了在训练数据集上训练模型，并对测试数据进行评估。这确保了模型在现实世界中部署时不会表现不佳。</p>
			<h3 id="_idParaDest-128"><a id="_idTextAnchor129"/>培训和评估</h3>
			<p>模型评估是模型的重要组成部分，决定了模型在实践中的可用性。基于一组给定的模型评估指标，我们需要在所有的试验和错误之后，决定最佳的模型。在每次迭代中，都会计算 R 平方值、准确度、精度和 F 值等指标。通常，整个数据被分为训练和测试数据(通常还包括验证集的第三部分)。该模型根据训练数据进行训练，并根据测试数据进行测试。这种分离确保了模型不做任何机械学习。用更专业的术语来说，模型没有过度拟合(在本章的<em class="italics">评估指标</em>一节中有更多关于这一点的内容)。通常，在工作流的这个阶段，人们可以决定返回并包含更多的变量，训练模型，并重新部署。重复该过程，直到模型的准确性(或其他重要指标)达到稳定水平。</p>
			<p>我们使用一个类似 R 中的<code>sample()</code>的随机数生成器函数将数据随机分成不同的部分，就像下一个练习 2 的步骤 2 中所做的那样。</p>
			<h3 id="_idParaDest-129"><a id="_idTextAnchor130"/>练习 41:创建由北京 PM2.5 数据集随机生成的训练和测试数据集</h3>
			<p>在本练习中，我们将从北京 PM2.5 数据集创建一个随机生成的训练和测试数据集。我们将重用在前面的练习中创建的<code>PM25</code>对象。</p>
			<p>执行以下步骤:</p>
			<ol>
				<li value="1">创建一个<code>num_index</code>变量，并将其设置为与北京 PM2.5 数据集中的观测值相等的值:<pre>num_index &lt;- nrow(PM25)</pre></li>
				<li>使用<code>sample()</code>功能，随机选择 70%的<code>num_index</code>值，并存储在<code>train_index</code> : <pre>train_index &lt;- sample(1:num_index, 0.7*nrow(PM25))</pre>中</li>
				<li>使用<code>train_index</code>从北京 PM2.5 数据集中随机选择一个行子集，并将它们存储在名为<code>PM25_Train</code> : <pre>PM25_Train &lt;- PM25[train_index,]</pre>的数据帧中</li>
				<li>将剩余的观察值存储到名为<code>PM25_Test</code> : <pre>PM25_Test &lt;- PM25[-train_index,]</pre>的数据帧中</li>
			</ol>
			<p>本练习展示了一个创建训练和测试集的简单示例。用于训练和测试的随机选择的集合确保模型没有偏见，并且在用于真实世界的看不见的数据之前，从所有可能的例子中学习得很好。</p>
			<h3 id="_idParaDest-130"><a id="_idTextAnchor131"/>部署模型</h3>
			<p>一旦选择了最佳模型，下一步就是让业务应用程序使用模型输出。该模型被托管为一个<strong class="bold">代表性状态转移</strong> ( <strong class="bold"> REST </strong> ) API。这些 API 是一种将 web 应用程序作为端点来托管的方法，该端点监听任何模型调用请求，并且通常返回一个 JSON 对象作为响应。</p>
			<p>模型的部署正在成为行业中所有机器学习项目的重要组成部分。一个不可部署的模型对一个公司来说是没有好处的，也许仅仅是为了研发的目的。越来越多的专业人员专门从事模型部署，这有时是一个冗长而复杂的过程。为了给模型部署以应有的重视，我们给了它一个专门的章节，那就是<em class="italics">第八章</em>、<em class="italics">模型部署</em>。</p>
			<h2 id="_idParaDest-131"><a id="_idTextAnchor132"/>回归</h2>
			<p>现在我们已经看到了机器学习的工作流程，我们将采用两种广泛使用的机器学习算法:回归和分类；两者都采用监督学习来训练模型。这本书的整个主题都围绕着这两种类型的算法。北京 PM2.5 数据集将被广泛用于演示这两种类型。数据集将有助于理解如何将回归问题转化为分类问题，反之亦然。</p>
			<h3 id="_idParaDest-132"><a id="_idTextAnchor133"/>简单和多元线性回归</h3>
			<p>回归是分析学和计量经济学中最有用和最基本的工具之一(经济学的一个分支，涉及使用数学方法，尤其是统计学，来描述经济系统)。在许多方面，现代机器学习植根于统计学，人们可以将这主要归功于弗朗西斯·高尔顿爵士的工作。高尔顿是英国维多利亚时代的统计学家和学者，对遗传学、心理学和人类学等领域有浓厚的兴趣和专业知识。他是第一个应用统计学方法研究人类行为和智力的人。值得注意的是，他的出版物《遗传地位回归平庸》中有许多基于回归的深刻发现。</p>
			<p>在本节中，我们将使用北京数据集简要分析影响 PM2.5 水平的各种因素。特别是，露点、温度、风速和压力等变量对 PM2.5 的影响将被探究。</p>
			<h3 id="_idParaDest-133"><a id="_idTextAnchor134"/>线性回归模型中的假设</h3>
			<p>由于回归从应用统计学中借用了许多概念来建模数据，因此它带有许多假设。人们不应该对任何数据集或问题应用回归算法。在建立任何模型之前，让我们检查一下线性回归的假设。</p>
			<p>下表显示了这些假设以及我们如何统计检验线性回归模型是否符合假设。该表还显示了违反假设时的一些纠正措施。我们将对这些假设进行详细讨论，并进行诊断分析，以在第 4 章、<em class="italics">回归中更详细地识别违规。</em></p>
			<div><div><img src="img/C12624_03_06.jpg" alt="Figure 3.6: Various assumptions in a linear regression model (Part 1).&#13;&#10;"/>
				</div>
			</div>
			<h6>图 3.6:线性回归模型中的各种假设(第一部分)。</h6>
			<div><div><img src="img/C12624_03_07.jpg" alt="Figure 3.7: Various assumptions in a linear regression model (Part 2).&#13;&#10;"/>
				</div>
			</div>
			<h6>图 3.7:线性回归模型中的各种假设(第二部分)。</h6>
			<h2 id="_idParaDest-134"><a id="_idTextAnchor135"/>探索性数据分析(EDA)</h2>
			<p>建立回归模型需要深入分析目标变量和输入变量之间的模式和关系。北京的数据集提供了可能影响大气中 PM2.5 水平的不同环境因素的数量级。</p>
			<h3 id="_idParaDest-135"><a id="_idTextAnchor136"/>练习 42:探索北京 PM2.5 数据集的 PM2.5、DEWP、温度和压力变量的时间序列视图</h3>
			<p>在本练习中，我们将把<code>pm2.5</code>、<code>DEWP</code>、<code>TEMP</code>和<code>PRES</code>变量可视化在一个时间序列图中，并观察这些变量中可能出现的任何模式。</p>
			<p>执行以下步骤来完成练习:</p>
			<ol>
				<li value="1">导入系统中所有需要的库:<pre>library(dplyr)
library(lubridate)
library(tidyr)
library(grid)
library(ggplot2)</pre></li>
				<li>接下来，使用名为<code>ymd_h</code> : <pre>PM25$datetime &lt;- with(PM25, ymd_h(sprintf('%04d%02d%02d%02d', year, month, day,hour)))</pre>的<code>lubridate</code>包函数将年、月和小时转换成日期时间</li>
				<li>使用以下命令绘制所有年份的 PM2.5、温度、DEWP 和压力:<pre>plot_pm25 &lt;- PM25 %&gt;%
  select(datetime, pm2.5) %&gt;%
  na.omit() %&gt;%
  ggplot() + 
  geom_point(aes(x = datetime, y = pm2.5), size = 0.5, alpha = 0.75) +
  ylab("PM2.5")
plot_TEMP &lt;- PM25 %&gt;%
  select(datetime, TEMP) %&gt;%
  na.omit() %&gt;%
  ggplot() + 
  geom_point(aes(x = datetime, y = TEMP), size = 0.5, alpha = 0.75) +
  ylab("TEMP")
plot_DEWP &lt;- PM25 %&gt;%
  select(datetime, DEWP) %&gt;%
  na.omit() %&gt;%
  ggplot() + 
  geom_point(aes(x = datetime, y = DEWP), size = 0.5, alpha = 0.75) +
  ylab("DEWP")
plot_PRES &lt;- PM25 %&gt;%
  select(datetime, PRES) %&gt;%
  na.omit() %&gt;%
  ggplot() + 
  geom_point(aes(x = datetime, y = PRES), size = 0.5, alpha = 0.75) +
  ylab("PRES")</pre></li>
				<li>Now, use the following command to plot the graphs:<pre>grid.newpage()
grid.draw(rbind(ggplotGrob(plot_pm25), ggplotGrob(plot_TEMP),ggplotGrob(plot_DEWP),ggplotGrob(plot_PRES), size = "last"))</pre><p>剧情如下:</p></li>
			</ol>
			<div><div><img src="img/C12624_03_08.jpg" alt="Figure 3.8: Scatterplot showing the trend and seasonality of environmental factors like temperature, dew point, and pressure, along with PM2.5 levels in Beijing from 2010 to 2014 end.&#13;&#10;"/>
				</div>
			</div>
			<h6>图 3.8:散点图显示了从 2010 年到 2014 年底北京的温度、露点和压力等环境因素以及 PM2.5 水平的趋势和季节性。</h6>
			<p>在本练习中，我们首先展示来自数据集的<code>PM2.5</code>、<code>DEWP</code>、<code>TEMP</code>和<code>PRES</code>变量的时间序列视图，并观察其模式。如图<em class="italics">图 3.8 </em>所示，观察到明显的季节性<code>DEWP</code>、<code>TEMP</code>、<code>PRES</code>显示季节性(同一模式每 12 个月重复一次)，PM2.5 似乎具有随机模式。这是一个早期迹象，表明我们不太可能看到这三个变量对 PM2.5 的任何影响。但是，让我们使用相关图进一步探索以确定这一假设，并观察变量之间是否存在任何关系。</p>
			<h3 id="_idParaDest-136"><a id="_idTextAnchor137"/>练习 43:进行相关性分析</h3>
			<p>在本练习中，我们将进行相关性分析，以研究各种因素之间的关系强度。</p>
			<p>执行以下步骤来完成练习:</p>
			<ol>
				<li value="1">使用以下命令将<code>corrplot</code>包导入系统:<pre>library(corrplot)</pre></li>
				<li>现在，创建一个新对象，并将所需的值从<code>PM25</code>存储到其中:<pre>corr &lt;- cor(PM25[!is.na(PM25$pm2.5),c("pm2.5","DEWP","TEMP","PRES","Iws","Is","Ir")])</pre></li>
				<li>Use the <code>corrplot</code> package to display the graphical representation of a correlation matrix:<pre>corrplot(corr)</pre><p>剧情如下:</p></li>
			</ol>
			<div><div><img src="img/C12624_03_09.jpg" alt="Figure 3.9: Correlation between all the pairs of variables in the Beijing dataset.&#13;&#10;"/>
				</div>
			</div>
			<h6>图 3.9:北京数据集中所有变量对之间的相关性。</h6>
			<p>首先，我们计算所有变量之间的相关性。由此得出的相关图显示，PM2.5 和其他变量之间似乎没有很强的相关性。然而，<code>PM2.5</code>和<code>DEWP</code>、<code>TEMP</code>和<code>Iws</code>显示了一些轻微的相关性，这表明了一些关系。这不应该令人惊讶，因为我们在<em class="italics">图 3.8 </em>中看到，虽然三个变量遵循季节性趋势，但 PM2.5 似乎更随机。请注意，我们没有对数据集进行任何处理或转换；这些发现直接来自我们的第一层次分析。我们将在后面的第四章、<em class="italics">回归</em>中详细介绍。现在，让我们用散点图来形象化变量之间的关系。</p>
			<h3 id="_idParaDest-137"><a id="_idTextAnchor138"/>练习 44:绘制散点图，探讨 PM2.5 水平与其他因素之间的关系</h3>
			<p>在本练习中，我们将使用散点图来探究<code>pm2.5</code>水平和其他因素之间的关系。我们想看看是否会出现任何有趣的模式或关系。散点图是对变量之间的关系进行探索性分析的一种简单而有效的可视化方法。</p>
			<p>执行以下步骤来完成练习:</p>
			<ol>
				<li value="1">将<code>ggplot2</code>包导入您的系统:<pre>library(ggplot2)</pre></li>
				<li>Plot the scatterplot between <code>DEWP</code> and <code>PM2.5</code>, with the <code>month</code> variable used for color:<pre>ggplot(data = PM25, aes(x = DEWP, y = pm2.5, color = month)) +  geom_point() +  geom_smooth(method='auto',formula=y~x, colour = "red", size =1.5)</pre><p>散点图如下:</p><div><img src="img/C12624_03_10.jpg" alt="Figure 3.10: Scatterplot showing the relationship between DEWP and PM2.5 levels.&#13;&#10;"/></div><h6>图 3.10:显示 DEWP 和 PM2.5 水平之间关系的散点图。</h6></li>
				<li>Plot the scatterplot between <code>TEMP</code> and <code>PM2.5</code>, with the <code>month</code> variable used for color:<pre>ggplot(data = PM25, aes(x = TEMP, y = pm2.5, color = month)) +  geom_point() +  geom_smooth(method='auto',formula=y~x, colour = "red", size =1.5)</pre><p>散点图如下:</p><div><img src="img/C12624_03_11.jpg" alt="Figure 3.11: Scatterplot showing the relationship between TEMP and PM2.5 levels.&#13;&#10;"/></div><h6>图 3.11:显示温度和 PM2.5 水平之间关系的散点图。</h6></li>
				<li>Create a scatterplot between <code>DEWP</code> and <code>PM2.5</code>, with an hour of the day used for color and separate views for months of the year:<pre>ggplot(data = PM25, aes(x = DEWP, y = pm2.5, color = hour)) +  geom_point() +  geom_smooth(method='auto',formula=y~x, colour = "red", size =1) +  facet_wrap(~ month, nrow = 4)</pre><p>散点图如下:</p></li>
			</ol>
			<div><div><img src="img/C12624_03_12.jpg" alt="Figure 3.12: Scatterplot showing the relationship between DEWP and PM2.5 split by month of the year.&#13;&#10;"/>
				</div>
			</div>
			<h6>图 3.12:显示 DEWP 和 PM2.5 之间关系的散点图，按一年中的月份划分。</h6>
			<p>为了测量变量之间的一些关系，我们使用了一个在<code>PM2.5</code>和<code>DEWP</code>之间的散点图和一条拟合线。注意，在代码中，我们向<code>geom_smooth()</code>传递了一个参数，即<code>method = "auto"</code>，它会根据数据自动决定使用哪个模型来拟合一行。如<em class="italics">图 3.10 </em>所示，直线不是直线。<code>geom_smooth</code>法选择<code>TEMP</code>和<code>PM2.5</code>图，如图<em class="italics">图 3.11 </em>所示。然而，我们可以更进一步，按月分割散点图，如图<em class="italics">图 3.12 </em>所示。这表明存在线性关系，但它高度依赖于季节。比如四月(用整数<code>4</code>表示)<code>DEWP</code>和<code>PM2.5</code>有近乎完美的直线拟合。我们将在<em class="italics">第 4 章</em>、<em class="italics">回归</em>中进一步详述这一讨论。</p>
			<p>因此，我们已经看到了一些违反假设的情况，以及环境因素和 PM2.5 之间缺乏强相关性。然而，似乎还有一些进一步研究的空间。在这个关于监督学习的介绍性章节中，我们将只关注基于我们的机器学习工作流程的方法。</p>
			<h4>注意</h4>
			<p class="callout">想了解更多关于 GAM 的内容，可以查阅这个文档:https://www . stat . CMU . edu/~ cshalizi/uADA/12/lectures/ch13 . pdf。</p>
			<h3 id="_idParaDest-138"><a id="_idTextAnchor139"/>活动 5:绘制 PRES 和 PM2.5 之间的散点图，按月份划分</h3>
			<p>在本活动中，我们将在<code>DWEP</code>和<code>PM2.5</code>之间创建一个散点图。通过这个活动，我们将学习使用<code>facet_wrap()</code>功能在<code>ggplot()</code>之上创建一个层，用于将散点图的可视化拆分为每个月，从而有助于观察任何季节性模式。</p>
			<p>执行以下步骤来完成活动:</p>
			<ol>
				<li value="1">在<code>ggplot</code>中，用<code>PRES</code>变量分配<code>a()</code>方法的组件。</li>
				<li>在<code>geom_smooth()</code>方法的下一层，设置<code>colour = "blue"</code>进行微分。</li>
				<li>Finally, in the <code>facet_wrap()</code> layer, use the <code>month</code> variable to draw a separate segregation for each month.<p>剧情如下:</p></li>
			</ol>
			<div><div><img src="img/C12624_03_13.jpg" alt="Figure 3.13: Scatterplot showing the relationship between PRES and PM2.5.&#13;&#10;"/>
				</div>
			</div>
			<h6>图 3.13:显示 PRES 和 PM2.5 之间关系的散点图。</h6>
			<h4>注意</h4>
			<p class="callout">这项活动的解决方案可在第 445 页找到。</p>
			<h3 id="_idParaDest-139"><a id="_idTextAnchor140"/>模型构建</h3>
			<p>我们已经简要地探讨了<code>PM2.5</code>和几个因素如<code>TEMP</code>和<code>DEWP</code>之间的关系。对于其他变量，如<code>PRES</code>、<code>Iwd</code>等，也可以进行同样的分析。在本节中，让我们创建一个线性模型。(即使我们知道选择的模型不是最好的，我们也会毫不犹豫地运行模型。机器学习中的试错法总是建立事实的最佳方式。)</p>
			<p>一般来说，线性回归模拟输入变量(自变量)和目标变量(因变量或解释变量)之间的线性关系。如果我们有一个解释变量，它被称为<strong class="bold">简单线性回归</strong>，如果有一个以上的解释变量，它被称为<strong class="bold">多元线性回归</strong>。以下等式是带有<em class="italics"> p </em>解释变量和<em class="italics"> n </em>观测值的线性回归或线性预测函数的数学表示:</p>
			<div><div><img src="img/C12624_03_20.jpg" alt=""/>
				</div>
			</div>
			<p>这里，每个<img src="img/C12624_03_21.png" alt="A picture containing furniture, table, seat, stool&#10;&#10;Description automatically generated"/>是<img src="img/C12624_03_22.png" alt=""/>的列值(解释变量)的向量，<img src="img/C12624_03_23.png" alt="A picture containing furniture&#10;&#10;Description automatically generated"/>是未知参数或系数。<img src="img/C12624_03_24.png" alt="A picture containing furniture, seat&#10;&#10;Description automatically generated"/>使该方程适用于简单线性回归。有许多算法可以将这个函数拟合到数据上。最流行的是<strong class="bold">普通最小二乘</strong> ( <strong class="bold"> OLS </strong>)。我们将在下一章回归中详细讨论 OLS。</p>
			<p>另一种思考<img src="img/C12624_03_25.png" alt="A picture containing furniture&#10;&#10;Description automatically generated"/>的方式是，它是一个线性预测函数，尽可能地拟合<img src="img/C12624_03_26.png" alt=""/>—维度空间中的观察值，最小化残差平方和(目标值的实际值与预测值的差异)。</p>
			<p>在下面的练习中，我们将跳过将数据集分为训练和测试，因为我们仍处于探索阶段，尚未决定正式进行建模练习。(我们将在下一章谈到这一点。)我们将使用 R 中的<code>lm()</code>方法来构建线性模型。同样，在下一章会有更多的细节。此时，注意到<code>lm()</code>使用一个或多个输入变量将目标变量拟合成直线就足够了。在简单的线性回归中，我们只使用一个变量来拟合直线，而在多元线性回归中，我们可以使用多个变量。</p>
			<h3 id="_idParaDest-140"><a id="_idTextAnchor141"/>练习 45:探索简单和多元回归模型</h3>
			<p>在本练习中，我们将探索简单和多元回归模型。</p>
			<p>执行以下步骤来完成练习:</p>
			<ol>
				<li value="1">将所需的库和包导入 R-Studio。</li>
				<li>接下来，创建一个名为<code>simple_PM25_linear_model</code>的 DataFrame 对象，并使用<code>lm()</code>方法构建一个线性模型:<pre>simple_PM25_linear_model &lt;- lm(pm2.5 ~ DEWP, data = PM25)</pre></li>
				<li>Print the summary of the object using the summary method, as illustrated here:<pre>summary(simple_PM25_linear_model)</pre><p>输出如下所示:</p><pre>Call:
lm(formula = pm2.5 ~ DEWP, data = PM25)
Residuals:
    Min      1Q  Median      3Q     Max 
-115.47  -61.26  -28.75   33.83  923.54 
Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 96.69984    0.44705  216.31   &lt;2e-16 ***
DEWP         1.09325    0.03075   35.55   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
Residual standard error: 90.69 on 41755 degrees of freedom
  (2067 observations deleted due to missingness)
Multiple R-squared:  0.02939,	Adjusted R-squared:  0.02936 
F-statistic:  1264 on 1 and 41755 DF,  p-value: &lt; 2.2e-16</pre></li>
				<li>接下来，创建另一个 DataFrame 对象，并使用<code>lm()</code>方法构建一个线性模型:<pre>multiple_PM25_linear_model &lt;- lm(pm2.5 ~ DEWP+TEMP+Iws, data = PM25)</pre></li>
				<li>Print the summary of the model object using the <code>summary</code> function:<pre>summary(multiple_PM25_linear_model)</pre><p>输出如下所示:</p><pre>A)
______________________________________________________________
Call:
lm(formula = pm2.5 ~ DEWP + TEMP + Iws, data = PM25)
Residuals:
    Min      1Q  Median      3Q     Max 
-149.02  -53.74  -16.61   34.14  877.82 
______________________________________________________________
B)
______________________________________________________________
Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 161.151207   0.768727  209.63   &lt;2e-16 ***
DEWP          4.384196   0.051159   85.70   &lt;2e-16 ***
TEMP         -5.133511   0.058646  -87.53   &lt;2e-16 ***
Iws          -0.274337   0.008532  -32.15   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
______________________________________________________________
C)
______________________________________________________________
Residual standard error: 81.51 on 41753 degrees of freedom
  (2067 observations deleted due to missingness)
Multiple R-squared:  0.216,	Adjusted R-squared:  0.2159 
F-statistic:  3834 on 3 and 41753 DF,  p-value: &lt; 2.2e-16
______________________________________________________________</pre></li>
			</ol>
			<h3 id="_idParaDest-141"><a id="_idTextAnchor142"/>模型解释</h3>
			<p>现在，基于简单和多元线性回归模型的先前输出，让我们试着理解输出的每个部分意味着什么。在这本书的这个节骨眼上，知道每一部分的意思就足够了；我们将在第四章、<em class="italics">回归</em>中讨论结果。</p>
			<ul>
				<li>第<code>lm()</code>部分方法，包含因变量和自变量，用符号<code>~</code>表示为公式。这类似于我们的线性预测函数。在简单的回归模型中，只有一个变量——<code>DEWP</code>——而在多元模型中，有<code>DEWP</code>、<code>TEMP</code>和<code>Iws</code>。您还可以看到残差的五个汇总统计数据(最小值、第一个四分位数、中值、第三个四分位数和最大值)。这表示预测值与实际值的差距。</li>
				<li>进入我们的预测方程，我们将得到预测。名为<code>Std</code>的栏目。误差是估计值的标准误差。取<code>Estimate</code>和<code>Std</code>的比值得到 t 值。误差，p 值突出了估计的统计显著性。视觉线索，也就是<code>*</code>和。符号基于 p 值。小于 0.001 的值得到一个三星，而介于 0.1 和 0.05 之间的值得到一个<code>.</code>(点)。三星表示最好的情况，对应于自变量的估计值在预测(或解释)因变量时是重要且有用的。换句话说，p 值有助于确定回归模型相对于空模型(只是因变量的平均值)的显著性。</li>
				<li>Part <strong class="bold">C</strong>:<p>这一部分是展示模型功效的部分。要观察的最重要的值是 R 平方值和调整后的 R 平方值，它们是统计测量值，表示回归模型中由自变量解释的因变量的变化百分比。</p></li>
			</ul>
			<p>浏览本章中关于评估指标的部分，了解模型在 R 平方和调整后的 R 平方指标上的表现。</p>
			<h2 id="_idParaDest-142"><a id="_idTextAnchor143"/>分类</h2>
			<p>与回归算法类似，分类也从因变量或目标变量中学习，并使用所有预测变量或自变量来找到正确的模式。主要的区别来自于这样一个想法，在分类中，目标变量是分类的，而在回归中，它是数字的。在本节中，我们将使用北京 PM2.5 数据集介绍逻辑回归来演示这一概念。</p>
			<h3 id="_idParaDest-143"><a id="_idTextAnchor144"/>逻辑回归</h3>
			<p><strong class="bold">逻辑回归</strong>是用于二元分类的最有利的白盒模型。白盒模型被定义为提供对为预测所做的整个推理的可视性的模型。对于所做的每一个预测，我们可以利用模型的数学方程，并解码所做预测的原因。还有一组完全是黑箱的分类模型，也就是说，我们决不能理解模型所利用的预测的推理。在我们只想关注最终结果的情况下，我们应该更喜欢黑盒模型，因为它们更强大。</p>
			<h3 id="_idParaDest-144"><a id="_idTextAnchor145"/>简介</h3>
			<p>尽管名称以<strong class="bold">回归</strong>结尾，逻辑回归是一种用于预测二元分类结果的技术，因此是分类问题的一个好选择。正如上一节所讨论的，我们需要一种不同的方法来为分类结果建模。这可以通过将结果转换成比值比或事件发生概率的对数来实现。</p>
			<p>让我们将这种方法提炼为更简单的结构。假设一个事件成功的概率是 0.7。那么，同一事件的故障概率将被定义为<em class="italics">1–0.7 = 0.3</em>。成功的几率被定义为成功的概率与失败的概率之比。那么成功的几率将是<em class="italics"> 0.7/0.3 = 2.33 </em>，也就是说，成功的几率是 2 比 1。如果成功的概率是 0.5，也就是 50%的几率，那么成功的几率是 1 比 1。逻辑回归模型可以用数学方法表示如下:</p>
			<div><div><img src="img/C12624_03_27.jpg" alt=""/>
				</div>
			</div>
			<p>这里，<img src="img/C12624_03_28.png" alt="A drawing of a person&#10;&#10;Description automatically generated"/>是比值比的对数，也叫<strong class="bold"> logit </strong>函数。进一步解决数学问题，我们可以推导出结果的概率，如下所示:</p>
			<div><div><img src="img/C12624_03_29.jpg" alt=""/>
				</div>
			</div>
			<p>讨论方程的数学背景和推导超出了本章的范围。但是，总而言之，logit 函数，也就是链接函数(或逻辑函数)，帮助逻辑回归将问题(预测结果)直观地重新架构为比值比的对数。这个问题解决后，有助于我们预测一个二元因变量的概率。</p>
			<h3 id="_idParaDest-145"><a id="_idTextAnchor146"/>逻辑回归的机理</h3>
			<p>就像线性回归一样，使用 OLS 方法估计变量的贝塔系数，逻辑回归模型利用了<strong class="bold">最大似然估计</strong> ( <strong class="bold"> MLE </strong>)方法。MLE 函数估计模型参数或β系数的最佳值集合，使得它最大化似然函数，即概率估计。也可以定义为所选模型与观测数据的<em class="italics">一致</em>。当估计出一组最佳参数值时，将这些值/β系数代入模型方程，如前所述，有助于估计给定样本的结果概率。类似于 OLS，MLE 是一个迭代过程。</p>
			<h3 id="_idParaDest-146"><a id="_idTextAnchor147"/>模型构建</h3>
			<p>像在 R 中构建逻辑回归模型的线性回归一样，我们使用<code>glm()</code>广义线性模型方法来拟合数据，并使用 logit 函数对观察值进行评分。</p>
			<p>使用 glm()函数的语法如下:</p>
			<pre>glm(Y ~ X1 + X2 + X3, data = &lt;train_data&gt;,family=binomial(link='logit'))</pre>
			<p>这里，Y 是我们的因变量，X1、X2 和 X3 是自变量。参数数据将采用定型数据集。family 参数设置为二项式(link='logit ')，这符合逻辑回归模型。</p>
			<h3 id="_idParaDest-147"><a id="_idTextAnchor148"/>练习 46:在北京 PM2.5 数据集中存储 3 小时的滚动平均值</h3>
			<p>在本练习中，我们将创建一个新变量，用于存储北京 PM2.5 数据集中 PM2.5 变量的 3 小时滚动平均值。滚动平均值将消除 PM2.5 读数中的任何噪音。</p>
			<p>让我们使用<code>zoo</code>包中的<code>rollapply</code>方法来完成练习:</p>
			<ol>
				<li value="1">将<code>year</code>、<code>month</code>、<code>day</code>和<code>hour</code>组合成一个新变量，称为<code>datetime</code> : <pre>PM25$datetime &lt;- with(PM25, ymd_h(sprintf('%04d%02d%02d%02d', year, month, day,hour)))</pre></li>
				<li>Remove the NAs and look at the top 6 values of the <code>pm2.5</code> variable in the PM2.5 dataset:<pre>PM25_subset &lt;- na.omit(PM25[,c("datetime","pm2.5")])
head(PM25_subset$pm2.5)</pre><p>输出如下所示:</p><pre>[1] 129 148 159 181 138 109</pre></li>
				<li>Store the <code>PM25_subset</code> into a <code>zoo</code> object of ordered observation with datetime as its index, and print the top 6 values:<pre>zoo(PM25_subset$pm2.5,PM25_subset$datetime)</pre><p>输出如下所示:</p><pre>2010-01-02 00:00:00 2010-01-02 01:00:00 2010-01-02 02:00:00 
                129                 148                 159 
2010-01-02 03:00:00 2010-01-02 04:00:00 2010-01-02 05:00:00 
                181                 138                 109 </pre></li>
				<li>Use the <code>rollapply</code> function to create a 3-hour rolling average of the <code>pm2.5</code> variable, and print the top 6 values:<pre>PM25_three_hour_pm25_avg &lt;- rollapply(zoo(PM25_subset$pm2.5,PM25_subset$datetime), 3, mean)</pre><p>输出如下所示:</p><pre>2010-01-02 01:00:00 2010-01-02 02:00:00 2010-01-02 03:00:00 
           145.3333            162.6667            159.3333 
2010-01-02 04:00:00 2010-01-02 05:00:00 2010-01-02 06:00:00 
           142.6667            117.3333            112.6667 </pre></li>
			</ol>
			<p>注意<code>145.33</code>值是<code>pm2.5</code>变量三个小时的平均值，如步骤 3 所示(<code>129</code>、<code>148</code>和<code>159</code>)。</p>
			<h3 id="_idParaDest-148"><a id="_idTextAnchor149"/>活动 6:转换变量并导出新变量以构建模型</h3>
			<p>在此活动中，我们将在构建模型之前执行一系列转换并导出新变量。我们需要将<code>pm2.5</code>变量转换成分类变量，以应用逻辑回归模型。</p>
			<p>在建立逻辑回归分类模型之前，需要执行以下步骤:</p>
			<ol>
				<li value="1">将年、月、日和小时组合成一个名为<code>datetime</code>的新变量。</li>
				<li>使用日期时间变量，计算 3 小时窗口内<code>pm2.5</code>值的平均值。将这个新变量命名为<code>PM25_three_hour_pm25_avg</code>。</li>
				<li>创建一个名为<code>pollution_level</code>的二进制变量。如果<code>PM25_three_hour_pm25_avg</code>大于<code>35</code>，它就会得到一个值<code>1</code>，否则就是<code>0</code>。</li>
				<li>以<code>pollution_level</code>为因变量，建立逻辑回归模型。</li>
				<li>Print the summary of the model.<p>最终输出如下:</p><pre>Call:
glm(formula = pollution_level ~ DEWP + TEMP + Iws, family = binomial(link = "logit"), 
    data = PM25_for_class)
Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.4699  -0.5212   0.4569   0.6508   3.5824  
Coefficients:
              Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)  2.5240276  0.0273353   92.34   &lt;2e-16 ***
DEWP         0.1231959  0.0016856   73.09   &lt;2e-16 ***
TEMP        -0.1028211  0.0018447  -55.74   &lt;2e-16 ***
Iws         -0.0127037  0.0003535  -35.94   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
(Dispersion parameter for binomial family taken to be 1)
    Null deviance: 49475  on 41754  degrees of freedom
Residual deviance: 37821  on 41751  degrees of freedom
AIC: 37829
Number of Fisher Scoring iterations: 5</pre><h4>注意</h4><p class="callout">这项活动的解决方案可在第 446 页找到。</p></li>
			</ol>
			<h3 id="_idParaDest-149"><a id="_idTextAnchor150"/>解读模型</h3>
			<p><code>glm()</code>输出的大部分看起来与<code>lm()</code>方法相似，但有一些新值，如下所示:</p>
			<ul>
				<li><strong class="bold">零偏差</strong></li>
				<li><strong class="bold">剩余偏差</strong></li>
				<li><strong class="bold">赤艾克信息标准</strong> ( <strong class="bold"> AIC </strong>)</li>
				<li><strong class="bold">费希尔得分</strong></li>
			</ul>
			<p>为避免评分，以上所有措施将在<em class="italics">第五章</em>、<em class="italics">分类</em>中详细描述。</p>
			<p>请参考本章中关于<em class="italics">评估指标</em>的下一节(基于<em class="italics">混淆矩阵的指标</em>一节)，了解该模型在 R 平方和调整后的 R 平方指标上的表现。</p>
			<h2 id="_idParaDest-150"><a id="_idTextAnchor151"/>评估指标</h2>
			<p>在本节中，我们将介绍所有用于评估机器学习模型预测质量的评估方法。基于因变量，我们有几种评估方法可供选择。在我们的机器学习工作流的训练和评估步骤中，我们提到，直到我们得到期望的结果，我们通过添加新的变量或改变参数来不断迭代训练模型。在每一次迭代中，我们试图为任何一个或两个评估指标进行优化。下表总结了用于回归、分类和推荐系统的各种类型的指标。鉴于本书的范围，我们将深入研究回归和分类算法的更多细节:</p>
			<div><div><img src="img/C12624_03_14.jpg" alt="Figure 3.14: Metrics for various types of machine learning algorithms.&#13;&#10;"/>
				</div>
			</div>
			<h6>图 3.14:各种机器学习算法的指标。</h6>
			<h3 id="_idParaDest-151"><a id="_idTextAnchor152"/>平均绝对误差(MAE)</h3>
			<p>绝对误差是方向不可知的，这意味着模型对测试数据集的因变量预测值是小于还是大于实际值并不重要。因此，在北京 PM2.5 数据集的示例中，MAE 将给出 PM2.5 预测的平均绝对误差(因变量的预测值和实际值之间的差异)，与误差方向(正或负)无关:</p>
			<div><div><img src="img/C12624_03_30.jpg" alt=""/>
				</div>
			</div>
			<p>这里，<img src="img/C12624_03_31.png" alt=""/>是因变量的第 I 次观测值，<img src="img/C12624_03_32.png" alt=""/>是预测值或期望值。</p>
			<h3 id="_idParaDest-152"><a id="_idTextAnchor153"/>均方根误差(RMSE)</h3>
			<p>与 MAE 类似，均方根误差也计算平均预测误差。但是，它是基于二次评分的，计算的是平均平方误差的平方根。此外，与 MAE 不同，MAE 采用预测值和实际值之间的绝对差值，RMSE 采用平方，在取平方根之前对高误差值增加更多权重:</p>
			<div><div><img src="img/C12624_03_33.jpg" alt=""/>
				</div>
			</div>
			<p>这里，<img src="img/C12624_03_34.png" alt=""/>表示第 I 次观测的因变量的实际值和估计值之差。</p>
			<h3 id="_idParaDest-153">R 平方</h3>
			<p>r 平方测量由线性模型解释的响应变量中方差的百分比(0 到 1 或 0%到 100%之间的值)。换句话说，它测量由输入要素解释的方差。0% R 平方意味着模型的输入特征不能解释响应变量。接近 100%意味着该模型是响应变量的良好预测器。例如，如果我们想预测某个地区的房价，可以使用卧室数量、面积等特征。靠近学校和市场决定了房产的价值。然而，R 平方不能单独用于评估模型的良好性。还需要对残差、正态性和异方差进行各种诊断检查。我们将在第四章、<em class="italics">回归</em>中详细讨论这一点。</p>
			<div><div><img src="img/C12624_03_35.jpg" alt=""/>
				</div>
			</div>
			<p>这里，<img src="img/C12624_03_36.png" alt=""/>是因变量的实际值和估计值的平方差之和，而<img src="img/C12624_03_37.png" alt=""/>表示因变量的实际值和均值的平方差之和。</p>
			<div><div><img src="img/C12624_03_38.jpg" alt=""/>
				</div>
			</div>
			<h3 id="_idParaDest-154"><a id="_idTextAnchor155"/>调整后的 R 平方</h3>
			<p>当我们在回归模型中添加新变量时，模型的 R 平方值会随着新变量对解释因变量变化的贡献增加而提高。(如果较新的变量设计得不好，并且与解释因变量无关，就会出现相反的论点。)因此，对于不知道变量数量的评估度量，我们通过在计算中结合<em class="italics"> n </em>和<em class="italics"> q </em>(分别为观察数量和变量数量)来惩罚 R 平方值。这被称为调整的 R 平方，根据观察值和变量的数量进行调整。在处理多元线性回归时，查看调整后的 R 平方是一个很好的做法。</p>
			<p><strong class="bold">均方误差</strong> ( <strong class="bold">均方误差</strong>):</p>
			<div><div><img src="img/C12624_03_39.jpg" alt=""/>
				</div>
			</div>
			<p>这里，<em class="italics"> n </em>是观测值的个数，<em class="italics"> q </em>是模型中系数的个数。</p>
			<p><strong class="bold"> MST </strong> ( <strong class="bold">均方总数</strong>):</p>
			<div><div><img src="img/C12624_03_40.jpg" alt=""/>
				</div>
			</div>
			<h3 id="_idParaDest-155"><a id="_idTextAnchor156"/>平均倒数排名(MRR)</h3>
			<p>MRR 广泛用于评估搜索引擎中的算法、推荐算法和数字空间中的许多其他信息检索算法。MRR 很容易理解。一般来说，它可以用来评估为输入生成响应列表的算法。例如，你在谷歌上看到的搜索结果和你在亚马逊上看到的产品推荐。下表显示了计算倒数排名的示例。MRR 的范围从 0 到 1；接近 1 的值表示该算法在列表顶部给出相关结果。</p>
			<div><div><img src="img/C12624_03_41.jpg" alt=""/>
				</div>
			</div>
			<div><div><img src="img/C12624_03_15.jpg" alt="Figure 3.15: Example of computing reciprocal rank.&#13;&#10;"/>
				</div>
			</div>
			<h6>图 3.15:计算倒数排名的例子。</h6>
			<h3 id="_idParaDest-156"><a id="_idTextAnchor157"/>练习 47:寻找评估指标</h3>
			<p>在本练习中，我们将找到 MAE、RMSE、R 平方、调整 R 平方和 MRR。</p>
			<p>执行以下步骤:</p>
			<ol>
				<li value="1">导入所需的库和包。</li>
				<li>创建一个名为<code>y_predicted</code>的变量，并从<code>multiple_PM25_linear_model</code> : <pre>y_predicted &lt;- predict(multiple_PM25_linear_model, data = PM25)</pre>中赋值</li>
				<li>使用以下命令分配来自<code>PM25</code>数据集的值:<pre>y_actual &lt;- PM25[!is.na(PM25$pm2.5),"pm2.5"]</pre></li>
				<li>Find the MAE using the mean function:<pre>MAE &lt;- mean(abs(y_actual - y_predicted))</pre><p>输出如下所示:</p><pre>## [1] 59.82112</pre></li>
				<li>Next, calculate the RMSE:<pre>RMSE &lt;- sqrt(mean((y_actual - y_predicted)^2))</pre><p>输出如下所示:</p><pre>## [1] 82.09164</pre></li>
				<li>Now, calculate the R-squared value using the following command:<pre>model_summary &lt;- summary(multiple_PM25_linear_model)
model_summary$r.squared</pre><p>输出如下所示:</p><pre>## [1] 0.216</pre></li>
				<li>Next, find the adjusted R-squared using the following command:<pre>model_summary$adj.r.squared</pre><p>输出如下所示:</p><pre>## [1] 0.2159</pre></li>
				<li>Finally, use the following command to find the MRR:<pre>Query_RR_Vector &lt;- c(1/3,1/4,1)
MRR &lt;- sum(Query_RR_Vector)/length(Query_RR_Vector)</pre><p>输出如下所示:</p><pre>## [1] 0.5277778</pre></li>
			</ol>
			<p>注意到 MAE 给出了一个值<code>59.82</code>而 RMSE 是<code>82.09,</code>，这显示了误差中的高方差。换句话说，观测值在预测中具有高误差(这增加了误差幅度的频率分布的方差);梅没有发现错误，而 RMSE 很好地放大了它。如果 MAE 和 RMSE 几乎相等，我们可以推断误差幅度的频率分布的方差很低，并且模型对所有的观测都做得很好。</p>
			<h3 id="_idParaDest-157"><a id="_idTextAnchor158"/>基于混淆矩阵的指标</h3>
			<p>在分类算法中使用基于混淆矩阵的度量。人们可以从混淆矩阵(也称为<code>A</code>和<code>B</code>)中获得一系列指标。否则，目标变量没有任何积极或消极的一面。列联表也可以是 NxN，其中<em class="italics"> N </em>是响应变量中类或类别的数量。例如，如果我们想对给定图像中的 26 个手写英文字母进行分类，我们需要一个 26x26 的矩阵:</p>
			<div><div><img src="img/C12624_03_16.jpg" alt="Figure 3.16: Elements of the confusion matrix.&#13;&#10;"/>
				</div>
			</div>
			<h6>图 3.16:混淆矩阵的元素。</h6>
			<p>如果我们将<strong class="bold"> TP </strong>、<strong class="bold"> TN </strong>、<strong class="bold"> FP </strong>和<strong class="bold"> FN </strong>排列成一个 2x2 的列联矩阵，我们得到混淆矩阵，如下表所示:</p>
			<div><div><img src="img/C12624_03_17.jpg" alt="Figure 3.17: Confusion matrix.&#13;&#10;"/>
				</div>
			</div>
			<h6>图 3.17:混淆矩阵。</h6>
			<h3 id="_idParaDest-158"><a id="_idTextAnchor159"/>精确度</h3>
			<p>准确性衡量模型对正面和负面示例的正确总体分类。矩阵中对角元素的总和(TP 和 TN)除以正和负观察值的总数给出了精度。在现实世界中，准确性并不总是一个可靠的指标。考虑到我们想要区分癌症 CT 扫描和良性 CT 扫描。很明显，我们可能有很多阴性扫描，很少有阳性扫描。这就导致了我们所说的<strong class="bold">不平衡数据集</strong>。如果该模型主要准确预测良性扫描，但在预测癌症 CT 扫描时产生显著误差，则准确性可能仍然很高，但该模型并不那么有用。</p>
			<div><div><img src="img/C12624_03_42.jpg" alt=""/>
				</div>
			</div>
			<h3 id="_idParaDest-159"><a id="_idTextAnchor160"/>灵敏度</h3>
			<p>为了解决我们讨论的关于<em class="italics">准确性</em>的问题，我们可以使用灵敏度(也称为回忆、命中率或<strong class="bold">真阳性率</strong> ( <strong class="bold"> TPR </strong>)和特异性(在下一节讨论)的组合。灵敏度给出了模型对于阳性病例(在 ct 扫描中检测癌症)的预测能力。我们从所有<strong class="bold">真阳性</strong> ( <strong class="bold"> TP </strong>)病例数与<strong class="bold">阳性</strong> ( <strong class="bold"> P </strong>)病例数之比获得灵敏度。</p>
			<div><div><img src="img/C12624_03_43.jpg" alt=""/>
				</div>
			</div>
			<h3 id="_idParaDest-160"><a id="_idTextAnchor161"/>特异性</h3>
			<p>特异性提供了对阴性样本正确预测的定量评估(例如，检测良性 ct 扫描)。我们从真阴性病例数与阴性病例数的比率中获得敏感性。</p>
			<div><div><img src="img/C12624_03_44.jpg" alt=""/>
				</div>
			</div>
			<p>高灵敏度和特异性值意味着更好的模型。在大多数情况下，我们试图平衡这两个指标以获得最佳模型。</p>
			<h3 id="_idParaDest-161"><a id="_idTextAnchor162"/> F1 分数</h3>
			<p>F1 得分通过取两者的调和平均值(适用于取两个或更多比率的平均值)将精确度和灵敏度结合起来，如以下公式所述。<strong class="bold">阳性预测值</strong> ( <strong class="bold"> PPV </strong>或 precision)衡量真阳性和假阳性总数的真预测数，即阳性病例的所有预测中有多少是正确的。</p>
			<div><div><img src="img/C12624_03_45.jpg" alt=""/>
				</div>
			</div>
			<p>F1 分数比准确性更稳健，但在不平衡类别的情况下仍然受到影响。</p>
			<p>评估分类模型的好坏没有好坏之分。机器学习实践者通常会查看许多指标的组合来得出模型的好坏。这就是为什么知道如何解释上面讨论的每个指标变得很重要。</p>
			<h3 id="_idParaDest-162"><a id="_idTextAnchor163"/>练习 48:使用训练数据的模型评估</h3>
			<p>在本练习中，我们将使用<code>caret</code>包中的<code>confusionMatrix</code>函数对训练数据进行模型评估。该函数打印准确性、敏感性、特异性等指标。</p>
			<p>执行以下步骤来完成练习:</p>
			<ol>
				<li value="1">将所需的库和包导入系统。</li>
				<li>创建一个变量名<code>predicated</code>并赋值，如下所示:<pre>predicted &lt;- ifelse(PM25_logit_model$fitted.values&gt;0.5, 1,0)</pre></li>
				<li>接下来，创建另一个名为<code>actual</code>的变量，如下所示:<pre>actual &lt;- PM25_for_class$pollution_level</pre></li>
				<li>导入插入符号库:<pre>library(caret)</pre></li>
				<li>Finally, use the <code>confusionMatrix</code> method to describe the performance of the classification model:<pre>confusionMatrix(predicted, actual)</pre><p>输出如下所示:</p><pre>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction     0     1
##          0  5437  2097
##          1  6232 27989
##                                           
##                Accuracy : 0.8005          
##                  95% CI : (0.7967, 0.8044)
##     No Information Rate : 0.7205          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.4444          
##  Mcnemar's Test P-Value : &lt; 2.2e-16       
##                                           
##             Sensitivity : 0.4659          
##             Specificity : 0.9303          
##          Pos Pred Value : 0.7217          
##          Neg Pred Value : 0.8179          
##              Prevalence : 0.2795          
##          Detection Rate : 0.1302          
##    Detection Prevalence : 0.1804          
##       Balanced Accuracy : 0.6981          
##                                           
##        'Positive' Class : 0               </pre></li>
			</ol>
			<p>本节描述了<code>confusionMatric()</code>输出结果中显示的许多指标。然而，在你阅读细节之前，这里有一个快速的总结。该 logistic 回归模型的准确率为 80%，符合标准。这表明，我们可以使用其他环境因素以 80%的准确度预测正常和高于正常的 PM2.5 值。但是，请注意，精确度是针对整个训练数据集的。我们没有将数据分为两部分来检查过度拟合情况，在这种情况下，模型在训练数据上测试时表现非常好，但在测试(或看不见的)数据上显示出较差的结果。</p>
			<p>敏感性和特异性分别为 46%和 93%。这意味着该模型对负面情况(高于正常 pm 2.5 1)有好处。通常，这两个指标之间必须有一个折衷。然而，在这种情况下，模型的优先级是能够预测尽可能多的高于正常状态的<strong class="bold">。因此，一旦我们有了混淆矩阵，高特异性是可取的；从中可以计算出所有的指标。</strong></p>
			<h3 id="_idParaDest-163"><a id="_idTextAnchor164"/>受试者工作特性(ROC)曲线</h3>
			<p>在分类模型的上下文中，预测的输出是作为定量估计获得的，通常是概率度量。在二元逻辑回归中，将一个观察结果与另一个观察结果进行分类的阈值通常选择为 0.5(例如，垃圾邮件与非垃圾邮件)。这意味着，如果概率大于 0.5，将其分类为垃圾邮件，如果不是，则为非垃圾邮件。现在，根据阈值的不同，您将在我们之前讨论的混淆矩阵中获得不同的 TP、TN、FP 和 FN 值。虽然在给定阈值(通常为 0.5)下查看混淆矩阵是一种标准做法，但它可能不会给我们提供模型在现实世界中是否表现良好的完整视图，这就是阈值选择至关重要的原因。</p>
			<p>ROC 曲线是一个优雅的可视化图，显示了在每个可能的阈值下，真阳性率(通常以灵敏度为参考)和真阴性率(通常以特异性为参考)之间的变化。它帮助我们确定正确的分类阈值。此外，ROC 曲线下的面积(称为 AUC)在 0 和 1 之间变化，它告诉我们模型有多好。接近 1 意味着该模型能够在大多数观察结果中成功地在正类和负类之间进行分类。</p>
			<p>使用 R 中的 ROCR 包，我们将使用逻辑回归获得 PM2.5 预测的 ROC 曲线。此外，我们将在下一个练习中观察 AUC。</p>
			<h3 id="_idParaDest-164"><a id="_idTextAnchor165"/>练习 49:创建 ROC 曲线</h3>
			<p>在这个练习中，我们将使用 ROCR 软件包来获得 ROC 曲线。</p>
			<p>执行以下步骤:</p>
			<ol>
				<li value="1">使用以下命令将 ROCR 包导入系统:<pre>library(ROCR)</pre></li>
				<li>接下来，定义 pred1 和 pref1 对象:<pre>pred1 &lt;- prediction(predict(PM25_logit_model), PM25_for_class$pollution_level)
perf1 &lt;- performance(pred1,"tpr","fpr")</pre></li>
				<li>Next, find the AUC using the following command:<pre>auc &lt;- performance(pred1,"auc")
as.numeric(auc@y.values)</pre><p>输出如下所示:</p><pre>## [1] 0.8077673</pre></li>
				<li>使用绘图命令绘制图形:<pre>plot(perf1)</pre> <div> <img src="img/C12624_03_18.jpg" alt="Figure 3.18: ROC curve between true positive rate (sensitivity) and false positive rate (specificity).&#13;&#10;"/> </div></li>
			</ol>
			<h6>图 3.18:真阳性率(灵敏度)和假阳性率(特异性)之间的 ROC 曲线。</h6>
			<h2 id="_idParaDest-165"><a id="_idTextAnchor166"/>总结</h2>
			<p>在这一章中，我们从构建机器学习工作流的过程开始，从设计问题开始，到部署模型。我们简要地讨论了简单和多重回归以及逻辑回归，以及解释和判断模型性能所需的所有评估指标。这两个算法分别演示了回归和分类问题的监督学习。</p>
			<p>在本章中，我们使用北京 PM2.5 数据集来建立模型。在此过程中，我们还通过简单地重新设计因变量，将回归问题转换为分类问题。这种重新设计通常用于现实世界中的问题，以适应特定的用例。</p>
			<p>在下一章中，我们将深入研究回归算法的细节，并将阐述线性回归之外的各种类型的回归算法，并讨论何时使用哪一种。</p>
		</div>
	

</body></html>