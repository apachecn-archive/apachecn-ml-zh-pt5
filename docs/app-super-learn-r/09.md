

# 九、顶级项目——基于研究论文

## 学习目标

本章结束时，您将能够:

*   使用 mlr 和 OpenML 对一个问题应用端到端的机器学习工作流，这涉及到识别研究文章。
*   训练机器学习模型，然后在测试数据集上使用该模型进行预测和评估。
*   对数据集执行重采样。
*   建立各种模型的设计实验。
*   为选择最佳模型建立基准。

在这一章中，我们将讨论基于现实世界问题的最新研究论文，并将再现其结果。

## 简介

在这最后一章，我们将专注于一个基于研究的顶级项目。将使用所有之前章节的思想，例如使用 SCQ 框架设计问题、识别数据源、预处理数据集、训练机器学习模型、评估模型、应用重采样技术以及许多其他概念。此外，本章还将重点关注基准模型、设计机器学习实验、在开源平台中合作，以及使研究工作可复制以造福更大的社区。

丰富的在线资源、计算能力和开箱即用的工具包解决方案使得成为机器学习专业人员的门槛变得最低。今天，我们有大量的快速启动算法作为 R 和 Python 等编程语言中的一个包中的函数提供，甚至作为 Google Cloud AutoML 或 Microsoft Azure Machine Learning Studio 等平台中的拖放。然而，在许多这样的快速启动 Hello World 模型中经常缺少的是对问题解决的敏锐关注和超越可用工具的能力。

除了奢侈的工具包之外，还有一个由来自学术界和工业界的许多主要从业者制作的面向研究的工作世界。当涉及到产生突破性和高质量的成果时，这种研究工作的重要性是巨大的。然而，这种研究工作的可访问性是有限的，因此阻止了机器学习实践者的广泛采用。人们不从事基于研究的工作的另一个原因是因为缺乏可重复性(主要是因为公共领域没有代码、研究发现不清楚或研究工作质量差)以及研究文章或论文中充满行话的理论(许多是用数学语言写的)。

这一章致力于这样的研究工作，这些工作经常被许多努力学习机器但仅限于使用博客或在线书籍中提倡的特定工具和软件包的学习者所忽视。我们将关注两个重要的研究工作，幸运的是，它们也在 R 包中找到了一席之地。下一节将介绍这项工作，并设定本章其余部分的流程。

## 探索研究工作

在这一章中，我们将探索两个最重要的研究工作，它们最终也成为了开源产品。本章的重点是自上而下的方法，我们将从优秀研究工作的起源开始，看看它是如何成为每个人使用的主流工具包的。在强调研究工作的同时，我们想强调的是，许多研究工作在市场上可用的标准工具包中找不到它的位置，但是如果稍微努力一点，就可以找到一些宝石。

我们建议跟随《https://paperswithcode.com》的创作者所付出的巨大努力。在社区的帮助下，代码为的**论文团队创建了一个免费开放的资源平台，提供机器学习论文、代码和评估表，并由自动化驱动。他们已经实现了代码到论文链接的自动化，现在他们正致力于从论文中自动提取评估指标。这项工作值得称赞，因为它将使最好的研究工作在喧嚣和丰富中脱颖而出。**

下表将重点介绍五个研究工作案例，这些案例是我们通过《带代码的论文》网站找到的。在本书中，你会看到很多 R 代码在机器学习工作流程的每个阶段使用不同的包。mlr 和 OpenML 的研究人员所做的工作现在被打包在 R 中，特别是，OpenML 是一个完整的平台。我们将学习如何利用 mlr 和 OpenML 平台来产生最佳的机器学习模型，而不仅仅是快速入门 **Hello World** 的例子。作为参考，请查看下表:

![Figure 9.1: Research papers used in this lesson for demonstration (Part 1) 
](img/C12624_09_01.jpg)

###### 图 9.1:本章用于演示的研究论文(第 1 部分)

![Figure 9.2: Research papers used in this lesson for demonstration (Part 2)
](img/C12624_09_02.jpg)

###### 图 9.2:本章用于演示的研究论文(第二部分)

## MLR 包

现在，我们将学习 mlr 包如何提供一个完整的框架来处理许多机器学习模型和问题。通常，在许多 ML 项目中，人们必须管理大量围绕大量实验的细节(也称为**试错迭代**)。每个实验都由许多训练组成，使用不同的机器学习算法、性能测量、超参数、重采样技术和预测。除非我们不系统地分析每个实验中获得的信息，否则我们将无法得出参数值的最佳组合。

使用 mlr 包的另一个优势来自于它从各种包中收集了丰富的机器学习算法。我们不必再为机器学习算法的不同实现安装多个包。相反，mlr 在一个地方提供所有内容。为了更好地理解这一点，请参考下表:

![Figure 9.3: The mlr Package (Part 1)
](img/C12624_09_03.jpg)

###### 图 9.3:MLR 包(第 1 部分)

**多标签分类算法**

以下模型可用于多标签分类的 mlr 包，其中一个观测值可分配给多个类别。这些模型有助于解决许多有用的问题，比如，在网飞，你会看到每部电影都可以被打上动作、冒险和幻想的标签。或者，在 YouTube 上，每天有数百万个视频被发布，一种自动算法可以将这些视频分为多个类别，从而有助于内容过滤和更好的搜索。

我们将使用这些算法以及上表中定义的分类器:

![Figure 9.4: Multilabel classification with the mlr package
](img/C12624_09_04.jpg)

###### 图 9.4:使用 mlr 包的多标签分类

### OpenML 包

OpenML 是一个协作平台，来自学术界和工业界的研究人员可以通过它自动共享、组织和审议机器学习实验、数据、算法和流程。该平台带来了高效的协作和可重复性。

R 中的 OpenML 包带有各种功能，允许用户搜索、上传和下载数据集，并执行机器学习相关的操作。用户可以上传 ML 实验的输出，与其他用户共享，并下载输出结果。这增强了工作的可重复性，加快了研究工作，并把不同领域的人聚集在一起。

## 来自研究论文的问题设计

在这一章中，我们将理解、分析和再现来自*学习多标签场景分类*论文的结果。我们将有效地使用 mlr 和 OpenML 包来重现结果。在此之前，让我们用 **SCQ 框架**写出纸上的**情境-复杂-问题**:

![Figure 9.5: SCQ from the paper Learning multi-label scene classification
](img/C12624_09_05.jpg)

###### 图 9.5: SCQ 从纸上学习多标签场景分类

## 场景数据集中的特征

本文使用`scene`数据集进行语义场景分类任务。数据集是自然场景的图像的集合，其中自然场景可以包含多个对象，使得多个类别标签可以描述该场景。例如，背景中有一座山的野外场景。在论文中，我们采用了第一幅图，它显示了两幅多标记图像，在一幅图像中描绘了两个不同的场景。*图 9.6* 是海滩和城市场景，而*图 9.7* 显示的是山脉:

![Figure 9.6: A beach and urban scene.
](img/C12624_09_06.jpg)

###### 图 9.6:海滩和城市场景。

![Figure 9.7: A mountains scene.
](img/C12624_09_07.jpg)

###### 图 9.7:山脉场景。

根据给定的图像，我们可以使用以下内容:

*   **颜色信息**:该信息在区分某些类型的室外场景时非常有用。
*   **空间信息**:该信息在各种情况下都很有用。例如，图像顶部的浅暖色可能对应日出。

文中使用 *CIE L*U*V** ，如空格，记为 Luv。Luv 空间提出了预期的感知一致性。在适应(从 XYZ 空间到 *L*U*V* 空间的数学变换)Luv 空间之后，使用 7×7 网格将图像分成 49 个块。然后，作者计算每个波段(RGB)的一阶和二阶矩(均值和方差)，它们分别对应于低分辨率图像和计算成本低的质量特征。总的来说，我们获得每幅图像的*49×2×3 = 294 个*特征向量。

数据集中剩余的六列对应于以真/假编码值表示的六个标签。如果一个图像属于两个类，那么相应的列将具有真值。

#### 注意

在色度学中，**国际照明委员会** ( **CIE** )于 1976 年采用了 CIE 1976 L*、u*、v*颜色空间，作为 1931 CIE XYZ 颜色空间的简单计算转换，但其试图实现感知均匀性，即两种颜色之间的差异或距离。

## 使用 mlr 和 OpenML 包实现多标签分类器

我们现在将看到如何使用 mlr 和 OpenML 包训练多标签分类器。首先，我们将从 OpenML 下载场景数据集。

### 练习 102:从 OpenML 下载场景数据集

在本练习中，我们将下载场景数据集，并对其进行设置以供进一步分析。

执行以下步骤来完成练习:

1.  为了通过 OpenML API 下载场景数据集，首先在[https://www.openml.org/register](https://www.openml.org/register)的 OpenML 网站中创建一个帐户。注册过程包括验证您的电子邮件地址，发布后您将获得访问 API 密钥的权限。T3图 9.8:OpenML 注册页面. 6
2.  登录到您的帐户后，导航到您的帐户并选择 API 身份验证选项。
3.  在“API 身份验证”页面上，从“API 密钥”部分选择并复制粘贴 API 密钥。带有 R 包的多标签分类 mlr 论文的作者上传了一堆带有 2016 _ multi label _ R _ benchmark _ paper 标签的数据集，我们现在可以从 OpenML 下载这些数据集，并开始复制他们的结果。我们将专门使用场景数据集(ID 为 40595)。
4.  在继续之前，打开 RStudio 并安装所有必需的软件包。
5.  导入所需的包和库:

    ```
    library(mlr)
    library(BBmisc)
    library(OpenML)
    library(batchtools)
    library(parallelMap)
    ```

6.  Use the API key from the OpenML and register the API key using the following command:

    ```
    setOMLConfig(apikey = “627394a14f562f0fa8bcc9ec443d879f”)
    ```

    输出如下所示:

    ```
    ## OpenML configuration:
    ##   server           : http://www.openml.org/api/v1
    ##   cachedir         : C:\Users\Karthik\AppData\Local\Temp\Rtmp6bSgE4/cache
    ##   verbosity        : 1
    ##   arff.reader      : farff
    ##   confirm.upload   : TRUE
    ##   apikey           : ***************************d879f
    ```

7.  Use the following command to download the dataset from the source:

    ```
    ds.list = listOMLDataSets(tag = “2016_multilabel_r_benchmark_paper”)
    ```

    输出如下所示:

    ```
    ## Downloading from ‘http://www.openml.org/api/v1/json/data/list/tag/2016_multilabel_r_benchmark_paper/limit/5000/status/active’ to ‘<mem>’.
    ```

8.  Next, we will use the ID 40595 to get the scene dataset:

    ```
    oml.data = lapply(40595, getOMLDataSet)
    df.oml.data.scene <- data.frame(oml.data)
    ```

    #### 注意

    在继续执行前两个命令之前，请确保安装了 farff 包。

9.  Create the DataFrame using the following command:

    ```
    df_scene = df.oml.data.scene
    labels = colnames(df_scene)[295:300]
    scene.task = makeMultilabelTask(id = “multi”, data = df_scene, target = labels)
    ```

    输出如下所示:

![Figure 9.9: Environment setting of the scene.task variable.
](img/C12624_09_09.jpg)

###### 图 9.9:场景任务变量的环境设置。

在本练习中，我们在 OpenML 中注册了一个帐户，并获得了一个 API 密钥。使用 API 密钥，我们能够下载场景数据集，该数据集在 OpenML 中具有 2016 _ multi label _ r _ benchmark _ paper 标签。最后，我们将数据集转换成数据框架。OpenML 提供了许多这样的协作特性。人们可以通过分配一个标签与更大的社区共享他们的代码、实验和流程。

## 构建学习者

**学习器**是 mlr 包中的机器学习算法实现。正如上一节 mlr 包中所强调的，mlr 中有丰富的学习函数集合。

对于我们的场景分类问题，mlr 包提供了以两种可能的方式构建多标签分类模型:

*   **适应方法**:在这种情况下，我们对整个问题采用一种显式算法。
*   **转换方法**:我们将问题转换成简单的二分类问题，然后应用可用的算法进行二分类。

### 适应方法

R 中的 mlr 包提供了两种算法自适应方法。第一，来自`randomForestSRC`包的多元随机森林算法，第二，内置于`rFerns`包的随机蕨类多标签算法。

mlr 中的`makeLearner()`函数为`rFerns`和`randomForestSRC`算法创建模型对象，如以下代码所示:

```
multilabel.lrn3 = makeLearner(“multilabel.rFerns”)
multilabel.lrn4 = makeLearner(“multilabel.randomForestSRC”)
multilabel.lrn3
```

输出如下，其中显示了有关 multilable.rFerns 模型的名称和预测类型等信息:

```
## Learner multilabel.rFerns from package rFernsd
## Type: multilabel
## Name: Random ferns; Short name: rFerns
## Class: multilabel.rFerns
## Properties: numerics,factors,ordered
## Predict-Type: response
## Hyperparameters:
```

#### 注意

在继续前两个命令之前，确保安装了 *rFerns* 和 *randomForestSRC* 包。

### 转化方法

构造学习器的第二种方法是使用`makeLearner()`函数，然后五个包装器函数中的任何一个(在下一节中描述)都可以用于问题转换。

### 二元相关法

在多标签分类问题中，每个标签都可以转化为一个二元分类问题。在这个过程中，任何一个观察都可以被分配多个标签。在 mlr 包中，`makeMultilabelBinaryRelevanceWrapper()`方法将二进制学习器方法转换为包装的二进制相关性多标签学习器。

### 分类器链法

分类器链包装器方法实现了一个多标签模型，其中二进制分类器被排列成一个链。每个模型都按照链中指定的顺序进行预测。该模型使用给定数据集中的所有要素，以及链中之前的所有模型预测。mlr 中的`makeMultilabelClassifierChainsWrapper()`方法用于创建分类器链包装器。

### 嵌套堆叠

然而，像分类器链一样，观察的类(或标签)不是实际的类，而是基于由训练模型(学习者)从链中的先前模型获得的类的估计。mlr 包中的`makeMultilabelNestedStackingWrapper()`方法用于创建嵌套堆叠包装器。

### 依赖二元相关法

mlr 包中的`makeMultilabelDBRWrapper`方法用于创建依赖的二进制相关性包装器。

### 堆叠

然而，像从属二进制相关方法一样，在训练阶段，用作每个标签的输入的标签是通过二进制相关方法获得的，而不是使用实际的标签。mlr 包中的`makeMultilabelStackingWrapper`方法用于创建堆叠包装器。

在下面的练习中，我们将看到如何使用`classif.rpart`方法生成决策树模型。

### 练习 103:使用 classif.rpart 方法生成决策树模型

在本练习中，我们将使用`classif.rpart`方法生成决策树模型，然后使用*二元相关性*和嵌套*堆叠*包装器对其进行转换。

执行以下步骤来完成练习:

1.  首先，使用`makeLearner`方法为`classif.rpart` :

    ```
    lrn = makeLearner(“classif.rpart”, predict.type = “prob”)
    ```

    创建对象
2.  接下来，使用`makeMultilabelBinaryRelevanceWrapper`方法:

    ```
    multilabel.lrn1 = makeMultilabelBinaryRelevanceWrapper(lrn)
    multilabel.lrn2 = makeMultilabelNestedStackingWrapper(lrn)
    ```

    创建堆叠包装器
3.  Next, print the model:

    ```
    lrn
    ```

    输出如下所示:

    ```
    Learner classif.rpart from package rpart
    Type: classif
    Name: Decision Tree; Short name: rpart
    Class: classif.rpart
    Properties: twoclass,multiclass,missings,numerics,factors,ordered,prob,weights,featimp
    Predict-Type: prob
    Hyperparameters: xval=0
    ```

4.  Print the stacking wrappers, as illustrated here:

    ```
    multilabel.lrn1
    ```

    前面命令的输出如下，它显示了模型类型、作为模型输出一部分的可用属性以及预测类型等信息:

    ```
    Learner multilabel.binaryRelevance.classif.rpart from package rpart
    Type: multilabel
    Name: ; Short name: 
    Class: MultilabelBinaryRelevanceWrapper
    Properties: numerics,factors,ordered,missings,weights,prob,twoclass,multiclass
    Predict-Type: prob
    Hyperparameters: xval=0
    ```

### 训练模型

我们可以像往常一样用多标签学习者和多标签任务作为输入来训练模型；使用`multilabel.lrn1`对象。

### 练习 104:训练模型

在本练习中，我们首先将数据随机分为训练和测试数据集，然后使用 mlr 包中的`tain()`函数和上一节中定义的`multilabel.lrn1`对象来训练模型。

执行以下步骤来完成练习:

1.  使用以下命令来训练、预测和评估数据集:

    ```
    df_nrow <- nrow(df_scene)
    df_all_index <- c(1:df_nrow)
    ```

2.  使用以下命令创建`test_index variable`:

    ```
    train_index <- sample(1:df_nrow, 0.7*df_nrow)
    test_index <- setdiff(df_all_index,train_index)
    ```

3.  Use the `train` function, which takes model object `multilabel.lrn1` (`scene.task` with only randomly selected `train_index` to train the model:

    ```
    scene_classi_mod = train(multilabel.lrn1, scene.task, subset = train_index)
    scene_classi_mod
    ```

    输出如下所示:

    ```
    Model for learner.id=multilabel.binaryRelevance.classif.rpart; learner.class=MultilabelBinaryRelevanceWrapper
    Trained on: task.id = multi; obs = 1684; features = 294
    Hyperparameters: xval=0
    ```

使用从`scene`数据集中随机选择的`1684`个观察值的`scene_classi_mod`模型是使用 R 中的`rpart`包训练的，这是机器学习中的**分类和回归树** ( **CART** )算法的实现，该算法包装了用于多标签分类的二进制相关性方法。

### 预测产量

在 mlr 中，可以像往常一样使用`predict`功能进行预测。输入参数是经过训练的模型；scene.task 数据集被分配给`task`和`test_index`参数，这对应于`test`数据集被分配给`subset`参数:

```
pred = predict(scene_classi_mod, task = scene.task, subset = test_index)
names(as.data.frame(pred))
[1] “id”                   “truth.Beach”          “truth.Sunset”         “truth.FallFoliage”   
 [5] “truth.Field”          “truth.Mountain”       “truth.Urban”          “prob.Beach”          
 [9] “prob.Sunset”          “prob.FallFoliage”     “prob.Field”           “prob.Mountain”       
[13] “prob.Urban”           “response.Beach”       “response.Sunset”      “response.FallFoliage”
[17] “response.Field”       “response.Mountain”    “response.Urban”
```

### 模型的性能

为了评估预测的性能，mlr 包提供了`performance()`函数，它将模型的预测以及我们想要计算的所有度量作为输入。通过`listMeasures()`可以列出多标签分类的所有可用度量。根据论文，我们在预测中使用了`hamloss`、`f1`、`subset01`、`acc`、`tpr`和`ppv`等度量:

```
MEASURES = list(multilabel.hamloss, multilabel.f1, multilabel.subset01, multilabel.acc, multilabel.tpr, multilabel.ppv)
performance(pred, measures = MEASURES)
```

前面命令的输出如下:

```
multilabel.hamloss       multilabel.f1 multilabel.subset01      multilabel.acc      multilabel.tpr 
          0.1260950           0.5135085           0.5878285           0.4880129           0.5477178 
     multilabel.ppv 
          0.7216733
```

以下命令将列出可用于多标签分类问题的所有测量值:

```
listMeasures(“multilabel”)
```

输出如下所示:

```
[1] “featperc”            “multilabel.tpr”      “multilabel.hamloss”  “multilabel.subset01” “timeboth”           
 [6] “timetrain”           “timepredict”         “multilabel.ppv”      “multilabel.f1”       “multilabel.acc”
```

### 重采样数据

为了评估学习算法的整体性能，我们可以进行一些重采样。要定义重采样策略，使用`makeResampleDesc()`或`makeResampleInstance()`。之后，运行`resample()`功能。使用以下默认方法计算汉明损耗:

```
rdesc = makeResampleDesc(method = “CV”, stratify = FALSE, iters = 3)
r = resample(learner = multilabel.lrn1, task = scene.task, resampling = rdesc,measures = list(multilabel.hamloss), show.info = FALSE)
r
```

输出如下所示:

```
Resample Result
Task: multi
Learner: multilabel.binaryRelevance.classif.rpart
Aggr perf: multilabel.hamloss.test.mean=0.1244979
Runtime: 4.28345
```

### 每个标签的二进制性能

我们可以计算一个二进制的性能度量，例如，准确度，或者每个标签的`auc`，`getMultilabelBinaryPerformances()`函数是有用的。我们可以将该函数应用于任何多标记预测，例如，也可以应用于重采样多标记预测。为了计算`auc`，我们需要预测概率:

```
getMultilabelBinaryPerformances(r$pred, measures = list(acc, mmce, auc))
```

输出如下所示:

```
##             acc.test.mean mmce.test.mean auc.test.mean
## Beach           0.8728708     0.12712921     0.7763484
## Sunset          0.9335272     0.06647279     0.9066371
## FallFoliage     0.9148317     0.08516826     0.8699105
## Field           0.9077690     0.09223099     0.8895795
## Mountain        0.7922725     0.20772746     0.7670873
## Urban           0.8213544     0.17864562     0.7336219
```

### 标杆管理模型

在基准实验中，不同的学习方法被应用于一个或多个数据集，目的是对涉及一个或多个性能测量的算法进行比较和排序。`mlr()`方法提供了一个非常健壮的框架来进行这样的实验，并有助于跟踪所有的实验结果进行比较。

### 进行基准实验

在我们的第一个实验中，我们使用了`mlr()`包的多标签`randomForestSRC`和`rFerns`学习器以及各种度量来获得我们的第一个基准。

在下面的练习中，我们将探讨如何对不同的学习者进行基准测试。

### 练习 105:探索如何对不同的学习者进行基准测试

在本练习中，我们将了解如何对我们到目前为止创建的各种学习者进行基准测试，并比较结果以选择多标签场景分类问题的最佳学习者(模型)。这有助于我们以结构化格式组织所有结果，以选择性能最佳的模型。

执行以下步骤来完成练习:

1.  首先，使用以下命令列出所有学员:

    ```
    lrns = list(makeLearner(“multilabel.randomForestSRC”),
                makeLearner(“multilabel.rFerns”)
                )
    MEASURES = list(multilabel.hamloss, multilabel.f1, multilabel.subset01, multilabel.acc, multilabel.tpr, multilabel.ppv)
    ```

2.  Conduct the benchmark experiment:

    ```
    bmr = benchmark(lrns, scene.task, measures = MEASURES)
    ```

    输出如下所示:

    ```
    ## Exporting objects to slaves for mode socket: .mlr.slave.options
    ## Mapping in parallel: mode = socket; cpus = 2; elements = 2.
    ```

3.  Now, execute the `bmr` object:

    ```
    bmr
    ```

    对于每个学员来说，模型训练的迭代将看起来像下面这样:

    ```
    Task: multi, Learner: multilabel.rFerns
    [Resample] cross-validation iter 9: multilabel.hamloss.test.mean=0.183,multilabel.f1.test.mean=0.653,multilabel.subset01.test.mean=0.768,multilabel.acc.test.mean=0.54,multilabel.tpr.test.mean= 0.9,multilabel.ppv.test.mean=0.564
    ...
    [Resample] Aggr. Result: multilabel.hamloss.test.mean=0.183,multilabel.f1.test.mean=0.663,multilabel.subset01.test.mean=0.756,multilabel.acc.test.mean=0.549,multilabel.tpr.test.mean=0.916,multilabel.ppv.test.mean=0.566
    ```

    下表显示了测试数据的各种测量值的平均值:

![Figure 9.10: Mean of various measures on the test data.
](img/C12624_09_10.jpg)

###### 图 9.10:测试数据的各种测量的平均值。

该表显示，`randomForestSRC`模型在所有指标上都比`rFerns`稍好，主要是在**hamlos 均值指标**上。

### 访问基准测试结果

`mlr()`方法提供了许多`getBMR`函数来从基准实验对象中提取有用的信息，比如性能、预测、学习器等等。

### 学员表现

`getBMRPerformances`函数在训练的每次迭代中给出基准中定义的所有度量的所有值。下表列出了使用`randomForestSRC`和`rFerns`学习者的每个测量的值。

```
getBMRPerformances(bmr, as.df = TRUE)
```

![Figure 9.11: Learner performances randomForestSRC
](img/C12624_09_11.jpg)

###### 图 9.11:学员表现 randomForestSRC

![Figure 9.12: Learner performances rFerns
](img/C12624_09_12.jpg)

###### 图 9.12:学习者表现

## 预测

我们还可以使用`getBMRPredictions`函数获得测试数据集上的预测。本节中的两个表显示了由 ID 列表示的一些图像的实际和预测标签。观察到预测并不完美，正如我们从相对较低的整体准确性中所预期的那样。

**使用 randomForestSRC 的预测**:

```
head(getBMRPredictions(bmr, as.df = TRUE))
```

![Figure 9.13: The actual labels.
](img/C12624_09_13.jpg)

###### 图 9.13:实际的标签。

![Figure 9.14: The predicted labels.
](img/C12624_09_14.jpg)

###### 图 9.14:预测的标签。

### 学习者和措施

`getBMRLearners`函数给出了基准测试中使用的学习者的详细信息。使用此功能可以获得超参数和预测类型等信息。类似地，`getBMRMeasures`函数提供了关于性能度量的细节，比如 best。下表显示了我们在基准测试中使用的度量的详细信息:

```
getBMRLearners(bmr)
```

输出如下所示:

```
## $multilabel.randomForestSRC
## Learner multilabel.randomForestSRC from package randomForestSRC
## Type: multilabel
## Name: Random Forest; Short name: rfsrc
## Class: multilabel.randomForestSRC
## Properties: missings,numerics,factors,prob,weights
## Predict-Type: response
## Hyperparameters: na.action=na.impute
## 
## 
## $multilabel.rFerns
## Learner multilabel.rFerns from package rFerns
## Type: multilabel
## Name: Random ferns; Short name: rFerns
## Class: multilabel.rFerns
## Properties: numerics,factors,ordered
## Predict-Type: response
## Hyperparameters:
```

运行`getBMRMeasures(bmr)`功能:

```
getBMRMeasures(bmr)
```

![Figure 9.15: Learners and measures (part 1).
](img/C12624_09_15.jpg)

###### 图 9.15:学习者和测量(第一部分)。

图 15 和 16 总结了`getBMRMeasures(bmr)`命令的结果:

![Figure 9.16: Learners and measures (part 2).
](img/C12624_09_16.jpg)

图 9.16:学习者和测量(第二部分)。

合并基准测试结果

通常，我们会运行多个实验，并希望将所有来自实验的基准纳入一个统一的值列表中，以比较结果。`mergeBenchmarkResults`功能有助于合并结果。

以下是基准测试:

```
lrns = list(makeLearner(“multilabel.randomForestSRC”),
            makeLearner(“multilabel.rFerns”)
            )
bmr = benchmark(lrns, scene.task, measures = MEASURES)
lrn.classif.randomForest = makeLearner(“classif.randomForest”)
bmr.BR.rf = benchmark(lrn.classif.randomForest, scene.task, measures = MEASURES)
mergeBenchmarkResults(list(bmr, bmr.BR.rf))
```

![Figure 9.17: Merging benchmark results.
](img/C12624_09_17.jpg)

###### 图 9.17:合并基准测试结果。

显然，将`classif.randomForest`与分类器链包装器一起使用会产生最高的准确性，并且在所有其他度量中也表现良好。

### 活动 14:使用 classif 获得二进制性能步骤。C50 学习者而不是 classif.rpart

在本活动中，我们将重温构建模型的整个流程，其中我们将使用`makeLearner`函数来指定`rpart`模型，取代`C50`。具体来说，我们将重新运行整个机器学习流程，从问题转换步骤开始，到使用 classif 获得二进制性能步骤。C50 学习者而不是`classif.rpart`。

执行以下步骤来完成活动:

1.  定义算法自适应方法。
2.  Use the problem transformation method, and change the `classif.rpart` learner to `classif.C50`.

    #### 注意

    您需要安装`C50`包来运行这段代码。

3.  打印学员详细信息。
4.  打印多标签学员详细信息。
5.  使用与训练数据集相同的数据集来训练模型。
6.  打印模型详细信息。
7.  使用我们之前在测试数据集上创建的 C50 模型预测输出。
8.  打印绩效评估。
9.  打印`listMeasures`变量的绩效评估。
10.  使用交叉验证方法运行重采样。
11.  打印二进制性能。

完成活动后，您应该会看到以下输出:

```
##             acc.test.mean mmce.test.mean auc.test.mean
## Beach           0.8608226     0.13917740     0.8372448
## Sunset          0.9401745     0.05982551     0.9420085
## FallFoliage     0.9081845     0.09181554     0.9008202
## Field           0.8998754     0.10012464     0.9134458
## Mountain        0.7710843     0.22891566     0.7622767
## Urban           0.8184462     0.18155380     0.7837401
```

#### 注意

这项活动的解决方案可在 466 页找到。

### 使用 OpenML 上传功能

为了改进实验的协作和版本控制，我们可以使用`uploadOMLFlow`函数将我们创建的流上传到 OpenML:

```
flow.id = uploadOMLFlow(makeLearner(“multilabel.randomForestSRC”))
```

输出如下所示:

```
Downloading from ‘http://www.openml.org/api/v1/flow/exists/mlr.multilabel.randomForestSRC/R_3.2.2-v2.b955a5ec’ to ‘<mem>’.
Do you want to upload the flow? (yes|no)
Uploading flow to the server.
Downloading response to: C:\Users\Karthik\AppData\Local\Temp\Rtmpe4W4BW\file3f044abf30f2.xml
Uploading to ‘http://www.openml.org/api/v1/flow’.
Flow successfully uploaded. Flow ID: 9708
```

我们鼓励学生探索 OpenML 平台，以找到更多这样的功能，因为该平台可以帮助世界各地的研究人员协作和共享他们的工作，使好的工作快速传播，并有助于利用研究人员的集体智慧建立最佳模型。

## 总结

在这一章中，我们使用来自 R 的 mlr 和 OpenML 包来构建一个完整的机器学习工作流，以解决多标签语义场景分类问题。mlr 包提供了一个丰富的机器学习算法和评估方法的集合，帮助我们快速实现，并促进了更快的实验过程，以获得问题的最佳模型。这个包还提供了许多包装函数来处理多标签问题。使用一个健壮的框架(如 mlr 中的框架)构建真实世界的机器学习模型有助于加速实现，并为整个项目提供一个结构。此外，使用 OpenML，我们可以使用已经可用的数据集和代码来再现研究工作，然后根据我们的需要修改它。这样一个平台提供了与全世界的研究人员进行大规模合作的能力。最后，我们还可以上传我们自己的机器学习流程，让其他人从我们离开的地方继续学习。

在本书中，我们的重点是用 R 编程语言教授监督学习。监督学习是一类为我们提供数据的标记观察的算法。探索性数据分析(EDA)方法有助于更好地理解数据集，SCQ 框架用于精确设计问题。在问题设计的基础上选择特征，并且在多轮实验和评估之后选择适当的监督学习模型。然后，我们学习了如何在生产环境中部署机器学习模型，企业中的应用程序团队可以使用这些模型。此外，在数据集具有数百个特征的情况下，我们使用特征缩减和选择技术。

我们想强调的是，在任何机器学习项目中，超过某个点(可以定义为从项目开始的 3 个月的努力或不同组合的 100 次试运行)，我们应该停下来，问问我们迄今为止所做的是否可以部署在生产环境中。如果答案是肯定的，那么就部署它，并持续监控响应以发现任何异常和改进。如果答案是否定的，回到绘图板，重新开始(显然，如果有这样的奢侈)。超参数微调、模型选择等阶段的机器学习是一门艺术，需要大量的试错实验才能得出最好的模型。