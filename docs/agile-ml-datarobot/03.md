# 二、机器学习基础知识

本章涵盖了机器学习的一些基本概念，将在本书中使用和参考。为了有效地使用 DataRobot，这是您需要知道的最起码的知识。有经验的数据科学家可以安全地跳过这一章。本章的目的不是让你对统计学或机器学习有一个全面的了解，而仅仅是一些关键思想和概念的复习。此外，重点是你需要知道的实际方面，以便理解核心思想，而不要进入太多的细节。让 DataRobot 自动构建模型可能很有诱惑力，但在没有基本理解的情况下这样做可能会适得其反。如果您领导一个数据科学团队，请确保您的团队中有经验丰富的数据科学家指导他人，并且有其他治理流程。

这些概念中的一些会在实际操作的例子中再次出现，但我们在这里涵盖了许多在具体例子中可能不会出现的概念，但在某些时候可能会出现在与您的项目相关的内容中。这里列出的主题可以作为指南，帮助您确定开始使用 DataRobot 等强大工具所需的一些基本知识。

在本章结束时，你将会学到一些有效使用 DataRobot 所需要知道的核心概念。在本章中，我们将讨论以下主要话题:

*   数据准备
*   数据可视化
*   机器学习算法
*   性能指标
*   了解结果

# 数据准备

在将算法应用于数据集之前，数据集需要符合某种模式。数据集也需要没有错误。某些方法和技术用于确保数据集为算法做好准备，这将是本节的重点。

## 监督学习数据集

由于 DataRobot 主要处理监督学习问题，我们将只关注监督机器学习的数据集(其他类型将在后面的部分中讨论)。在监督机器学习问题中，我们提供所有答案作为数据集的一部分。想象一个数据表，其中每行代表一组线索及其相应的答案(*图 2.1* ):

![Figure 2.1 – Supervised learning dataset
](img/Figure_2.1_B17159.jpg)

图 2.1–监督学习数据集

这个数据集由包含线索的列组成(这些被称为**特征**，还有一列是答案(这被称为**目标**)。给定一个看起来像这样的数据集，算法学习如何在给定一组线索的情况下产生正确的答案。不管你的数据是什么形式，你的任务是首先转换它，使它看起来像图 2.1 中的表格。请注意，您拥有的线索可能分布在多个数据库或 Excel 文件中。您必须将所有这些信息汇集到一个表格中。如果你拥有的数据集很复杂，你将需要使用 SQL 之类的语言，使用诸如**Python**Pandas 或 **Excel** 之类的工具，或者使用诸如 **Paxata** 之类的工具。

## 时间序列数据集

时间序列或预测问题将时间作为其数据集的关键组成部分。它们与监督学习数据集相似，略有不同，如图*图 2.2* 所示:

![Figure 2.2 – Time series dataset
](img/Figure_2.2_B17159.jpg)

图 2.2-时间序列数据集

您需要确保时间序列数据集如上图所示。它应该有一个基于日期或时间的列，一个包含您试图预测的系列值的列，以及一组所需的线索。如果需要预测多个时间序列，还可以添加有助于对不同序列进行分类的列。例如，您可能对预测日期 5 和 6 的销售量感兴趣。如果您的数据是其他形式的，则需要将其转换为类似于上图的形式。

## 数据清理

你得到的数据通常会有错误。例如，在应该包含数字的字段中可能有文本。您可能会看到一个价格列，其中的值有时可能包含一个$符号，但在其他时候没有符号。DataRobot 可以捕获其中的一些，但有时自动化工具不会捕获这些，因此您需要仔细查看和分析数据集。有时将您的数据上传到 DataRobot 以查看它找到了什么，然后使用它的分析来确定接下来的步骤是非常有用的。有些清理需要在 DataRobot 之外执行，所以要准备好迭代几次以正确设置数据。需要注意的常见问题包括:

*   列中的数据类型错误
*   列中的混合数据类型
*   数字列中的空格或其他字符，使它们看起来像文本
*   同义词或拼写错误的单词
*   编码为字符串的日期
*   不同格式的日期

## 数据规范化和标准化

当不同的数据特征具有不同的比例和范围时，比较它们对目标值的影响变得更加困难。此外，许多算法在处理不同范围的值时有困难，有时会导致稳定性问题。避免这些问题的一种方法是规范化(不要与数据库范式混淆)或标准化这些值。

在规范化(也称为缩放)中，您可以缩放值，使其范围从 0 到 1:

Xnormalized = (X – Xmin) / (Xmax – Xmin)

另一方面，标准化使数据居中，使平均值为零，并对其进行缩放，使标准偏差为 1。这也被称为 **z 得分**数据:

X 标准化=(X–Xmean)/XSD

这里，Xmean 是所有 X 值的平均值，XSD 是 X 值的标准差。

通常，您不需要担心这一点，因为 DataRobot 会根据需要自动为数据集执行此操作。

## 离群值

离群值是与数据集的其余部分相比似乎不合适的值。这些值可以很大，也可以很小。通常，偏离平均值三个标准差以上的值被视为异常值，但这仅适用于值预计呈正态分布的要素。异常值通常来自数据质量问题或一些不寻常的情况，这些情况被认为没有足够的相关性来进行训练。被视为异常值的数据点通常会从数据集中移除，以防止它们压倒您的模型。经验法则只是为了突出候选人。您将不得不使用您的判断来确定是否有任何值是异常值，以及它们是否需要被移除。DataRobot 将再次突出显示潜在的异常值，但是您必须检查这些数据点，并确定是删除它们还是保留它们。

## 缺失值

这是数据集中一个非常普遍的问题。您的数据集可能包含许多缺失值，标记为 **NULL** 或 **NaN** 。在某些情况下，你会看到一个**？**，或者您可能会看到一个不寻常的值，如 **-999** ，组织可能会用它来表示一个缺失或未知的值。如何选择处理这些值在很大程度上取决于您试图解决的问题以及数据集所代表的内容。很多时候，您可能会选择删除包含缺失值的数据行。有时，这是不可能的，因为您可能没有足够的数据，并且删除这样的行可能会导致删除数据集的很大一部分。有时，您会看到某个要素(或列)中可能缺少大量的值。在这些情况下，您可能希望从数据集中移除该要素。

处理这种情况的另一种可能的方法是用合理的猜测来填充缺失的值。这可以采用零值、该特征的平均值或该特征的中值的形式。对于分类数据，缺失值通常被视为它们自己独立的类别。

更复杂的方法使用 k-最近邻算法根据其他类似的数据点计算缺失值。没有一个答案每次都是合适的，所以你需要运用你对问题的判断和理解来做出决定。最后一个选择是让它保持原样，让 DataRobot 想出如何处理这种情况。DataRobot 有许多插补策略和算法来处理缺失值。但是你必须小心，因为这并不总是导致最好的解决方案。与经验丰富的数据科学家交谈，利用您对业务问题的理解来规划行动路线。

## 类别编码

在许多问题中，你必须将你的特征转换成数值。这是因为许多算法不能处理分类数据。有许多方法可以对分类值进行编码，DataRobot 内置了许多这样的方法。这些技术中的一些是一次性编码、省去一个编码和目标编码。我们不会进入细节，因为通常您会让 DataRobot 为您处理这一点，但可能会有这样的情况，由于您对业务问题的理解，您希望自己以特定的方式对其进行编码。DataRobot 的这一特性可以节省大量时间，并且通常可以很好地解决大多数问题。

## 合并类别

有时候，你有包含大量类别的分类数据。虽然有一些方法可以处理大量的类别计数(如前一节所讨论的)，但是很多时候，合并类别是明智的。例如，您可能有许多类别包含很少的数据点，但彼此非常相似。在这种情况下，您可以将它们合并到一个类别中。在其他情况下，可能只是有人使用了不同的拼写、同义词或缩写。在这种情况下，最好将它们合并到一个类别中。有时，您可能希望将数字要素分割成对用户或利益相关者具有业务意义的条块。这是一个数据准备的例子，你需要根据你对问题的理解自己去做。您应该在将数据上传到 DataRobot 之前执行此操作。

## 目标泄漏

有时，数据集包含从目标本身派生的特征。这些是事先不知道的或者在预测时不知道的。无意中使用这些特性来构建模型会导致下游问题。这个问题称为目标泄漏。应仔细检查数据集，并从训练要素中移除此类要素。DataRobot 还将自动分析这些特征，并尝试标记任何可能导致目标泄漏的特征。

## 术语-文档矩阵

您的数据集可能包含包含文本或注释的要素。这些笔记通常包含对决策有用的重要信息。然而，许多算法不能直接使用这个文本。该文本必须被解析成数值，以便对建模算法有用。有几种方法可以做到这一点，最常用的方法是术语文档矩阵。此处的文档是指单个文本或注释条目。这些文档中的每一个都可以被解析成术语。现在，您可以计算一个术语在文档中出现的次数。这个结果可以存储在一个称为**项频率** ( **TF** )矩阵的矩阵中。这些信息中的一些也可以在单词云中可视化。DataRobot 会自动为你构建这些词云。虽然 TF 很有用，但它也有局限性，因为有些术语可能在所有文档中都很常见，因此它们在区分它们时并不十分有用。这引出了另一个想法，即我们也许应该寻找对一个文档来说有些独特的术语。这种赋予仅在某些文档中出现的术语更多权重的概念是称为**逆文档频率** ( **IDF** )。一个术语在一个文档中出现多次(TF)和它比较罕见(IDF)的组合被称为TFIDF。TFIDF 是 DataRobot 会自动为您计算并应用于包含文本的要素的东西。

## 数据转换

虽然 DataRobot 将为您进行许多数据转换(并且它一直在添加更多的数据)，但有许多转换会影响您的模型，但 DataRobot 将无法捕捉。你将不得不自己做这些。例如，对数、平方、平方根、绝对值和差值等数学变换。一些简单的操作可以在 DataRobot 内部设置，但对于更复杂的操作，您必须在 DataRobot 外部或在 Paxata 等工具中执行操作。有时，您会进行变换来线性化您的问题或处理具有长尾数据的要素。DataRobot 自动执行的一些转换如下:

*   计算聚合，如计数、最小值、最大值、平均值、中值、最频繁值和熵
*   基于时间的功能的广泛列表，如随时间变化、随时间最大值和随时间平均值
*   一些文本提取特性，如字数统计、提取的标记和术语文档矩阵
*   地理空间数据中的地理空间特征

我们将在第四章 、*为 DataRobot* 准备数据中再次详细讨论这个话题。

## 共线性检查

在任何给定的数据集中，都会有与其他要素高度相关的要素。本质上，它们携带了与其他一些特征相同的信息。通常需要移除与数据集中某些其他要素高度重复的要素。DataRobot 会自动为您执行这些检查，并将标记这些共线要素。这对于线性模型尤其重要，但是一些新的方法可以更好地处理这个问题。使用什么样的阈值取决于建模算法和您的业务问题。在 DataRobot 中，从用于建模的特征集中删除这些特征是相当容易的。

DataRobot 还生成一个关联矩阵，显示不同的功能如何相互关联。这有助于识别共线要素以及要在模型中使用的关键候选要素。通过分析相关矩阵，您可以深入了解数据和问题。在 [*第 5 章*](B17159_05_Final_NM_ePub.xhtml#_idTextAnchor097) 、*用 DataRobot* 进行探索性数据分析中，我们将讨论如何做到这一点的例子。

## 数据分区

在你开始构建模型之前，你需要把你的数据集分成三个部分。这些部分被称为训练、验证和保持。这三个部分在模型构建过程中有不同的用途。通常将数据集的 10-20%分成维持集。剩下的部分被进一步分割，70-80%用于训练，20-30%用于验证集。这样做是为了确保模型不会过度拟合，并且部署中的预期结果与模型构建期间看到的结果一致。

只有训练数据集用于训练模型。验证集设计用于调整算法，以便通过执行多个交叉验证测试来优化结果。最后，在构建模型之后，使用维持集对模型进行测试，测试的数据是它以前从未见过的。如果维持集的结果是可接受的，那么可以考虑部署该模型。

DataRobot 自动化了这个过程的大部分，但是它允许用户自定义分割百分比，以及应该如何进行分区。它还对时间序列或预测问题执行类似的功能，通过自动拆分数据进行基于时间的回溯测试。

# 数据可视化

数据分析师或数据科学家需要做的最重要的任务之一是理解数据集。数据可视化是理解这一点的关键。DataRobot 提供了各种可视化数据集的方法来帮助您理解数据集。这些可视化是自动为您构建的，因此您可以花时间分析它们，而不是准备它们。让我们看看这些是什么以及如何使用它们。

当您进入项目的数据页面(*图 1.20* )时，您将看到数据集的概要信息。仔细检查这些信息，从整体上理解您的数据集。如果您点击**功能关联**菜单(左上角)，您将看到这些功能是如何相互关联的(*图 2.3* ):

![Figure 2.3 – Feature associations using mutual information
](img/Figure_2.3_B17159.jpg)

图 2.3–使用交互信息的特征关联

此图显示了使用互信息度量的相互关系。**互信息** ( **米**)利用信息论来确定你从一个特征获得的关于另一个特征的信息量。与皮尔逊相关系数相比，使用 MI 的好处在于它可用于任何类型的特征。该值从 0(两个特征是独立的)到 1(它们携带相同的信息)。这有助于确定哪些要素适合作为模型的候选要素，哪些要素不会提供任何有用的信息或者是多余的。在模型构建开始之前，理解和使用这个视图是非常重要的，即使 DataRobot 自动使用这些信息来做出建模决策。

还有另一个类似的度量标准。如果您单击前面屏幕截图底部的指标下拉菜单，您可以选择另一个名为 **Cramer's V** 的指标。一旦选择了 Cramer 的 V，你会看到一个类似的图形视图(*图 2.4* ):

![Figure 2.4 – Feature associations using Cramer's V
](img/Figure_2.4_B17159.jpg)

图 2.4–使用克莱姆 V 的特征关联

Cramer 的 V 是 MI 的另一种度量标准，其用法类似。其值的范围也是从 0(无关系)到 1(特征高度相关)。克莱姆 V 通常与分类变量一起使用，作为皮尔逊相关系数的替代。

请注意，DataRobot 自动找到了相关特征的聚类。每个聚类用不同的颜色进行颜色编码，并且在*图 2.4* 中按聚类对特征进行排序。您可以放大特定的集群以进一步检查它们。这是DataRobot环境的一个重要特征，因为很少有数据科学家知道或利用这个想法。聚类很重要，因为它们突出了相互关联的特征组。这些复杂的相互依赖对于理解业务问题非常重要。通常，唯一知道这些复杂的相互依赖关系的人是具有丰富领域经验的人。大多数其他人甚至不会意识到这些复杂性。如果你是一个领域的新手，那么理解这些将给你相当于多年的经验。仔细研究这些，与你的业务专家讨论，充分理解他们试图强调什么，然后利用这些见解来改进你的模型和业务流程。

另外，请注意 DataRobot 提供了前 10 个最强关联的列表。记下这些联系并花些时间思考它们对你的问题意味着什么是很重要的。这些和你对自己领域的了解一致吗，还是有一些惊喜？惊喜往往会带来关键的洞见，而这些洞见可能对你的业务有价值。在下面的列表中，您会看到一个**查看特征关联对**按钮。如果你点击那个按钮，你会看到*图 2.5* :

![Figure 2.5 – Feature association details
](img/Figure_2.5_B17159.jpg)

图 2.5–功能关联详情

此图详细显示了两个选定特征之间的关系。在本例中，一个要素是分类的，而另一个是数字的。该图显示了这两者之间的关系，并可以提供对该问题的更多见解。一定要调查这些关系，尤其是那些可能违反直觉的关系。

现在，您可以点击具体的特性来查看它们是如何分布的(*图 2.6* ):

![Figure 2.6 – Feature details
](img/Figure_2.6_B17159.jpg)

图 2.6–功能详情

该视图显示了值如何分布以及它们如何与目标值相关的直方图。需要重点关注的是没有足够数据和非线性的范围。这些可以给你关于特征工程的想法。在这些方面，您可能会问为什么系统会表现出这种行为？

完成这些背景工作后，您现在就可以开始研究建模算法了。

# 机器学习算法

现在有数百种机器学习算法可用于机器学习项目，并且每天都有更多的算法被发明出来。DataRobot 支持广泛的开源机器学习算法，包括几种深度学习算法——Prophet、基于 SparkML 的算法和 H2O 算法。现在让我们来看看存在哪些类型的算法以及它们的用途(*图 2.7* ):

![Figure 2.7 – Machine learning algorithms
](img/Figure_2.7_B17159-DESKTOP-C2VUV36.jpg)

图 2.7–机器学习算法

我们的焦点将主要集中在 DataRobot 支持的算法类型上。这些算法类型将在以下小节中描述。

### 监督学习

当您可以提供一个答案(也称为标签)作为训练数据集的一部分时，将使用受监督的学习算法。对于监督学习，你必须将数据集的一个特征指定为答案，算法会通过查看多个示例并从这些示例中学习来尝试学习预测答案。不同类型的答案见*图 2.8* :

![Figure 2.8 – Targets for supervised learning algorithms
](img/Figure_2.8_B17159.jpg)

图 2.8–监督学习算法的目标

DataRobot 功能主要集中在监督学习算法上。集合中包括深度学习算法以及来自 SparkML 和 H2O 的大数据算法。DataRobot 具有内置的最佳实践，可以为您的问题和数据集选择最适合的算法。有四种主要类型的监督学习问题:

### 回归

回归问题是那些答案(目标)采用数字形式的问题(见*图 2.8* )。回归模型尝试拟合一条曲线，以使整个训练数据集的预测值和实际值之间的误差最小化。有时，甚至一个分类问题也可以建立为一个数值回归问题。在这种情况下，答案是一个数字，然后可以通过使用阈值将其转换为 bin。逻辑回归就是这样一种方法，它产生一个介于零和一之间的值。您可以将低于某个阈值的所有答案标记为 0，将高于该阈值的所有答案标记为 1。根据问题，可以使用线性和非线性回归算法。基于回归线与数据的匹配程度来评估模型。使用的典型指标有 **RMSE** 、 **MAPE** 、 **LogLoss** 和 **Rsquared** 。使用的典型算法有 **XGBoost** 、**弹性网**、**随机森林**、 **GA2M** 。

### 二元分类

二元分类问题的答案只能是两个不同的值(称为类)。这些可以是 0 或 1、是或否等形式。请参考*图 2.8* 中二元分类的目标特征示例。你通常面临的一个典型问题是阶级不平衡。当大部分数据集偏向一个类时，就会出现这种情况。当存在足够的训练数据时，这些问题通常通过对过度表示的类进行下采样来解决。如果做不到这一点，可以尝试对代表性不足的类进行过采样，或者使用其他方法。这些方法没有一个是完美的，有时你必须尝试不同的方法来看看什么是最好的。DataRobot 提供了机制，以在需要时指定下采样。一些常用于二元分类的算法有**逻辑回归**、 **K 近邻**、**基于树的算法**、 **SVM** 和**朴素贝叶斯**。在分类问题的情况下，最好避免使用准确性作为评估结果的度量。结果通常以混淆矩阵的形式显示出来(在本章后面会有描述)。在这种情况下，DataRobot 将自动选择合适的指标。

### 多类分类

多类分类问题是你试图预测两个以上的类或类别的问题。目标可能看起来像什么的简单例子，见*图 2.8* 。最近增加了多类功能，许多 DataRobot 功能可能无法解决此类问题。由于缩减采样不可用，您可能希望在将数据集上载到 DataRobot 之前调整采样。另外，请注意，通过将类折叠成两个类，您可以经常将您的问题折叠成一个二元分类问题。对于您的用例来说，这可能行得通，也可能行不通，但是如果需要的话，这是一个选项。此外，并不是所有的算法都适用于多类问题。DataRobot 将自动选择合适的算法来建立多类问题的模型。要使用的典型指标是 AUC、对数损失或平衡准确度。结果通常以混淆矩阵的形式显示出来(在本章后面会有描述)。使用的典型算法有 XGBoost、Random Forest 和 TensorFlow。

### 时间序列/预测

时间序列或预测模型在 DataRobot 中也被称为时间感知模型。在这些问题中，您有随时间变化的数据，并且您对预测/预报未来的目标值感兴趣(*图 2.2* )。DataRobot 不仅支持 ARIMA 等时间序列的常用算法，还可以将这些问题改编为机器学习回归问题，然后应用 XGBoost 等算法来解决这些问题。这些问题需要将序列转换为平稳序列，并需要大量的特征工程来创建基于时间的特征。这些问题还要求你考虑到过去可能重复发生的重要事件(比如假期或重大购物日)。时间序列模型还需要通过一种称为回溯测试的方法来处理验证和测试的特殊方式:

![Figure 2.9 – Backtesting for time series problems
](img/Figure_2.9_B17159.jpg)

图 2.9-时序问题的回溯测试

在回溯测试中，模型是使用过去的数据构建的，然后使用模型从未见过的较新的维持数据进行测试。这种基于时间的维持数据切片也称为超时验证。DataRobot 为您自动化了许多这些任务，我们将在后面看到更多细节。

### 算法

让我们回顾一下 DataRobot 中使用的一些主要算法。这里，我们仅提供这些算法的高级概述。这些算法可以通过改变它们的超参数来针对给定的问题进行调整。对于任何特定算法的更详细理解，可以参考机器学习书籍或 DataRobot 文档。一些重要的算法如下:

*   **随机森林**。通过创建多个决策树模型来构建随机森林模型，然后使用输出的平均值。这是通过创建训练数据的引导样本并在这些样本上构建决策树(*图 2.10* )来实现的:

![Figure 2.10 – Random forest
](img/Figure_2.10_B17159.jpg)

图 2.10–随机森林

随机森林模型处理缺失数据和非线性，并且已经证明在许多情况下非常有效。随机森林模型可用于回归和分类问题:

*   **XGBoost** :也被称为**极端**梯度提升树，是基于决策树的算法，已经变得非常流行，因为它们倾向于产生非常有效的预测，并且可以处理缺失值。它们可以处理非线性问题和特征之间的相互作用。XGBoost 建立在随机森林模型的基础上，通过创建一个随机森林，然后在先前树的剩余部分上创建树。这样，每一组新的树都能产生更好的结果。XGBoost 可以用于回归以及分类问题。
*   **Rulefit** : Rulefit 模型是简单规则的集合。你可以把这些规则想象成像决策树一样连在一起。规则适配模型更容易理解，因为大多数人可以联系到应用于解决问题的规则组合。DataRobot 通常构建这种模型来帮助您理解问题并提供见解。您可以进入**模型**选项卡的洞察部分，查看从规则匹配模型中生成的洞察以及给定规则对问题的有效性。它们可用于分类和回归问题。
*   **ElasticNet** 、**岭回归器**、**拉索回归器**:这些模型使用正则化来确保模型不会过度拟合，也不会过于复杂。正则化是通过添加更多要素的惩罚来实现的，这反过来又会迫使模型放弃一些要素或降低它们的相对影响。拉索回归器(也称为 **L1 回归器**)使用的惩罚权重是系数的绝对值。使用套索的效果是，它试图将系数减少到零，从而选择重要的特征，并删除那些贡献不大的特征。岭回归器(也称为 **L2 回归器**)使用的惩罚权重是系数的平方。这样做的效果是降低系数的幅度。 **ElasticNet** 用于指代使用套索和脊正则化来产生更简单且正则化的模型的线性模型。当您有许多相互关联的特性时，这就很方便了。
*   **逻辑回归**:逻辑回归是一种非线性回归模型，用于二元分类。输出是概率的形式，其值的范围从 0 到 1。这通常与阈值一起使用，将值指定为 0 或 1。
*   **SVM** ( **支持向量机**):这个是一个分类算法，试图找到一个最能区分类别的向量。很容易看出这在二维空间中是什么样子(*图 2.11* )，但该算法在高维空间中工作良好。SVM 的另一个好处是它能够通过使用非线性核函数来处理非线性，这可用于线性化问题:

![Figure 2.11 – Targets for supervised learning algorithms
](img/Figure_2.11_B17159.jpg)

图 2.11–监督学习算法的目标

*   **GA2M** ( **广义加法模型**):这是一种罕见的算法，它提供了可理解性，同时即使在非线性问题中也提供了高精度。名称中的数字“2”表示它能够模拟特性之间的交互。GAM 模型输出是已装箱的单个特征的效果输出的总和。由于 GAM 允许这些效应是非线性的，它可以捕捉问题的非线性本质。模型的结果可以表示为一个简单的表格，向您显示每个特征对整体答案的贡献。这种类型的表格表示很容易被大多数人理解。对于可理解性和可解释性非常重要的行业或用例，这可能是您可以选择的最佳选项之一。
*   **K-最近邻**:这是一个非常简单的算法，可以找到 K 个最近的数据点(基于一种特定的计算距离的方式)。现在它找到了这 k 个点的分类答案。然后，它会确定得票最多的答案，并将其指定为答案。使用的默认距离度量是**欧几里德**距离，但是 DataRobot 根据数据集选择合适的度量。用户还可以指定要使用的特定距离度量。
*   **张量流**。TensorFlow 是一个基于深度神经网络的深度学习模型。深度神经网络是一种隐藏了由人工神经元集合组成的深层网络。神经元具有高度非线性的激活功能，这使得它们能够适应高度非线性的问题。这些模型非常擅长在不需要特征工程的情况下产生高精度，但是与其他算法相比，它们需要更多的训练数据。这些模型通常被认为非常不透明，容易过拟合，因此不适合某些应用。它们尤其适用于难以提取特征和特征工程的应用，例如图像处理。这些模型可用于回归和分类问题。
*   **Keras 神经网络** : Keras 是建立在 TensorFlow 之上的高级深度学习库，允许将多种类型的深度学习模型纳入 DataRobot。作为一个更高级的库，它使得构建 TensorFlow 模型变得容易得多。上一节描述的所有内容都适用于 Keras。DataRobot 中的特定实现非常适合稀疏数据集，对于文本处理和分类问题尤其有用。

## 无监督学习

无人监督的学习问题是那些没有给你提供答案或标签的问题。这种问题的例子是聚类或异常检测。DataRobot 并没有为这些问题提供太多帮助，但是它确实有一些异常或异常值检测的能力。这些问题是你的数据点以一种很少发生的方式不寻常。示例包括欺诈检测、网络安全漏洞检测、故障检测和数据异常检测。DataRobot 允许您建立一个没有目标的项目，然后它将尝试识别异常数据点。对于任何聚类问题，您都应该尝试使用 Python 或 R 来创建聚类模型。

## 强化学习

强化学习问题是指你想要学习一系列由代理人做出的决策，从而实现某个目标。该目标与给予完全或部分实现该目标的代理的奖励相关联。本次训练没有可用的数据集，因此代理必须尝试多次(使用不同的策略)，并在每次尝试中都有所收获。经过多次尝试，代理将学会产生最佳回报的策略或规则。正如你现在可以猜到的，这些算法在你没有数据的时候效果最好，但是你可以在真实世界(或者一个合成世界)中反复实验。正如我们之前讨论的，DataRobot 并不是解决这类问题的合适工具。

## 集合/混合模型

集成是一种技术,用于创建一个聚集或混合其他模型预测的模型。不同的算法有时能够更好地利用问题或数据集的不同方面。这意味着，很多时候，您可以通过组合几个好的模型来提高预测准确性。这当然会增加复杂性和成本。DataRobot 提供了许多混合方法，并且在大多数情况下，会为您的项目自动构建混合模型。然后，您可以评估准确性的提高是否足以证明额外的复杂性是合理的。

## 蓝图

在 DataRobot 中，每个模型都与一个蓝图相关联。蓝图是 DataRobot 用来训练特定模型的一步一步的配方。示例见*图 2.12* :

![Figure 2.12 – Model blueprint
](img/Figure_2.12_B17159.jpg)

图 2.12–模型蓝图

蓝图显示了 DataRobot 构建该特定模型所采取的所有步骤，包括 DataRobot 完成的任何数据准备和功能工程。点击任何特定的框将显示关于所采取的行动、所使用的参数以及所使用的特定算法的文档的更多细节。这也是为您自动创建的建模项目的很好的文档。

现在，让我们看看如何确定算法的表现。为此，我们需要一些性能指标。

# 绩效指标

DataRobot 为模型提供了广泛的性能指标。您必须指定您想要用来优化项目模型的指标。通常，要使用的最佳指标是 DataRobot 推荐的指标。一旦模型建立，DataRobot 还会计算其他指标，因此您可以跨多个指标查看模型的结果。请记住，没有适合所有情况的完美指标，您应该谨慎选择用于评估结果的指标。这里列出了一些关于常用指标的详细信息:

*   **RMSE** ( **均方根误差** ): RMSE 是一种度量标准，它首先计算误差的平方(实际误差和预测误差之差)。然后对整个数据集进行平均，然后计算平均值的平方根。鉴于这一指标取决于值的范围，其解释取决于问题。您不能比较两个不同数据集的 RMSE。当数据不是高度倾斜时，此指标经常用于回归问题。
*   **MAPE** ( **平均绝对百分比误差** ): MAPE 在某种程度上类似于 RMSE，它首先计算百分比误差的绝对值。然后，在数据集上对这些值进行平均。鉴于这一指标是根据百分比来衡量的，比较不同数据集的 MAPE 更容易。但是，您必须注意，非常小的值(或零值)的百分比误差往往看起来非常大。
*   SMAPE ( **对称 MAPE** ): SMAPE 类似于 MAPE，但是解决了上面讨论的一些缺点。SMAPE 限制百分比的上限值，这样小值的误差就不会超过度量。这使得 SMAPE 成为一个很好的度量标准，您可以轻松地比较不同的问题。
*   **Accuracy**: Accuracy is one of the metrics used for classification problems. It can be represented as follows:

    *准确度=正确预测数/总预测数*

    本质上是正确预测的数量与所有预测的数量之比。对于不平衡的问题，这个度量标准可能会产生误导，因此它本身从来不会用来确定一个模型做得有多好。它通常与其他指标结合使用。

*   **Balanced Accuracy**: Balanced accuracy overcomes the issues with accuracy by normalizing the accuracy across the two classes being predicted. Let's say that the two classes are A and B:

    *(A)A 的准确率=正确预测 A 的数量/A 的总数*

    (B)*B 的准确率=正确 B 预测的数量/B 的总数*

    (c) *平衡精度= A 的准确率+B 的准确率/2*

    平衡的精度实质上是 A 的准确率和 b 的准确率的平均值。

*   **AUC**(**ROC 曲线下面积** ): AUC 是**ROC**(**Received Operator 特性**)曲线下的面积。该度量经常用于分类问题，因为这也克服了与准确性度量相关的缺陷。ROC 曲线表示真阳性率和假阳性率之间的关系。AUC 从 0 到 1，它显示了模型在两个类别之间的区分程度。值 0.5 表示随机模型，因此您希望模型的 AUC 大于 0.5。
*   **伽玛偏差**:伽玛偏差用于目标值为伽玛分布时的回归问题。对于这样的目标，gamma 偏差是预测值与实际值的平均偏差(使用对数似然函数)的两倍。完全符合的模型偏差为零。
*   **泊松偏差**:泊松偏差用于回归问题，目的是统计有偏差的数据。它的工作方式非常类似于伽玛偏差。
*   **LogLoss** : LogLoss(也称为交叉熵损失)是对分类问题预测概率不准确性的度量。值为 0 表示模型完美，随着模型变得越来越差，logloss 值也会增加。
*   Rsquared : Rsquared 是一个用于回归问题的度量标准，它告诉我们拟合线代表数据集的程度。其值介于 0 和 1 之间。0 表示模型不佳，无法解释任何变化，而值 1 表示模型完美，可以解释 100%的变化。这是最常用的指标之一，但是它可能会遇到这样的问题:您可以通过添加更多的变量来增加它，而不一定改进模型。它也不适用于非线性问题。

既然我们已经讨论了一些常用的指标，让我们看看如何查看其他结果来评估您的模型的质量，以及不同特性对您的模型的影响。

# 了解结果

在本节中，我们将讨论各种指标和其他信息的可视化，以理解建模练习的结果。这些是重要的可视化，除了查看上一节中讨论的模型度量之外，还需要仔细检查。这些可视化效果是 DataRobot 为其训练的任何模型自动生成的。

## 电梯图表

lift 图显示了模型在预测目标值方面的有效性。由于数据点的数量通常非常大，无法显示在一个图形中，提升图对输出进行排序，并将数据聚合到多个条柱中。然后比较每个箱中预测值和实际值的平均值(*图 2.13* ):

![Figure 2.13 – Lift chart
](img/Figure_2.13_B17159.jpg)

图 2.13-提升图

前面的提升图显示了预测如何从低到高排序，然后分箱(本例中为 60 个分箱)。现在，您可以看到每个箱中的平均预测值和平均实际值。这让你对模型在整个范围内的表现有所了解。您可以看到是否有模型表现更差的范围。如果模型在对您的业务很重要的范围内表现不佳，您可以进一步调查，看看如何在该范围内改进模型。您还可以考察不同的模型，看看是否有一个模型在更重要的区域做得更好。提升图对回归问题更有意义。

## 混淆矩阵(二进制和多类)

对于分类问题，评估模型结果的最佳方法之一是查看混淆矩阵及其相关度量标准(*图 2.14* )。该选项卡适用于多类问题:

![Figure 2.14 – Confusion matrix
](img/Figure_2.14_B17159.jpg)

图 2.14–混淆矩阵

混淆矩阵映射了每个类别的预测计数与实际计数(频率)。再来看轿车一栏。绿色大圆圈表示我们将轿车正确分类为轿车的次数。在那一栏，你还会看到红点，那里的模型预测它是一辆轿车，但它是一个不同的类型。你可以看到所有课程的这些内容。相对比例应该让你知道你的模型做得有多好，哪里有困难。

如果你选择了一个特定的类，你可以在右边查看特定类的混淆矩阵。您可以看到两列(+表示预测轿车，-表示预测非轿车)。类似的，你看到两排(+是轿车的地方，和-不是轿车的时候)。您还会看到一些重要的定义和指标:

*   **真阳性** ( **TP** ) =其中是轿车，预测为轿车
*   **误报** ( **FP** ) =其中不是轿车但被预测为轿车
*   **真否定** ( **TN** ) =其中不是轿车并且被预测为不是轿车
*   **假阴性** ( **FN** ) =其中是轿车但被预测为不是轿车

使用这些，我们现在可以计算这个类的一些具体指标:

*   *精度=预测的正确部分= TP/所有肯定预测= TP/(TP+FP)*
*   *回忆=实际值的正确分数= TP/所有正实际值= TP/(TP+FN)*
*   F1 得分=精确度和召回率的调和平均值。所以，1/F1 = 1/精度+1/召回

## 大鹏鸟

该选项卡可用于二进制分类问题。 **ROC** ( **受试者操作者特征**)曲线是真阳性率和假阳性率的关系。这条曲线下的面积称为 AUC。它从 0 到 1，显示了模型对两个类别的区分程度(*图 2.15* ):

![Figure 2.15 – ROC curve and confusion matrix
](img/Figure_2.15_B17159.jpg)

图 2.15-ROC 曲线和混淆矩阵

您还可以看到混淆矩阵(如前所述)和两个类的相关度量。您可以移动阈值并评估由此产生的权衡和累积收益。由于大多数问题在某种意义上是不对称的，真正的肯定与真正的否定相比具有不同的商业价值，所以您应该选择对您的商业问题有意义的阈值。

## 精度随时间变化

该选项卡可用于时间序列问题(*图 2.16* )，比较一段时间内序列的实际值和预测值:

![Figure 2.16 – Model accuracy over time
](img/Figure_2.16_B17159.jpg)

图 2.16–模型准确性随时间的变化

您可以查看回溯测试或维持数据集的这些值。该图将清楚地显示出模型表现不佳的地方，以及您可能希望关注哪些方面来改进您的模型。

## 功能影响

除了模型性能，你首先要了解的一件事是这些特性对你的模型性能有多大影响。**功能影响**选项卡(*图 2.17* )对于理解您的模型可能是最关键的:

![Figure 2.17 – Feature impacts
](img/Figure_2.17_B17159.jpg)

图 2.17–功能影响

该图显示了最重要功能的排序列表。对于每个特性，您可以看到特性对该模型的相对影响。你可以看到哪些功能贡献很小；这可用于通过删除一些影响很小的功能来创建新的功能列表。

## 特征匹配

**特征拟合**选项卡(*图 2.18* )向显示了特征贡献的另一种视图。该图显示了按重要性排序的功能:

![Figure 2.18 – Feature Fit
](img/Figure_2.18_B17159.jpg)

图 2.18–特征匹配

对于所选要素，它显示了要素值范围内的预测值与实际值的比较情况。查看这些关键特性的图表可以深入了解一个特性如何影响结果、表现较好的值的范围以及表现最差的范围。这有时会突出显示您可能需要收集更多数据来改进模型的区域。

## 功能效果

**特征效果**显示与**特征拟合** ( *图 2.19* )非常相似的信息。在该图中，特征按**特征影响**排序。另外，**特征效应**集中于部分相关性:

![Figure 2.19 – Feature Effects and Partial Dependence
](img/Figure_2.19_B17159.jpg)

图 2.19-特征效应和部分相关性

部分依赖图是您想要仔细研究的最重要的图之一。这些图告诉您一个特性值的变化如何影响其他特性值范围内的目标平均值的变化。这种洞察力对于理解业务问题、理解模型正在做什么，以及更重要的是，模型的哪些方面是可操作的以及什么范围的值将产生最大的影响是至关重要的。

## 预测解释

**预测解释**根据正在评分的特定实例或行的特征值来描述特定预测的原因(*图 2.20* )。请注意，这与**特性影响**不同，后者告诉您特性在全局层面的重要性:

![Figure 2.20 – Prediction Explanations
](img/Figure_2.20_B17159.jpg)

图 2.20–预测解释

**预测解释**可以为整个数据集或数据子集生成，如前面的屏幕截图所示。例如，它将提供模型预测特定值的三大原因。在某些用例中，由于法规原因，有时需要这些解释，但产生这些解释是一个好主意，因为它们确实有助于理解为什么模型以某种方式预测，并且在验证或捕捉模型中的错误时非常有用。DataRobot 使用两种算法来计算解释: **XEMP** ( **基于样本的解释**)或 **Shapley 值**。XEMP 受更多型号的支持，默认情况下处于选中状态。下一节将介绍 Shapley 值。

## 沙普利值

**沙普利** **值** ( **SHAP** )是产生预测解释的备选机制(*图 2.21* )。如果您想使用 SHAP 进行解释，您必须在按下**开始**按钮之前，在项目设置期间的高级选项中指定。一旦 DataRobot 开始建立模型，你就不能切换到 SHAP。SHAP 值仅适用于线性或基于树的模型，不适用于集合模型:

![Figure 2.21 – SHAP-based explanations
](img/Figure_2.21_B17159.jpg)

图 2.21-基于 SHAP 的解释

SHAP 价值观基于合作博弈理论，该理论试图为合作项目中团队成员的贡献赋值。在机器学习的背景下，当有一组特征协作进行预测时，它试图分配特定特征的贡献值。SHAP 值是相加的，您可以很容易地看出最终答案中有多少是由特定的特征值决定的。

# 总结

在本章中，我们涵盖了一些基本的机器学习概念，这些概念在我们阅读剩余章节时会派上用场，并且在您的数据科学之旅中也会很有用。请注意，我们只涵盖了高层次的概念，根据您的工作角色，您可能希望更详细地探索一些领域。我们还将这些材料与 DataRobot 如何执行某些功能以及您需要更加关注的地方联系起来。

希望这能让你对 DataRobot 将要展示的内容有所了解，以及在项目的不同阶段应该把注意力放在哪里。由于 DataRobot 自动完成了大量的模型构建和预测任务，因此可能会忽略 DataRobot 自动为您生成的许多输出。请抵制这种诱惑。DataRobot 软件花费了相当多的精力和资源来产生这些输出，这是有充分理由的。它也为你做了很多繁重的工作，所以请利用这些能力。具体来说，我们讨论了以下内容:在数据准备过程中需要注意什么？什么样的数据可视化对理解数据集很重要？有哪些关键的机器学习算法，什么时候用？你如何衡量你的模型结果的好坏？你如何评估模型的性能并理解模型告诉你的问题？

现在我们知道了基础知识，我们将在下一章开始我们的数据科学之旅，学习如何理解业务问题，以及如何将其转化为可以通过使用机器学习来解决的规范。