<html><head/><body>


	
		<title>B18216_11_ePub</title>
		
	
	
		<div><h1 id="_idParaDest-211"><em class="italic"> <a id="_idTextAnchor217"/>第十一章</em>:以终端用户为中心的人工智能</h1>
			<p>在本书的最后 10 章中，我们已经走过了可解释的人工智能的整个景观(<strong class="bold"/>(<strong class="bold"/>)，涵盖了在实践中用于可解释的<a id="_idIndexMarker748"/>不同维度的不同类型的可解释方法(<em class="italic">数据</em>、<em class="italic">模型</em>、<em class="italic">结果</em>和<em class="italic">最终用户</em>)。XAI 是一个活跃的研究领域，我认为它还没有充分发挥潜力。但是这个领域正在迅速发展，伴随着更广泛的人工智能领域，我们将见证许多新的算法、方法和工具在未来被开发出来。最有可能的是，XAI 的新方法和工具将优于现有的方法和工具，并将能够解决在第 10 章<a href="B18216_10_ePub.xhtml#_idTextAnchor209"><em class="italic"/></a><em class="italic">XAI 行业最佳实践</em>中讨论的 XAI 的一些<em class="italic">公开挑战。不幸的是，我们不能扩大本书的范围，以涵盖所有可能的方法来 XAI。然而，这本书的目标是提供一个领域的概念理解与所需的实践技能的混合，以便它是一个有用的初学者的起点，甚至增加了 XAI 应用知识的专家的知识。</em></p>
			<p>在前一章中，我们从行业角度讨论了实现可解释的<strong class="bold">机器学习</strong> ( <strong class="bold"> ML </strong>)系统<a id="_idIndexMarker749"/>的推荐实践。我们还讨论了 XAI 目前面临的挑战，以及一些缓解这些挑战的建议方法。考虑到这些现有的挑战，在本章中，我们将重点讨论<strong class="bold">以终端用户为中心的人工智能</strong> ( <strong class="bold">耐力</strong>)的思想体系<a id="_idIndexMarker750"/>。这是一个经常用来指可持续和可扩展的人工智能解决方案的术语，这些解决方案以用户为中心。建议您在开始本章之前先阅读上一章，以便更好地理解。对 XAI 来说，耐力既不是新算法，也不是新的复杂工具。反而是一种修行；这是一个有条不紊的纪律，以弥合人工智能终端用户的差距。</p>
			<p>这一章对于来自人工智能和<strong class="bold">人机交互</strong> ( <strong class="bold">人机交互</strong>)领域的研究人员来说尤其有用，他们从<em class="italic">多学科的角度</em>看待 XAI。考虑到无缝的<strong class="bold">用户体验</strong> ( <strong class="bold"> UX </strong>)，它对那些希望使用人工智能解决问题的商业领袖也很有用。对于人工智能开发者和思想领袖，本章将帮助你设计你的人工智能解决方案，以终端用户为中心，促进人工智能的采用。</p>
			<p>本章主要关注以下主题:</p>
			<ul>
				<li>以用户为中心的 XAI/ML 系统</li>
				<li>使用 EUCA 的快速 XAI 原型</li>
				<li>努力提高用户对使用 XAI 的人工智能/人工智能系统的接受度</li>
				<li>提供令人愉快的 UX</li>
				<li>XAI 的下一步是什么？</li>
			</ul>
			<p>让我们继续讨论下一部分的第一个话题。</p>
			<h1 id="_idParaDest-212">以用户为中心的 XAI/ML 系统</h1>
			<p>对于大多数工业问题，人工智能解决方案是孤立开发的，只有在最小可行的解决方案准备就绪后，用户才会在开发过程的最后阶段被引入。使用这种传统的方法，经常会发现产品领导或产品经理倾向于从开发团队的角度来设计解决方案，以满足用户的目标。嗯，这种方法绝对是好的，对于某些需要技术团队通过抽象进行开发的用例来说，它可能真的很好。然而，如果用户不参与实施过程的早期阶段，通常会发现用户不愿意采用该解决方案。因此，耐力思想集中于通过从解决方案的设计阶段就让最终用户参与进来来开发解决方案。</p>
			<p>耐力意识形态<a id="_idIndexMarker754"/>关注人机交互的原则，强调用户分布式认知的重要性。有了这种思想，由<strong class="bold">用户界面</strong> ( <strong class="bold"> UI </strong>)、<em class="italic"> AI 算法</em>、<em class="italic">底层数据集</em>、<em class="italic"> XAI 组件</em>和<em class="italic">终端用户体验</em>组成的整个解决方案被整体视为一个<em class="italic">系统</em>，而不是孤立地考虑各个组件。这确保了可解释性被嵌入到系统中，而不是作为附加服务提供给用户。据我观察，大多数工业人工智能解决方案是作为一个单独的组件孤立开发的，然后作为一个<em class="italic">附件</em>或<em class="italic">高级功能</em>添加到主软件系统中。同样，XAI 组件在单独开发后也被视为附加功能。因此，无缝 UX 可能会受到阻碍，人工智能解决方案和 XAI 组件的主要优势<a id="_idIndexMarker755"/>可能无法实现其全部潜力。这就是为什么我们应该专注于整个以用户为中心的 XAI/ML 系统的设计和开发。</p>
			<p>接下来，让我们讨论一下在设计解决方案时应该考虑的以终端用户为中心的 XAI 的各个方面。</p>
			<h2 id="_idParaDest-213"><a id="_idTextAnchor220"/>以最终用户为中心的 XAI 的不同方面</h2>
			<p>在本节中，我们<a id="_idIndexMarker756"/>将讨论在使用耐力思想设计 XAI 系统以弥合人工智能和最终用户之间的差距时，应整合的不同人为因素原则。</p>
			<h3>目标相关性</h3>
			<p>人机交互领域试图解决的主要<a id="_idIndexMarker757"/>问题是<em class="italic">谁是用户？</em>和<em class="italic">他们的需求是什么？</em>或者换句话说，它试图为用户理解解决方案的<em class="italic">目标相关性</em>。如果所提供的解决方案不能通过满足用户的需求而不引入其他挑战来有效地解决问题，那么它就是不相关的。不考虑目标相关性可能是大多数人工智能解决方案要么被废弃，要么带着许多怀疑被采纳的主要原因之一。</p>
			<p>评估目标相关性的推荐方法是检查用户是否可以在不引入其他挑战的情况下实现他们的目标。除了目标相关性，我经常建议评估解决方案的影响。当解决方案不存在时，可以通过获取用户的反馈来定性地测量解决方案的影响。</p>
			<h3>将用户需求与人工智能的优势联系起来</h3>
			<p>如前所述，在大多数工业用例中，XAI 被孤立地用于提供可解释性，而没有考虑用户需求。相反，利用耐力的思想，XAI 应该将用户需求与人工智能算法的强度联系起来。一旦确定了用户需求，<em class="italic">将用户需求转化为数据需求和模型需求</em>。如果底层数据集不足以满足所有用户需求，使用<strong class="bold">以数据为中心的 XAI </strong>到<a id="_idIndexMarker759"/>向用户传达数据集的局限性。如果确定了模型需求，使用 XAI 来解释模型的工作，并相应地进行调整以满足用户的需求。</p>
			<p>但是这个过程<a id="_idIndexMarker760"/>可能具有挑战性，因为它涉及识别用户现有的<em class="italic">心理模型</em>。随着人工智能和 XAI 的引入，现有的工作流程应该不会被打乱。</p>
			<p>此外，还建议使用 XAI，你尝试解释人工智能解决方案是否增加了任何独特的价值。但是设计可解释性方法来证明优势，而不是所使用的底层技术。例如，如果系统向用户传达复杂的深度学习算法用于预测结果，它不会增加用户的信心。相反，如果系统传达智能解决方案帮助用户以比传统方法快五倍的速度达到他们的目标，用户将同意采用该解决方案。</p>
			<h3>用户界面——连接用户和人工智能解决方案的媒介</h3>
			<p>考虑到传统方法，大多数人工智能实践者只关注开发精确的人工智能模型，而很少关注用户与模型的交互。通常，用户与 AI 组件的交互是由软件工程团队决定的；不幸的是，在大多数组织中，数据科学和人工智能团队在孤岛中工作。但是是用户界面控制着人工智能模型的可见性、可解释性或可解释性的水平，并在影响用户对系统的信任方面起着至关重要的作用。</p>
			<p>在<a href="B18216_10_ePub.xhtml#_idTextAnchor209"> <em class="italic">第十章</em> </a>、<em class="italic"> XAI 行业最佳实践</em>中，在讨论<strong class="bold">交互机器学习</strong> ( <strong class="bold"> IML </strong>)的同时，我们<a id="_idIndexMarker762"/>讨论了用户通过 UI 与系统的交互如何让用户对 AI/ML 系统的工作更有信心。因此，用户界面应该与人工智能模型及其可解释方法保持一致，以校准用户的信任度。你可以在 Google PAIR 的 People + AI 指南中找到更多关于<a id="_idIndexMarker763"/>使用 UI 校准用户信任度的信息:<a href="https://pair.withgoogle.com/chapter/explainability-trust/">https://pair.withgoogle.com/chapter/explainability-trust/</a>。</p>
			<h3>最终用户尽早参与解决方案的开发过程</h3>
			<p>与传统方法不同，以用户为中心的方法建议在开发过程的早期就让最终用户参与进来。最终用户实际上应该从系统 UI 的设计阶段就参与进来，这样用户的需求才能正确地映射到界面中。类似于解决方案的设计和开发生命周期，可解释性也应该通过从用户那里获得持续的反馈，在一个迭代的过程中发展。</p>
			<p>由于耐久性意识形态将 XAI/ML 系统视为一个解决方案，因此整个解决方案应该有一个<em class="italic">设计阶段</em>、<em class="italic">原型阶段</em>、<em class="italic">开发阶段</em>和<em class="italic">评估阶段</em>。这四个阶段将共同形成<em class="italic">一个设计和开发的迭代</em>。同样，整个解决方案应该在几次迭代中成熟，让用户参与到每次迭代的每个阶段。这个过程也与软件工程中遵循的<em class="italic">敏捷方法</em>一致。用户在每个阶段的参与确保收集有用的反馈，以评估用户的需求是否被解决方案满足。早期参与还可以确保用户熟悉新系统的设计和工作。用户对系统的熟悉程度提高了系统的采用率。</p>
			<h3>将反馈与个性化联系起来</h3>
			<p>正如上一节所讨论的，在解决方案的设计和开发的每个阶段，用户反馈的重要性是不可避免的。但是有时候，一个解决方案的通用框架并不能满足用户的所有需求。</p>
			<p>例如，当使用反事实的例子时，使用用于预测的所有特征生成一个例子在技术上是可能的。但是假设用户只对改变一组特定的可操作变量感兴趣。在这种情况下，受控反事实应该只修改用户感兴趣的特征。已经发现，定制的个性化解决方案通常比通用解决方案对最终用户更有用。因此，利用从用户那里获得的反馈，尝试提供满足用户具体痛点的个性化解决方案。</p>
			<h3>上下文和可操作的人工智能</h3>
			<p>正如我们之前在第 10 章<em class="italic">【XAI 行业最佳实践】</em>中讨论的那样，解释应该与上下文相关<a id="_idIndexMarker766"/>并具有可操作性。整个 XAI/ML 系统也应该与用户的行为保持一致，并且应该具有上下文感知能力。XAI 在将人工智能与用户的动作联系起来以及将任何人工智能<a id="_idIndexMarker767"/>解决方案修改为上下文相关的人工智能解决方案方面发挥着至关重要的作用。</p>
			<p><em class="italic"> Oliver Brdiczka </em>在他的文章<em class="italic">中<a id="_idIndexMarker768"/>定义了<a id="_idIndexMarker768"/>以下<a id="_idIndexMarker769"/>情境人工智能的四大支柱:</em></p>
			<ul>
				<li>可理解的:上下文相关的人工智能系统应该能够解释它的知识和工作。</li>
				<li><strong class="bold">适应性</strong>:情境<a id="_idIndexMarker771"/>人工智能系统应该能够适应用户在不同环境中的不同需求。</li>
				<li><strong class="bold">可定制</strong>:<a id="_idIndexMarker772"/>用户应该能够控制或修改系统以满足他们的需求。</li>
				<li>环境感知:系统<a id="_idIndexMarker773"/>应该能够感知与人类相同层次的事物。</li>
			</ul>
			<p>下图显示了上下文 AI 的四个不同的<a id="_idIndexMarker774"/>组件:</p>
			<div><div><img src="img/B18216_11_001.jpg" alt="Figure 11.1 – Four components of contextual AI (inspired by https://business.adobe.com/blog/perspectives/contextual-ai-the-next-frontier-of-artificial-intelligence) &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 11.1-情境人工智能的四个组成部分(灵感来自 https://business . adobe . com/blog/perspectives/contextual-AI-the next-frontier-of-artificial-intelligence)</p>
			<p>因此，考虑到<a id="_idIndexMarker775"/>以用户为中心的方法，XAI/ML 系统的<a id="_idIndexMarker776"/> XAI 组件应该提供可操作的见解，并且它应该是上下文相关的，以进一步弥合人工智能和最终用户之间的差距。既然我们已经讨论了以用户为中心的方法来弥合人工智能和最终用户之间可能的差距，考虑到在<a href="B18216_10_ePub.xhtml#_idTextAnchor209"> <em class="italic">第十章</em> </a>，<em class="italic"> XAI 行业最佳实践</em>中讨论的 XAI 的公开挑战，让我们讨论使用<strong class="bold">最终用户为中心的可解释人工智能</strong> ( <strong class="bold"> EUCA </strong>)框架来制作快速 XAI 原型<a id="_idIndexMarker777"/>。</p>
			<h1 id="_idParaDest-214"><a id="_idTextAnchor222"/>使用 EUCA 的快速 XAI 原型</h1>
			<p>在前面的<a id="_idIndexMarker778"/>部分，我们讨论了以用户为中心的 XAI/ML 系统的关键要素。在本节中，将强调快速原型制作<a id="_idIndexMarker779"/>在耐久性理念中的重要性。<em class="italic">快速原型</em>是软件工程中主要采用的概念，因为软件可能是人类创造的最具可塑性的东西。构建快速原型是在软件产品开发过程的早期收集有用的用户反馈的一种方法。因此，即使是设计以用户为中心的 XAI/ML 系统，快速原型也是非常重要的。</p>
			<p>金等人在他们的研究工作《以终端用户为中心的可解释人工智能框架》中介绍了一个叫的工具包。EUCA 是一个非常有趣的框架，主要由 UX 研究人员、人机交互研究人员和设计人员、人工智能科学家和开发人员设计，用于为非技术终端用户快速构建 XAI 原型。在 https://github.com/weinajin/end-user-xai<a href="https://github.com/weinajin/end-user-xai"/>可以获得 EUCA 框架的官方 GitHub 库。强烈建议使用 EUCA 构建低保真度原型，并根据 XAI/ML 系统的持续用户反馈迭代改进原型。</p>
			<p>该框架提供了以下重要的<a id="_idIndexMarker783"/>组件:</p>
			<ul>
				<li>设计人性化解释的 12 种解释形式</li>
				<li>用于与功能原型集成的相应 XAI 算法</li>
				<li>相关设计模板及其用法示例</li>
				<li>建议的原型工作流</li>
				<li>从用户研究结果中获得的各种解释方法的详细优点和缺点</li>
				<li>对终端用户的不同解释需求进行科学分析(例如信任校准、偏见检测以及与人工智能解决分歧)</li>
			</ul>
			<p>下图说明了 EUCA 框架目前支持的不同类型的解释方法:</p>
			<div><div><img src="img/B18216_11_002.jpg" alt="Figure 11.2 – Different types of explanation methods supported in EUCA &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 11.2-EUCA 支持的不同类型的解释方法</p>
			<p>这个<a id="_idIndexMarker785"/>框架是一个很好的起点，并明确推荐<a id="_idIndexMarker786"/>用于构建快速 XAI 原型。接下来，让我们讨论一些额外的努力来增加用户对 AI/ML 系统的接受度。</p>
			<h1 id="_idParaDest-215">努力提高用户对使用 XAI 的人工智能/人工智能系统的接受度</h1>
			<p>在本节中，我们<a id="_idIndexMarker787"/>将讨论<a id="_idIndexMarker788"/>一些推荐的实践，以提高使用 XAI 的 AI/ML 系统的接受度。在大多数软件系统中，<strong class="bold">用户验收测试</strong> ( <strong class="bold"> UAT </strong>)阶段用于确定软件的<em class="italic">通过</em>或<em class="italic">不通过</em>。类似地，在最后的生产阶段之前，越来越多的组织喜欢为 AI/ML 系统做一个健壮的 UAT 过程。但是<em class="italic">当做人工智能/人工智能系统的 UAT 时，人工智能算法的可解释性有多重要？</em> <em class="italic">可解释性能增加 AI 的用户接受度吗？</em>简而言之就是<em class="italic">是的</em>！让我们通过以下几点来了解原因:</p>
			<ul>
				<li><strong class="bold">用户接受度是用户信任度的见证</strong>——由于 XAI 可以增加用户对 AI 的信任度，因此增加了用户接受解决方案的几率。在 UAT 阶段，信任是无法建立的。相反，应该从一开始就建立信任，并在整个开发过程中保持信任。系统的功能和限制应该从一开始就进行沟通，以便对什么是可能的，什么是不可能的设定一个明确的预期。</li>
				<li><strong class="bold">风险承受能力评估作为 UAT 标准</strong>–很明显，人工智能系统不可能每次都 100%准确。实现零误差或零故障的系统实际上是不可能的。但是作为推荐的做法，记录系统可能的故障点是很重要的，系统潜在故障的后果被称为<strong class="bold">风险</strong>。<strong class="bold">风险容忍度</strong>是系统在不造成巨大冲击的情况下所能允许的最大误差<a id="_idIndexMarker791"/>。因此，在 UAT 阶段，定义解决方案的风险并估计用户的最大风险承受能力是非常重要的。系统在风险承受范围内运行的能力应被视为 UAT 进程的成功标准。</li>
				<li><strong class="bold">在 UAT 流程</strong>之前，尽可能多地进行用户研究——用户研究以及对用户反馈的定性和定量分析是评估系统影响和信任度的特定方法。因此，在 UAT 流程之前，执行多个<a id="_idIndexMarker792"/>用户研究<a id="_idIndexMarker793"/>，并确保用户在直接将系统投入生产之前接受原型解决方案。</li>
			</ul>
			<p>前面的<a id="_idIndexMarker794"/>方法是增加用户接受度的某些方法，但最终，用户接受度取决于整体 UX。在下一节，我们将进一步讨论提供一个愉快的 UX 的重要性。</p>
			<h1 id="_idParaDest-216">提供一个令人愉快的 UX</h1>
			<p>在本节中，我们将重点介绍整体 UX 对推广采用 XAI/洗钱系统的重要性。亚伦·沃尔特，在他的书<em class="italic">为情感而设计</em>(【https://abookapart.com/products/designing-for-emotion】的)中，提到了用户需求的一些基本<a id="_idIndexMarker795"/>要素，在更高的动机能够影响用户的行为之前，必须满足这些要素。根据他的用户需求层次，令人愉快的 UX 位于金字塔的顶端。下图显示了 Aaron Walter 的用户需求层次结构:</p>
			<div><div><img src="img/B18216_11_003.jpg" alt="Figure 11.3 – Aaron Walter's hierarchy of user needs&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 11.3-Aaron Walter 的用户需求层次</p>
			<p>这种用户需求层次定义了最终用户的基本需求，在满足用户的任何高级需求之前，应该满足这些基本需求。所以，如果一个系统只有<em class="italic">功能性</em>、<em class="italic">可靠性</em>和<em class="italic">可用性</em>，那么采用这个系统是不够的，除非整个 UX 是令人愉快的！因此，XAI/ML 系统也应该考虑提供无缝的整体体验，以真正弥合人工智能终端用户的差距。</p>
			<p>这就把我们带到了本书最后一章的结尾。我们将在下一部分总结讨论的关键话题。</p>
			<h1 id="_idParaDest-217"><a id="_idTextAnchor225"/>总结</h1>
			<p>在这一章中，我们主要讨论了在 XAI/ML 系统的设计和开发中使用耐久性的思想。我们已经讨论了使用 XAI 引导我们实现最终用户构建 XAI/ML 系统的主要目标的重要性。使用本章中介绍的一些原则和推荐的最佳实践，我们可以在很大程度上弥合人工智能和最终用户之间的差距！</p>
			<p>这也把我们带到了这本书的结尾！祝贺你到达终点！这本书经过精心设计，包括对各种 XAI 概念和术语的概念性理解，使用流行的 XAI 框架解决应用问题的实际例子，从工业角度看的真实生活例子和经验，以及对重要研究文献的参考，以进一步扩展您的知识。这本书从工业和学术研究的角度向你介绍了 XAI 领域。本书中讨论的开放挑战和 XAI 研究课题的下一阶段是人工智能研究社区正在探索的重要研究问题。</p>
			<p>尽管这本书几乎触及了 XAI 领域的每一个方面，但显然还有更多需要探索和解开。我的建议是不要把自己局限于这本书所提供的内容。相反，使用这本书作为参考起点，但探索和应用从这本书获得的知识到实际的使用案例，并向前一步，为社区作出贡献！</p>
			<h1 id="_idParaDest-218"><a id="_idTextAnchor226"/>参考文献</h1>
			<p>请参考以下资源以获取更多信息:</p>
			<ul>
				<li><em class="italic">谷歌配对的人+人工智能指南</em>:【https://pair.withgoogle.com/chapter/explainability-trust/ T2】</li>
				<li><em class="italic">金等</em>，【】https://arxiv.org/abs/2102.02437:以终端用户为中心的可解释人工智能框架:<a href="https://arxiv.org/abs/2102.02437"/></li>
				<li><em class="italic">https://github.com/weinajin/end-user-xai EUCA:以终端用户为中心的可解释人工智能框架 GitHub 知识库</em>:<a href="https://github.com/weinajin/end-user-xai">T3】</a></li>
				<li><em class="italic">伦沃特</em>，<em class="italic">为情感而设计</em>:【https://abookapart.com/products/designing-for-emotion】T4</li>
				<li><em class="italic">奥利弗·布迪茨卡</em>，<em class="italic">情境人工智能:人工智能的下一个前沿</em>:<em class="italic"/><a href="https://business.adobe.com/blog/perspectives/contextual-ai-the-next-frontier-of-artificial-intelligence">https://business . adobe . com/blog/perspectives/Contextual-AI-The-Next-Frontier-of-Artificial-Intelligence</a></li>
			</ul>
		</div>
	

</body></html>