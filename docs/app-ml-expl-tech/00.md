

# 前言

**可解释的人工智能(XAI)** 是一个新兴领域，旨在使**人工智能(人工智能)**更接近非技术终端用户。XAI 承诺使**机器学习(ML)** 模型透明、可信，并促进人工智能在工业和研究用例中的应用。

这本书是为在 XAI 获得实用技能而设计的，独特地融合了工业和学术研究的观点。从事数据科学、ML、深度学习和人工智能工作的 ML/AI 专家将能够将他们的知识用于这本 XAI 实用指南，以弥合人工智能和最终用户之间的差距。这本书提供了一个实践方法的实施和相关的 XAI 方法，将有你启动和运行，并在任何时候生产。

最初，你会对 XAI 有一个概念性的了解，以及为什么需要它。然后，你将通过利用最先进的方法和框架，获得在 AI/ML 问题解决过程中利用 XAI 的必要实践经验。最后，你将获得必要的指导方针，带领 XAI 进入下一步，并弥合人工智能和最终用户之间的现有差距。

到本书结束时，你将能够使用 Python 实现 XAI 方法和途径来解决工业问题，解决遇到的关键痛点，并遵循 AI/ML 生命周期中的最佳实践。

# 这本书是给谁的

这本书是为活跃在 ML 领域和相关领域的科学家、研究人员、工程师、建筑师和经理设计的。总的来说，任何对使用人工智能解决问题感兴趣的人都会从这本书中受益。建议你具备 Python、ML、深度学习、数据科学的基础知识。本书非常适合担任以下角色的读者:

*   数据和人工智能科学家
*   人工智能/人工智能工程师
*   AI/ML 产品经理
*   人工智能产品所有者
*   人工智能/人工智能研究人员
*   用户体验和人机交互研究人员

一般来说，任何具有 Python 基础知识的 ML 爱好者都能够阅读、理解并应用从本书中获得的知识。

# 这本书涵盖了什么

[*第一章*](B18216_01_ePub.xhtml#_idTextAnchor014) ，*可解释技术的基本概念，*给出了对可解释 AI 的必要介绍，并帮助你理解它的重要性。本章涵盖了与可解释性技术相关的各种术语和概念，这在本书中经常使用。这一章也涵盖了人类友好的可解释的 ML 系统的关键标准和评估可解释技术质量的不同方法。

[*第二章*](B18216_02_ePub.xhtml#_idTextAnchor033) 、*模型可解释方法、*讨论了用于解释黑盒模型的各种模型可解释方法。其中一些是模型不可知的，一些是模型特定的。这些方法中的一些提供全局可解释性，而另一些提供局部可解释性。本章将向你介绍各种可以用来解释 ML 模型的技术，并提供正确选择可解释性方法的建议。

[*第三章*](B18216_03_ePub.xhtml#_idTextAnchor053) ，*以数据为中心的方法，*介绍了以数据为中心的 XAI 的概念。本章涵盖了各种技术，从数据属性、数据量、数据一致性、数据纯度和从基础训练数据集生成的可操作洞察方面解释了 ML 系统的工作。

[*第四章*](B18216_04_ePub.xhtml#_idTextAnchor076) ，*LIME for Model inter ability*，涵盖了应用最流行的一个 XAI 框架，叫做 LIME。本章讨论了 LIME 算法工作背后的直觉，以及该算法的一些重要属性，这些属性使得生成的解释对人友好。本章还讨论了 LIME 算法的某些优点和局限性，以及将 LIME 应用于分类问题的代码教程。

[*第 5 章*](B18216_05_ePub.xhtml#_idTextAnchor088) ，*在 ML 中使用 LIME 的实际体验*是上一章的扩展，但更侧重于 LIME Python 框架在不同类型数据集上的实际应用，如图像、文本以及结构化表格数据。本章还介绍了一些实用的代码示例，以提供使用 Python LIME 框架的实际知识。本章还介绍了 LIME 是否适合生产级 ML 系统。

[*第六章*](B18216_06_ePub.xhtml#_idTextAnchor107) 、*模型可解释性使用 SHAP* 重点理解 SHAP Python 框架对于模型可解释性的重要性。它涵盖了对沙普利价值观和 SHAP 的直观理解。本章还讨论了如何通过各种可视化和解释器方法使用 SHAP 进行模型解释。本章还介绍了使用 SHAP 解释回归模型的代码演练。最后，我们将讨论 SHAP 的主要优势和局限性。

[*第 7 章*](B18216_07_ePub.xhtml#_idTextAnchor128) ，*在 ML 中使用 SHAP 的实践经验*提供了使用 SHAP 处理表格结构数据以及图像和文本等非结构数据的必要实践经验。我们已经讨论了在 SHAP 可以得到的不同的解释器，包括模型特定的和模型不可知的解释能力。在本章中，我们应用 SHAP 解释了线性模型、树集成模型、卷积神经网络模型，甚至变压器模型。本章还介绍了必要的代码教程，以提供使用 Python SHAP 框架的实践知识。

[*第八章*](B18216_08_ePub.xhtml#_idTextAnchor154) ，*与 TCAV 的人性化解释*涵盖了谷歌 AI 开发的框架 TCAV 的概念。本章提供了对 TCAV 的概念性理解以及应用 Python TCAV 框架的实际操作。本章讨论了 TCAV 的主要优势和局限性，以及关于可以使用基于概念的解释来解决的潜在研究问题的有趣想法。

[*第九章*](B18216_09_ePub.xhtml#_idTextAnchor172) 、*其他流行的 XAI 框架*涵盖了 Python 中可用的大约七个流行的 XAI 框架——DALEX、Explainerdashboard、InterpretML、ALIBI、DiCE、ELI5、H2O AutoML explainers。我们已经讨论了每个框架支持的解释方法、实际应用以及每个框架的各种优缺点。本章还提供了一个快速比较指南，帮助你决定考虑你自己的用例时应该选择哪个框架。

[*第十章*](B18216_10_ePub.xhtml#_idTextAnchor209) ， *XAI 行业最佳实践*聚焦于为工业问题设计可解释的 AI 系统的最佳实践。在这一章中，我们已经讨论了 XAI 的公开挑战以及考虑到公开挑战的可解释的 ML 系统的必要设计指南。我们还强调了考虑以数据为中心的可解释方法、交互式机器学习和规范见解对于设计可解释的 AI/ML 系统的重要性。

[*第十一章*](B18216_11_ePub.xhtml#_idTextAnchor217) 、*以最终用户为中心的人工智能*介绍了以最终用户为中心的人工智能(耐力)思想，用于可解释 AI/ML 系统的设计和开发。我们已经讨论了使用 XAI 来引导最终用户的主要目标对于构建可解释的 AI/ML 系统的重要性。使用本章介绍的一些原则和推荐的最佳实践，我们可以在很大程度上弥合人工智能和最终用户之间的差距！

# 为了充分利用这本书

要运行本书中提供的代码教程，您需要一个带有 Python 3.6+的 Jupyter 环境。这可以通过以下任一方式实现:

*   通过 **Anaconda Navigator** 在你的机器上安装一个，或者用 **pip** 从头开始安装。
*   使用基于云的环境，例如**谷歌合作实验室**、 **Kaggle 笔记本**、 **Azure 笔记本**或**亚马逊 SageMaker** 。

如果你是 Jupyter 笔记本的新手，可以看看代码库中提供的补充信息:[https://github . com/packt publishing/Applied-Machine-Learning-explability-Techniques/blob/main/SupplementaryInfo/code setup . MD](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/SupplementaryInfo/CodeSetup.md)。

也可以看一下[https://github . com/packt publishing/Applied-Machine-Learning-explability-Techniques/blob/main/supplement aryinfo/Python packageinfo . MD](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/SupplementaryInfo/PythonPackageInfo.md)和[https://github . com/packt publishing/Applied-Machine-Learning-explability-Techniques/blob/main/supplement aryinfo/datasetinfo . MD](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/SupplementaryInfo/DatasetInfo.md)获取教程笔记本中使用的 Python 包和数据集的补充信息。

有关安装本书中使用的 Python 包的说明，请参考代码库中提供的特定笔记本。如果需要任何额外的帮助，请参考特定包的原始项目库。您可以使用**PyPi**(【https://pypi.org/】T2)来搜索特定的包并导航到项目的代码库。考虑到软件包更改的频率，预计这些软件包的安装或执行指令会不时更改。我们还测试了代码库提供的补充信息下的 *Python 包信息自述文件*中详细描述的特定版本的代码。因此，如果在以后的版本中出现任何不正常的情况，请安装自述文件中提到的特定版本。

如果你正在使用这本书的数字版本，我们建议你自己输入代码或者从这本书的 GitHub 库中获取代码(下一节有链接)。这样做将帮助您避免任何与复制和粘贴代码相关的潜在错误。

对于没有接触过 ML 或数据科学的初学者，建议顺序阅读本书，因为许多重要的概念在前面的章节中有足够详细的解释。经验丰富的 ML 或数据科学专家对 XAI 领域相对较新，他们可以浏览前三章，对所使用的各种术语有清晰的概念理解。对于第四至第九章，任何顺序对经验丰富的专家来说都可以。对于所有级别的从业者，建议您在阅读完所有九章后再阅读第十章和第十一章。

关于提供的代码，建议您要么阅读每一章，然后运行相应的代码，要么您可以在阅读特定章节的同时运行代码。Jupyter 笔记本中还添加了充足的理论，帮助您了解笔记本的整体流程。

当你阅读这本书时，建议你记下书中涉及的重要术语，并试着思考如何应用所学的概念或框架。在阅读完这本书并浏览完所有的 Jupyter 笔记本后，希望你能受到启发，将新学到的知识运用到行动中去！

# 下载示例代码文件

你可以从 GitHub 的 https://GitHub . com/packt publishing/Applied-Machine-Learning-explability-Techniques 下载本书的示例代码文件。如果代码有更新，它会在 GitHub 库中更新。

我们在[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)也有丰富的书籍和视频目录中的其他代码包。看看他们！

# 下载彩色图片

我们还提供了一个 PDF 文件，其中有本书中使用的截图和图表的彩色图像。你可以在这里下载:[https://packt.link/DF7lG](https://packt.link/DF7lG)。

# 使用的惯例

本书通篇使用了许多文本约定。

`Code in text`:表示文本中的码字、数据库表名、文件夹名、文件名、文件扩展名、路径名、伪 URL、用户输入和 Twitter 句柄。下面是一个例子:“对于这个例子，我们将使用`RegressionExplainer`和`ExplainerDashboard`子模块。”

代码块设置如下:

```
pdp = PartialDependence(
```

```
    predict_fn=model.predict_proba,
```

```
    data=x_train.astype('float').values,
```

```
    feature_names=list(x_train.columns),
```

```
    feature_types=feature_types)
```

```
pdp_global=pdp.explain_global(name='Partial Dependence')
```

当我们希望将您的注意力吸引到代码块的特定部分时，相关的行或项目以粗体显示:

```
explainer = shap.Explainer(model, x_test)
```

```
shap_values = explainer(x_test)
```

```
shap.plots.waterfall(shap_values[0], max_display = 12,
```

```
                     show=False)
```

**Bold** :表示一个新术语、一个重要单词或您在屏幕上看到的单词。例如，菜单或对话框中的单词以**粗体**出现。这里有一个例子:“由于这些已知的缺点，寻找一个健壮的**可解释的人工智能(XAI)** 框架的工作仍在进行。”

提示或重要注意事项

像这样出现。

# 取得联系

我们随时欢迎读者的反馈。

**总体反馈**:如果您对本书的任何方面有疑问，请发邮件至 customercare@packtpub.com[给我们，并在邮件主题中提及书名。](mailto:customercare@packtpub.com)

**勘误表**:虽然我们已经尽力确保内容的准确性，但错误还是会发生。如果你在这本书里发现了一个错误，请告诉我们，我们将不胜感激。请访问 www.packtpub.com/support/errata[并填写表格。](http://www.packtpub.com/support/errata)

**盗版**:如果您在互联网上遇到我们作品的任何形式的非法拷贝，如果您能提供我们的地址或网站名称，我们将不胜感激。请通过 copyright@packt.com 的[联系我们，并提供材料链接。](mailto:copyright@packt.com)

**如果你有兴趣成为一名作家**:如果有你擅长的主题，并且你有兴趣写书或投稿，请访问 authors.packtpub.com。

# 分享你的想法

一旦你阅读了*应用机器学习解释技巧*，我们很想听听你的想法！请点击这里直接进入亚马逊对这本书的评论页面，并分享你的反馈。

您的评论对我们和技术社区非常重要，将有助于我们确保提供高质量的内容。