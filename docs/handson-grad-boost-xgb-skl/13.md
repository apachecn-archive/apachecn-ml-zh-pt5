

# *第十章* : XGBoost 模型部署

在 XGBoost 的最后一章中，您将把所有的东西放在一起，开发新的技术来构建一个健壮的机器学习模型，这个模型是行业现成的。为行业部署模型与为研究和竞争构建模型略有不同。在工业中，自动化很重要，因为新数据会频繁到达。更多地强调程序，而不是强调通过调整机器学习模型来获得微小的百分点。

具体来说，在这一章中，你将获得关于**一键编码**和**稀疏矩阵**的重要经验。此外，您将实现并定制 scikit-learn transformers，以自动化机器学习管道，对混合了**分类**和**数字**列的数据进行预测。在本章结束时，你的机器学习管道将为任何传入的数据做好准备。

在本章中，我们将讨论以下主题:

*   编码混合数据

*   定制 sci kit-学习变压器

*   最终确定 XGBoost 模型

*   构建机器学习管道

# 技术要求

本章的代码可以在[https://github . com/packt publishing/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/tree/master/chapter 10](https://github.com/PacktPublishing/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/tree/master/Chapter10)找到。

# 编码混合数据

想象一下，你在一家教育技术公司工作，你的工作是预测学生的成绩，以提供旨在弥合技术技能差距的服务。第一步是将包含学生成绩的数据加载到`pandas`中。

## 加载数据

由贵公司提供的学生成绩数据集可以通过加载已经为您导入的`student-por.csv`文件来访问。

从导入`pandas`和消除警告开始。然后，下载数据集并查看前五行:

```
import pandas as pd
import warnings
warnings.filterwarnings('ignore')
df = pd.read_csv('student-por.csv')
df.head()
```

以下是预期的输出:

![Figure 10.1 – The Student Performance dataset as is](img/B15551_10_01.jpg)

图 10.1–学生表现数据集

欢迎来到工业世界，数据并不总是像预期的那样出现。

建议查看 CSV 文件。这可以在 Jupyter 笔记本中通过找到本章的文件夹并点击`student-por.csv`文件来完成。

您应该看到以下内容:

![Figure 10.2 – The Student Performance CSV file](img/B15551_10_02.jpg)

图 10.2–学生成绩 CSV 文件

正如您在前面的图中看到的，数据由分号分隔。CSV 代表`pandas`的带有一个`sep`参数，其中代表**分隔符**，可以设置为分号，(*)；*)，如下:

```
df = pd.read_csv('student-por.csv', sep=';')
df.head()
```

以下是预期的输出:

![Figure 10.3 – The Student Performance dataset ](img/B15551_10_03.jpg)

图 10.3–学生表现数据集

既然 DataFrame 看起来像预期的那样，混合了类别值和数值的 ，我们必须清除**空值**。

## 清除空值

您可以通过调用`df.insull()`上的`.sum()`方法来查看空值的所有列。以下是调查结果的摘录:

```
df.isnull().sum()
school        0
sex           1
age           1
address       0
…
health        0
absences      0
G1            0
G2            0
G3            0
dtype: int64
```

您可以使用条件符号查看这些列的行，方法是将`df.isna().any(axis=1)`放在带有`df`的括号内:

```
df[df.isna().any(axis=1)]
```

以下是预期的输出:

![Figure 10.4 – The Student Performance null data](img/B15551_10_04.jpg)

图 10.4-学生成绩空数据

最好是看到中间的空列，Jupyter 根据列的数量默认删除了空列。这很容易通过将`max columns`设置为`None`来纠正，如下所示:

```
pd.options.display.max_columns = None
```

现在，再次运行代码会显示所有列:

```
df[df.isna().any(axis=1)]
```

以下是预期输出的摘录:

![Figure 10.5 – Null data from all rows of the Student Performance dataset](img/B15551_10_05.jpg)

图 10.5-学生成绩数据集中所有行的空数据

如您所见，现在显示了所有列，包括`'guardian'`下隐藏的空值。

数值空值可以设置为-999.0，或者其他值，XGBoost 将使用 [*第 5 章*](B15551_05_Final_NM_ePUB.xhtml#_idTextAnchor117) ， *XGBoost 发布*中介绍的`missing`超参数为您找到最佳替代值。

下面是用`-999.0`填充`'age'`列的代码:

```
df['age'].fillna(-999.0)
```

接下来，分类列可以由模式填充。模式是列中最常见的情况。但是，仅当空值的数量很大时，使用模式填充分类列可能会扭曲结果分布。只有两个空值，所以我们的分布不会受到影响。另一个选项包括用'`unknown`'字符串替换分类空值，这可能在一次性编码后成为它自己的列。请注意，XGBoost 需要数字输入，因此从 2020 年起，`missing`超参数不能直接应用于分类列。

以下代码将`'sex'`和`'guardian'`分类列转换为`mode`:

```
df['sex'] = df['sex'].fillna(df['sex'].mode())
df['guardian'] = df['guardian'].fillna(df['guardian'].mode())
```

由于我们的空值在前两行中，我们可以发现它们已经使用`df.head()`进行了更改:

```
df.head()
```

以下是预期的输出:

![Figure 10.6 – The Student Performance dataset with the null values removed (first five rows only)](img/B15551_10_06.jpg)

图 10.6–删除空值后的学生成绩数据集(仅前五行)

空值已经如预期的那样全部被清除。

接下来，我们将使用 one-hot 编码将所有分类列转换为数字列。

## 一键编码

之前，我们使用`pd.get_dummies`将所有分类变量转换为`0`和`1`的数值，其中`0`表示不存在，`1`表示存在。虽然这种方法是可以接受的，但是它有一些缺点。

第一个缺点是`pd.get_dummies`的计算开销很大，正如你在前面章节中等待代码运行时发现的那样。第二个缺点是`pd.get_dummies`不能很好地转化为 scikit-learn 的管道，这个概念我们将在下一节探讨。

scikit-learn 的`OneHotEncoder`是`pd.get_dummies`的一个很好的替代品。像`pd.get_dummies`一样，一键编码将所有分类值转换为`0`和`1`，其中`0`表示不存在，`1`表示存在，但与`pd.get_dummies`不同，它的计算开销并不大。`OneHotEncoder`使用稀疏矩阵代替密集矩阵，节省空间和时间。

稀疏矩阵通过只存储值不包括 0 的数据来节省空间。通过使用更少的比特，同样数量的信息得以保存。

此外，`OneHotEncoder`是一个 scikit-learn 转换器，这意味着它是专门设计用于机器学习管道的。

在 scikit-learn 的过去版本中，`OneHotEncoder`只接受数字输入。在这种情况下，使用`LabelEncoder`进行中间步骤，首先将所有分类列转换为数字列。

要在特定列上使用`OneHotEncoder`,您可以使用以下步骤:

1.  将`dtype`对象的所有分类列转换成一个列表:

    ```
    categorical_columns = df.columns[df.dtypes==object].tolist()
    ```

2.  导入并初始化`OneHotEncoder`:

    ```
    from sklearn.preprocessing import OneHotEncoder
    ohe = OneHotEncoder()
    ```

3.  在列上使用`fit_transform`方法:

    ```
    hot = ohe.fit_transform(df[categorical_columns])
    ```

4.  `0`或`1`。

5.  如果你想看到`hot`稀疏矩阵的实际样子，你可以打印出来如下:

    ```
    print(hot)
    ```

    以下是调查结果的摘录:

    ```
      (0, 0)		1.0
      (0, 2)		1.0
      (0, 5)		1.0
      (0, 6)		1.0
      (0, 8)		1.0
    …  
    0 have been skipped. For instance, the 0th row and the 1st column, denoted by (0, 1), has a value of 0.0 in the dense matrix, but it's skipped over in the one-hot matrix.
    ```

如果你想要更多关于稀疏矩阵的信息，只需输入下面的变量:

```
hot
```

结果如下:

```
<649x43 sparse matrix of type '<class 'numpy.float64'>'
	with 11033 stored elements in Compressed Sparse Row format>
```

这告诉我们矩阵是由`43`乘以`649`，但是只有`11033`的值被存储，节省了大量的空间。请注意，对于有许多零的文本数据，稀疏矩阵非常常见。

## 组合独热编码矩阵和数字列

既然我们已经有了一个一键编码的稀疏矩阵，我们必须将它与原始数据帧的数字列结合起来。

首先，让我们隔离数字列。这可以通过将`exclude=["object"]`参数作为`df.select_dtypes`的输入来完成，T1 选择特定类型的列，如下所示:

```
cold_df = df.select_dtypes(exclude=["object"])
cold_df.head()
```

以下是预期的输出:

![Figure 10.8 – The Student Performance dataset's numerical columns](img/B15551_10_08.jpg)

图 10.8–学生成绩数据集的数字列

这些是我们正在寻找的列。

对于这种大小的数据，我们有一个选择，即将稀疏矩阵转换为常规数据帧，如前面的屏幕截图所示，或者将该数据帧转换为稀疏矩阵。让我们追求后者，考虑到工业中的数据帧可能变得巨大，节省空间可能是有利的:

1.  要将`cold_df`数据帧转换为压缩的稀疏矩阵，从`scipy.sparse`导入`csr_matrix`并将数据帧放入其中，如下所示:

    ```
    from scipy.sparse import csr_matrix
    cold = csr_matrix(cold_df)
    ```

2.  最后，通过导入和使用`hstack`来堆叠热和冷两个矩阵，这水平地组合了稀疏矩阵:

    ```
    from scipy.sparse import hstack
    final_sparse_matrix = hstack((hot, cold))
    ```

3.  通过将稀疏矩阵转换为密集矩阵并照常显示数据帧，验证`final_sparse_matrix`是否按预期工作:

    ```
    final_df = pd.DataFrame(final_sparse_matrix.toarray())
    final_df.head()
    ```

    以下是预期的输出:

![Figure 10.9 – The DataFrame of the final sparse matrix](img/B15551_10_09.jpg)

图 10.9–最终稀疏矩阵的数据框架

输出向右移动到一起显示一位热码和数字列。

既然数据已经为机器学习做好了准备，让我们使用转换器和管道来自动化这个过程。

# 定制 scikit-学习变形金刚

既然我们有了将数据帧转换成机器学习就绪的稀疏矩阵的过程，那么用转换器来概括该过程将是有利的，这样就可以很容易地为新数据的到来重复该过程。

Scikit-learn 转换器通过使用一种用于查找模型参数的`fit`方法和一种用于将这些参数应用于数据的`transform`方法，与机器学习算法一起工作。这些方法可以组合成一个单一的`fit_transform`方法，在一行代码中适应和转换数据。

当一起使用时，各种转换器，包括机器学习算法，可以在同一管道中一起工作，以便于使用。然后将数据放入管道中，对其进行拟合和转换，以获得所需的输出。

Scikit-learn 附带了许多优秀的转换器，比如分别用于标准化和规范化数据的`StandardScaler`和`Normalizer`，以及用于转换空值的`SimpleImputer`。但是，当数据包含分类列和数字列的混合时，就像这里的情况一样，您必须小心。在某些情况下，scikit-learn 选项可能不是自动化的最佳选项。在这种情况下，创建您自己的变形金刚来做您想做的事情是值得的。

## 定制变压器

创建你自己的变形金刚的关键是使用 scikit-learn 的`TransformerMixin`作为你的超类。

下面是在 scikit-learn 中创建定制转换器的一般代码大纲:

```
class YourClass(TransformerMixin):
    def __init__(self):
        None
    def fit(self, X, y=None):
        return self
    def transform(self, X, y=None):
        # insert code to transform X
        return X
```

如你所见，你不需要初始化任何东西，`fit`总是可以返回`self`。简单地说，您可以将所有用于转换数据的代码放在`transform`方法下。

现在您已经了解了定制的一般工作方式，让我们创建一个定制的转换器来处理不同类型的空值。

### 自定义混合空值估算器

让我们通过创建一个定制的混合空值估算器来看看这是如何工作的。这里，定制的原因是用不同的方法处理不同类型的列，以纠正空值。

以下是步骤:

1.  导入`TransformerMixin`并定义一个以`TransformerMixin`为超类的新类:

    ```
    from sklearn.base import TransformerMixin 
    class NullValueImputer(TransformerMixin):
    ```

2.  用`self`作为输入初始化类。如果这没什么用也没关系:

    ```
    def __init__(self):
    None
    ```

3.  创建一个以`self`和`X`为输入的`fit`方法，带`y=None`，返回`self`:

    ```
    def fit(self, X, y=None):
    return self
    ```

4.  创建一个`transform`方法，将`self`和`X`作为输入，使用`y=None`，通过返回一个新的`X`来转换数据，如下所示:

    ```
    def transform(self, X, y=None):
    ```

    我们需要根据列分别处理空值。

    下面是根据列类型将 null 值转换为 mode 或`-999.0`的步骤:

    a)通过将列转换为列表来循环遍历这些列:

    ```
    for column in X.columns.tolist():
    ```

    b)在循环中，通过检查哪些列属于`object`数据类型来访问字符串列:

    ```
        if column in X.columns[X.dtypes==object].tolist():
    ```

    c)将字符串(`object`)列的空值转换为模式:

    ```
            X[column] = X[column].fillna(X[column].mode())
    ```

    d)否则，用`-999.0`填充栏:

    ```
        else:
            X[column]=X[column].fillna(-999.0)
          return X
    ```

在前面的代码中，您可能想知道为什么要使用`y=None`。原因是当在流水线中包括机器学习算法时，将需要`y`作为输入。通过将`y`设置为`None`，将仅按照预期对预测器列进行更改。

既然已经定义了定制的估算器，就可以通过对数据调用`fit_transform`方法来使用它。

让我们通过从 CSV 文件建立一个新的 DataFrame 来重置数据，并使用定制的`NullValueImputer`在一行代码中转换空值:

```
df = pd.read_csv('student-por.csv', sep=';')
nvi = NullValueImputer().fit_transform(df)
nvi.head()
```

以下是预期的输出:

![Figure 10.10 – The Student Performance DataFrame after NullValueImputer()](img/B15551_10_10.jpg)

图 10.10-nullvalueinputr()后的学生成绩数据帧

如您所见，所有空值都已被清除。

接下来，让我们像以前一样将数据转换成一个一键编码的稀疏矩阵。

### 一键编码混合数据

我们将在这里将类似的步骤应用于上一节中的步骤，通过创建一个定制的转换器，在将分类列与数字列作为稀疏矩阵连接之前，对分类列进行一次性编码(对于这种大小的数据集，密集矩阵也是可以的):

1.  用`TransformerMixin`作为超类定义一个新类:

    ```
    class SparseMatrix(TransformerMixin):
    ```

2.  用`self`作为输入初始化类。如果这没什么用也没关系:

    ```
    def __init__(self):
        		None
    ```

3.  创建一个将`self`和`X`作为输入并返回`self`的`fit`方法:

    ```
    def fit(self, X, y=None):
        		return self
    ```

4.  创建一个`transform`方法，将`self`和`X`作为输入，转换数据，并返回一个新的`X`:

    ```
    def transform(self, X, y=None):
    ```

    下面是完成转换的步骤；首先只访问`object`类型的分类列，如下所示:

    a)将分类列放入列表中:

    ```
        		categorical_columns= X.columns[X.dtypes==object].tolist()
    ```

    b)初始化`OneHotEncoder`:

    ```
        		ohe = OneHotEncoder() 
    ```

    c)用`OneHotEncoder`转换分类列:

    ```
    hot = ohe.fit_transform(X[categorical_columns])
    ```

    d)仅通过排除字符串来创建数字列的数据框架:

    ```
    cold_df = X.select_dtypes(exclude=["object"])
    ```

    e)将数字数据帧转换成稀疏矩阵:

    ```
            	cold = csr_matrix(cold_df)
    ```

    f)将两个稀疏矩阵合并成一个:

    ```
             final_sparse_matrix = hstack((hot, cold))
    ```

    g)将其转换为 a **压缩稀疏行** ( **CSR** )矩阵以限制误差。请注意，XGBoost 需要 CSR 矩阵，这种转换可能会根据您的 XGBoost 版本自动进行:

    ```
             final_csr_matrix = final_sparse_matrix.tocsr()
             return final_csr_matrix
    ```

5.  现在我们可以通过在`SparseMatrix`上使用强大的`fit_transform`方法来转换没有空值的`nvi`数据:

    ```
    sm = SparseMatrix().fit_transform(nvi)
    print(sm)
    ```

    这里给出的预期输出被截断以节省空间:

    ```
      (0, 0)	1.0
      (0, 2)	1.0
      (0, 5)	1.0
      (0, 6)	1.0
      (0, 8)	1.0
      (0, 10)	1.0
      :	:
      (648, 53)	4.0
      (648, 54)	5.0
      (648, 55)	4.0
      (648, 56)	10.0
      (648, 57)	11.0
      (648, 58)	11.0
    ```

6.  您可以通过将稀疏矩阵转换回密集矩阵来验证数据是否符合预期，如下所示:

    ```
    sm_df = pd.DataFrame(sm.toarray())
    sm_df.head()
    ```

    以下是预期的密集输出:

![Figure 10.11 – The sparse matrix converted into a dense matrix](img/B15551_10_11.jpg)

图 10.11–稀疏矩阵转换成密集矩阵

这似乎是正确的。该图显示了第 27 列的`0.0`的值和第 28 列的`1.0`值。前面的一位热码编码输出不包括(`0`、`27`)，并显示(`0`、`28`)的值`1.0`，与密集输出匹配。

既然已经转换了数据，让我们将两个预处理步骤合并到一个管道中。

## 预处理流水线

在建立机器学习模型的时候，标准的做法是先把数据分成`X`和`y`。当考虑管道时，转换预测列`X`，而不是目标列`y`，是有意义的。此外，为以后提供测试集也很重要。

在将数据放入机器学习管道之前，让我们将数据分成训练集和测试集，并将测试集留在后面。我们从顶部开始，如下所示:

1.  首先，将 CSV 文件作为数据帧读取:

    ```
    df = pd.read_csv('student-por.csv', sep=';')
    ```

    为学生成绩数据集选择`X`和`y`时，需要注意的是最后三列都包括学生成绩。这里有两个潜在的研究是有价值的:

    a)将以前的成绩作为预测值列

    b)不包括以前的成绩作为预测列

    假设您的 EdTech 公司希望根据社会经济变量进行预测，而不是根据以前获得的分数，因此忽略前两个分数列，索引为- `2`和- `3`。

2.  选择最后一列为`y`，除最后三列外的所有列为`X`:

    ```
    y = df.iloc[:, -1]
    X = df.iloc[:, :-3]
    ```

3.  现在导入`train_test_split`并将`X`和`y`分成一个训练集和一个测试集:

    ```
    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2)
    ```

现在，让我们使用以下步骤来构建管道:

1.  从`sklearn.pipeline`第一次导入`Pipeline`:

    ```
    from sklearn.pipeline import Pipeline
    ```

2.  接下来，按顺序使用语法(name，transformer)作为`Pipeline`的参数来分配元组:

    ```
    data_pipeline = Pipeline([('null_imputer', NullValueImputer()), ('sparse', SparseMatrix())])
    ```

3.  最后，通过将`X_train`放在`data_pipeline`的`fit_transform`方法中，转换`X_train`，我们的预测器列:

    ```
    X_train_transformed = data_pipeline.fit_transform(X_train)
    ```

现在，您有了一个没有空值的数值稀疏矩阵，可以用作机器学习的预测器列。

此外，您有一个管道，可以用来在一行代码中转换任何传入的数据！现在让我们最终确定一个 XGBoost 模型来进行预测。

# 最终确定 XGBoost 模型

是时候构建一个健壮的 XGBoost 模型来添加到管道中了。继续导入`XGBRegressor`、`numpy`、`GridSearchCV`、`cross_val_score`、`KFold`和`mean_squared_error`，如下所示:

```
import numpy as np
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import cross_val_score, KFold
from sklearn.metrics import mean_squared_error as MSE
from xgboost import XGBRegressor
```

现在让我们建立模型。

## 第一个 XGBoost 模型

该学生成绩数据集的预测值列`y_train`有一个有趣的值范围，如下所示:

```
y_train.value_counts()
```

结果是这样的:

```
11    82
10    75
13    58
12    53
14    42
15    36
9     29
16    27
8     26
17    24
18    14
0     10
7      7
19     1
6      1
5      1
```

如你所见，数值范围从`5` - `19`，包括`0`。

因为 target 列是有序的，这意味着值是按数字顺序排列的，所以回归比分类更可取，即使输出是有限的。在通过回归训练模型之后，最终结果可以被舍入以给出最终预测。

以下是使用该数据集对`XGBRegressor`评分的步骤:

1.  首先使用`KFold`设置交叉验证:

    ```
    kfold = KFold(n_splits=5, shuffle=True, random_state=2)
    ```

2.  现在定义一个交叉验证函数，使返回`cross_val_score`:

    ```
    def cross_val(model):
        scores = cross_val_score(model, X_train_transformed, y_train, scoring='neg_root_mean_squared_error', cv=kfold)
        rmse = (-scores.mean())
        return rmse
    ```

3.  通过使用`XGBRegressor`调用`cross_val`并使用`missing=-999.0`作为输入来建立基本分数，以便 XGBoost 可以找到最佳替代:

    ```
    cross_val(XGBRegressor(missing=-999.0))
    ```

    比分是这样的:

    ```
    2.9702248207546296
    ```

这是一个令人尊敬的起始分数。19 种可能性中`2.97`的均方根误差表示等级在几个精确度以内。这几乎是 15%，使用美国 A-B-C-D-F 系统，这在一个字母等级内是准确的。在行业中，你甚至可以使用统计数据包括一个置信区间来提供一个预测区间，这是一个推荐的策略，超出了本书的范围。

现在您有了一个基线分数，让我们微调超参数来改进模型。

## 微调 XGBoost 超参数

让我们从检查`n_estimators`提前停止开始。回想一下，为了使用提前停止，我们可以检查一个测试文件夹。创建测试折叠需要进一步拆分`X_train`和`y_train`:

1.  这里是第二个`train_test_split`,可用于创建验证目的的测试集，确保隐藏真实的测试集以备后用:

    ```
    X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_train_transformed, y_train, random_state=2)
    ```

2.  现在定义一个函数，该函数使用提前停止来返回回归变量的最佳估计数(参见 [*第 6 章*](B15551_06_Final_NM_ePUB.xhtml#_idTextAnchor136) *，XGBoost 超参数*):

    ```
    def n_estimators(model):
        eval_set = [(X_test_2, y_test_2)]
        eval_metric="rmse"
        model.fit(X_train_2, y_train_2, eval_metric=eval_metric, eval_set=eval_set, early_stopping_rounds=100)
        y_pred = model.predict(X_test_2)
        rmse = MSE(y_test_2, y_pred)**0.5
        return rmse  
    ```

3.  现在运行`n_estimators`功能，将设置为`5000`的最大值:

    ```
    n_estimators(XGBRegressor(n_estimators=5000, missing=-999.0))
    ```

    以下是输出的最后五行:

    ```
    [128]	validation_0-rmse:3.10450
    [129]	validation_0-rmse:3.10450
    [130]	validation_0-rmse:3.10450
    [131]	validation_0-rmse:3.10450
    Stopping. Best iteration:
    [31]	validation_0-rmse:3.09336
    ```

    分数如下:

    ```
    3.0933612343143153
    ```

使用我们的默认模型，31 估计目前给出最好的估计。那将是我们的起点。

接下来，这里有一个`grid_search`函数，我们已经多次使用过，它搜索超参数网格并显示最佳参数和最佳分数:

```
def grid_search(params, reg=XGBRegressor(missing=-999.0)):
    grid_reg = GridSearchCV(reg, params, scoring='neg_mean_squared_error', cv=kfold)
    grid_reg.fit(X_train_transformed, y_train)
    best_params = grid_reg.best_params_
    print("Best params:", best_params)
    best_score = np.sqrt(-grid_reg.best_score_)
    print("Best score:", best_score)
```

这里有几个推荐的微调模型的步骤:

1.  从`1`到`8`范围内的`max_depth`开始，同时将`n_estimators`设置为`31`:

    ```
    grid_search(params={'max_depth':[1, 2, 3, 4, 6, 7, 8], 
                        'n_estimators':[31]})
    ```

    结果是这样的:

    ```
    Best params: {'max_depth': 1, 'n_estimators': 31}
    Best score: 2.6634430373079425
    ```

2.  将`max_depth`从`1`缩小到`3`，同时将`min_child_weight`从`1`调整到`5` 并将`n_esimtators`保持在`31`:

    ```
    grid_search(params={'max_depth':[1, 2, 3], 
                        'min_child_weight':[1,2,3,4,5], 
                        'n_estimators':[31]})
    ```

    结果是这样的:

    ```
    Best params: {'max_depth': 1, 'min_child_weight': 1, 'n_estimators': 31}
    Best score: 2.6634430373079425
    ```

    没有任何改善。

3.  你可以通过强制`min_child_weight`取值为`2`或`3`，同时包含从`0.5`到`0.9`的`subsample`，来保证一些改变。此外，增加`n_estimators`可能有助于给模型更多的学习时间:

    ```
    grid_search(params={'max_depth':[2],
                        'min_child_weight':[2,3],
                        'subsample':[0.5, 0.6, 0.7, 0.8, 0.9],
                       'n_estimators':[31, 50]})
    ```

    结果如下:

    ```
    Best params: {'max_depth': 1, 'min_child_weight': 2, 'n_estimators': 50, 'subsample': 0.9}
    Best score: 2.665209161229433
    ```

    分数几乎相同，但稍差。

4.  缩小`min_child_weight`和`subsample`，同时将`0.5`到`0.9`的范围用于`colsample_bytree`:

    ```
    grid_search(params={'max_depth':[1],
                        'min_child_weight':[1, 2, 3], 
                        'subsample':[0.6, 0.7, 0.8], 
                        'colsample_bytree':[0.5, 0.6, 0.7, 0.8, 0.9, 1],
                       'n_estimators':[50]})
    ```

    结果是这样的:

    ```
    Best params: {'colsample_bytree': 0.9, 'max_depth': 1, 'min_child_weight': 3, 'n_estimators': 50, 'subsample': 0.8}
    Best score: 2.659649642579931
    ```

    这是迄今为止最好的成绩。

5.  保持最佳电流值，用`colsample_bynode`和`colsample_bylevel`尝试从`0.6`到`1.0`的范围:

    ```
     grid_search(params={'max_depth':[1],
                        'min_child_weight':[3], 
                        'subsample':[.8], 
                        'colsample_bytree':[0.9],
                        'colsample_bylevel':[0.6, 0.7, 0.8, 0.9, 1],
                        'colsample_bynode':[0.6, 0.7, 0.8, 0.9, 1],
                        'n_estimators':[50]})
    ```

    这里给出的结果是:

    ```
    Best params: {'colsample_bylevel': 0.9, 'colsample_bynode': 0.8, 'colsample_bytree': 0.9, 'max_depth': 1, 'min_child_weight': 3, 'n_estimators': 50, 'subsample': 0.8}
    Best score: 2.64172735526102
    ```

    分数又提高了。

对基础学习者到`dart`和`gamma`的进一步实验没有产生新的收获。

根据时间和项目的范围，进一步调优超参数，甚至在`RandomizedSearch`中一起尝试它们是值得的。在工业界，你很有可能会接触到云计算，在那里便宜的、可抢占的**虚拟机** ( **虚拟机**)将允许更多的超参数搜索来找到更好的结果。请注意，scikit-learn 目前没有提供一种方法来停止耗时的搜索，以便在代码完成之前保存最佳参数。

现在我们有了一个健壮的模型，我们可以继续前进并测试这个模型。

## 测试模型

现在您已经有了一个潜在的最终模型，根据测试集测试它是很重要的。

回想一下，测试集没有在我们的管道中进行转换。幸运的是，在这一点上，只需要一行代码来转换它:

```
X_test_transformed = data_pipeline.fit_transform(X_test)
```

现在，我们可以使用上一节中选择的最佳调整的超参数来初始化模型，使其适合训练集，并根据被阻止的测试集对其进行测试:

```
model = XGBRegressor(max_depth=2, min_child_weight=3, subsample=0.9, colsample_bytree=0.8, gamma=2, missing=-999.0)
model.fit(X_train_transformed, y_train)
y_pred = model.predict(X_test_transformed)
rmse = MSE(y_pred, y_test)**0.5
rmse
```

分数如下:

```
2.7908972630881435
```

分数会高一点，虽然这可能是因为翻牌的缘故。

如果不是，我们的模型与验证集拟合得有点过紧，这可能发生在微调超参数并密切调整它们以改进验证集的时候。该模型概括得相当好，但它可以概括得更好。

对于接下来的步骤，当考虑分数是否可以提高时，有以下选项可用:

*   返回超参数微调。

*   保持模型不变。

*   基于超参数知识进行快速调整。

快速调整超参数是可行的，因为模型可能过拟合。例如，增加`min_child_weight`和降低`subsample`应该有助于模型更好地概括。

让我们为最终模型做最后调整:

```
model = XGBRegressor(max_depth=1,
                       min_child_weight=5,
                       subsample=0.6, 
                       colsample_bytree=0.9, 
                       colsample_bylevel=0.9,
                       colsample_bynode=0.8,
                     n_estimators=50,
                       missing=-999.0)
model.fit(X_train_transformed, y_train)
y_pred = model.predict(X_test_transformed)
rmse = MSE(y_pred, y_test)**0.5
rmse
```

结果如下:

```
2.730601403138633
```

注意，分数提高了。

此外，你绝对不应该来回尝试提高坚持测试分数。然而，在收到测试分数后，做一些调整是可以接受的；否则，你永远不会比第一个结果更好。

现在剩下的就是完成管道。

# 构建机器学习管道

完成机器学习管道需要将机器学习模型添加到之前的管道中。在`NullValueImputer`和`SparseMatrix`之后需要一个机器学习元组，如下:

```
full_pipeline = Pipeline([('null_imputer', NullValueImputer()),  ('sparse', SparseMatrix()), 
('xgb', XGBRegressor(max_depth=1, min_child_weight=5, subsample=0.6, colsample_bytree=0.9, colsample_bylevel=0.9, colsample_bynode=0.8, missing=-999.0))]) 
```

这个流水线现在已经完成了一个机器学习模型，它可以适用于任何`X`、`y`组合，如下所示:

```
full_pipeline.fit(X, y)
```

现在，您可以对目标列未知的任何数据进行预测:

```
new_data = X_test
full_pipeline.predict(new_data)
```

以下是预期输出的前几行:

```
array([13.55908  ,  8.314051 , 11.078157 , 14.114085 , 12.2938385, 11.374797 , 13.9611025, 12.025812 , 10.80344  , 13.479145 , 13.02319  ,  9.428679 , 12.57761  , 12.405045 , 14.284043 , 8.549758 , 10.158956 ,  9.972576 , 15.502667 , 10.280028 , ...
```

为了获得现实的预测，数据可以四舍五入如下:

```
np.round(full_pipeline.predict(new_data))
```

预期输出如下所示:

```
array([14.,  8., 11., 14., 12., 11., 14., 12., 11., 13., 13.,  9., 13., 12., 14.,  9., 10., 10., 16., 10., 13., 13.,  7., 12.,  7.,  8., 10., 13., 14., 12., 11., 12., 15.,  9., 11., 13., 12., 11.,  8.,
...
11., 13., 12., 13.,  9., 13., 10., 14., 12., 15., 15., 11., 14., 10., 14.,  9.,  9., 12., 13.,  9., 11., 14., 13., 11., 13., 13., 13., 13., 11., 13., 14., 15., 13.,  9., 10., 13.,  8.,  8., 12., 15., 14., 13., 10., 12., 13.,  9.], dtype=float32)
```

最后，如果新数据到来，它可以与以前的数据连接，并通过相同的管道放置，以获得更强的模型，因为新模型可能适合更多的数据，如下所示:

```
new_df = pd.read_csv('student-por.csv')
new_X = df.iloc[:, :-3]
new_y = df.iloc[:, -1]
new_model = full_pipeline.fit(new_X, new_y)
```

现在，此模型可用于对新数据进行预测，如以下代码所示:

```
more_new_data = X_test[:25]
np.round(new_model.predict(more_new_data))
```

预期产出如下:

```
array([14.,  8., 11., 14., 12., 11., 14., 12., 11., 13., 13.,  9., 13., 12., 14.,  9., 10., 10., 16., 10., 13., 13.,  7., 12.,  7.],
      dtype=float32)
```

有一个小问题。

如果您只想对一行数据进行预测，该怎么办？如果在管道中运行一行，得到的稀疏矩阵将不会有正确的列数，因为它只会对单行中出现的类别进行一键编码。这将导致数据中的*不匹配*错误，因为机器学习模型已经适合需要更多行数据的稀疏矩阵。

一个简单的解决方案是将新的数据行与足够多的数据行连接起来，以保证存在完整的稀疏矩阵，其中所有可能的分类列都已转换。我们已经看到这适用于从`X_test`开始的 25 行，因为没有错误。在这种特殊情况下，使用来自`X_test`的 20 行或更少行将导致不匹配错误。

因此，如果您想使用单行数据进行预测，将单行数据与`X_test`的前`25`行连接起来，并按如下方式进行预测:

```
single_row = X_test[:1]
single_row_plus = pd.concat([single_row, X_test[:25]])
print(np.round(new_model.predict(single_row_plus))[:1])
```

结果是这样的:

```
[14.]
```

你现在知道机器学习模型如何被包括在管道中，以对新数据进行转换和预测。

# 总结

恭喜你坚持到了这本书的结尾！这是一次非凡的旅程，从基本的机器学习和`pandas`开始，到构建您自己定制的变压器、管道和函数，以在行业场景中部署健壮、微调的 XGBoost 模型，并使用稀疏矩阵对新数据进行预测。

一路走来，您已经了解了 XGBoost 的故事，从第一个决策树到随机森林和梯度推进，然后发现了使 XGBoost 如此特别的数学细节和复杂性。您一次又一次地看到 XGBoost 优于其他机器学习算法，并且您在调整 XGBoost 的各种超参数方面获得了必要的实践，包括`n_estimators`、`max_depth`、`gamma`、`colsample_bylevel`、`missing`和`scale_pos_weight`。

您了解了物理学家和天文学家如何在历史上重要的案例研究中获得关于我们宇宙的知识，并且您了解了 XGBoost 通过不平衡数据集和替代基础学习者的应用的广泛范围。你甚至通过高级特征工程、非相关系综和堆叠从 Kaggle 竞赛中学到了交易技巧。最后，您学习了先进的工业自动化流程。

至此，您对 XGBoost 的了解已经处于高级水平。现在，您可以高效、快速、有力地使用 XGBoost 来解决即将出现的机器学习问题。当然，XGBoost 并不完美。如果你正在处理非结构化数据，比如图像或文本，**神经网络**可能会为你提供更好的服务。对于大多数机器学习任务，尤其是那些有表格数据的任务，XGBoost 通常会给你带来优势。

如果你有兴趣在 XGBoost 继续深造，我个人推荐你参加 Kaggle 比赛。原因是 Kaggle 比赛由经验丰富的机器学习从业者组成，与他们竞争会让你变得更好。此外，Kaggle 竞赛提供了一个结构化的机器学习环境，由许多致力于同一问题的从业者组成，这导致了共享的笔记本和论坛讨论，可以进一步推动教育过程。正如本书所概述的，XGBoost 也是在这里首次因希格斯玻色子竞赛而声名鹊起。

现在，您可以满怀信心地进入 XGBoost 的大数据世界，推进研究，参加竞赛，并构建可用于生产的机器学习模型。