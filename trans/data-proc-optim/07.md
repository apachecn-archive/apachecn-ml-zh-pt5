# *第五章*:数据可视化与剖析

当您转换数据时，您通常需要探索您的数据，以便很好地了解如何塑造数据，从而从中获得洞察力。您可能需要检查缺失值，确保列内的一致性，获得唯一值的计数，绘制直方图，获得前 *n* 个值，或者生成描述性分析。擎天柱给了我们工具让这一切发生。

在本章中，我们将深入剖析我们在 [*第 3 章*](B17166_03_Final_VK_epub.xhtml#_idTextAnchor064) *、数据争论、*中看到的分析器及其数据类型，并了解我们如何充分利用这一特性对特定数据执行操作，以根据需要设置、删除或替换值。

Optimus 还可以提供有关数据质量的信息，并提供工具来轻松处理和转换我们的数据。

我们将在本章中讨论的主题如下:

*   数据质量
*   探索性数据分析
*   数据剖析
*   缓存和刷新

# 技术要求

Optimus 可以与多种后端技术一起处理数据，包括 GPU。有了 GPU，擎天柱用的是**激流**，需要 NVIDIA 卡。关于需求的更多信息，请前往第一章[](B17166_01_Final_SB_epub.xhtml#_idTextAnchor015)**中的 *GPU 配置*部分，嗨擎天柱！*。*

 *你可以在[https://github . com/packt publishing/Data-Processing-with-Optimus](https://github.com/PacktPublishing/Data-Processing-with-Optimus)找到本章的所有代码。

# 数据质量

在 Optimus 中，我们称之为对与特定 profiler 数据类型`URL`匹配的列中的值的数量进行计数的过程，Optimus 将对执行以下操作的列中的值的数量进行计数:

*   匹配 URL 格式，比如`"google.com"`。
*   不匹配的网址格式，如`"google"`。
*   它还会计算空值。

Optimus 在 profiler 中有许多数据类型，这些数据类型是结合正则表达式和数字类型检测推断出来的。作为参考，在下表中，我们列出了探查器数据类型和 Python 数据类型:

![Figure 5.1 – Optimus profiler datatypes
](img/B17166_Table_01.jpg)

图 5.1–Optimus profiler 数据类型

这些数据类型是在运行探查器时推断出来的。此外，如果您确定分析器数据类型应该具有特定的数据类型，您可以更改分析器:

```
from optimus import Optimus 
op = Optimus("pandas")
df = op.load.file("foo.csv")
df.cols.quality()
```

`df.cols.quality`将返回以下内容:

```
{'name': {'match': 4,
  'missing': 0,
  'mismatch': 0,
  'profiler_dtype': {'dtype': 'str', 'categorical': True}},
'job': {'match': 2,
  'missing': 0,
  'mismatch': 2,
  'profiler_dtype': {'dtype': 'int', 'categorical': True}},
'id': {'match': 4,
  'missing': 0,
  'mismatch': 0,
  'profiler_dtype': {'dtype': 'int', 'categorical': True}}}
```

`quality`方法返回一个字典，以列名作为键，包含匹配、不匹配、缺失值、源文件名(如果适用)和`profiler_dtype`，T5 是 Optimus 推断的抽象类型。

第一次运行探查器时，使用数据集的示例来推断列的数据类型。让我们来看一个例子，我们想要改变一个列的推断数据类型:

```
df = df.cols.set_dtype("salary", "int")
```

在前面的代码中，我们更改了`salary`列的推断数据类型。如果我们获得了概要分析器或者获得了该列的数据质量统计数据，我们将会得到不同的结果。如果我们想改变多列的数据类型，我们可以调用`df.cols.dtype`，传递一个字典如下:

```
df = df.cols.set_dtype({"salary": "int", "age": "str"}) 
```

在本例中，我们将一个列设置为字符串。这可以减少数据质量的不匹配。

有一些特殊的数据类型在内部被视为一个字符串，但是受到一种格式的约束，比如电子邮件、URL 和一些日期时间值。

在其他情况下，datetime 列的值在内部可以是本机 datetime 类型(如果所选引擎支持)。

还可以扩展 Optimus 支持的数据类型。我们将在接下来的章节中看到更多关于这个主题的内容。

通过设置不同的数据类型，我们能够更精确地检查数据的质量。让我们更多地了解它。

## 处理匹配、不匹配和空值

在 Optimus 中，为了识别满足给定条件的每一行的值，我们使用了掩码，这些掩码是告诉我们每个值是否满足条件的布尔值行。例如，当获得具有一些空值的列的空掩码时，该掩码将在除了具有空值的行之外的所有行中具有值 **False** ，这些行将具有 **True** :

```
df = op.create.dataframe({"numbers": [1, 2, None, 4]})
df.mask.missing("numbers").print()
```

我们将获得以下结果:

```
  numbers
   (bool)
---------
        0
        0
        1
        0
```

该掩码用于执行不同的行操作，如行过滤或值替换。稍后我们会看到更多相关内容；首先，我们将看到如何使用掩码处理匹配和不匹配。

假设我们有以下数据集:

```
df = op.create.dataframe({"numbers": [1, 2, "Hello", 4, "World"]})
numbers
(object)
----------
1
2
Hello
4
World
```

如果我们想知道哪些值匹配主要的数据类型(在本例中是 int ),我们使用`mask.match`,传递`"int"`作为第二个参数:

```
df.mask.match("numbers", "int").print()
```

我们将获得以下输出:

```
  numbers
   (bool)
---------
        1
        1
        0
        1
        0
```

要使用这个掩码过滤，我们可以使用`select`或`drop`，将掩码作为第一个参数传递给:

```
df.rows.select(df.mask.match("numbers", "int")).print()
```

我们将得到以下输出:

```
   numbers
  (object)
----------
         1
         2
         4
```

现在我们将删除这一行:

```
df.rows.drop(df.mask.match("numbers", "int")).print()
```

我们将获得以下输出:

```
numbers
(object)
----------
Hello
World
```

要使用`mask`替换这些值，我们可以执行以下操作:

```
df.cols.set("numbers", value=0, where=df.mask.mismatch("numbers", "int")).print()
```

在前面的示例中，我们使用`mismatch`而不是进行匹配。这使我们能够替换列中所有不是数字的值。这样做的结果如下:

```
   numbers 
  (object) 
---------- 
         1 
         2 
         0 
         4 
         0
```

通过不向`mask`上的`mismatch`方法传递类型，Optimus 将使用之前推断的可用数据类型，如果它可用的话:

```
df.cols.dtypes("numbers")
df.mask.mismatch("numbers")
```

前面的代码将与下面的代码行为相同:

```
df.cols.dtypes("numbers")
df.mask.mismatch("numbers", df["numbers"].profile.dtypes() )
```

这意味着我们可以简单地调用下面的代码，并且仍然得到相同的结果:

```
df.cols.set("numbers", value=0, where=df.mask.mismatch("numbers"))
```

我们还将获得以下输出:

```
   numbers 
  (object) 
---------- 
         1 
         2 
         0 
         4 
         0
```

如果我们不知道应该在 a 列中使用什么类型，并且我们已经将该信息缓存在我们的数据集中，那么这是很有帮助的。

我们学会了如何根据数据的质量来处理数据，以及如何清理我们的数据。一旦清理完毕，我们就可以使用这些数据来获得一些统计数据。让我们学习如何！

# 探索性数据分析

**探索性数据分析** ( **EDA** )当你开始探索你的数据时，这是至关重要的一步。它可以给你它的主要特征的总体概述，比如最小值和最大值，以及平均值和中值。此外，它可以帮助您检测模式、数据不一致和异常值。

探索数据的第一步是应用 EDA 技术，以便更好地理解要处理的数据。应用该技术的主要目标如下:

*   最大限度地深入了解数据集
*   来揭开潜在的结构
*   提取重要的变量
*   检测异常值和异常值

我们可以通过四种方式对 EDA 进行分类:

*   **单变量，非图形**:这里，数据分析只应用于一个变量。单变量分析的主要目的是描述数据并找出其中存在的模式。
*   **单个变量，图形化**:单个变量的图形化方法可以是一种非常直观的方式来浏览您的列。Optimus 中可用的一些图有直方图、频率表和箱线图。
*   **多变量，非图形**:当你想分析多个变量之间的关系时，你可以依靠交叉制表或统计等方法。
*   **多变量，图形化**:这些方法让你以图形化的方式探索多个变量之间的关系。擎天柱可以在散点图和热图方面提供帮助。

正如你所看到的，在 Optimus 中你可以很容易地计算出几乎所有你需要深入了解的数据。

在深入一些示例之前，让我们加载一个类似商店库存的数据帧:

```
from optimus import Optimus 
op = Optimus("pandas")
df = op.load.file("store.csv")
df.print(10, ["name", "code"])
```

在前面的代码中，我们调用了`print`,但是在本例中，我们请求的是这个数据集的前十行和两列。这将打印以下内容:

```
       id  name        code              price
  (int64)  (object)    (object)      (float64)
---------  ----------  ----------  -----------
        1  pants       L15              173.47
        2  shoes       SH                69.99
        3  shirt       RG30              30
        4  pants       J10               34.99
        5  pants       JG15             132.99
        6  shoes       B                 57.99
        7  pants       JG20             179.99
        8  pants       L20               95
        9  shirt       FT50              50
       10  pants       JG15             169.99
```

但是让我们通过应用一些可用的方法来深入了解整个列。

## 单变量非图形方法

在 Optimus 中，您可以使用某些方法来获得对数据的非图形洞察。让我们看看其中的一些。

要计算列中的最小值，使用以下公式:

```
df.cols.min("id")
```

这将返回以下输出:

```
1
```

如果您还想计算列中的最大值，您可以使用`max`，如下所示:

```
df.cols.max("id")
```

这将返回以下内容:

```
504
```

另一方面，如果您想要计算众数(这是列中最常见的值)，您可以使用以下方法:

```
df.cols.mode("price")
```

这将根据数据返回一个字典或单个值:

```
50.0
```

要计算列中的中值，请使用以下公式:

```
df.cols.median("price")
```

这将返回一个数值:

```
104.99
```

要计算四分位数范围，即 Q1 和 Q3 之间的范围，请使用以下公式:

```
df.cols.iqr("id")
```

我们将得到以下值:

```
130.01
```

要计算列中的平均值，请使用以下公式:

```
df.cols.mean("id")
```

这将返回以下值:

```
121.30525793650794
```

此外，为了计算列中的标准偏差，我们可以使用`std`:

```
df.cols.std("price")
```

我们会得到一个数值:

```
93.16652086384731
```

要计算列中的方差，请使用以下公式:

```
df.cols.var("price")
```

我们将获得以下值:

```
8680.000609873696
```

你也可以计算偏斜度。这将告诉您概率分布是向左还是向右倾斜:

```
df.data["price"].skew()
```

我们会得到一个数值:

```
1.0015117495305208
```

对于峰度，它是概率分布“尾部”的一种度量，使用以下公式:

```
df.cols.kurtosis("price")
```

此将返回以下值:

```
0.45556375186033016
```

我们也可以通过它们可能的属性来计算一些值。让我们看看其中的一些。

要计算一列中的所有零，可以使用以下方法:

```
df.cols.count_zeros("discount")
```

我们将得到`"discount"`中零的数量:

```
294
```

要计算一列中所有的空值，可以使用以下方法:

```
df.cols.count_nulls("discount")
```

我们将得到以下整数:

```
0
```

要计算一列中的所有空白值，可以使用以下方法:

```
df.cols.count_na("discount")
```

我们将得到一个整数值:

```
0
```

要计算一列中所有唯一值的个数，可以使用以下方法:

```
df.cols.count_uniques("price")
```

这个将返回一个包含`"price"`中所有唯一值的整数:

```
192
```

正如我们所看到的，通过使用这些方法中的任何一种，您都可以很容易地从一个专栏中获得特定的见解。现在让我们看看如何以图形方式浏览数据。

## 单变量图形方法

图形化数据检查可以非常直观地洞察您的数据。

Optimus 使用了`matplotlib`和`seaborn`，两个非常有用的绘图库。此外，请记住，您可以以 Python 字典格式输出数据，并使用最适合您需求的库。

现在，让我们从之前加载的数据集中绘制一些数据。

### 柱状图

直方图告诉我们中每个数字数据片的数量有多少个值，例如，有多少人属于特定的年龄组。

要获得数值列的直方图，可以使用以下方法:

```
df.cols.hist("id",5)
```

这将打印一个 Python 字典，显示下限和上限以及它们之间的值计数:

```
{'hist': {'price': [
{'lower': 5.0, 'upper': 103.3675, 'count': 250},   
{'lower': 103.3675, 'upper': 201.735, 'count': 179},   
{'lower': 201.735, 'upper': 300.1025, 'count': 39},
{'lower': 300.1025, 'upper': 398.47, 'count': 36}
]}}
```

要绘制直方图，您可以使用以下方法:

```
df.plot.hist()
```

这将显示以下输出:

![Figure 5.2 – Histogram chart generated using Optimus
](img/B17166_05_1.jpg)

图 5.2–使用 Optimus 生成的直方图

这个图表让我们深入了解一个数字列在数字范围中的分布。如果列不是数字而是分类的，您可以创建一个频率表。

### 频率

使用`frequency`方法，您可以计算一个值在一个或多个列中出现的次数。默认情况下，这以降序显示。

在 Optimus 中，要获得任一(或每一)列的前五个频繁值，可以使用以下代码:

```
df.cols.frequency("code", 5)
```

这将打印一个 Python 字典，其中的值和计数按降序排列:

```
{'frequency': {'code': {'values': [
{'value': 'JG15', 'count': 60},
{'value': 'JG10', 'count': 43},
{'value': 'SK', 'count': 37},
{'value': 'L15', 'count': 33},
{'value': 'J15', 'count': 32}
]}}}
```

您可以使用以下内容绘制频率图表:

```
df.plot.frequency("code", 40)
```

这将显示 40 个像这样的条形:

![Figure 5.3 – Frequency chart generated using Optimus
](img/B17166_05_2.jpg)

图 5.3-使用 Optimus 生成的频率表

使用这个，您可以找出一列中最频繁出现的值，正如第二个参数中输入的数字一样详细。

现在，让我们了解一种更高级的数值数据可视化。

### 箱形图

箱线图是一种基于五个数字汇总(最小值、第一个四分位数(Q1)、中值、第三个四分位数(Q3)和最大值)显示数据分布的标准化方式。

箱形图对于分析数字列很有用。让我们来看看如何获得生成它们所需的数据:

```
df.cols.boxplot("price")
```

这将打印一个 Python 字典，其中包含打印箱线图所需的所有数据，如均值、中值、第一个和第三个四分位数、胡须和异常点(也称为飞行者):

```
{'price': {
    'mean': 121.30525793650794,
    'median': 104.99,
    'q1': 44.99,
    'q3': 175.0,
    'whisker_low': -150.02499999999998,
    'whisker_high': 370.015,
    'fliers': [
        {'price': 374.99},
        {'price': 395.0},
        {'price': 390.0},
        {'price': 395.0},
        {'price': 398.47},
        {'price': 380.0},
        {'price': 375.0}
    ],
    'label': 'price'
}}
```

要用 Optimus 得到一个方框图，你可以使用下面的:

```
df.plot.box("age")
```

这将显示以下图形:

![Figure 5.5 – Box plot generated using Optimus
](img/B17166_05_3.jpg)

图 5.5-使用 Optimus 生成的箱线图

这种图可以告诉你你的异常值和它们的值。它还能告诉你你的数据是否对称，你的数据分组有多紧密，你的数据是否以及如何偏斜。

既然我们已经了解了可以帮助我们单独研究各个列的图表，那么让我们深入研究其他类型的图表，这些图表可以帮助我们更全面地了解多个变量。

## 多变量非图形方法

为了了解整个数据集以及它的变量是如何相互关联的，你可以使用这些类型的方法。我们来讨论一下。

### 交叉制表

交叉列表(也称为交叉表或列联表)是一个二维表格，记录了具有表格值中描述的特定特征的受访者的频率。它提供了关于两个变量之间关系的有价值的信息。

要在 Optimus 中获得一个交叉表，可以使用下面的代码:

```
df = op.create.dataframe(A=[18,21,62,44], B=[45,42,25,21])
df.cols.crosstab("A", "B")
```

这将输出以下内容:

```
{21: {18: 0, 21: 0, 44: 1, 62: 0},
 25: {18: 0, 21: 0, 44: 0, 62: 1},
 42: {18: 0, 21: 1, 44: 0, 62: 0},
 45: {18: 1, 21: 0, 44: 0, 62: 0}}
```

您也可以将它输出到数据帧中:

```
df.cols.crosstab("A", "B", output="dataframe")
```

此将打印以下内容:

```
         A         21         25         42         45
  (object)    (int64)    (int64)    (int64)    (int64)
----------  ---------  ---------  ---------  ---------
        18          0          0          0          1
        21          0          0          1          0
        44          1          0          0          0
        62          0          1          0          0
```

如您所见，列`A`是作为索引维护的。让我们用另一种方法来看两列之间的关系。

### 相互关系

两个变量的相关性可以传达两列的相关程度。该值用介于-1 和 1 之间的数值表示。值为-1 表示每列的值反向相关，值为 1 表示每列依赖于另一列，或者它们甚至可能以不同的方式表示同一变量。

要获得两列的相关性，可以使用以下方法:

```
df = op.create.dataframe(A=[1,2,3,4], B=[4,5,0,7], C=[-1,-2,-5,-6])
df.cols.correlation(["A", "B"])
```

这将返回一个数值:

```
0.17541160386140586
```

如果不是而是使用`"*"`传递超过两列甚至整个数据集，您将得到一个表示相关矩阵的字典:

```
df.cols.correlation("*")
```

这将显示以下内容:

```
{'A': {'A': 1.0, 'B': 0.17541160386140586, 'C': -0.9761870601839528},
 'B': {'A': 0.17541160386140586, 'B': 1.0, 'C': 0.0},
 'C': {'A': -0.9761870601839528, 'B': 0.0, 'C': 1.0}}
```

让我们看看如何获得整个数据集的图形化视图。

## 多变量图形方法

了解多列(甚至整组列)的一个好方法是使用多变量图形方法。让我们看看其中的一些。

### 热图

热图图是笛卡尔空间中的一种图，显示关于两个变量的信息。它用颜色变化来测量二维现象的大小。

要获取 Python 字典格式的热点图，您可以使用以下内容:

```
df.cols.heatmap("fare")
```

这将返回以下输出:

```
{'frequency': {'name': {'values': [{'value': 'optimus', 'count': 2},
    {'value': 'bumblebee', 'count': 2}]},
  'job': {'values': [{'value': '1', 'count': 1},
    {'value': 'Leader', 'count': 1},
    {'value': 'Espionage', 'count': 1},
    {'value': '3', 'count': 1}]},
  'id': {'values': [{'value': '1', 'count': 1},
    {'value': '2', 'count': 1},
    {'value': '4', 'count': 1},
    {'value': '3', 'count': 1}]
}}}
```

要从特定列绘制热图，请使用:

```
df.plot.heatmap("price", "id", 30, 30)
```

这个会显示如下的剧情:

![Figure 5.4 – Heat map generated using Optimus
](img/B17166_05_4.jpg)

图 5.4–使用 Optimus 生成的热图

如您所见，重叠的多个值将显示为深黄色，以表示聚类中有多少个点。

### 相关矩阵

相关矩阵将向我们显示所有给定列之间的相关系数。在绘制之前，让我们加载另一个包含更多数字列的数据集:

```
df = op.load.file("titanic3.xls")
df.plot.correlation("*")
```

这将显示`df`中每一列之间的关联矩阵:

![Figure 5.6 – Optimus correlation plot
](img/B17166_05_5.jpg)

图 5.6–Optimus 关联图

每对可比较的列中都有一个颜色编码的值。这对于查看数据中的模式非常有用。

请记住，Optimus 可以以 Python 字典格式提供所有这些数据，例如:

*   使用`df.cols.hist()`的直方图
*   使用`df.cols.frequency()`的频率图表
*   使用`df.cols.boxplot()`的方框图
*   使用`df.cols.scatter()`的散点图

为了更全面地了解数据，你可以询问数据集的完整概要。我们去看看。

# 数据剖析

Optimus 中有一个方便的函数叫做`profile`，它返回关于我们数据集的有用统计数据。让我们看看如何使用它:

```
df.profile(bins=5)
```

这段代码将返回一个字典:

```
{'columns': {'id': {'stats': {'match': 504,
    'missing': 0,
    'mismatch': 0,
    'profiler_dtype': {'dtype': 'int', 'categorical': True},
    'frequency': [{'value': 1, 'count': 1},
     {'value': 332, 'count': 1},
     {'value': 345, 'count': 1},
     {'value': 344, 'count': 1},
     {'value': 343, 'count': 1}],
    'count_uniques': 504},
   'dtype': 'int64'},
  'name': {'stats': {'match': 504,
    'missing': 0,
    'mismatch': 0,
    'profiler_dtype': {'dtype': 'str', 'categorical': True},
    'frequency': [{'value': 'pants', 'count': 254},
     {'value': 'shoes', 'count': 134},
     {'value': 'shirt', 'count': 116}],
    'count_uniques': 3},
   'dtype': 'object'},
  'code': {'stats': {'match': 504,
    'missing': 0,
    'mismatch': 0,
    'profiler_dtype': {'dtype': 'str', 'categorical': True},
    'frequency': [{'value': 'JG15', 'count': 60},
     {'value': 'JG10', 'count': 43},
     {'value': 'SK', 'count': 37},
     {'value': 'L15', 'count': 33},
     {'value': 'J15', 'count': 32}],
    'count_uniques': 39},
   'dtype': 'object'},
  'price': {'stats': {'match': 504,
    'missing': 0,
    'mismatch': 0,
    'profiler_dtype': {'dtype': 'decimal', 'categorical': 
False},
    'hist': [{'lower': 5.0, 'upper': 103.3675, 'count': 250},
     {'lower': 103.3675, 'upper': 201.735, 'count': 179},
     {'lower': 201.735, 'upper': 300.1025, 'count': 39},
     {'lower': 300.1025, 'upper': 398.47, 'count': 36}]},
   'dtype': 'float64'},
  'discount': {'stats': {'match': 294,
    'missing': 0,
    'mismatch': 210,
    'profiler_dtype': {'dtype': 'int', 'categorical': True},
    'frequency': [{'value': '0', 'count': 294},
     {'value': '5%', 'count': 65},
     {'value': '20%', 'count': 63},
     {'value': '15%', 'count': 54},
     {'value': '50%', 'count': 16}],
    'count_uniques': 6},
   'dtype': 'object'}},
'name': 'store.csv',
'file_name': ['store.csv'],
'summary': {'cols_count': 5,
  'rows_count': 504,
  'dtypes_list': ['float64', 'int64', 'object'],
  'total_count_dtypes': 3,
  'missing_count': 0,
  'p_missing': 0.0}
}
```

使用这个 Python 字典，您可以获得关于特定列的信息和关于整个数据帧的统计信息。

对于 dataframe stats，您可以使用`profile.summary()`获得以下内容:

*   `cols_count`:数据帧中的列数
*   `rows_count`:数据帧中的行数
*   `dtypes_list`:数据帧中的数据类型列表
*   `total_count_dtypes`:数据帧中数据类型的计数
*   `missing_count`:数据帧中缺失值的数量
*   `p_missing`:数据帧中缺失值的百分比

使用`profile.columns()`，您可以获得数据帧中每一列的信息。在这里面，你可以使用两个键，`stats`和`dtype.`

在`stats`中，您可以获得以下信息:

*   `match`:与`profiler_dtype`匹配的列中值的个数
*   `missing`:缺失值的个数
*   `Mismatch`:列中与`profiler_dtype`不匹配的值的数量，不包括空值
*   `profiler_dtype`:Optimus 推断的数据类型
*   `Frequency`:前 *n* 值降序排列
*   `Hist`:每个箱中的值的密度
*   `count_uniques`:唯一值的个数

Optimus 将根据数据类型计算频率或直方图。它将计算数字数据类型的直方图和字符串数据类型的频率。

所有这些显示的信息可以让我们快速了解数据集中的内容，但是通过缓存这些元数据，我们可以赢得一些时间。让我们了解更多。

# 缓存刷新

探索大数据可能是一个非常耗时的过程。您需要对一列进行操作，转换它的数据，检查输出是否是您想要的，并将它与另一列中的数据进行比较，包括它的频率、直方图和描述性分析。

为了帮助您加速工作，Optimus 知道何时需要重新计算 profiler 统计数据，因此您不必等待，如果您正在处理大数据，这将非常有帮助。

在内部，Optimus 声明了一些触发列概要重新计算的动作。要获得需要重新计算的操作的完整列表，可以使用以下命令:

```
from optimus.helpers.constants import Actions
Actions.list()
```

`Actions.list()`会给我们一个 Python 列表:

```
['profiler_dtype', 'lower', 'upper', 'proper', 'pad', 'trim', 'reverse', 'remove', 'left', 'right', 'mid', 'replace', 'fill_na', 'cast', 'is_na', 'z_score', 'nest', 'unnest', 'set', 'string_to_index', 'date_format', 'index_to_string', 'min_max_scaler', 'max_abs_scaler', 'apply_cols', 'impute', 'extract', 'abs', 'math', 'variance', 'slice', 'clip', 'drop', 'keep', 'cut', 'to_float', 'to_integer', 'to_boolean', 'to_string', 'years', 'append', 'port', 'domain', 'domain_scheme', 'subdomain', 'host', 'domain_params', 'domain_path', 'email_domain', 'email_user', 'select_row', 'drop_row', 'between_drop', 'sort_row']
```

如果你看看这些名字，它们中的一些与我们已经使用过的处理数据的函数相匹配。

# 总结

在这一章中，我们学习了如何从我们的数据中提取高质量的数据，这样我们就可以应用一个转换来塑造它，并开始获取高质量的统计数据，这可以帮助我们理解数据之间的关系，并提取更好的见解。

此外，我们还看到 Optimus 如何绘制这些数据，并将其转换成易于使用和理解的格式。

现在我们知道了如何深入研究我们的数据，在下一章中，我们将学习如何应用字符串聚类技术来轻松地找到不同值的组，这些值可能是同一事物的替代表示。*