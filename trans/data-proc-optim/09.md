# 七、特征工程

既然我们已经讨论了如何根据需要形成我们的数据，那么让我们来讨论一下特征工程。

如果你想创建一个机器学习模型，你输入数据。该输入数据包括算法创建模型所需的特征。这些特征需要具有特定的特征；例如，它不能有空值，或者数据需要符合特定的概率分布。

通过特征工程，您可以准备输入数据集，使其符合算法的要求，还可以提高机器学习模型的性能，从而使用我们已有的数据创建新的要素。

因此，在本章中，我们将讨论以下主题:

*   处理缺失值
*   处理异常值
*   扔掉
*   变量变换
*   一键编码
*   特征分割
*   缩放比例

# 技术要求

Optimus 可以与多种后端技术一起处理数据，包括 GPU。对于 GPU，Optimus 用的是 **RAPIDS** ，需要 NVIDIA 卡。关于需求的更多信息，请参见 [*第一章*](B17166_01_Final_SB_epub.xhtml#_idTextAnchor015) 的 *GPU 配置*部分。

你可以在 https://github . com/packt publishing/Data-Processing-with-Optimus 找到本章的所有代码。

# 处理缺失值

处理数据时最常见的情况之一是在数据集中查找缺失值。

处理缺失值很重要，因为，例如，如果你想让许多机器学习算法正常工作，它们就不能有缺失值。或者，如果您正在创建一个报告，您不希望显示包含空值聚合的统计信息。

需要注意的是，Optimus 将`None`和`NaN` ( **不是数字**)值视为可互换值，以表示空值。要处理它们，你可以做两件事:删除数据或估算数据。在这一节中，我们将展示 Optimus 如何帮助完成这两项任务，而不提供何时使用每种方法的详尽统计解释。让我们看看Optimus如何帮助我们完成这两项任务。

## 删除数据

在这种情况下，我们将看到如何使用删除包含缺失值的整行或整列。

### 拆卸一排

首先，让我们用许多列中的一些空值创建一个数据帧:

```py
import numpy as np
df = op.create.dataframe({
    "A":[11,2,3,45,6,np.nan,2],
    "B":[1,2,np.nan,45,6,2,3],
    "C":[1,2,3,45,6,2,np.nan],
    "D":[1,2,3,45,6,2,np.nan],
    "E":[1,2,3,45,6,2,np.nan]
})
df.print()
         A           B           C           D            E
  (float64)   (float64)   (float64)   (float64)   (float64)
-----------  ----------  ----------  ----------  ----------
         11           1           1           1           1
          2           2           2           2           2
          3         nan           3           3           3
         45          45          45          45          45
          6           6           6           6           6
        nan           2           2           2           2
          2           3         nan         nan         nan
```

使用以下命令删除所有带有缺失值的行:

```py
print(df.rows.drop_na())
         A           B           C           D            E
  (float64)   (float64)   (float64)   (float64)   (float64)
-----------  ----------  ----------  ----------  ----------
         11           1           1           1           1
          2           2           2           2           2
         45          45          45          45          45
          6           6           6           6           6
```

### 删除列

要了解如何删除包含空值的列，我们必须首先为它创建一个数据框架:

```py
df = op.create.dataframe({
    "A":[11,2,3,45,6],
    "B":[1,2,None,45,6],
    "C":[1,2,3,45,6]
})
```

让我们打印数据帧以便更好地了解空值在哪里:

```py
df.print()
        A            B          C
  (int64)    (float64)    (int64)
---------  -----------  ---------
       11            1          1
        2            2          2
        3          nan          3
       45           45         45
        6            6          6
```

然后，删除`B`一栏:

```py
print(df.cols.drop("B"))
        A          C
  (int64)    (int64)
---------  ---------
       11          1
        2          2
        3          3
       45         45
        6          6
```

请记住，您还可以传递列名列表，如下所示:

```py
print(df.cols.drop(["A", "B"]))
```

在前面的例子中，我们删除了列`A`和`B`。让我们看看如何处理缺失值。

## 插补

插补指用替代值更新缺失数据。您可能丢失数据的原因可能是由于填写调查时的人为错误，甚至是来自流量传感器的数据流中断。

与删除相比，插补是更可取的选择，因为您永远不知道您决定删除的数据会如何影响模型的性能。

Optimus 提供了可以处理数字字符串数据的函数。让我们看看它是如何工作的。

### 数值插补

Optimus依靠的`impute`方法。使用这种方法，您可以轻松处理连续值。您可以应用以下四种技术之一来处理空值:

*   平均
*   中位数
*   最频繁
*   常数

让我们看一些例子。

首先，让我们创建一个包含一列数字的数据框架:

```py
import numpy as np
df = op.create.dataframe({"A":[1,2,3,45,6,2,np.nan]})
df.print()
```

这将打印一列整数，最后的值表示为`nan`:

```py
         A
  (float64)
-----------
          1
          2
          3
         45
          6
          2
        nan
```

现在我们将使用`impute`计算所有值的`median`值，并将其应用于`nan`值:

```py
df.cols.impute("A",data_type="continuous", strategy="mean")
```

现在，用平均值`9.83333`代替`nan`值:

```py
          A
  (float64)
-----------
          1
          2
          3
         45
          6
          2
    9.83333
```

有了平均值，你可以应用中值策略来替换`nan`，如下:

```py
df.cols.impute("A",strategy="median").print()
```

您将获得以下输出:

```py
          A
  (float64)
-----------
          1
          2
          3
         45
          6
          2
        2.5
```

此外，您可以使用最频繁的值(这也称为分类插补)，如下所示:

```py
print(df.cols.impute("A",strategy="most_frequent"))
```

您将获得以下输出:

```py
          A
  (float64)
-----------
          1
          2
          3
         45
          6
          2
          2
```

如果您的数据与之前的任何案例都不匹配，您可以用您输入的任何值替换`nan`值:

```py
print(df.cols.impute("A", strategy="constant", 
                     fill_value=1))
```

此将打印以下输出:

```py
          A
  (float64)
-----------
          1
          2
          3
         45
          6
          2
          1
```

现在我们知道了如何处理数字列，让我们学习如何处理字符串值。

### 字符串插补

当涉及到到字符串列时，Optimus 只给你使用`most_frequent`方法。让我们创建一个要使用的数据框架:

```py
df = op.create.dataframe({
    "A":[1,2,3,45,6,2,3],
    "B":["Optimus", "Bumblebee", "Eject", "Optimus", 
         "Bumblebee", "Eject", np.nan]
})
```

它的工作方式与处理字符串值相同:

```py
print(df.cols.impute("B", strategy="most_frequent"))
 A    B
 1    Optimus
 2    Bumblebee
 3    Eject
45    Optimus
 6    Bumblebee
 2    Eject
 3    Bumblebee
```

如您所见，有很多选项可以估算缺失值。现在，是时候学习如何处理异常值了。

# 处理异常值

异常值是指远离样本中所有其他数据点且与之不相似的数据点:

![Figure 7.1 – Outlier (marked in red)
](img/B17166_07_01.jpg)

图 7.1–异常值(用红色标记)

异常值可使用图形(箱线图)和非图形方法检测，图形方法更直观。让我们谈谈非图形统计方法:

*   Tukey 或百分位数
*   z 分数
*   修改的 z 分数

为了展示 Optimus 如何处理异常值，让我们在考虑所有数据的同时创建一个具有正负极值的数据集。它们的值将介于 40 和-50 之间:

```py
df = op.create.dataframe(
         {"A":[1,2,3,45,6,-50,np.nan],
          "B":["Optimus","Bumblebee","Eject","Optimus",
               "Bumblebee","Eject",np.nan] })
```

现在，让我们应用这三种方法。

## Tukey

**Tukey** 是一种检测离群值的数学方法。这里使用四分位数。Optimus 使用这种方法计算下限和上限，如下所示:

*   下限:Q1-1.5 *智商
*   上限:Q3+1.5 *智商

这里，Q1 是第一个四分位数，Q3 是第三个四分位数，智商是四分位数之间的范围。

在 Tukey 中，超出该值范围的每个数据点都被视为异常值。

使用`info`方法，你可以对这种方法有一个大致的了解:

```py
df.outliers.tukey("A").info()
```

对于 Tukey，您可以通过上限值和下限值获得异常值和非异常值的计数:

```py
{
 'count_outliers': 2,
 'count_non_outliers': 4,
 'lower_bound': -4.75,
 'lower_bound_count': 1,
 'upper_bound': 11.25,
 'upper_bound_count': 1,
 'q1': 1.25,
 'median': 2.5,
 'q3': 5.25,
 'iqr': 4.0
}
```

`lower_bound`和`upper_bound`值代表极限值，在该极限值之后，值被视为异常值。在这种情况下，被视为异常值的值是在-4.75 和 11.25 范围之外的值。

现在，如果您只想获得异常值，您可以使用`select`方法:

```py
print(df.outliers.tukey("A").select())
```

这将返回包含异常值的数据帧:

```py
          A  B
  (float64)  (object)
-----------  ----------
         45  Optimus
        -50  Eject
```

如果您想要丢弃异常值，您可以使用`drop`方法:

```py
print(df.outliers.tukey("A").drop())
```

如您所见，值 45 被视为异常值，已从数据集中移除:

```py
          A  B
  (float64)  (object)
-----------  ----------
          1  Optimus
          2  Bumblebee
          3  Eject
          6  Bumblebee
        nan  nan
```

您也可以分别使用`select_upper_bound()`和`select_lower_bound()`方法选择高于上限和低于下限的值:

```py
Print(df.outliers.tukey("A").select_lower_bound())
```

通过这样做，您将获得数据框架底部的异常值:

```py
          A  B
  (float64)  (object)
-----------  ----------
        -50  Eject
```

如果您想要选择高于上限的数据，您可以使用`select_upper_bound()`，就像这样:

```py
print(df.outliers.tukey("A").select_upper_bound())
```

通过这样做，您将获得数据帧的顶部异常值:

```py
          A  B
  (float64)  (object)
-----------  ----------
         45  Optimus
```

Tukey 有其他有用的方法，你可以用来获得更多关于 Tukey 方法结果的信息。

要计算非异常值，您可以使用`non_outliers_count`方法:

```py
df.outliers.tukey("A").non_outliers_count()
```

这将打印以下输出:

```py
4
```

要计算异常值，请使用以下命令:

```py
df.outliers.tukey("A").count()
```

您将获得以下输出:

```py
3
```

要获得关于四分点和胡须的信息，请使用以下命令:

```py
df.outliers.tukey("A").whiskers()
```

上述示例将打印包含以下值的 Python 字典:

```py
{'lower_bound': -4.75, 'upper_bound': 11.25, 'q1': 1.25, 'median': 2.5, 'q3': 5.25, 'iqr': 4.0}
```

就像 Tukey 一样，可以使用 Z-score 来获得不同的界限。

## Z 分数

Z 分数在统计学领域是一个非常有用的概念。它向我们展示了一个数据点是否偏离了一组值的平均值，如果偏离了，偏离了多远。更具体地说，Z 分数告诉我们，与平均值相比，一个数据点有多少标准偏差。

如果任何数据点的 Z 得分大于 22，则该数据点与其余数据点非常不同，可以被视为异常值。

在 Optimus 中，通过使用`threshold`参数，您可以指出一个点应该偏离平均值多少个标准偏差，从而将其视为异常值:

```py
threshold=2
print(df.outliers.z_score("A", threshold).select())
```

这将返回包含异常值的数据帧:

```py
          A
  (float64)
-----------
         31
        -21
```

为了更好地理解这一点，让我们计算一下`A`列的 Z 分数:

```py
print(df.cols.z_score("A"))
```

这将返回以下输出:

```py
          A
  (float64)
-----------
  -0.224362
  -0.143592
 -0.0628213
    2.19875
    0.17949
   -2.00131
        nan
  -0.143592
   0.017949
```

如果你想去掉离群值，你可以使用`drop`方法，如下:

```py
print(df.outliers.z_score("A", threshold).drop())
```

这将返回以下输出:

```py
          A
  (float64)
-----------
          1
          2
          3
          6
        nan
          2
          4
          6
```

与 Tukey 方法一样，我们可以分别获得高于和低于下限和上限的数据。

如果你想选择高于上限的数据，你可以使用`select_lower_bound()`，就像这样:

```py
print(df.outliers.z_score("A").select_lower_bound())
```

这将返回数据帧底部的异常值:

```py
          A
  (float64)
-----------
        -21
```

要选择顶部的选项，您可以使用以下命令:

```py
print(df.outliers.z_score("A").select_upper_bound())
```

这个将得到如下输出:

```py
          A
  (float64)
-----------
         31
```

类似于 Tukey，在 Z_score 中，你有`info()`、`non_outliers_count()`、`threshold).count()`。

如果希望避免误导边界，可以向 Z 得分的修改版本传递一个阈值。

## 修改后的 Z 值

我们使用 Z 得分找出潜在的异常值，但是，这可能不准确，尤其是对于较小的样本量，因为最大 Z 得分最多是*(n1)/sqrt(n)*。

作者 *Iglewicz* 和 *Hoaglin* 推荐使用修改后的 Z 分数:

*Mi=0.6745(xi 中值(x))/MAD*

这里， **MAD** 表示**中值绝对偏差**。

在Optimus中，你可以轻松应用`modified_z_score`。让我们看看它是如何工作的。

前述作者还建议使用阈值`3.5`:

```py
print(df.outliers.modified_z_score("A", threshold=3.5).select())
          A
  (float64)
-----------
         31
        -21
```

与`z_score`方法一样，您可以使用`modified_z_score`检查修改后的 Z 分值:

```py
print(df.outliers.modified_z_score("A", threshold).select())
          A
  (float64)
-----------
     0.6745
    0.33725
          0
      9.443
    1.01175
      8.094
        nan
    0.33725
    0.33725
```

您可以使用以下命令删除异常值:

```py
print(df.outliers.modified_z_score("A", threshold).drop())
```

您将获得以下输出:

```py
        A
  (float64)
-----------
          1
          2
          3
          6
        nan
          2
          4
          6
```

与 Z 分数类似，使用修改后的 Z 分数，您也可以使用`info`、`count`和`non_outliers_count`方法计数。这三种方法都将我们的数据分组以获得异常值，但是我们也可以使用宁滨以一种定制的方式将这些数据分组。让我们来看看。

# 宁滨

宁滨的思想是将一些值分组到一个特定的类别中，从而减少数据集中唯一值的数量。

例如，假设我们正在创建一列数字，如下所示:

```py
df = op.create.dataframe(A=[1,2,3,31,6,-21,np.nan,2,4,6])
          A
  (float64)
-----------
          1
          2
          3
         31
          6
        -21
        nan
          2
          4
```

在这里，我们可以将的值分为低、中、高三类。为此，我们可以使用`cut`方法:

```py
df.cols.cut("A", bins = [0,4,6,35] ,
            labels = ["low", "medium","high"])
```

`cut`方法将把`low`值赋给 0 到 4 之间的任何值，`medium`赋给 4 到 6 之间的任何值，`high`赋给 6 到 35 之间的任何值:

```py
A
(category)
------------
low
low
low
high
medium
nan
nan
low
low
```

谈论垃圾箱的工作原理很重要。Optimus将包括最右边的边，但不包括左边的边。我们使用的面元[0，4，6，35]将表示为(0，4)，(4，6)，(6，35)。这意味着当宁滨时，Optimus 将不会为第一个 bin 取 0 值，但会为第二个 bin 取 4 值，也不会为第二个 bin 取 4 值，但会为第二个 bin 取 6 值:

![Figure 7.2 – How cut works in Optimus
](img/B17166_07_02.jpg)

图 7.2–cut 在 Optimus 中的工作原理

您也可以将`cut`应用于分类数据，如下所示:

```py
df = op.create.dataframe(A=["Maracaibo", "Caracas", "CDMX",
                            "Monterrey", "Bogota"])
print(df.cols.cut("A", ["Maracaibo", "Caracas", "CDMX", 
                        "Monterrey", "Bogota"], 
                  labels=["Venezuela", "Venezuela", 
                          "Mexico", "Mexico", "Colombia"]))
```

这将返回一个数据帧，其中我们将每个状态分组到它们各自的状态:

```py
A
(object)
----------
Venezuela
Venezuela
Mexico
Mexico
Colombia
```

宁滨通常用于建立更健壮的模型，从而以数据丢失和性能为代价防止过度拟合。分类列合并值会有所帮助，从而减少唯一值的总数。

但是，它主要为包含数字数据的列提供类别，牺牲了分辨率。这对于某些机器学习算法来说可能是多余的。

# 变量转换

一些机器学习模型，如线性和逻辑回归，假设变量遵循正态分布。更有可能的是，真实数据集中的变量将遵循更偏态的分布。

通过对这些变量进行一些转换，并将它们的偏态分布映射到正态分布，我们可以提高模型的性能。

绘制直方图或使用 Q-Q 图可以让您了解数据是正态分布还是偏态分布。

接下来，我们将看看您可以用来调整数据分布的四种方法。

## 对数变换

这是最简单的和最流行的不同类型的转换，并涉及一个显著影响分布形状的实质性转换。

我们可以使用它(自然对数 ln 或以 10 为底的对数)使极度偏斜的分布更少偏斜，特别是对于右偏斜(或正偏斜)的分布。

在 Optimus 中，您可以使用`log`方法:

```py
print(df.cols.log("A"))
```

这将把日志应用到列:

```py
          A
  (float64)
-----------
          0
    0.30103
   0.477121
    1.65321
   0.778151
   0.845098
        nan
```

该方法将来自`A`的值转换成其对数。另一种可用于转换正偏态分布的方法是平方根。让我们来看看。

## 平方根变换

另一个简单的变换，这个对分布形状有一个平均效果:它比对数变换弱，也用于减少正偏分布。

平方根变换的一个优点是可以应用于零值。

在 Optimus 中，您可以为此使用`sqrt`方法:

```py
print(df.cols.sqrt("A"))
          A
  (float64)
-----------
          1
    1.41421
    1.73205
     6.7082
    2.44949
    2.64575
        nan
```

正如我们已经知道的，方法将返回转换后的 dataframe，但是现在在`A`列上有平方根值。除了平方根变换，您还可以对右偏分布使用倒数变换。

## 相互转化

倒数变身是一个强大的变身，具有激进的效果。倒数会反转相同符号值的顺序，因此大值会变小。负倒数保持相同符号的值之间的顺序。

你应该注意到这个函数不是为 0 定义的。

在 Optimus 中，你可以像这样使用`reciprocal`方法:

```py
print(df.cols.reciprocal("A"))
          A
  (float64)
-----------
          1
        0.5
   0.333333
  0.0222222
   0.166667
   0.142857
        nan
```

正如您所看到的，这里显示的值是输入值的倒数。您可以使用其他已知的变换，如指数或幂变换。

## 指数或幂变换

动力转换对分配形状有合理的影响；通常，我们应用幂变换(通常是 2 的幂)来减少左偏。

在 Optimus 中，你可以使用`pow`或`exp`方法来完成这个任务。试试看哪一个能给你更好的结果:

```py
print(df.cols.pow("A", 2))
          A
  (float64)
-----------
          1
          4
          9
       2025
         36
         49
        nan
```

如您所见，这些值发生了巨大的变化。

但是如果我们不使用数字列呢？对此，我们有一个方法叫做`string_to_index`。让我们来看看。

## 要索引的字符串

索引字符串将一个数值分配给列中的每个相同值。让我们来看看它是如何工作的。

首先，让我们创建一个包含几个重复值的数据帧:

```py
df = op.create.dataframe({
    "A":["Optimus","Bumblebee","Eject","Optimus","Eject"]
})
```

这将为您提供如下所示的数据帧:

```py
A
(object)
----------
Optimus
Bumblebee
Eject
Optimus
Eject
```

现在，让我们应用`string_to_index`方法:

```py
print(df.cols.string_to_index())
```

这将创建一个列，并将值`0`分配给`Bumblebee`、`1`分配给`Eject`、以及`2`分配给`Optimus`:

```py
A             A_string_to_index
(object)                (int32)
----------  -------------------
Optimus                       2
Bumblebee                     0
Eject                         1
Optimus                       2
Eject                         1
```

在这个例子中，我们给`A`上的每个值分配了一个索引。我们可以这样做，以允许机器学习算法将此列用作数字列。现在，让我们看看另一种方法，也允许这样做，但以更好的方式，称为一热编码。

# 一键编码

One-hot encoding 是一个将分类数据转换为更容易用于机器学习算法的替代形式的过程，这反过来会导致更好的预测。

为了说明其工作原理，假设我们有以下数据框架:

```py
df = op.create.dataframe({"A":["Optimus","Bumblebee","Eject", "Megatron"], "B":["Transformer","Transformer","Transformer","Decepticon"]})
A           B
(object)    (object)
----------  -----------
Optimus     Transformer
Bumblebee   Transformer
Eject       Transformer
Megatron     Decepticon
```

大多数机器学习算法只能处理数字，因此，通过 one-hot 编码，我们将创建一个包含类别名称的列，如果观察值属于特定类别，则将 0 或 1 分配给该行:

```py
print(df.encoding.one_hot_encoder("B"))
```

这将导致以下输出:

```py
A           B              B_Decepticon    B_Transformer
(object)    (object)            (uint8)          (uint8)
----------  -----------  --------------  ---------------
Optimus     Transformer               0                1
Bumblebee   Transformer               0                1
Eject       Transformer               0                1
Megatron     Decepticon               1                0
```

这里`Megatron`属于的`Decepticon`类，所以编号`1`被分配给`B_Decepticon`列，而`0`被分配给`B_Transformer`。

但是，如果我们的值比类别更复杂，我们需要应用其他方法将这些值拆分到多个列中。

# 特征分割

特征分割是一种技术，包括从一列中分割数值以创建新的数值。一个很好的例子是将保存在一列中的名字和姓氏拆分为两个单独的列，或者将日期拆分为三列，分别表示月中的日期、月份和年份。分割特征的主要目的是为机器学习算法提供更好解释的小数据包数据，并最终提高机器学习模型的性能。

对于特色分割，我们可以使用`unnest`方法，我们在第 3 章 的 [*中看到过。然而，在那里，我们专注于如何产生特征来支持我们的机器学习算法。*](B17166_03_Final_VK_epub.xhtml#_idTextAnchor064)

首先，让我们从包含一些字符串值的数据帧开始:

```py
df = op.create.dataframe({"A":["Argenis Leon","Luis Aguirre","Favio Vasquez",np.nan]})
print(df.cols.unnest("A"," ", drop=True))
```

`drop`参数将删除您正在分割的列，返回姓名和姓氏以及数据帧中的任何其他列:

```py
A_0         A_1
(object)    (object)
----------  ----------
Argenis     Leon
Luis        Aguirre
Favio       Vasquez
nan
```

另一种常见的情况是将日期拆分为日、月和年。首先，让我们创建一个包含一些日期的数据框架:

```py
df = op.create.dataframe({"A":["10/04/1980","20/05/1995","01/08/1990",np.nan]})
```

现在，让我们将它们分成三列，同时保留原始列:

```py
df.cols.unnest("A", "/", splits=3, 
               output_cols=["day","month","year"])
A                  day       month        year
(object)      (object)    (object)    (object)
----------  ----------  ----------  ----------
10/04/1980          10          04        1980
20/05/1995          20          05        1995
01/08/1990           1          08        1990
```

我们已经知道，`unnest`用给定的分隔符将我们的值分开，这对于机器学习的数据准备非常有用。另一种准备数据的方法是缩放数值。让我们来看看。

# 缩放

缩放包括将数据集中的数字特征纳入相同的值范围。例如，在一个数据集中，您可能期望年龄范围在 30 到 75 岁之间，工资在 30，000 美元到 120，000 美元之间。因为两个特征的比例非常不同，这可能会损害模型的性能。

虽然缩放对于许多算法来说不是强制性的，但一些基于距离计算的算法，如 k-NN 或 k-means，需要具有缩放的连续特征才能运行良好。

为了帮助你完成这项任务，Optimus 给了你三种缩放方法:

*   正常化
*   标准化
*   最大 abs 定标器

为了向您展示它们是如何工作的，让我们从创建一个简单的数据帧开始:

```py
df = op.create.dataframe({"A":[1.12,3.2,4.35,6.3,7.3,np.nan]})
```

现在，让我们学习如何应用规范化。

## 正常化

标准化(也称为最小-最大标准化)在 0 和 1 之间的固定范围内缩放所有值。在 Optimus 中，您可以通过使用`cols`访问器来使用`min_max_scaler`方法，就像这样:

```py
print(df.cols.min_max_scaler("A"))
```

这里，输出将被缩放:

```py
          A
  (float64)
-----------
          0
    0.33657
   0.522654
   0.838188
          1
        nan
```

请记住和您总是可以使用`output`参数将结果输出到另一列，就像这样:

```py
print(df.cols.min_max_scaler("A", output_cols="A_normalized"))
```

这对于维护数据集中的两列非常有用，因为该方法应用了一个不可还原的函数。让我们来看一个叫做`standard_scaler`的类似方法。

## 标准化

标准化(或 Z 分数标准化)重新调整值以确保平均值为 0，标准差为 1。在 Optimus 中，您可以使用`standard_scaler`方法:

```py
print(df.cols.standard_scaler("*"))
```

这将导致以下缩放的列:

```py
          A
  (float64)
-----------
   -1.51526
  -0.569926
 -0.0472666
   0.838981
    1.29347
        nan
```

正如我们可以看到的，我们将得到大于 1 小于 0 的值，不像归一化。另一种缩放方法是 max abs scaler。让我们来看看。

## 最大 abs 定标器

此方法用于使用最大绝对值来缩放要素。

这个估计器修改每个特征，使得对于训练集，每个特征的最大绝对值正好是 1.0。它不会移动或更改数据，因此不会消除任何一致性。

在 Optimus 中，你可以像这样使用`max_abs_scaler`方法:

```py
print(df.cols.max_abs_scaler("*"))
```

作为回报，您将得到一个包含换算值的列:

```py
          A
  (float64)
-----------
   0.153425
   0.438356
    0.59589
   0.863014
          1
        nan
```

我们可以看到，这个结果的最大值为 1。

对于不同的情况，我们有很多选项来调整列的值。

# 总结

在这一章中，我们讨论了很多为机器学习算法准备数据的技术。

其中一种技术是插补，它对于包含空值的数据很有用。对于包含意外值的数据，我们可以应用异常值处理。

通过使用宁滨，我们可以对数字数据进行分类。如果我们的数字数据没有正确分布，我们可以通过应用变量转换来消除偏斜，使用我们在前面章节中看到的方法。

另一方面，一键编码允许我们将一列中的值分成多个布尔列。我们可以使用特征分割将包含大量数据的一个值分割成多个值。最后，我们学习了如何使用多种方法来扩展我们的数据。

现在你已经了解了所有这些技术，你可以向机器学习迈出第一步了。

在下一章中，我们将学习如何使用我们已经准备好的数据，通过 Optimus 中可用的方法来创建模型。