# 三、数据处理

现在我们的数据已经加载到内存中，我们需要转换它，使它满足我们的需要。首先，我们将讨论转换、搜索和替换数据，包括字符串、日期、电子邮件和 URL。谈到数字数据，我们将回顾 Optimus 中可用的数学和三角函数。

为了结束这一章，我们将学习如何编写一些自定义函数来扩展数据整理的可能性并改进 Optimus。

我们将在本章中讨论的主题如下:

*   探索 Optimus 数据类型
*   操作柱
*   尝试用户定义的函数

# 技术要求

Optimus 可以与多种后端技术一起处理数据，包括 GPU。对于 GPU，Optimus 用的是**激流**，需要 NVIDIA 卡。更多关于这方面的要求，请到第一章[](B17166_01_Final_SB_epub.xhtml#_idTextAnchor015)**的 *GPU 配置*部分，嗨Optimus！*。*

 *你可以在[https://github . com/packt publishing/Data-Processing-with-Optimus](https://github.com/PacktPublishing/Data-Processing-with-Optimus)找到本章的所有代码。

# 探索 Optimus 数据类型

数据类型是数据帧的灵魂:它们定义了一个值如何在内存中表示，更重要的是，它将使用多少内存。Optimus 支持的每种数据帧技术都有不同的数据类型来表示特定的数据。最常见的是数值、字符串值和日期时间值。通过访问相应的网站或文档，您可以找到每种技术支持的数据类型。该信息可在本章的*进一步阅读*部分找到。

除了内部数据表示，Optimus 试图丰富数据，让用户更好地了解数据是如何被整理的。例如，当您看到一个 *email* 类型的列时，在内部，它只是一个字符串列，但是当请求进行概要分析时，它会向我们提供关于列上有多少不匹配(与类型不匹配的数据点)的反馈。我们将在本书的后面更多地讨论分析器。

## 转换数据类型

Optimus 被设计成让你转换成任何你需要的数据类型，不管数据采取什么形式。在大多数 dataframe 技术的情况下，如果您尝试从不兼容的数据类型转换，例如从非整数值(如字符串形式的`"optimus"`)转换为整数，将会引发错误。

让我们开始使用字典创建一些数据作为示例。在这个数据中，我们将包括一些汽车人和他们的工作，但也包括一些占位符数值和一个出生列来测试一些功能:

```py
df = op.create.dataframe({
    "name": ["optimus", "bumblebee", "eject", 2],
    "job": ["Leader", "Espionage", 1, 3],
    "id": [1, 2, 3, 4],
    "birth": ["22/10/10", "22/08/08", "23/07/07", "22/10/10"]
})
name        job                id  birth
(object)    (object)      (int64)  (object)
----------  ----------  ---------  ----------
optimus     Leader              1  22/10/10
bumblebee   Espionage           2  22/08/08
eject       1                   3  23/07/10
2           3                   4  22/10/10
```

让我们做一个小测试。通过使用`df.data`，您可以访问数据帧的内部表示。如果您使用 pandas 引擎，您将获得一个 pandas 数据帧:

```py
print(df.data)
print(type(df.data))
        name        job  id     birth
0    optimus     Leader   1  22/10/10
1  bumblebee  Espionage   2  22/08/08
2      eject          1   3  23/07/07
3          2          3   4  22/10/10
<class 'pandas.core.frame.DataFrame'>
```

正如我们所看到的，我们打印了内部数据帧及其类型，这给了我们一个与调用`print(df)`不同的结果。

让我们看看当我们试图将内部数据帧的字符串列的值转换成整数值时，会发生什么情况:

```py
df.data["name"].astype(int)
```

这将引发以下错误:

```py
ValueError: invalid literal for int() with base 10: 'optimus'
```

对于熊猫，您可以使用`pd.to_numeric()`来处理这种类型的场景。然而，它似乎打破了我们在数据框架上操作的流程。

现在，让我们看看Optimus如何处理这件事。

让我们将数据集的`name`列的数据类型转换为整数:

```py
df.cols.to_integer("name")
```

我们将看到类似如下的结果:

```py
     name  job                id  birth
  (int64)  (object)      (int64)  (object)
---------  ----------  ---------  ----------
        0  Leader              1  22/10/10
        0  Espionage           2  22/08/08
        0  1                   3  23/07/10
        2  3                   4  22/10/10
```

`to_integer`方法将非整数值转换成`0`。

现在，让我们使用`to_float`将`"name"`列的数据类型转换为 float:

```py
df.cols.to_float("name")
       name  job                id  birth
  (float64)  (object)      (int64)  (object)
-----------  ----------  ---------  ----------
        nan  Leader              1  22/10/10
        nan  Espionage           2  22/08/08
        nan  1                   3  23/07/10
          2  3                   4  22/10/10
```

这里，非浮点兼容值被转换成`nan`(不是数字)。如果 dataframe 内部不支持`nan`值(例如，使用 pandas 1.0 之前版本时的 pandas dataframe)，非整数值将被转换为`0`。

另一方面，将`int`列转换为字符串可能不会改变值显示给用户的方式，但会改变内部列的数据类型:

```py
df.cols.to_string("id")
```

正如我们将看到的，`id`列数据类型从`int`变为`object`:

```py
name        job                 id  birth
(object)    (object)      (object)  (object)
----------  ----------  ----------  ----------
optimus     Leader               1  22/10/10
bumblebee   Espionage            2  22/08/08
eject       1                    3  23/07/10
2           3                    4  22/10/10
```

对于 datetime，我们可以将一个字符串转换成 datetime 对象，这样我们就可以应用这个函数来提取日期元素，如日、月、年、小时、分钟和秒。

对于这个函数，您必须在第二个参数中包含格式。您也可以为此使用`format`关键字:

```py
df.cols.to_datetime("birth", "YY/mm/dd")
```

正如我们将看到的，这将把`birth`列转换成 datetime 数据类型:

```py
name        job                id  birth
(object)    (object)      (int64)  (datetime64[ns])
----------  ----------  ---------  -------------------
optimus     Leader              1  2022-10-10 00:00:00
bumblebee   Espionage           2  2022-08-08 00:00:00
eject       1                   3  2023-07-10 00:00:00
2           3                   4  2022-10-10 00:00:00
```

当我们转换 dataframe 的数据类型时，我们可能会隐式转换列的值，但这不是预期的行为。如果我们想要清理或转换数据帧的列，我们可以使用一些操作，就像我们接下来将要探索的那样。

# 操作栏

为了理解列操作，首先，我们来看看一些最常见的操作，它们是用于选择列的。在 Optimus 中，你有强大的`select`功能，它为管理大多数选择情况提供了多个选项。

## 选择列

选择列的最简单的用例是使用它的名称:

```py
df.cols.select("job").print()
```

您将得到作业列数据作为响应:

```py
job
(object)
----------
Leader
Espionage
1
3
```

如果您想通过全名选择多个列，可以使用 Python 列表，如下所示:

```py
df.cols.select(["name", "job"]).print()
```

这将返回`name`和`job`列数据:

```py
name        job
(object)    (object)
----------  ----------
optimus     Leader
bumblebee   Espionage
eject       1
2           3
```

正如我们已经知道的，如果我们想要保存修改后的数据帧，我们必须将操作结果赋回`df`，如下所示:

```py
df = df.cols.select("name", "job", "id")
```

另一个方便的参数是`invert`，您可以使用它来反转单个或一系列文件的选择:

```py
df.cols.select("job", invert=True).print()
```

这将返回除`name`列之外的所有列:

```py
name               id
(object)      (int64)
----------  ---------
optimus             1
bumblebee           2
eject               3
2                   4
```

您还可以应用正则表达式来选择列。对于本例，使用`^n.`正则表达式，您可以获得所有以字母 n 开头的列:

```py
df.cols.select(regex="^n.").print()
name
(object)
----------
optimus
bumblebee
eject
2
```

最后，您可以按数据类型选择列，如下所示:

```py
df.cols.select(data_type="int").print()
```

这样，您就可以获得整数数据类型的所有列，以防您想要过滤掉非数字数据。但是，这在报表数据框架中可能没有用，例如:

```py
       id
  (int64)
---------
        1
        2
        3
        4
```

接下来，我们将看看移动列。

## 移动列

要更改数据集的列的顺序，您可以使用`df.cols.move`，它可以帮助我们轻松地组织我们的列。要使用它，您必须将列(或单个列)输入到函数中，告诉它将所选列相对于引用列放置在哪里。让我们看一个例子:

```py
df.cols.move(["name", "job"], "after", "id")
```

这将把数据集的列组织成表单`["id", "name", "job"]`。如果您将`"end"`而不是`"after"`传递给`position`参数(第二个),并且不向`ref_col`(第三个)传递任何东西，这个顺序也是有效的:

```py
df.cols.move(["name", "job"], "end")
```

`position`参数有四个可能的值:

*   `"before"`:移动已通过的一列或多列，使其位于`ref_col`中的一列之前。
*   `"after"`:移动被传递的一列或多列，使它们位于`ref_col`中的一列之后。
*   `"beginning"`:这会将传递的一列或多列放在开头。对于`ref_col`不需要任何值。
*   `"end"`:这将把传递的一列或多列放在最后。不需要`ref_col`的任何值。

现在，让我们看看重命名列。

## 重命名列

您可以通过简单地使用`df.cols.rename`来轻松地重命名一列或一列列表。这个函数只使用两个参数，其中您必须输入要更改其名称的列的名称以及您希望它拥有的名称。它还支持两个参数的数组，允许通过只调用一次函数来重命名多个列。让我们看两个例子:

```py
df = df.cols.rename(["name", "job"], ["string_name", "string_job"])
df = df.cols.move("id", "int_id")
```

保存在`df`上的结果数据帧将包含`["int_id"`、`"string_name"`和`"string_job"]`列。

## 移除列

Optimus 有两个主要的函数，允许我们过滤数据集中的列:`drop`和`select`。第一个选项允许我们选择从数据集中删除哪些列，而第二个选项则相反，删除所有未输入的列。

如果我们调用`df.cols.drop("job")`，那么`"job"`列将从数据集中删除，剩下`"id"`和`"name"`。相反，如果我们调用`df.cols.select("job")`，那么只有该列会出现在结果数据集中。此外，两个函数都支持数组中的多列，如下所示:

```py
df.cols.select(["job", "name"])
```

在前面的示例中，我们通过将`"id"`和`"name"`传递给`df.cols.select`来隐式地从数据集中移除`"id"`。

## 输入和输出列

Optimus 中一个方便而强大的功能是可以操作一组、多组或整组列，并轻松控制输出。

一些函数(具体来说，每个改变列内容的函数)可以被配置，这样它就可以应用于一列列表。Optimus 还允许我们将那些变异的列保存在一组新列中，这些新列已经被追加到数据集。

比如，`df = df.cols.upper("name")`会对 name 列进行变异并覆盖，将字符串转换成大写(后面我们会学习`upper`和其他字符串函数是如何工作的)，然后将得到的 dataframe 保存到`df`，覆盖之前的那个。让我们看看每种情况，包括动态生成的输出列名，以及将整个数据集输入到一个操作中。

您可以通过运行以下命令来**修改单个列**:

```py
df = df.cols.upper("name")
```

这里，我们正在修改`"name"`并创建 0 个新列。

您可以通过运行以下命令**修改多个列**:

```py
df = df.cols.upper(["name", "job"])
```

这里，我们正在修改`"name"`和`"job"`并创建 0 个新列。

您可以通过运行以下命令**修改单个列并将其保存到新的列**:

```py
df = df.cols.upper("name", output_cols="name_upper")
```

我们在这里不修改现有的列；相反，我们从操作`"name"`的结果中创建`"name_upper"`:

您可以通过运行以下命令**修改多个列并保存到一组新的列**:

```py
df = df.cols.upper(["name", "job"], output_cols=["name_upper", "job_upper"])
```

我们在这里不修改以前存在的列；相反，我们从操作`"name"`和`"job"`的结果中创建`"name_upper"`和`"job_upper"`。

通过运行以下命令，您可以使用后缀修改多个列并保存到一组新的列中:

```py
df = df.cols.upper(["name", "job"], "upper")
```

同样，我们不是修改现有的列；相反，我们正在创建`"name_upper"`和`"job_upper"`，但是这一次，名称是从操作`"name"`和`"job"`的结果中动态生成的。

您可以`"*"`:

```py
df = df.cols.upper("*")
```

这里，我们修改数据集中的每一列。

注意，你也可以**连锁操作**，如下图所示:

```py
df = df.cols.upper("name").cols.lower("job")
```

这个特定的命令会将列名转换成大写，将作业列转换成小写。

既然我们已经很好地理解了数据类型的工作方式以及如何管理输入和输出列，那么让我们看看可以对它们应用哪些函数。

## 管理功能

如果您想要创建、复制、删除或重命名数据集中的一个或多个列，语法与前面显示的基本操作非常相似。

调用`drop`方法将从数据集中删除列:

```py
df = df.cols.drop("job")
```

这只会删除名为`"job"`的列。

如果想删除除一列(或多列)以外的所有列，可以调用`keep`:

```py
df = df.cols.keep("id")
```

在前面的例子中，我们删除了除`id`之外的所有列。

要重命名列，`output_cols`参数不是可选的。让我们看一个例子:

```py
df = df.cols.rename("name", "first_name")
```

在前面的代码中，我们只是简单地将`name`列重命名为`first_name`，但是如果我们想要重命名一系列列而不是一个列，我们只需传递两个名称列表。

`duplicate`方法以类似的方式工作——它只需要`output_cols`参数。这里您可以看到一个包含两列而不是一列的示例:

```py
df = df.cols.duplicate(["name", "id"], ["first_name", "id_number"])
```

对于创建列，有很多选项。最常见的是`set`，它也可以设置现有列的内容，但是在本例中，我们使用它来创建一个填充了`None`的新列:

```py
df = df.cols.set("last_name", None)
```

如果您创建了一个空列，您可以使用`fill_na`将所有的`None`值替换为任何其他值:

```py
df = df.cols.fill_na("last_name", "Placeholder Value")
```

`fill_na`方法对于已经存在且部分填充的列也很有用，因为它只会设置列中空行的值。

## 字符串功能

字符串函数是自描述的。让我们看看所有的功能和每个功能的简要描述。我们只看其中几个例子，因为有些操作非常相似:

![](img/B17166_03_001.jpg)

图 3.1–字符串函数

让我们以`upper` 函数来说明这个操作是如何工作的。如果要对一列进行操作，请执行以下操作:

```py
print(df.cols.upper("name"))
```

这将转换标题为`"name"`的列:

```py
name(object)    job(object)      id(int64)
--------------  -------------  -----------
OPTIMUS         leader                   1
BUMBLEBEE       espionage                2
EJECT           1                        3
2               3                        4
```

这是最基本的操作。让我们看看如何用函数的输出创建一个新列，而不是替换原来的列:

```py
print(df.cols.upper("name", "upper_name"))
```

这将创建一个名为`"upper_name"`的新列，其中包含来自`name`的大写值:

```py
name(object)    upper_name(object)    job(object)      id(int64)
--------------  --------------------  -------------  -----------
optimus         OPTIMUS               leader                   1
bumblebee       BUMBLEBEE             espionage                2
eject           EJECT                 1                        3
2               2                     3                        4
```

所有字符串函数都可以应用于任何数据类型。例如，您可以将`df.cols.pad`调用到一个整数列，Optimus 会在应用`pad`函数之前将该列的数据类型转换为 string:

```py
print(df.cols.pad("id", 3, "0"))
```

这将修改现有的`id`列:

```py
name(object)    upper_name(object)    job(object)      id(object)
--------------  --------------------  -------------  -----------
optimus         OPTIMUS               leader                 001
bumblebee       BUMBLEBEE             espionage              002
eject           EJECT                 1                      003
2               2                     3                      004
```

正如我们所看到的，Optimus 试图不那么严格地转换数据类型，而不是在操作可能不兼容的列时引发错误。这对于将一列的字符串值与另一列的数值连接起来很有用；为此，我们可以使用`nest`功能。让我们来看看。

### 合并和拆分列

当处理日期、姓名、地址或任何相当复杂的字符串数据时，合并和拆分是非常有用的功能。Optimus 为此提供了两个功能:`df.cols.nest`和`df.cols.unnest`。

为了说明这一点，首先，让我们看一个具有两列的示例数据集，出于示例目的，这两列将被拆分和合并——一列具有一对字符串格式的数字，表示二维空间中的一个点，另一列表示另一维空间中的点。这些数据纯粹是为了演示如何合并和拆分列:

```py
df = op.create.dataframe({ 
    "xy_position": ["42.8, 7.7", "23.3, 25.1", "35.6, 50.5", "52.7, 67.4"],
    "depth": [10.5, 50.1, 20.2, 97.0]
})
df.print()
xy_position          depth
(object)         (float64)
-------------  -----------
42.8, 7.7             10.5
23.3, 25.1            50.1
35.6, 50.5            20.2
52.7, 67.4            97 
```

首先，让我们看看如何通过对第一个维度应用`unnest`函数来将所有维度分成三列:

```py
df.cols.unnest("xy_position", separator=", ", output_cols=["x", "y"], drop=True).print()
```

我们将得到以下结果:

```py
          x           y        depth
   (object)    (object)    (float64)
-----------  ----------  -----------
       42.8         7.7         10.5
       23.3        25.1         50.1
       35.6        50.5         20.2
       52.7        67.4         97
```

正如我们所看到的，结果列现在可以作为数字列来操作，因为它们具有匹配的格式。

另一方面，假设我们运行`nest`函数来连接两个原始列:

```py
df.cols.nest(["xy_position", "depth"], separator=", ", output_col="xyz_position", drop=True).print()
```

我们将得到以下结果:

```py
xyz_position
(object)
----------------
42.8, 7.7, 10.5
23.3, 25.1, 50.1
35.6, 50.5, 20.2
52.7, 67.4, 97.0
```

这导致数据帧只有一列，包括所有三个维度。

当您拆分任何列时，它会在创建新列之前将其值转换为字符串，因此它的行为与预期一致。类似地，当联接两个或更多列时，无论输入列的类型如何，结果列都倾向于字符串。

### 搜索和替换

当我们有很多字符串数据时，替换列值中的字符或单词可能会很有用。为此，我们可以使用`df.cols.replace`，它允许我们搜索一个或多个值、单词或子字符串，并用给定的字符串替换它们。

让我们来看一个例子，其中有一些任意的名称，由稍后将被替换的字符分隔。为此，我们将再次使用一些汽车人:

```py
df = op.create.dataframe({
    "name": ["Optimus, Prime", "Arcee, Ariel", "Bumblebee/Maggiolino"]
})
df.print()
```

这将打印出以下内容:

```py
name       
(object)            
-----------------------
Optimus, Prime       
Arcee, Ariel
Bumblebee/Maggiolino
```

正如我们所看到的，该列中的名称是使用两个不同的分隔符输入的，即`", "`和`"/"`。现在，让我们运行`replace`功能:

```py
df.cols.replace("name", [", ", "/"], " ", search_by="chars").print()
```

在这里，我们得到了这种特定情况下的正确格式:

```py
name
(object) 
---------------------
Optimus Prime
Arcee Ariel
Bumblebee Maggiolino
```

在前面的例子中，我们用一个空白字符(`" "`)替换了所有的`", "`和`"/"`匹配。

## 数字功能

数值函数可分为三角函数和数学函数。与字符串操作一样，它支持所有的列类型，但要按预期方式工作，则取决于它们的内容:

![Figure 3.2 – Trigonometric functions
](img/B17166_03_002.jpg)

图 3.2–三角函数

在说明`sin`函数如何工作之前，让我们用数字和字符串创建一些示例任意数据。我们稍后将尝试操作:

```py
df = op.create.dataframe({ "values": [0.5, 2, "3.14"] })
df.print()
    values
  (object)
----------
      0.5 
      2   
      3.14
```

正如我们所看到的，`values`列被推断为对象列，因为我们将`"3.14"`作为字符串输入，但是当我们应用`sin`函数时，这应该不是问题:

```py
df.cols.sin("values").print()
```

我们将得到以下输出:

```py
     values
  (float64)
-----------
0.479426   
0.909297   
0.00159265 
```

在前面的例子中，我们可以看到当我们应用一个数值函数时，Optimus 是如何推断出一个数值类型的。

除了三角函数之外，还有其他函数可用:

![Figure 3.3 – Mathematical functions
](img/B17166_03_003.jpg)

图 3.3–数学函数

让我们看看`log`是如何工作的，因为它有一个额外的参数，不像其他的:

```py
df.cols.log("values", 5).print()
```

我们将得到相同的列，但是这一次，`values`中的所有数字都将有它们的对数:

```py
     values
  (float64)
-----------
  -0.430677
   0.430677
   0.710946
```

我们可以看到，当`5`作为底数的时候，所有的原始值都被它的对数代替了。

## 日期和时间功能

还有几个与日期和时间相关的功能:

![Figure 3.4 – Date and time functions
](img/B17166_03_004.jpg)

图 3.4–日期和时间函数

使用这些函数中的任何一个都有助于更改格式或从列值中提取数据。例如，假设我们有以下数据集，其中包含一些任意日期:

```py
date
(object)
----------
01/21/2021
09/09/2020
03/07/2020
```

我们可以调用`df.cols.year`从日期列中存储的值中只提取年份:

```py
df.cols.year("date")
```

我们将会得到以下结果:

```py
date
(object)
----------
2021
2020
2020
```

另一方面，`date_format`稍微高级一点，要求我们输入新的格式，如下所示:

```py
df.cols.date_format("date", output_format="%m-%d-%Y")
```

我们将得到以下结果:

```py
date
(object)
----------
01-21-2021
09-09-2020
03-07-2020
```

接下来，我们将看看 URL 函数。

## 网址功能

在 Optimus 中，URL 是作为字符串在内部处理的。但是，如果格式正确，您可以使用这些函数从 URL 中提取数据:

![Figure 3.5 – URL functions
](img/B17166_03_005.jpg)

图 3.5-URL 功能

例如，您可以使用 URL 的域、子域和端口创建一个新列。让我们看一个带有 URL 值的例子:

```py
from optimus import Optimus
op = Optimus("pandas") 

data = {"A": ["https://www.hi-optimus.com:8080/index.php?a=1"] }  
df = op.create.dataframe(data)

df["port"] = df.cols.port("A")
df["subdomain"] = df.cols.subdomain("A")
df["domain"] = df.cols.domain("A")
```

接下来，我们将看看电子邮件功能。

## 电子邮件功能

除了 URL 之外，Optimus 还可以处理电子邮件，并提供一些功能来方便数据提取:

![Figure 3.6 – Email functions
](img/B17166_03_006.jpg)

图 3.6–电子邮件功能

让我们看一个使用一些任意电子邮件的例子:

```py
df = op.create.dataframe({"A": ["optimus@cybertron.com"]})

df["username"] = df.cols.email_username("A")
df["domain"] = df.cols.email_domain("A")
```

在前面的例子中，我们采用了不同的方法；也就是说，通过将数据集设置为属性来创建新的数据集。如果赋值右侧的输出是一个具有单列的 dataframe，它将连接两个数据集。

现在我们已经看了 Optimus 中所有可用的函数，让我们学习如何编写我们自己的函数。

# 试验用户定义的函数

Optimus 试图提供开箱即用的最常用的功能，这样你就可以专注于你的工作，而不是写代码。当然，有时您需要编写自定义函数来完成任务。

在我们深入研究**用户定义的函数** ( **UDF** )之前，让我们探索几个关于如何处理数据的场景。两种这样的场景被称为矢量化和非矢量化执行。理解这一点很重要，因为它会对性能产生非常大的影响。

**向量化执行**指的是在一条语句中同时对一个向量的多个分量执行的操作。向量只是一系列元素，如下所示:

```py
[0, 1, 2, 3, 4, 5]
```

在**非向量化**操作的情况下，函数在每个元素中执行，一次一个。在前面的列表中，我们需要传递每个元素来执行一个操作。这就是为什么使用矢量化函数可以缩短我们工作流程中的处理时间。让我们看看这在 Optimus 中是如何工作的。

在 Optimus 中，vector 是如下所示的列，带有一系列数字。我们将以此为例:

```py
data = {"A": [0, 1,2,3,4,5], "B":[6,7,8,9,10,11] }df = op.create.dataframe(data)
df.print()
        A          B
  (int64)    (int64)
---------  ---------
        0          6
        1          7
        2          8
        3          9
        4         10
        5         11
```

现在我们将学习在 Optimus 中使用 apply。

## 使用应用

要在 Optimus 中应用 UDF，你可以定义自己的函数并使用`df.cols.apply`方法。例如，要定义一个将`2`添加到整列的函数，运行以下代码:

```py
def add_two(pandas_series):
    print(type(pandas_series))
    return pandas_series + 2

df.cols.apply("A", add_two).print()
```

这将输出整个数据集，其中`"A"`列的值增加了 2:

```py
        A          B
  (int64)    (int64)
---------  ---------
        2          6
        3          7
        4          8
        5          9
        6         10
        7         11
```

当您编写自己的 UDF 时，您必须注意如何处理传递给函数的数据。在这种情况下，因为我们使用的是 pandas 引擎，所以传递给函数的值是一个 pandas 系列，它支持以矢量化方式执行加号运算符。

但是有些函数是不能矢量化的。为此，我们可以使用`mode="map"`参数对每个元素执行一个函数:

```py
def add_two(single_value):    
    print(type(single_value))
    return single_value + 2

df.cols.apply("A", add_two, mode="map").print()
```

在这种情况下，`print`将被执行五次——每个元素一次:

```py
<class 'int'>
<class 'int'>
<class 'int'>
<class 'int'>
<class 'int'>
<class 'int'>
        A          B
  (int64)    (int64)
---------  ---------
        2          6
        3          7
        4          8
        5          9
        6         10
        7         11
```

另外，请记住，您可以使用星号`"*"`将函数应用于数据集中的每一列:

```py
def add_two(value):
    return value + 2
print(df.cols.apply("*", add_two))
```

这将为每列(`A`和`B`)的中的每个元素加 2，并打印出来:

```py
        A          B
  (int64)    (int64)
---------  ---------
        2          8
        3          9
        4         10
        5         11
        6         12
        7         13
```

至此，我们已经了解了如何处理一列或多列中的数据。现在，让我们学习如何使用不同列中的多个值进行计算。

### 多列计算

让我们探索一个流行的函数，因为我们正在讨论向量化的函数:哈弗斯距离。这个代表一个球体表面上两点之间的距离，可以用来计算地球上两点之间的距离。

这个函数有趣的地方在于它使用了可以矢量化的多种计算。

这里，我们将使用一个来自纽约酒店的流行数据源，我们将计算从一个特别受欢迎的餐厅到数据中每一家酒店的距离。

让我们从从文件加载数据帧开始:

```py
df = op.load.file("DCIGNP2AYL.txt")
```

现在，我们可以从 Optimus 导入函数，并定义我们的自定义函数:

```py
from optimus.functions import F
def haversine(lat1, lon1, lat2, lon2):    
    MILES = 3959
    lat1, lon1, lat2, lon2 = map(F.radians, [lat1, lon1, lat2, lon2])
    dlat = lat2 - lat1 
    dlon = lon2 - lon1         
    a = F.sin(dlat/2)**2 + F.cos(lat1) * F.cos(lat2) * F.sin(dlon/2)**2
    c = 2 * F.asin(F.sqrt(a))  
    total_miles = MILES * c
    return total_miles 
df["distance"] = haversine(40.671, -73.985, df["latitude"], df["longitude"])
```

然后，我们可以使用`select`和`print`来获得具有先前计算的距离的列:

```py
print(df.cols.select("distance"))
```

这将打印以下内容:

```py
   distance
  (float64)
-----------
139.607
139.747
142.191
137.276
...
```

探究整个剧本，我们可以看到`from optimus.functions import F`的用法。这将使您能够访问我们在本章中探索的所有函数，所有这些函数都可以用于创建自定义和更复杂的计算。

## 支持多引擎

需要注意的是，在撰写本文时，在 2021 年 1 月日， **cuDF** 和 **Dask cuDF** 不支持字符串的 uDF 函数。另外，不支持 UDF 数值函数，所以我们需要直接依赖 cuDF。让我们来看看:

```py
import numpy as np
import cudf
from cudf.datasets import randomdata

df = randomdata(nrows=10, dtypes={"a": float, "b": bool, "c": str}, seed=12)
def udf(x):
    if x > 0:
        return x + 5
    else:
        return x - 5
df["a"].applymap(udf)
```

对于更复杂的逻辑(比如从多个输入列或行中访问值)，您需要使用一个 Numba JITed CUDA 内核:

```py
from numba import cuda
@cuda.jit
def multiply(in_col, out_col, multiplier):
    i = cuda.grid(1)
    if i < in_col.size: # boundary guard
        out_col[i] = in_col[i] * multiplier
```

`create`函数将乘以`a`列中的每个元素，并将结果输出到`e`列。

现在，为了应用这个函数，我们将使用`forall`方法。使用`forall`，您需要指定输出的大小，并将想要处理的数据传递到 dataframe 中:

```py
size = len(df['a'])
df['e'] = 0.0
multiply.forall(size)(df['a'].data, df['e'].data, 10.0)
```

如你所见，这是一种非常不同的应用 UDF 的方法。我们希望，在未来，我们可以将它抽象化，使其更加用户友好。

有关如何将 UDF 应用于 cuDF 和 Dask-cuDF 的更多信息，请阅读 RAPIDS 文档:[https://docs.rapids.ai/api/cudf/stable/guide-to-udfs.html](https://docs.rapids.ai/api/cudf/stable/guide-to-udfs.html)。

# 总结

在这一章中，我们学习了基本的 Optimus 函数，这些函数被设计来覆盖数据帧中最常见的工作，例如选择、移动和删除列，以及对字符串、数字、日期和更具体的数据(如 URL 和电子邮件)应用函数。

我们还学习了如何编写自定义函数，以及如何使用矢量化函数来充分发挥硬件的潜力。

在下一章中，我们将学习如何连接多个数据集，这样我们就可以根据自己的需要调整数据。

# 延伸阅读

每个引擎都在内部处理一种数据类型来表示数字、字符串和日期。以下链接可以帮助您了解每个引擎中的不同数据类型:

*   **熊猫/达斯克**:[https://pbpython.com/pandas_dtypes.html](https://pbpython.com/pandas_dtypes.html)。
*   CuDF/Dask-cuDF 。在 https://github.com/rapidsai/cudf/issues/3360 有一个未解决的问题。
*   **火花**:[https://spark.apache.org/docs/latest/sql-ref-datatypes.html](https://spark.apache.org/docs/latest/sql-ref-datatypes.html)。*