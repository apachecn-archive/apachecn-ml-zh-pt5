

# 三、DanfoJS 入门

与其他编程语言相比， **Python** 数据科学和机器学习生态系统非常成熟，但当涉及到数据表示和客户端时， **JavaScript** 占据了至高无上的地位。从其强大的数据表示工具到其在浏览器中的易用性，JavaScript 总是被推荐使用。

在本章中，我们将向您介绍 Danfo.js 库，从而为您提供一个在 JavaScript 中进行数据分析和操作的有效工具。我们将讨论 Danfo.js 的核心数据结构——数据帧和系列。我们将向您展示如何将不同类型的文件(如 JSON、Excel 和 CSV)加载到 Danfo.js 中，最后，您将了解 Danfo.js 中一些重要的可用函数，这些函数使 JavaScript 中的数据分析和预处理变得更加容易。

在本章中，我们将讨论以下主题:

*   你为什么需要 Danfo.js
*   安装 Danfo.js
*   系列和数据框架简介
*   Danfo.js 中的基本函数和方法
*   数据加载和使用不同的文件格式

# 技术要求

为了理解本章内容，您应该具备以下条件:

*   Chrome、Safari、Opera 或 Firefox 等现代浏览器
*   系统上安装的 **Node.js** 、Danfo.js 和 **Dnotebook**

本章代码可在此处获得:[https://github . com/packt publishing/Building-Data-Driven-Applications-with-danfo . js/tree/main/chapter 03](https://github.com/PacktPublishing/Building-Data-Driven-Applications-with-Danfo.js/tree/main/Chapter03)。

注意

对于大部分代码片段，你可以在这里在线使用 Dnotebook:[https://playnotebook.jsdata.org/](https://playnotebook.jsdata.org/)。

# 为什么你需要 Danfo.js

要成功地将一个用 Python 编写的机器学习项目带到 web 上，需要进行大量的流程和任务，比如模型部署，用 **Flask** 、 **FastAPI** 或 **Django** 等框架创建 API 路由，然后用 JavaScript 向模型发送 HTTP 请求。你可以清楚地观察到这个过程涉及到很多 JavaScript。如果我们可以只用 JavaScript 来执行所有这些过程，那就太棒了，不是吗？好消息是我们可以。

在过去的几年中，浏览器的计算能力稳步增长，可以支持高度密集的计算，因此在数据密集型任务方面，JavaScript 具有挑战 Python 的优势。

在 Node.js 的帮助下，JavaScript 可以访问本地计算机上可用的 GPU，使我们能够使用 Node.js 作为后端，纯 JavaScript 作为前端，进行全栈机器学习项目。

使用 JavaScript 的一个好处是推理可以在客户端很容易地完成，因此数据不必离开客户端到服务器。此外，JavaScript 为我们的程序提供了跨平台支持，在**内容交付网络** ( **CDN** )的帮助下，应用程序开发所需的所有 JavaScript 包都可以轻松使用，无需安装。

随着 **TensorFlow.js** 和 Danfo.js 等工具的引入，我们看到了数据科学和机器学习生态系统中对 JavaScript 的更多支持。

想象一个强大的数据处理库，比如 web 上的**Python pandas**(【https://pandas.pydata.org/】T42)，想想将这样一个工具注入流行的现代 JavaScript 框架的能力，比如 **Vue** 或**React**；可能性是无穷无尽的。这就是 Danfo.js 带给网络的力量。

JavaScript 开发人员已经进行了各种尝试，试图将熊猫的数据处理能力带到网络上。因此，我们有像`pandas-js`、`dataframe-js`、`data-forge`和`jsdataframe`这样的库。

将 Python pandas 移植到 JavaScript 的需求主要是因为需要在浏览器中执行数据预处理和操作任务。

这是一个关于**堆栈溢出**([https://Stack Overflow . com/questions/30610675/python-pandas-equivalent-in-JavaScript/43825646](https://stackoverflow.com/questions/30610675/python-pandas-equivalent-in-JavaScript/43825646))的线程，它详细概述了在 JavaScript 中进行数据预处理和操作的不同工具，但这些工具中的大多数都失败了，原因如下两个，如线程中所述:

*   单个库缺乏协作(许多库试图做不同的事情)
*   大多数图书馆没有熊猫的主要特征，如图:[https://github.com/pandas-dev/pandas#main-features](https://github.com/pandas-dev/pandas#main-features )

除了这里列出的两个原因，我们在尝试大多数现有工具时观察到的另一个问题是缺乏像 Python 的熊猫一样的良好用户体验。熊猫很受欢迎，由于 JavaScript 创建的大多数工具都模仿熊猫，所以最好有一个与熊猫非常相似的用户体验。

构建 Danfo.js 是为了解决现有数据处理库面临的差距和问题。该 API 是在 pandas API 的基础上精心建模的，因此为来自 Python 背景的人提供了类似的体验，同时为 JavaScript 开发人员提供了简单直观的 API。

除了简单和熟悉的 API 之外，Danfo.js 的速度更快还要感谢 TensorFlow.js，它支持所有的数学运算。Danfo.js 在不到一年的时间里在 GitHub 上获得了超过 1，500 颗星，并被 Google 的 TensorFlow.js 团队接受([https://blog . tensor flow . org/2020/08/introducing-danfo-js-pandas-like-library-in-JavaScript . html](https://blog.tensorflow.org/2020/08/introducing-danfo-js-pandas-like-library-in-JavaScript.html))。此外，值得一提的是，由于积极的贡献者，Danfo.js 得到了很好的维护和不断的发展，他们确保了它的最新和稳定。

除了前面的原因之外，我们决定在 Danfo.js 上写这本书还有更多原因，以便给你在 JavaScript 中执行数据操作任务所需的技能和知识。在下一节中，我们将开始学习如何在浏览器和 Node.js 环境中安装和导入 Danfo.js。

# 安装 Danfo.js

Danfo.js 在浏览器和 Node.js 环境中都很容易获得。要在浏览器中使用 Danfo.js，您可以将`script`标签添加到您的`HTML`文件的标题中，如下所示:

```py
<head>
      ...
     <script src="https://cdn.jsdelivr.net/npm/danfojs@0.2.7/lib/bundle.min.js"></script>
      ...
</head>
```

在撰写本文时，针对浏览器环境的 Danfo.js 的最新版本是 0.2.7。这很可能已经改变了，但是请放心，本书中使用的所有代码和片段将在未来的版本中工作。

注意

要安装或获取 Danfo.js 的最新版本，你可以在官方文档的【https://danfo.jsdata.org/release-notes】这里查看发布页面。

在 Node.js 环境中，可以使用`yarn`安装 Danfo.js ，如下面的代码所示:

```py
//NPM
npm install danfojs-node
// Yarn
yarn add danfojs-node
```

安装后，您可以使用以下任何命令导入 Danfo.js:

```py
//Common js style
const dfd = require("danfojs-node")
// ES6 style
import * as dfd from 'danfojs-node'
```

注意

为了练习，你总是可以使用 https://playnotebook.jsdata.org/，就像前一章讨论的那样。有了这个，你就可以在线使用 Dnotebook 进行快速实验。要在 Dnotebook 中使用最新版本的 Danfo.js，您可以随时使用`load_package`函数。

Danfo.js 的浏览器和 Node.js 版本遵循相同的 API 设计。主要区别在于，在浏览器中，Danfo.js 被添加到名为`dfd`的全局范围中。因此，`dfd`变量可用于所有 JavaScript 或 HTML 文件。

现在我们已经完成了安装，我们将进入下一节，讨论 Danfo.js 和 Series 中可用的主要数据结构和方法。

# 介绍系列和数据框架

Danfo.js 公开了两种主要的数据结构，Series 和 DataFrames，所有的数据操作都可以很容易地完成。数据帧和系列为不同类型的数据提供了一个通用的表示，因此相同的数据处理过程可以应用于不同格式的数据集。

在这一节中，我们将看看创建系列和数据帧的不同方法。我们将看到如何处理数据帧和序列格式的数据。我们还将研究不同的数据框架和数据处理的系列方法。

我们将从如何处理系列数据结构中的数据开始这一部分。

## 系列

Series 为处理一维数据提供了一个入口点，比如一个包含一系列相同数据类型的值的数组。

在本节中，我们将通过以下系列方法熟悉系列数据结构:

```py
 *  table() and print() method:let sdata= new dfd.Series([1,3,5,7,9,11])
table( sdata) // Displays the table in Dnotebook
```

前面的代码给出了下面的输出表:

![Figure 3.1 – Series table
](img/B17076_3_1.jpg)

图 3.1–系列表

在前面的代码片段中，我们利用`table()`来打印系列表。这是因为我们在本章的大部分代码中都使用了 Dnotebook。要在浏览器或 Node.js 控制台中打印数据帧或系列，您可以按如下方式调用`print()`:

```py
 sdata.print() // will give us same output as table( sdata)
```

在随后的代码中，我们将总是使用`table()`函数，它允许我们在浏览器网页上打印数据帧。

*   `.index`属性:默认情况下，除非指定，否则系列表的列名总是 0。还要注意，系列表的索引范围是从数据的`0`到`n – 1`，其中`n`是数据的长度。该指数也可以通过以下方式获得:

    ```py
    console.log(sdata.index) // [0,1,2,3,4,5]
    ```

*   `.dtype` and `astype()`: Sometimes the data passed into a Series might not be homogeneous, and may contain fields with mixed data types, as follows:

    ```py
    let sdata = new dfd.Series([1,2,3, "two:","three"])
    console.log(sdata.dtype)
    // string
    ```

    `dtype`输出了`string`，而数据属于不同的数据类型，因此我们总是可以更改`dtype`，如以下代码所示:

    ```py
    sdata.astype('int32')
    ```

    前面的代码改变了序列的数据类型，但是它并没有将数据中的字符串转换成`int32`。因此，如果我们对数据执行数值运算，这将抛出一个错误。

*   The `.tensor` attribute: The data in a Series can be obtained in two main formats – as JavaScript `series.tensor` is a valid TensorFlow.js tensor, and as such all supported tensor operations can be performed on it. For example, in the following code, we call the exponential function on the Series `tensor` object:

    ```py
    sdata.tensor.exp(2).arraySync()
    // [3,7,20,55,148]
    ```

    在前面的代码中，我们能够打印出系列数据的指数，因为我们可以访问底层张量。`arraySync`方法返回张量的数组格式。再来看`set_index()`方法。

*   The `set_index()` method: The index can be specified when creating a Series data structure. We demonstrate this in the following code:

    ```py
    series = new dfd.Series([1,2,3,4,5], {index: ["one","two", "three", "four", "five"]})
    table(series)
    ```

    这将设置序列的索引并替换默认的数字索引，如下所示:

![Figure 3.2 – Series with a named index
](img/B17076_3_2.jpg)

图 3.2–带有命名索引的系列

我们可以随时改变一个系列的默认索引值，如下面的代码所示:

```py
sdata = new dfd.Series(["Humans","Life","Meaning","Fact","Truth"])
new_series = sdata.set_index({ "index": ["H", "L", "M","F","T"] })
table(new_series)
```

`sdata.set_index()`重置索引，返回如图*图 3.2* ( *左*)所示的新序列，不改变原序列。我们可以通过将`inplace`键设置为`true`来设置`set_index()`实际更新原始系列的索引，而不返回新系列:

```py
sdata.set_index({ index: ["H", "L", "M","F","T"] , inplace: true })
```

我们现在来看看`.apply()`方法。

*   The `.apply()` method: Since a Series is a single-dimensional array, it is easy to apply operations similar to how it would be done if working with an array in JavaScript. Series have a method called `.apply` to which you can apply any function on each value of the Series data:

    ```py
    sdata = new dfd.Series(["Humans","Life","Meaning","Fact","Truth"])
    series_new = sdata.apply((x) => {
     return x.toLocaleUpperCase()
    })
    table(series_new)
    ```

    这通过对每个值应用`x.toLocaleUpperCase()`将序列中的每个字符串转换为大写。下图显示了对系列数据应用`x.toLocaleUpperCase`前后的表格输出:

![Figure 3.3 – Left: setting the index to string. Right: using apply to convert all strings to uppercase
](img/B17076_3_3.jpg)

图 3.3–左侧:将索引设置为字符串。右:使用 apply 将所有字符串转换为大写

对于对系列数据的每个值执行数值运算，`.apply`方法也很方便:

```py
sf = new dfd.Series([1, 2, 3, 4, 5, 6, 7, 8])
sf_new = sf.apply(Math.log)
table(sf_new)
```

我们使用了`.apply`函数来查找序列中每个值的对数。对于所有其他数学运算也可以这样做。

上述代码输出下表:

![Figure 3.4 – Applying math ops (Math.log) to each value of a Series
](img/B17076_3_4.jpg)

图 3.4–将数学运算(Math.log)应用于序列的每个值

系列数据结构也包含`.map`方法，类似于`.apply`。此方法将序列的每个值映射到另一个值:

```py
sf = new dfd.Series([1,2,3,4])
map = { 1: "ok", 2: "okie", 3: "frit", 4: "gop" }
sf_new = sf.map(map)
table(sf_new)
```

该映射接受对象和函数作为参数。在前面的代码中，我们创建了一个名为`map`的对象，它包含作为键的序列中的值以及每个键应该映射到的值。

前面的代码输出下表:

![Figure 3.5 – Using map on Series values
](img/B17076_3_5.jpg)

图 3.5–对系列值使用映射

接下来我们就来看看`.isna()`的方法。

*   The `.isna()` method: The data we've been passing into the Series so far seems to be okay and contains no missing values or undefined values, but when working with real data, we will always have `NaN` or undefined values. We can always check whether such values exist in our Series:

    ```py
    sf_nan = new dfd.Series([1,2, NaN, 20, undefined, 100])
    table(sf_nan)
    ```

    作为测试，我们创建一个包含`NaN`和一个未定义变量的序列。我们获得以下输出:

![Figure 3.6 – Table containing a Series frame with NaN values
](img/B17076_3_6.jpg)

图 3.6–包含具有 NaN 值的系列帧的表格

让我们检查包含`NaN`和未定义值的行；对于这些行中的每一行，我们输出`true`，如果不是，则用`false`表示，如以下代码所示:

```py
table(sf_nan.isna())
```

我们获得以下输出:

![Figure 3.7 – The isna table for the Series data
](img/B17076_3_7.jpg)

图 3.7–系列数据的 isna 表

`.add()`方法如下。

*   The `.add()` method: The Series data structure also supports element-wise operations (such as addition, subtraction, multiplication, and division) between Series, and after this operation, the indexes are automatically aligned:

    ```py
    sf1  = new dfd.Series([2,20,23,10,40,5])
    sf2  = new dfd.Series([30,20,40,10,2,3])
    sf_add = sf1.add(sf2)
    table(sf_add)
    ```

    我们有以下输出:

![Figure 3.8 – Adding two Series 
](img/B17076_3_8.jpg)

图 3.8–添加两个系列

前面的代码片段将`sf2`系列添加到`sf1`，并且每行的每个值都是按元素添加的。

还要注意，单个值可以传递给`sf1.add`，这将为`sf1`系列中的每个元素添加一个常数值:

```py
table(sf1.add(10))
```

以下是上述代码的输出:

![Figure 3.9 – Adding a constant value to Series elements
](img/B17076_3_9.jpg)

图 3.9–向系列元素添加常数值

之前显示的运算适用于所有其他数学运算以及级数。

在下一小节中，我们将研究数据帧的操作，如何创建数据帧，以及如何用数据帧操作处理数据。

## 数据帧

DataFrame 表示系列的集合，尽管与系列不同，它基本上是包含多列和多行的数据的二维表示(尽管它也可以表示更高维度)。

DataFrame 基本上可以使用 JavaScript 对象来构造，如以下代码所示:

```py
data = {
  artist: ['Drake','Rihanna','Gambino', 'Bellion', 'Paasenger'],
  rating: [5, 4.5, 4.0, 5, 5],
  dolar: [ '$1m', '$2m','$0.1m', '$2.5m','$3m']
}
df = new dfd. DataFrame (data)
table(df) 
// print out the  DataFrame 
```

生成的数据帧应该如下所示:

![Figure 3.10 – DataFrame table
](img/B17076_3_10.jpg)

图 3.10–数据框架表

在前面的代码中，创建了包含键和值的 JavaScript 对象数据。注意以下关于 JavaScript 对象的:

*   每个键包含一个代表每列数据的列表值。
*   每个键代表列和列名。
*   每个键必须具有相同长度的列表值。

以下是处理数据帧数据结构的常用方法:

*   The `head()` and `tail()` methods: Sometimes, while working on a big dataset, you might need to see the first set of rows (maybe the first 5 rows or the first 30 rows, as much as you like) and also the last rows in the data.

    因为我们的数据帧包含 5 行，所以让我们打印表格的前两行:

    ```py
    table(df.head(2))
    ```

    默认情况下，`head()`方法打印出数据帧的前五行，但是我们可以指定`2`,因为我们的数据很小。

    下表显示了上述代码的结果:

![Figure 3.11 – Table for df.head(2)
](img/B17076_3_11.jpg)

图 3.11–测向头表(2)

同样，为了查看数据帧中的最后一组行，我们使用了`tail()`方法。默认情况下，`tail`方法打印出数据帧中的最后五行:

```py
table(df.tail(2))
```

`tail`函数接收一个值，该值指定从 DataFrame 表的末尾开始打印的行数，如下所示:

![Figure 3.12 – Printing the last two rows
](img/B17076_3_12.jpg)

图 3.12–打印最后两行

*   `data`变量包含的数据，表示为数组中的数组。数据数组中的每个数组包含按行排列的值，因为它将在 DataFrame 表中表示；`[Drake, 5, $1m]`代表 DataFrame 中的一行，而每个值(`Drake`、`5`、`$1m`)代表不同的列。`Drake`属于`artist`列，`$1m`属于`dollar`列，如下图所示:

![Figure 3.13 – DataFrame table
](img/B17076_3_13.jpg)

图 3.13–数据框架表

回想一下我们说过的数据帧是系列的集合，因此可以像访问 JavaScript 对象元素一样从数据帧中访问每个系列。下面是如何做到这一点:

```py
table(df.artist)
```

请注意，`artist`是数据帧中一列的名称，因此，如果我们将数据帧视为一个对象，`artist`是键，键的值是一个序列。前面的代码应该输出下表:

![Figure 3.14 – Column Series
](img/B17076_3_14.jpg)

图 3.14–色谱柱系列

`artist`栏也可以通过`df['artist']`进入:

```py
table(df['dollar'])
```

该方法也输出与正在使用的初始`df.dollar`方法相同的结果:

![Figure 3.15 – Accessing column values
](img/B17076_3_15.jpg)

图 3.15-访问列值

除了通过类似对象的方法访问列值，我们还可以如下更改列数据:

```py
df['dollar'] = ['$20m','$10m', '$40m', '$35m', '$10m']
```

如果我们要打印出`df.dollar`，我们将获得以下输出:

![Figure 3.16 – Changing the column value
](img/B17076_3_16.jpg)

图 3.16–更改列值

列数据的更改也可以通过创建一个系列帧，然后将其分配给数据帧中的一列来完成，如下所示:

```py
rating = new dfd.Series([4.9,5.0, 7.0, 3.0,2.0])
df['rating'] = rating
table(df['rating'])
```

上述代码更改了列 rating 的值，并输出下表:

![Figure 3.17 – Changing column data with a Series value
](img/B17076_3_17.jpg)

图 3.17–用系列值更改列数据

这种使用系列数据更新列数据的方法在处理时间相关列时非常方便。我们可能需要提取日期列中的小时或月，并用提取的信息(小时或月)替换该列。

让我们向数据帧添加一个日期列:

```py
date = [ "06-30-02019", "07-29-2019", "08-28-2019", "09-12-2019","12-03-2019" ]
df.addColumn({column: "date", value: date})
```

我们利用`addColumn`方法向数据帧添加一个新列。`addColumn`方法接受一个必须包含以下键的对象参数:

a)添加的`column`的名称

b)新的`value`为列

前面的代码应该输出下表:

![Figure 3.18 – Adding a new column
](img/B17076_3_18.jpg)

图 3.18–添加新列

创建的新列是日期-时间列，因此我们可以将该列转换为时间序列数据结构，然后提取该列中每个数据点的月份名称:

```py
date_series = df['date']
df['date'] = date_series.dt.month_name()
```

我们提取日期列，并将其分配给一个`date_series`变量。从`date_series`(实际上是一个序列数据结构)中，我们提取每个值的月份名称。序列数据结构包含`dt`方法，该方法将序列结构转换为时间序列结构，然后使用`month_name()`方法提取月份名称。

上述代码输出下表:

![Figure 3.19 – Extracting the month name
](img/B17076_3_19.jpg)

图 3.19-提取月份名称

我们接下来要研究的方法是`.values`和`.tensor`。

*   `.values` and `.tensor`: The DataFrame values, that is, each column value, can be obtained as a giant array using `df.values`:

    ```py
    df.values
    //output
    [[Drake,4.9,$20m,Jun],[Rihanna,5,$10m,Jul],[Gambino,7,$40m,Aug],[Bellion,3,$35m,Sep],[Passenger,2,$10m,Dec]]
    ```

    有时，我们可能想要获取数据帧作为机器学习操作的张量，因此下面显示了如何获取数据帧作为张量值:

    ```py
    df.tensor
    //output
    {"kept":false,"isDisposedInternal":false,"shape":[5,4],"dtype":"string","size":20,"strides":[4],"dataId":{},"id":28,"rankType":"2"}
    ```

    `tensor`属性返回 TensorFlow.js 张量数据结构。因为张量必须总是包含唯一的数据类型，所以我们的数据帧中的所有数据点都被转换成一个`dtype`字符串。

*   The `.transpose()` method: Since we made the claim that a DataFrame is a two-dimensional representation of data, we should be able to transpose the DataFrame:

    ```py
    df.transpose()
    ```

    `df.transpose()`将列列表作为索引移动，将索引作为列移动，如下表所示:

![Figure 3.20 – Transposing a DataFrame 
](img/B17076_3_20.jpg)

图 3.20-转置数据帧

我们可以获得数据帧的索引，并查看该列现在是否是当前索引:

```py
df2 = df.transpose()
console.log(df2.index) 
// [artist,rating,dollar,date]
```

前面的代码是转置数据帧的索引。在前面的例子中，索引一直是一个数值，但是通过这个例子，它表明索引也可以是一个字符串。

*   The `.set_index()` method: Using the DataFrame itself, before transposing it, let's change the index of the DataFrame from integers to a string index:

    ```py
    df3 = df.set_index({key:["a","b","c","d","e"]})
    ```

    使用 DataFrame 中的`set_index`方法用给定的键值设置索引。`set_index`还接受`inplace`键(`inplace`键是一个布尔键，它接收`true` 或`false`作为值，但缺省值是`false`)键来指定是应该更新数据帧还是应该返回包含更新的新数据帧。

    下面的表显示了前面代码的结果:

![Figure 3.21 – Setting the index of the DataFrame 
](img/B17076_3_21.jpg)

图 3.21–设置数据帧的索引

由于索引可以是任何内容，我们还可以将数据帧的索引设置为数据帧中的一列:

```py
df4 = df.set_index({key:"artist"})
```

这一次，`set_index`接受一个值，而不是一个建议索引值的数组。如果单个值作为键索引传递，`set_index`认为它应该作为 DataFrame 中的一列。

`artist`列中的值用于替换默认索引。还要注意的是，`inplace`的默认值是`false`，因此会创建一个新的数据帧，并返回更新后的索引。

下面显示了创建的数据帧的输出:

![Figure 3.22 – Setting the index to the artist column
](img/B17076_3_22.png)

图 3.22–设置艺术家列的索引

现在，你应该知道如何创建系列和数据框架，以及如何利用它们各自的方法进行数据处理。

在下一节中，我们将研究 Danfo.js 中一些常用于数据分析和处理的基本函数和方法。

# danfo . js 中的基本功能和方法

在本节中，我们将看看一些与序列和数据相关的重要函数和方法。每个数据结构中的方法都很多，我们可以随时访问文档以获得更多的方法。本节将仅提及一些最常用的方法:

*   `loc`和`iloc`分度
*   排序:`sort_values`和`sort_index`方法
*   `Filter`
*   算术运算，如`add`、`sub`、`div`、`mul`和`cumsum`

## loc 和 iloc 索引

使用`loc`和`iloc`方法可以更容易地访问数据帧的行和列；两种方法都允许你指定你想要访问的行和列。对于那些来自 Python 的 pandas 库的人来说，Danfo.js 中实现的`loc`和`iloc`格式应该很熟悉。

`loc`方法用于访问带有非数字索引的数据帧，如下所示:

```py
df_index = df4.loc({rows:['Bellion','Rihanna','Drake']})
```

利用上一节中最后更新的数据帧，我们使用`loc`方法从数据帧中获取某个行索引。该索引值在`rows`关键元素中指定:

![Figure 3.23 – Accessing specific row index values
](img/B17076_3_23.jpg)

图 3.23–访问特定的行索引值

另外，`loc`和`iloc`方法给了我们分割数组的能力。这对 Python 用户来说应该很熟悉。不知道是什么也不用担心；下面的例子将展示它的含义和操作方法。

为了获得一系列索引，我们甚至可以为非数字索引指定上限和下限:

```py
df_index = df4.loc({rows:["Rihanna:Bellion"]})
```

只要数据帧的列名和索引是字符串，就使用`loc`方法。对于前面的代码，我们指定要提取`Rihanna`行索引和`Bellion`行索引之间的数据值。

这个冒号有助于指定范围边界。下表显示了上述代码的输出:

![Figure 3.24 – String indexing
](img/B17076_3_24.jpg)

图 3.24–字符串索引

除了索引行之外，我们还可以提取特定的列:

```py
df_index = df4.loc({rows:["Rihanna:Bellion"], columns:["rating"]})
```

一个`columns`键被传入`loc`以提取名为`rating`的列。

下表显示了上述代码的结果:

![Figure 3.25 – Column and row indexing
](img/B17076_3_25.jpg)

图 3.25–列和行索引

我们还可以指定索引列的范围，如下所示:

```py
df_loc= df4.loc({rows:["Rihanna:Bellion"], columns:["rating:date"]})
```

这将返回一个类似如下的表:

![Figure 3.26 – Column range
](img/B17076_3_26.jpg)

图 3.26–色谱柱范围

从上表中，我们可以看到范围与行索引有很大不同；列索引不包括上限。

DataFrame 中的`loc`方法使用字符来索引行数据和列数据。`iloc`做同样的事情，但是使用整数来索引行和列。

使用下表所示的初始数据帧，我们将使用`iloc`方法执行索引:

![Figure 3.27 – The artist table
](img/B17076_3_27.jpg)

图 3.27–艺术家表

让我们使用`iloc`来访问*图 3.27* 中所示表格的索引`2`到`4`:

```py
t_df = df.iloc({rows:['2:4']})
table(t_df)
```

`iloc`方法接受与`loc`方法相同的关键字:关键字`rows`和`columns`。这些数字被包装在一个字符串中，因为我们要执行`loc`方法。

下表显示了上述代码的结果:

![Figure 3.28 – Indexing table rows from 2 to 4 using a closed upper bound
](img/B17076_3_28.jpg)

图 3.28–使用封闭的上限将表行从 2 索引到 4

切片数组(花式索引)

那些来自 Python 的人对切片数组会很熟悉。在 Python 中，可以使用一定范围的值来索引数组，例如`test = [1,2,3,4,5,6,7] test [2:5] => [3,4,5]`。JavaScript 没有这个属性，因此 Danfo.js 通过将范围作为字符串传递来实现这一点，并从字符串中提取上限和下限。

与上一示例中对行所做的相同的切片操作也可以在列上进行:

```py
column_df = df.iloc({columns:['1:']})
table(column_df)
```

`df.iloc({columns:['1:']})`用于从索引 1(代表`rating`列)开始提取列，直到最后一列。对于整数索引，只要没有指定上限，它就会选择最后一列作为上限。

在本节中，我们讨论了索引和索引数据帧的不同方法。在下一节中，我们将讨论按列值和行索引对数据帧进行排序。

## 分拣

Danfo.js 支持两种数据排序方法——根据索引或者根据列值。此外，系列数据只能按索引排序，因为它是具有单列的 DataFrame 对象。DataFrames 有一个名为`sort_values`的方法，使您能够按特定的列对数据进行排序，因此，通过对特定的列进行排序，我们可以相对于该列对所有其他列进行排序。

让我们创建一个包含数字的数据帧:

```py
data = {"A": [-20, 30, 47.3],
         "B": [ -4, 5, 6],
         "C": [ 2, 3, 30]}
df = new dfd. DataFrame (data)
table(df)
```

这会输出下表:

![Figure 3.29 – DataFrame of numbers
](img/B17076_3_29.jpg)

图 3.29–数字的数据框架

现在，让我们按照列`B`中的值对数据帧进行排序:

```py
df.sort_values({by: "C", inplace: true, ascending: false})
table(df)
```

`sort_values`方法接受以下关键字参数:

*   `by`:用于对数据帧进行排序的列的名称。
*   `inplace`:原始数据帧是否需要更新(`true`或`false`)。
*   `ascending`:该列是否按升序排序。默认值始终为`false`。

在前面的代码片段中，我们指定按列`C`对数据帧进行排序，并将`inplace`设置为`true`，因此数据帧被更新，列也按降序排序。下表显示了输出:

![Figure 3.30 – DataFrame sorted by column values
](img/B17076_3_30.jpg)

图 3.30–按列值排序的数据帧

有时我们可能不想更新原始数据帧本身。这里存在着`inplace`关键词的影响:

```py
sort_df = df.sort_values({by: "C", inplace:false, ascending: false})
table(sort_df)
```

在前面的代码中，DataFrame 是按列排序的。让我们尝试按索引对相同的数据帧进行排序:

```py
index_df = sort_df.sort_index({ascending:true})
table(index_df)
```

`sort_index`也接受关键字参数:`ascending`和`inplace`。我们将关键字`ascending`设置为`true`，这将为我们提供索引以升序排列的数据帧。

获得以下输出:

![Figure 3.31 – Sorted index DataFrame 
](img/B17076_3_31.jpg)

图 3.31-排序索引数据框架

在系列中排序需要一个非常简单的方法；通过调用`sort_values`方法进行排序，如下所示:

```py
data1 = [20, 30, 1, 2, 4, 57, 89, 0, 4]
series = new dfd.Series(data1)
sort_series = series.sort_values()
table(sort_series)
```

`sort_values`方法也接受关键字参数，`ascending`和`inplace`。默认情况下，`ascending`设置为`true`，`inplace`设置为`false`。

下表显示了上述代码的结果:

![Figure 3.32 – Sorting a Series by value
](img/B17076_3_32.jpg)

图 3.32–按值排序系列

注意`sort_values`和`sort_index`方法也适用于包含字符串的列和索引。

使用我们的`artist`数据框架，让我们尝试用一个字符串对一列进行排序，如下所示:

```py
sort_df = df.sort_values({by: "artist", inplace:false, ascending: false})
table(sort_df)
```

使用`artist`列以降序对数据帧进行排序。这会产生一个表格，根据第一个字符，第一行是`Rihanna`，后面是`Passenger`:

![Figure 3.33 – Sorting by the string column
](img/B17076_3_33.jpg)

图 3.33–按字符串列排序

在本节中，我们看到了如何通过列值和行索引对数据帧进行排序。在下一节中，我们将了解如何过滤数据帧值。

## 过滤

在数据操作和处理过程中，根据列中的某些特定值过滤出数据帧的行在大多数情况下非常方便。Danfo.js 有一个名为`query`的方法，用于根据列中的值过滤行。

`query`方法在以下关键字参数中采用:

*   `column`:列名
*   `is`:指定要使用的逻辑运算符(`>, <, >=, <=, ==`)
*   `to`:用于过滤数据帧的值
*   `inplace`:更新原始数据帧或返回新数据帧

这里有一个关于`query`方法如何工作的例子。

首先，我们创建一个数据帧:

```py
data = {"A": [30, 1, 2, 3],
        "B": [34, 4, 5, 6],
        "C": [20, 20, 30, 40]}

df = new dfd. DataFrame (data)
```

下图显示了该表:

![Figure 3.34 – DataFrame 
](img/B17076_3_34.jpg)

图 3.34–数据框

让我们按列`B`中的值对数据帧进行排序:

```py
query_df = df.query({ column: "B", is: ">", to: 5 })
table(query_df)
```

这里，我们通过一个大于 5 的值来过滤列`B`。这将导致在列`B`中返回包含大于 5 的值的行，如下所示:

![Figure 3.35 – Filtered by a value greater than 5 in column B
](img/B17076_3_35.jpg)

图 3.35–通过 B 列中大于 5 的值过滤

让我们通过检查列`C`中的值是否等于`20`来过滤数据帧:

```py
query_df = df.query({ column: "C", is: "==", to: 20})
table(query_df)
```

这样，我们获得以下输出:

![Figure 3.36 – Filtered by values equal to 20 in column C
](img/B17076_3_36.jpg)

图 3.36–按 C 列中等于 20 的值过滤

在本节中，我们看到了如何通过列值过滤数据帧。在下一节中，我们将看到如何执行不同的算术运算。

## 算术运算

在本小节中，我们将研究不同的算术运算以及如何使用它们来预处理我们的数据。

诸如加、减、乘、除之类的算术运算可以在下列各项之间进行:

*   一个数据帧和一个系列
*   一个数据帧和一个数组
*   一个数据帧和一个`scalar`值

我们从在数据帧和`scalar`值之间执行算术运算开始:

```py
data = {"Col1": [10, 45, 56, 10], 
        "Col2": [23, 20, 10, 24]}
ar_df = new dfd. DataFrame (data)
//add a scalar variable
add_df = ar_df.add(20)
table(add_df)
```

`add`方法是，用于在数据帧的每一行添加一个`20`的`scalar` 变量。`add`方法接受两个参数:

*   `other`:表示数据帧、序列、数组或`scalar`。
*   `axis`:指定操作是按行应用还是按列应用。行轴用`0`表示，列用`1`表示。默认为`0`。

对于`scalar`操作，我们得到以下结果:

![Figure 3.37 – Left: original DataFrame. Right: DataFrame after doing scalar addition
](img/B17076_3_37.jpg)

图 3.37–左侧:原始数据帧。右图:进行标量加法后的数据帧

让我们创建一个序列并将其传递给`add`方法:

```py
add_series = new dfd.Series([20,30])
add_df = ar_df.add(add_series, axis=1)
table(add_df)
```

创建一个包含两行元素的序列。这个两行元素等于`ar_df`数据帧中的列数，意味着`add_series`的第一行值属于`ar_df`的第一列，就像第二行值对应`ar_df`的第二列一样。

上一段的解释是说`20`会用来乘`Col1`，`30`会用来乘`Col2`。为了实现这一点，我们将轴指定为`1`，它告诉 add 操作按列执行操作，如下表所示:

![Figure 3.38 – Add operation between the DataFrame and Series
](img/B17076_3_38.jpg)

图 3.38–数据帧和系列之间的加法运算

数据帧和序列之间的加法操作在数据帧和普通 JavaScript 数组之间是相同的，因为序列只是一个具有一些扩展功能的 JavaScript 数组。

让我们看看两个数据帧之间的操作:

```py
data = {"Col1": [1, 4, 5, 0], 
         "Col2": [2, 0, 1, 4]}

data2 = {"new_col1": [1, 5, 20, 10],
         "new_Col2": [20, 2, 1, 2]}
df = new dfd.DataFrame(data)
df2 = new dfd.DataFrame(data2)

df_new = df.add(df2)
```

首先，我们创建两组数据帧，然后将它们相加；但是我们必须确保两个数据帧具有相同的列数和行数。此外，该操作是按行进行的。

操作实际上并不关心两个数据帧是否具有相同的列名，但是得到的列名是我们添加到前一个数据帧的数据帧的列。

下表显示了在前面的代码中创建的数据帧的结果:

![Figure 3.39 – From left to right: tables for DataFrames df and df2 and addition between df and df2
](img/B17076_3_39.jpg)

图 3.39–从左至右:数据帧 df 和 df2 以及 df 和 df2 之间的加法表

对于`sub()`、`mul()`、`div()`、`pow()`和`mod()`方法，添加操作的例子是相同的。

此外，对于数据帧和序列，有一组称为累积的数学运算，包括以下方法:

*   累计和:`cumsum()`
*   累计最小值:`cummin()`
*   累积最大值:`cummax()`
*   累积积:`cumprod()`

就传入的参数而言，这些操作都是相同的。它们都接受要执行操作的轴:

```py
data = [[11, 20, 3], [1, 15, 6], [2, 30, 40], [2, 89, 78]]
cols = ["A", "B", "C"]
df = new dfd. DataFrame (data, { columns: cols })
new_df = df.cumsum({ axis: 0 })
```

我们通过指定数据和列来创建数据帧，然后沿着`0`轴执行累积求和。

下表显示了上述代码的结果:

![Figure 3.40 – Left: the DataFrame before cumsum(). Right: the DataFrame after cumsum()
](img/B17076_3_40.jpg)

图 3.40–左图:累计()之前的数据帧。右图:cumsum()后的数据帧

让我们沿着数据帧的轴`1`执行一个`cumsum`操作:

```py
new_df = df.cumsum({ axis: 1 })
```

这为我们提供了下表:

![Figure 3.41 – cumsum along axis 1
](img/B17076_3_41.jpg)

图 3.41–沿轴 1 的累计

同样的累积操作也可以应用于系列。让我们将相同的累积和应用于系列数据:

```py
series = new dfd.Series([2,3,4,5,6,7,8,9])
c_series = series.cumsum()
table(c_series)
```

`cumsum`在一个系列中不接受任何论证。通过前面的操作，我们得到了下面的输出，表*图 3.42* 是应用累积序列之前的原始序列。

下表显示了前面代码中`series.cumsum()`操作的结果:

![Figure 3.42 – The cumulative sum Series
](img/B17076_3_42.jpg)

图 3.42–累积和序列

所有其他累积操作，如`cumprod`、`cummin`和`cummax`，使用方式与前述`cumsum`示例中的操作相同。

在这一节中，我们研究了不同的算术运算以及如何利用这些运算来预处理数据。在下一节中，我们将深入探讨逻辑运算，比如如何在数据帧和序列、数组以及`Scalar`值之间执行逻辑运算。

## 逻辑运算

在本节中，我们将了解如何执行逻辑运算，例如比较 DataFrame 与序列、数组和标量值之间的值。

调用和使用逻辑运算的方式与算术运算的工作方式非常相似。可以在以下各项之间进行逻辑运算:

*   一个数据帧和一个系列
*   一个数据帧和一个数组
*   数据帧和标量值

实现了以下逻辑操作:

*   等于(`==` ): `.eq()`
*   大于(`>` ): `gt()`
*   小于(`<` ): `lt()`
*   不等于(`!=` ): `ne()`
*   小于或等于(`<=` ): `le()`
*   大于或等于(`>=` ): `ge()`

所有这些方法都接受同一个参数，其中是`other`和`axis`。使用`lt()`方法，让我们看看它们是如何工作的:

```py
data = {"Col1": [10, 45, 56, 10],
        "Col2": [23, 20, 10, 24]}
df = new dfd. DataFrame (data)
df_rep = df.lt(20)
table(df_rep)
```

该代码检查数据帧中的每个值是否都小于 20。结果如下图所示:

![Figure 3.43 – Left: DataFrame for df. Right: DataFrame for df_rep
](img/B17076_3_43.jpg)

图 3.43–左侧:测向的数据帧。右图:df_rep 的数据帧

同样，可以对数据帧和序列进行相同的操作，如下所示:

```py
series = new dfd.Series([45,10])
df_rep = df.lt(series, axis=1)
table(df_rep)
```

数据框的`series`操作按列进行。下表是结果:

![Figure 3.44 – Logical operation between a DataFrame and Series
](img/B17076_3_44.jpg)

图 3.44-数据帧和序列之间的逻辑运算

让我们在两个数据帧之间执行逻辑运算，如下所示:

```py
data = {"Col1": [10, 45, 56, 10],
         "Col2": [23, 20, 10, 24]}
data2 = {"new_col1": [10, 45, 200, 10],
         "new_Col2": [230, 200, 110, 24]}

df = new dfd.DataFrame (data)
df2 = new dfd.DataFrame (data2)

df_rep = df.lt(df2)
table(df_rep)
```

该代码输出以下结果:

![Figure 3.45 – Logical operation between DataFrames
](img/B17076_3_45.jpg)

图 3.45-数据帧之间的逻辑运算

在本节中，我们研究了一些基本的数据帧操作，比如如何通过列值过滤数据帧。我们还看到了如何通过列值和行索引对数据帧进行排序。此外，本节还深入探讨了使用`loc`和`iloc`对数据帧进行索引，最后，我们研究了算术和逻辑运算。

在下一节中，我们将深入研究如何使用不同的数据格式，如何将这些文件解析成 Danfo.js，以及如何将它们转换成 DataFrame 或 Series。

# 数据加载和处理不同的文件格式

在这一节中，我们将看看如何处理不同的文件格式。Danfo.js 提供了一个方法来处理三种不同的文件格式:CSV、Excel 和 JSON。以这些格式呈现的数据可以很容易地被读取并以数据帧的形式呈现。

以下是每种文件格式所需的方法:

*   `read_csv()`:读取 CSV 文件
*   `read_json()`:读取 JSON 文件
*   `read_excel()`:读取显示为`.xslx`的 Excel 文件

这些方法都可以从本地和互联网读取数据。此外，这些方法只能访问`Node.js`环境中的本地文件。在 web 上，这些方法可以读取提供的文件(CSV、JSON 和。`xslx`文件)，前提是这些文件在互联网上可用。

让我们看看如何在 Node.js 环境中读取本地文件:

```py
const dfd = require("Danfo.Js-node")
dfd.read_csv('titanic.csv').then(df => {
  df.head().print()
})
```

首先，我们导入danfo . js 的 Node.js 版本，然后调用`read_csv()`来读取同一目录中的`titanic.csv`文件。注意如果要读取的文件不在同一个目录下，你需要指定路径。

`df.head().print()`打印 Node.js 控制台中 DataFrame 表的前五行；`print()`函数类似于我们在 Dnotebook 中使用的`table()`函数。我们从前面的代码中获得了下表:

![Figure 3.46 – DataFrame table read from a CSV file
](img/B17076_3_46.jpg)

图 3.46–从 CSV 文件读取数据帧表

同样，同样的事情也可以在网络上完成，但是我们将使用`http`链接，这使得相同的数据可以在线获得:

```py
csvUrl =
      "https://storage.googleapis.com/tfjs-examples/multivariate-linear-regression/data/boston-housing-train.csv";
dfd.read_csv(csvUrl).then((df) => {
  df.print()
});
```

这与前面的代码块产生了相同的结果。同样的事情也适用于所有其他文件格式方法:

```py
const dfd = require("Danfo.Js-node")

dfd.read_excel('SampleData.xlsx', {header_index: 7}).then(df => {
  df.head().print()
})
```

`read_excel()`方法接受一个可选的配置参数，确保 Excel 文件被正确解析:

*   `source`:检索 Excel 文件的字符串、URL 或本地文件路径。
*   `sheet_name`(可选):要解析的工作表的名称。默认为第一张工作表。
*   `header_index`(可选):int，表示标题列的行的索引。
*   `data_index`(可选):int，表示数据开始位置的行的索引。

在前面的代码块中，我们将`header_index`值指定为`7`，因为标题列就位于那里，因此我们得到了以下结果:

![Figure 3.47 – DataFrame table read from an Excel file
](img/B17076_3_47.jpg)

图 3.47–从 Excel 文件中读取数据帧表

就传入的参数而言，`read_json()`方法与`read_csv()`非常相似；该方法只接受 JSON 文件的 URL 或 JSON 文件所在的目录路径:

```py
const dfd = require("Danfo.Js-node")
dfd.read_json('book.json').then(df => {
  df.head().print()
})
```

这从同一个目录中读取一个名为`book.json`的文件，并输出以下内容:

![Figure 3.48 – DataFrame read from a JSON file
](img/B17076_3_48.jpg)

图 3.48–从 JSON 文件读取的数据帧

另外，Danfo.js 包含一个名为`reader`的终极表格文件读取器方法；这个方法可以读取 CSV 和 Excel。它还可以读取 https://frictionlessdata.io/的[无摩擦规范中规定的`Datapackage`等其他文件。](https://frictionlessdata.io/)

`reader`方法利用位于[https://github.com/frictionlessdata/frictionless-js](https://github.com/frictionlessdata/frictionless-js)的一个名为`Frictionless.js`的包来读取本地或远程文件。

`reader`方法具有与`read_csv`和`read_excel`相同的 API 设计，只是它可以读取两种文件类型，如以下代码所示:

```py
const dfd = require("Danfo.Js-node")
// for reading csv
dfd.read('titanic.csv').then(df => {
  df.head().print()
})
```

从前面的代码，我们输出同一个表，如图*图 3.48* 所示。

## 将一个数据帧转换成另一种文件格式

经过一系列的数据处理后，我们可能想把最终的数据帧转换成一种文件格式，以便正确保存。js 实现了一个将数据帧转换成 CSV 格式的方法。

让我们将目前创建的数据帧转换成 CSV 文件。请注意，这只适用于 Node.js 环境:

```py
df.to_csv("/home/link/to/path.csv").then((csv) => {
    console.log(csv);
}).catch((err) => {
    console.log(err);
})
```

此操作(`df.to_csv()`)将数据帧保存在指定路径目录下的 CSV 文件中，并使用指定的名称(`path.csv`)。

在本节中，我们研究了如何读取不同格式的文件，如 Danfo.js 中提供的 CSV、JSON 和 Excel。我们研究了读取这些文件的不同方法，还研究了读取这些文件格式的更通用的方法。

我们还看到了如何将数据帧转换成用户指定的文件格式。

# 总结

在这一章中，我们讨论了为什么需要 Danfo.js，然后研究了 Series 和 DataFrames 实际上是什么。我们还讨论了 Danfo.js 中的一些基本功能，并在 DataFrames 和 Series 中实现了这些功能。

我们还看到了如何使用数据帧和系列方法来处理和预处理数据。我们看到了如何根据列值过滤数据帧。我们还根据行索引和列值对数据帧进行了排序。本章使我们能够执行日常的数据操作，例如读取不同格式的文件，转换格式，以及在预处理成所需的文件格式后保存数据帧。

在下一章，我们将研究数据分析、整理和转换。我们将进一步讨论数据处理和预处理，并了解如何处理缺失的数字以及如何处理字符串和时间序列数据。