

# 四、数据分析、整理、转化

**数据分析**、**整理**和**转换**是任何数据驱动项目的重要方面，作为一名数据分析师/科学家，你的大部分时间都将花在某种形式的数据处理上。虽然 JavaScript 是一种灵活的语言，具有操作数据结构的良好特性，但编写实用函数来一直执行数据整理操作是非常乏味的。因此，我们在 Danfo.js 中构建了强大的数据整理和转换功能，这可以大大减少在这个阶段花费的时间。

在本章中，我们将向您展示如何在现实世界的数据集上实际使用 Danfo.js。您将了解如何加载不同类型的数据集，并通过执行诸如处理缺失值、计算描述性统计数据、执行数学运算、合并数据集和执行字符串操作等操作来分析这些数据集。

在本章中，我们将讨论以下主题:

*   转换数据
*   组合数据集
*   系列数据存取器
*   计算统计数据

# 技术要求

要了解本章内容，您应该具备以下条件:

*   Chrome、Safari、Opera 或 Firefox 等现代浏览器
*   系统上安装的 Node.js、Danfo.js 和 Dnotebook
*   用于下载数据集的稳定互联网连接

Danfo.js 的安装说明可以在 [*第三章*](B17076_03_ePub_RK.xhtml#_idTextAnchor066) 、*danfo . js 入门*中找到，而 Dnotebook 的安装步骤可以在 [*第二章*](B17076_02_ePub_RK.xhtml#_idTextAnchor045) 、*Dnotebook-JavaScript 的交互计算环境*中找到。

注意

如果你不想安装任何软件或库，你可以在[https://playnotebook.jsdata.org/](https://playnotebook.jsdata.org/)使用在线版本的 Dnotebook。但是，在使用任何功能之前，不要忘记安装最新版本的 Danfo.js！

# 转换数据

数据转换是根据定义的步骤/过程，将数据从一种格式(主格式)转换为另一种格式(目标格式)的过程。数据转换可能简单，也可能复杂，这取决于数据集的结构、格式、最终目标、大小或复杂性，因此，了解 Danfo.js 中可用于执行这些转换的功能非常重要。

在这一节中，我们将介绍 Danfo.js 中用于进行数据转换的一些特性。在每个小节下，我们将介绍几个函数，包括`fillna`、`drop_duplicates`、`map`、`addColumns`、`apply`、`query`和`sample`，以及对数据进行编码的函数。

## 替换缺失值

许多数据集带有缺失值，为了从这些数据集中获取最多的数据，我们必须进行某种形式的数据填充/替换。Danfo.js 提供了一个`fillna`方法，当给定一个 DataFrame 或 Series 时，它可以自动用指定的值填充任何缺失的字段。

当您将数据集加载到 Danfo.js 数据结构中时，所有缺失的值(可能是未定义的、空的、null、无等等)都存储为`NaN`，因此，`fillna`方法可以很容易地找到并替换它们。

### 替换序列中的值

`Series`对象的`fillna`方法的签名如下:

```
Series.fillna({value, inplace})
```

`value`参数是您想要用于替换缺失值的新值，而`inplace`参数用于指定是直接对对象还是副本进行更改。让我们来看一个例子。

假设我们有以下系列:

```
sdata = new dfd.Series([NaN, 1, 2, 33, 4, NaN, 5, 6, 7, 8])
sdata.print() //use print to show series in browser or node environment 
table(sdata) //use table to show series in Dnotebook environment
```

在您的 Dnotebook 环境中，`table(sdata)`将显示如下图所示的表格:

![Figure 4.1 – Series with missing values
](img/B17076_4_01.jpg)

图 4.1–缺失值的序列

注意

如果您在浏览器或 Node.js 环境中工作，您可以在控制台中查看`print`函数的输出。

要替换缺失值(`NaN`)，我们可以做如下操作:

```
sdata_new = sdata.fillna({ value: -999})
table(sdata_new) 
```

打印输出给我们提供了下表:

![Figure 4.2 – Series with missing values
](img/B17076_4_02.jpg)

图 4.2–缺失值的序列

还可以就地填充缺失的值，也就是说，可以直接变异对象，而不是创建新的对象。这可以在下面的代码中看到:

```
sdata.fillna({ value: -999, inplace: true})
table(sdata)
```

在处理大型数据帧或序列的情况下，就地填充有助于减少内存使用。

### 替换数据帧中的值

`fillna`函数也可用于填充数据帧中缺失的值。DataFrame 对象的`fillna`方法的签名如下:

```
DataFrame.fillna({columns, value, inplace})
```

首先，让我们了解一下参数:

*   `columns`:参数`columns`是您想要填充的列名数组。
*   `values`:参数`values`也是一个数组，大小必须与`columns`相同，它保存了要替换的相应值。
*   `inplace`:指定我们是应该修改当前数据帧还是返回一个新的。

现在，我们来看一个的例子。

假设我们有以下数据帧:

```
data = {"Name":["Apples", "Mango", "Banana", undefined],
            "Count": [NaN, 5, NaN, 10], 
            "Price": [200, 300, 40, 250]}

df = new dfd.DataFrame(data)
table(df)
```

代码的输出如下图所示:

![Figure 4.3 – DataFrame with missing values
](img/B17076_4_03.jpg)

图 4.3–缺失值的数据框

就填充缺失值而言，我们有两种方法可以达到这个目的。首先，我们可以用单个值填充所有缺少的字段，如下面的代码片段所示:

```
df_filled = df.fillna({ values: [-99]})
table(df_filled)
```

代码输出如下图所示:

![Figure 4.4 – Filling in all the missing values in a DataFrame with a single value
](img/B17076_4_04.jpg)

图 4.4–用单个值填充数据帧中所有缺失的值

大多数情况下，当处理数据框架时，用同一字段填充所有缺失值是不可取的，甚至是没有用的，因为您必须考虑到不同字段具有不同类型的值，这意味着填充策略会有所不同。

为了处理这样的情况，我们可以指定一个列列表和它们相应的值来填充它们，正如我们将在这里展示的。

使用我们在上一个示例中使用的相同数据帧，我们可以指定`Name`和`Count`列，并用`Apples`和`–99`值填充它们，如下所示:

```
data = {"Name":["Apples", "Mango", "Banana", undefined],
            "Count": [NaN, 5, NaN, 10], 
            "Price": [200, 300, 40, 250]}

df = new dfd.DataFrame(data)
df_filled = df.fillna({columns: ["Name", "Count"], values: ["Apples", -99]})
table(df_filled)
```

该代码的输出如下图所示:

![Figure 4.5 – Filling in the missing values in a DataFrame with specific values
](img/B17076_4_05.jpg)

图 4.5–用特定值填充数据框中缺失的值

注意

填充值(如-9、-99 和-999)通常用于表示数据分析中的缺失。

让我们在下一节中看看如何删除重复项。

## 删除重复项

在数据框架中处理系列或列时，重复字段是常见的情况。例如，看看下面代码中的系列:

```
data = [10, 45, 56, 10, 23, 20, 10, 10]
sf = new dfd.Series(data)
table(sf)
```

该代码的输出如下图所示:

![Figure 4.6 – Series with duplicate fields
](img/B17076_4_06.jpg)

图 4.6–具有重复字段的序列

在前面的图中，您可以看到值`10`出现了多次。如果需要，您可以使用`drop_duplicates`功能轻松删除这些副本。`drop_duplicates`功能的签名如下:

```
Series.drop_duplicates({inplace, keep)
```

`drop_duplicates`函数只有两个参数，第一个参数(`inplace`)非常简单。第二个参数`keep`可以用来指定保留哪个副本。您可以保留系列中的第一个或最后一个副本。这有助于在删除重复项后保留序列中的结构、顺序或值。

让我们来看看实际情况。在下面的代码块中，我们删除了所有重复的值，只保留第一个出现的值:

```
data1 = [10, 45, 56, 10, 23, 20, 10, 10, 20, 20]
sf = new dfd.Series(data1)
sf_drop = sf.drop_duplicates({keep: "first"})
table(sf_drop)
```

该代码的输出如下图所示:

![Figure 4.7 – Series after dropping duplicates with keep set to first
](img/B17076_4_07.jpg)

图 4.7–删除重复项并将“保持”设置为“第一”后的系列

查看前面的输出，您可以看到副本的第一个值被保留，而其他值被删除。相反，让我们将`keep`参数设置为`last`并观察字段顺序的变化:

```
sf_drop = sf.drop_duplicates({keep: "last"})
table(sf_drop)
```

该代码的输出如下图所示:

![Figure 4.8 – Series after dropping duplicates with keep set to last
](img/B17076_4_08.jpg)

图 4.8–删除重复项并将保留设置为最后一项后的系列

注意最后的`10`和`20`重复字段被保留，并且顺序与我们设置`keep`到`first`时不同。下图将帮助您理解删除重复项时的`keep`参数:

![Figure 4.9 – Difference between the output when keep is set to first or last
](img/B17076_4_09.jpg)

图 4.9–当 keep 设置为 first 或 last 时输出之间的差异

从上图中，您会发现将`keep`设置为`first`或`last`的主要区别在于结果值的顺序。

在下一小节中，我们将看看使用`map`函数的数据转换。

## 用地图功能进行数据转换

在某些情况下，您可能需要对序列或数据框列中的每个值进行转换。当你有一些自定义函数或映射，并想很容易地应用到每个字段时，这通常是有用的。Danfo.js 提供了一个名为`map`的简单接口，可以在这里使用。让我们看一个例子。

让我们假设在`grams`中有一个项目及其相应权重的数据框架，如以下代码所示:

```
df = new dfd.DataFrame({'item': ['salt', 'sugar', 'rice', 'apple', 'corn', 'bread'],
'grams': [400, 200, 120, 300, 70.5, 250]})
table(df)
```

该代码的输出如下图所示:

![Figure 4.10 – DataFrame with items and their corresponding weights in grams
](img/B17076_4_10.jpg)

图 4.10–包含物品及其相应重量(克)的数据框

我们想创建一个名为`kilograms`的新列，它的值是相应的克数，但转换成千克数。在这里，我们可以做到以下几点:

1.  用下面的代码创建一个`convertToKg`函数:

    ```
    function convertToKg(gram){   return gram / 1000 }
    ```

2.  调用`grams`列上的`map`函数，如下面的代码块所示:

    ```
    kilograms = df['grams'].map(convertToKg)
    ```

3.  Add the new `kilograms` column to the DataFrame using the `addColumn` function, as shown in the following code:

    ```
    df.addColumn({ "column": "kilograms", "value": kilograms  });
    ```

    将所有这些放在一起，我们有以下代码:

    ```
    df = new dfd.DataFrame({'item': ['salt', 'sugar', 'rice', 'apple', 'corn', 'bread'],
    'grams': [400, 200, 120, 300, 70.5, 250]})
    function convertToKg(gram){
      return gram / 1000
    } 
    kilograms  = df['grams'].map(convertToKg)
    df.addColumn({ "column": "kilograms", "value": kilograms  });
    table(df)
    ```

    代码输出如下图所示:

![Figure 4.11 – DataFrame with items and their corresponding weights in grams
](img/B17076_4_11.jpg)

图 4.11–以克为单位显示物品及其相应重量的数据框

`map`函数也可以执行一对一的映射，当你传递给它一个带有键值对的对象时。这可以用于编码、快速映射等等。让我们来看一个例子。

假设我们有以下系列:

```
sf = new dfd.Series([1, 2, 3, 4, 4, 4])
```

这里，我们希望将每个数值映射到其对应的名称。我们可以指定一个`mapper`对象并将其传递给`map`函数，如下面的代码所示:

```
mapper = { 1: "one", 2: "two", 3: "three", 4: "four" }
sf = sf.map(mapper)
table(sf)
```

该代码的输出如下图所示:

![Figure 4.12 – Series with numeric values mapped to string names
](img/B17076_4_12.jpg)

图 4.12–数值映射到字符串名称的序列

`map`函数在处理序列时非常有用，但有时，您可能希望将函数应用于特定的轴(行或列)。在这种情况下，您可以使用另一个名为`apply`的 Danfo.js 函数。

在下一节中，我们将介绍`apply`功能。

## 使用应用功能进行数据转换

`apply`函数可用于将函数或转换映射到数据帧中的特定轴。它比`map`函数更高级更强大，我们将解释为什么。

首先，我们可以在指定的轴上应用张量运算。让我们来看一个包含以下值的数据帧:

```
data = [[1, 2, 3], [4, 5, 6], [20, 30, 40], [39, 89, 78]]
cols = ["A", "B", "C"]
df = new dfd.DataFrame(data, { columns: cols })
table(df)
```

该代码的输出如下图所示:

![Figure 4.13 – Sample DataFrame with three columns
](img/B17076_4_13.jpg)

图 4.13–包含三列的样本数据框架

现在，我们可以在指定的轴上应用任何兼容的张量运算。例如，在下面的代码中，我们可以对数据帧中的每个元素应用一个`softmax`函数([https://en.wikipedia.org/wiki/Softmax_function](https://en.wikipedia.org/wiki/Softmax_function)):

```
function sum_vals(x) {
    return x.softmax()
}
let df_new = df.apply({axis: 0, callable: sum_vals })
table(df_new)
```

该代码的输出如下图所示:

![Figure 4.14 – DataFrame after applying a softmax function element-wise
](img/B17076_4_14.jpg)

图 4.14-应用 softmax 函数元素后的数据帧

注意

我们将轴设置为`0`用于元素式张量运算。这是因为有些张量运算不能按元素来执行。你可以在[https://js.tensorflow.org/api/latest/](https://js.tensorflow.org/api/latest/)了解更多支持的操作。

让我们看看另一个应用函数的例子，它可以分别作用于列(轴= 1)和行(轴= 0)。

为此，我们将使用 TensorFlow `sum`函数，如下面的代码所示。首先，让我们将它应用于行轴:

```
data = [[1, 2, 3], [4, 5, 6], [20, 30, 40], [39, 89, 78]] 
cols = ["A", "B", "C"] 
df = new dfd.DataFrame(data, { columns: cols })
function sum_vals(x) { 
    return x.sum() 
} 
df_new = df.apply({axis: 0, callable: sum_vals }) 
table(df_new)
```

打印`df_new`数据帧产生以下输出:

![Figure 4.15 – DataFrame after applying the sum function across the row (0) axis
](img/B17076_4_15.jpg)

图 4.15–在行(0)轴上应用 sum 函数后的数据帧

使用与前面相同的数据帧，将轴更改为`1`进行列操作，如以下代码片段所示:

```
df_new = df.apply({axis: 1, callable: sum_vals }) 
table(df_new)
```

打印数据帧会产生以下输出:

![Figure 4.16 – DataFrame after applying the sum function across the column (1) axis
](img/B17076_4_16.jpg)

图 4.16–对列(1)轴应用求和函数后的数据帧

自定义 JavaScript 函数也可以和`apply`函数一起使用。这里唯一需要注意的是，您不需要指定轴，因为 JavaScript 函数是按元素方式应用的。

让我们看一个将`apply`与 JavaScript 函数一起使用的例子。在下面的代码块中，我们将`toLowerCase`字符串函数应用于 DataFrame 中的每个元素:

```
data = [{ short_name: ["NG", "GH", "EGY", "SA"] },
             { long_name: ["Nigeria", "Ghana", "Eqypt", "South Africa"] }]
df = new dfd.DataFrame(data)
function lower(x) {
    return '${x}'.toLowerCase()
}
df_new = df.apply({ callable: lower })
table(df_new)
```

打印数据帧会产生以下输出:

![Figure 4.17 – DataFrame after applying a JavaScript function element-wise
](img/B17076_4_17.jpg)

图 4.17–按元素应用 JavaScript 函数后的数据帧

`apply`函数非常强大，可用于对数据帧或系列中的列或行应用自定义转换。在下一小节中，我们将看看过滤和查询数据帧和数据系列的不同方式。

## 过滤和查询

当我们需要获得满足特定布尔条件的数据子集时，过滤和查询是很重要的。过滤和查询可以使用`query`方法在数据帧和序列上完成，我们将在下面的例子中演示。

假设我们有一个包含以下列的数据帧:

```
data = {"A": [30, 1, 2, 3],
         "B": [34, 4, 5, 6],
         "C": [20, 20, 30, 40]}
cols = ["A", "B", "C"]
df = new dfd.DataFrame(data, { columns: cols })
table(df)
```

打印数据帧会产生以下输出:

![Figure 4.18 – DataFrame with sample values for querying
](img/B17076_4_18.jpg)

图 4.18–带有查询示例值的数据框架

现在，让我们过滤数据帧，只返回那些`B`列的值大于`5`的行。这将返回行`0`和`3`。我们可以用`query`函数来实现，如下面的代码所示:

```
df_filtered = df.query({ column: "B", is: ">", to: 5})
table(df_filtered)
```

这为我们提供了以下输出:

![Figure 4.19 – DataFrame after querying
](img/B17076_4_19.jpg)

图 4.19-查询后的数据帧

`query`方法接受所有的 JavaScript 布尔操作符(`>`、`<`、`>=`、`<=`和`==`)，并且也作用于字符串列，如下例所示。

首先，让我们创建一个包含字符串列的数据帧:

```
data = {"A": ["Ng", "Yu", "Mo", "Ng"],
            "B": [34, 4, 5, 6], 
            "C": [20, 20, 30, 40]}

df = new dfd.DataFrame(data)
table(df)
```

输出如下图所示:

![Figure 4.20 – DataFrame before applying the string query
](img/B17076_4_20.jpg)

图 4.20–应用字符串查询前的数据帧

接下来，我们将使用等于运算符(`"=="`)运行一个查询:

```
query_df = df.query({ column: "A", is: "==", to: "Ng"})
table(query_df)
```

这导致输出如下:

![Figure 4.21 – DataFrame after applying the string query
](img/B17076_4_21.jpg)

图 4.21–应用字符串查询后的数据帧

在大多数情况下，您查询的数据帧很大，因此您可能希望就地执行查询。这可以通过将`inplace`指定为`true`来实现，如以下代码块所示:

```
data = {"A": [30, 1, 2, 3],
         "B": [34, 4, 5, 6],
         "C": [20, 20, 30, 40]}

cols = ["A", "B", "C"]
df = new dfd.DataFrame(data, { columns: cols })
df.query({ column: "B", is: "==", to: 5, inplace: true })
table(df)
```

打印数据帧会产生以下输出:

![Figure 4.22 – DataFrame after performing an inplace query
](img/B17076_4_22.jpg)

图 4.22–执行就地查询后的数据帧

`query`方法非常重要，当通过特定属性过滤数据时，您会经常用到它。使用`query`函数的另一个好处是它允许`inplace`功能，这意味着它对过滤大型数据集很有用。

在下一小节中，我们将看看另一个有用的概念，叫做随机抽样。

## 随机抽样

**从数据帧或序列中随机取样**在需要随机重新排列行时很有用。这在**机器学习** ( **ML** )之前的预处理步骤中非常有用。

让我们看一个使用随机抽样的例子。假设我们有一个包含以下值的数据帧:

```
data = [[1, 2, 3], [4, 5, 6], [20, 30, 40], [39, 89, 78]] 
cols = ["A", "B", "C"] 
df = new dfd.DataFrame(data, { columns: cols }) 
table(df)
```

这导致以下输出:

![Figure 4.23 – DataFrame before random sampling
](img/B17076_4_23.jpg)

图 4.23-随机取样前的数据帧

现在，让我们通过调用 DataFrame 上的`sample`函数来随机选择两行，如以下代码所示:

```
async function load_data() {
  let data = {
    Name: ["Apples", "Mango", "Banana", "Pear"],
    Count: [21, 5, 30, 10],
    Price: [200, 300, 40, 250],
  };

  let df = new dfd.DataFrame(data);
  let s_df = await df.sample(2);
  s_df.print();

}
load_data()
```

这导致输出如下:

![Figure 4.24 – DataFrame in browser console after randomly sampling two rows
](img/B17076_4_24.jpg)

图 4.24–随机采样两行后浏览器控制台中的数据帧

在前面的代码中，您会注意到代码被包装在一个`async`函数中。这是因为`sample`方法返回一个承诺，因此，我们必须等待结果。前面的代码可以在浏览器或 node.js 环境中执行，但是需要稍微调整一下才能在 Dnotebook 中运行。

如果您想在 Dnotebook 中运行确切的代码，您可以像这样调整它:

```
var sample;
async function load_data() {
  let data = {
    Name: ["Apples", "Mango", "Banana", "Pear"],
    Count: [21, 5, 30, 10],
    Price: [200, 300, 40, 250],
  };

  let df = new dfd.DataFrame(data);
  let s_df = await df.sample(2);
  sample = s_df

}
load_data()
```

在前面的代码中，可以看到我们使用`var`显式定义了`sample`。这使得`sample`变量可用于所有单元格。在这里使用`let`声明将使变量只对定义它的单元格可用。

接下来，在新的单元格中，您可以使用`table`方法打印示例数据帧，如以下代码所示:

```
table(sample)
```

这会产生以下输出:

![Figure 4.25 – DataFrame in Dnotebook after randomly sampling two rows
](img/B17076_4_25.jpg)

图 4.25-随机取样两行后 Dnotebook 中的数据帧

在下一节中，我们将简要讨论 Danfo.js 中可用的一些编码特性。

## 编码数据帧和序列

**编码**是另一个重要的变换，可以在 ML 或**统计建模**之前应用于数据帧/序列。这是一个重要的数据预处理步骤，总是在将数据输入模型之前执行。

ML 或统计模型只能处理数值，因此，所有字符串/分类列都必须适当地转换为数值形式。编码有很多种，比如**一键编码**、**标签编码**、**均值编码**等等，根据你拥有的数据类型不同，编码的选择也可能不同。

Danfo.js 目前支持两种流行的编码方案:*标签*和*一键编码器*，在接下来的章节中，我们将解释如何使用它们。

### 标签编码器

标签编码器将一列中的类别映射到一个介于 0 和该列中唯一类的数量之间的整数值。让我们看一个在数据帧上使用它的例子。

假设我们有以下数据帧:

```
data = { fruits: ['pear', 'mango', "pawpaw", "mango", "bean"] ,
            Count: [20, 30, 89, 12, 30],
            Country: ["NG", "NG", "GH", "RU", "RU"]}
df = new dfd.DataFrame(data)
table(df)
```

打印数据帧会产生以下输出:

![Figure 4.26 – DataFrame before encoding
](img/B17076_4_26.jpg)

图 4.26–编码前的数据帧

现在，让使用`LabelEncoder`对`fruits`列进行编码，如下面的代码块所示:

```
encode = new dfd.LabelEncoder() 
encode.fit(df['fruits']) 
```

在前面的代码块中，您会注意到我们首先创建了一个`LabelEncoder`对象，然后在列(`fruits`)上创建了名为`fit`方法的。`fit`方法只是学习并存储编码器对象中的映射。稍后我们将看到，这可以用于转换任何列/数组。

调用`fit`方法后，我们必须调用`transform`方法来应用标签，如下面的代码块所示:

```
sf_enc = encode.transform(df['fruits']) 
table(sf_enc)
```

打印数据帧会产生以下输出:

![Figure 4.27 – DataFrame before label encoding
](img/B17076_4_27.jpg)

图 4.27–标签编码前的数据帧

从前面的输出中，您可以看到每个标签都被赋予了唯一的整数。如果在`fit`(学习)阶段`transform`在一个新类别不可用的列上被调用，它用值`–1`表示。让我们来看一个例子，同时使用与前一个例子相同的编码器:

```
new_sf = encode.transform(["mango","man", "car", "bean"])
table(new_sf)
```

打印数据帧会产生以下输出:

![Figure 4.28 – DataFrame after applying transform to an array with new categories
](img/B17076_4_28.jpg)

图 4.28–对具有新类别的数组应用变换后的数据帧

在前面的例子中，您可以看到我们正在使用新的类别(`man`和`car`)在一个数组上调用训练好的编码器。注意，输出中用`–1`代替了这些新的类别，正如我们之前解释的那样。

接下来，我们来谈谈一键编码。

### 一键编码

One-hot 编码主要应用于数据集中的有序类别。在这个编码方案中，二进制值`0`(热)和`1`(冷)用于编码唯一的类别。

使用与上一节相同的 DataFrame，让我们创建一个 hot encoder 对象，并将其应用于`country`列，如下面的代码块所示:

```
encode = new dfd.OneHotEncoder()  
encode.fit(df['country']) 
sf_enc = encode.transform(df['country']) 
table(sf_enc)
```

打印数据帧会产生以下输出:

![Figure 4.29 – DataFrame after one-hot encoding
](img/B17076_4_29.jpg)

图 4.29–一键编码后的数据帧

从前面的输出中，您可以看到，对于每个唯一的类别，一系列的 1 和 0 用于替换类别，并且我们现在已经生成了两个额外的列。下面的图让我们直观地了解每个独特的类别是如何映射到一个热门类别的:

![Figure 4.30 – One-hot encoding mapping for three categories
](img/B17076_4_30.jpg)

图 4.30–三个类别的一键编码映射

Danfo.js 中最后一个可用的编码特性是`get_dummies`函数。该函数的工作方式与 one-hot encoding 函数相同，但主要区别在于，您可以将它应用于整个数据帧，它会自动对找到的任何分类列进行编码。

让我们看一个使用`get_dummies`功能的例子。假设我们有以下数据帧:

```
data = { fruits: ['pear', 'mango', "pawpaw", "mango", "bean"] ,
            count: [20, 30, 89, 12, 30],
            country: ["NG", "NG", "GH", "RU", "RU"]}
df = new dfd.DataFrame(data)
table(df)
```

打印数据帧会产生以下输出:

![Figure 4.31 – DataFrame before applying the get_dummies function
](img/B17076_4_31.jpg)

图 4.31-应用 get_dummies 函数前的数据帧

现在，我们可以通过将 DataFrame 传递给`get_dummies`函数来一次性对所有分类列(`fruits`和`country`)进行编码，如下面的代码块中的所示:

```
df_enc = dfd.get_dummies({data: df})
table(df_enc)
```

打印数据帧会产生以下输出:

![Figure 4.32 – One-hot encoding a mapping for three categories
](img/B17076_4_32.jpg)

图 4.32–一键编码三个类别的映射

从上图中，您可以看到`get_dummies`函数自动检测到了`fruits`和`country`分类变量，并对它们进行了一键编码。列是自动生成的，它们的名称以相应的列和类别开始。

注意

您可以指定要编码的列，以及命名每个编码列的前缀。要查看更多可用选项，请参考 Danfo.js 官方文档:[https://danfo.jsdata.org/](https://danfo.jsdata.org/)。

在下一个部分，我们将看看组合数据集的各种方法。

# 组合数据集

可以使用 Danfo.js 中的内置函数将 DataFrames 和 Series组合在一起。存在像`danfo.merge`和`danfo.concat`这样的方法，根据不同的配置，可以帮助您使用熟悉的类似数据库的连接来组合不同形式的数据集。

在这一节中，我们将简要讨论这些连接类型，从`merge`函数开始。

## 数据帧合并

`merge`操作类似于数据库`Join`操作，因为它对在对象中找到的列或索引执行连接操作。`merge`操作的签名如下:

```
danfo.merge({left, right, on, how}) 
```

让我们了解一下每个参数意味着什么:

*   `left`:要合并到的左侧数据帧/系列。
*   `right`:要合并到的右侧数据帧/系列。
*   `on`:要连接的列的名称。这些列必须同时出现在左侧和右侧数据框架中。
*   `how`:参数`how`指定合并应该如何进行。它类似于数据库风格的连接，可以是`left`、`right`、`outer`或`inner`。

Danfo.js `merge`函数非常类似于 pandas `merge`函数，因为它执行类似于关系数据库连接的内存连接操作。下表提供了 Danfo 的合并方法和 SQL 连接的比较:

![Figure 4.33 – Comparing the Danfo.js merge methods to SQL joins 
](img/B17076_4_33.jpg)

图 4.33-比较 Danfo.js 合并方法和 SQL 连接(来源:pandas Doc:https://pandas . pydata . org/pandas-docs/stable/user _ guide/merging . html # brief-primer-on-merge-methods-relational-algebra)

在下面的部分，我们将给出一些例子来帮助你理解如何以及何时使用`merge`功能。

### 通过单键进行内部合并

默认情况下，在单个公共键上合并数据帧会导致内部连接。内部连接要求两个数据帧有匹配的列值，它返回两者的交集；也就是说，它返回的数据帧只包含那些具有共同特征的行。

假设我们有两个数据帧，如以下代码所示:

```
data = [['K0', 'k0', 'A0', 'B0'], ['k0', 'K1', 'A1', 'B1'],
            ['K1', 'K0', 'A2', 'B2'], ['K2', 'K2', 'A3', 'B3']]
data2 = [['K0', 'k0', 'C0', 'D0'], ['K1', 'K0', 'C1', 'D1'],
            ['K1', 'K0', 'C2', 'D2'], ['K2', 'K0', 'C3', 'D3']]
colum1 = ['Key1', 'Key2', 'A', 'B']
colum2 = ['Key1', 'Key2', 'A', 'D']

df1 = new dfd.DataFrame(data, { columns: colum1 })
df2 = new dfd.DataFrame(data2, { columns: colum2 })
table(df1)
```

打印第一个数据帧导致以下输出:

![Figure 4.34 – First DataFrame to perform a merge operation on
](img/B17076_4_34.jpg)

图 4.34–执行合并操作的第一个数据帧

我们现在将打印第二个数据帧，如下所示:

```
table(df2)
```

这会产生以下输出:

![Figure 4.35 – Second DataFrame to perform a merge operation on
](img/B17076_4_35.jpg)

图 4.35–执行合并操作的第二个数据帧

接下来，我们将执行内部连接，如下面的代码所示:

```
merge_df = dfd.merge({left: df1, right: df2, on: ["Key1"]})
table(merge_df)
```

打印数据帧会产生以下输出:

![Figure 4.36 – Inner merge of two DataFrames on a single key
](img/B17076_4_36.jpg)

图 4.36–单个键上两个数据帧的内部合并

从前面的输出中，您可以看到`Key1`中的内部连接产生了一个包含数据帧 1 和数据帧 2 中所有值的数据帧。这也被称为两个数据帧的**笛卡尔乘积**。

我们可以更进一步，合并多个键。我们将在下一节中讨论这一点。

### 两个键的内部合并

对两个键执行内部合并也将返回两个数据帧的交集，但它将只返回在数据帧的左右两侧都找到的键的行。

使用我们之前创建的相同数据帧，我们可以对两个键执行内部连接，如以下代码所示:

```
merge_mult_df = dfd.merge({left: df1, right: df2, on: ["Key1", "Key2"]})
table(merge_mult_df)
```

打印数据帧会产生以下输出:

![Figure 4.37 – Inner merge of two DataFrames on two keys
](img/B17076_4_37.jpg)

图 4.37–两个键上两个数据帧的内部合并

从前面的输出中，您可以看到对两个键执行内部合并会产生一个数据帧，其中只有这些键出现在数据帧的左侧和右侧。

### 单个键上的外部合并

正如我们在前面的表格中看到的，外部合并执行两个数据帧的联合。也就是说，它从两个数据帧中都存在的键中返回值。对单个键执行外部联接将返回与对单个键执行内部联接相同的结果。

使用前面的相同数据帧，我们可以指定`how`参数来将合并行为从默认的`inner`连接更改为`outer`，如下面的代码所示:

```
merge_df = dfd.merge({ left: df1, right: df2, on: ["Key1"], how: "outer"})
table(merge_df)
```

打印数据帧会产生以下输出:

![Figure 4.38 – Outer merge of two DataFrames on a single key
](img/B17076_4_38.jpg)

图 4.38–单个键上两个数据帧的外部合并

从上图可以看出，第一个带键的数据帧(`K0`、`K0`、`K1`、`K2`)和第二个带键的数据帧(`K0`、`K1`、`K1`、`K2`)的并集是(`K0`、`K0`、`K1`、`K1`、`K2`)。这些密钥然后被用于联合数据帧。这样做之后，我们收到了上表中显示的结果。

我们还可以对两个键执行外部连接。这将不同于两个键的内部连接，我们将在下面的小节中看到。

### 两个键的外部合并

仍然使用前面的相同数据帧，我们可以添加第二个键，如以下代码所示:

```
merge_df = dfd.merge({ left: df1, right: df2, on: ["Key1", "Key2"], how: "outer"})
table(merge_df)
```

打印数据帧会产生以下输出:

![Figure 4.39 – Outer merge of two DataFrames on two keys
](img/B17076_4_39.jpg)

图 4.39–两个键上两个数据帧的外部合并

在前面的输出中，我们可以看到返回的行总是有键出现在`Key1`和`Key2`中。如果第一个数据帧中的键不在第二个数据帧中，则值总是用`NaN`填充。

注意

Danfo.js 中的合并不支持一次合并两个以上的键。这在未来可能会改变，所以如果你需要这样一个特性的支持，一定要查看官方 Danfo.js GitHub 库([https://github.com/opensource9ja/danfojs](https://github.com/opensource9ja/danfojs))中的*讨论*部分。

在接下来的章节中，我们将简要地看看左右连接，这在执行合并时也很重要。

### 左右合并

右连接和左连接非常简单；它们只返回在指定的`how`参数中有关键字的行。例如，假设我们将`how`参数指定为`right`，如以下代码所示:

```
merge_df = dfd.merge({ left: df1, right: df2, on: ["Key1", "Key2"], how: "right"})
table(merge_df)
```

打印数据帧会产生以下输出:

![Figure 4.40 – Right merge of two DataFrames on two keys
](img/B17076_4_40.jpg)

图 4.40–两个键上两个数据帧的右合并

生成的图表仅显示其键出现在右侧数据帧中的行。这意味着在执行合并时，右数据帧具有更高的优先级。

如果我们将`how`设置为`left`，则给予左侧数据帧更高的优先级，我们只能看到其键出现在左侧数据帧中的行。下面的代码展示了一个执行`left`连接的例子:

```
merge_df = dfd.merge({ left: df1, right: df2, on: ["Key1", "Key2"], how: "left"})
table(merge_df)
```

打印数据帧会产生以下输出:

![Figure 4.41 – Left merge of two DataFrames on two keys
](img/B17076_4_41.jpg)

图 4.41–两个键上两个数据帧的左侧合并

查看前面的输出，我们可以确认结果行更倾向于左边的数据帧。

Danfo.js `merge`函数非常强大和有用，当您开始处理多个具有重叠键的数据集时，它会派上用场。在下一节中，我们将介绍另一个有用的函数，称为**串联**，用于转换数据集。

## 数据拼接

串联数据是另一种重要的数据组合技术，顾名思义，这基本上是沿着一个轴将数据连接、堆叠或排列在一起。

Danfo.js 中串联数据的函数被公开为`danfo.concat`，该函数的签名如下:

```
danfo.concat({df_list, axis}) 
```

让我们了解一下每个参数代表什么:

*   `df_list`:参数`df_list`是一个你想要连接在一起的数据帧或序列的数组。
*   `axis`:参数`axis`可以接受一行(0)或一列(1)并指定对象对齐的轴。

接下来，我们将给出一些例子来帮助你理解如何使用`concat`功能。首先，我们将学习如何沿着行轴连接三个数据帧。

### 沿着行轴(0)连接数据帧

首先，让我们创建三个数据帧，如下面的代码所示:

```
df1 = new dfd.DataFrame( 
    { 
           "A": ["A_0", "A_1", "A_2", "A_3"], 
           "B": ["B_0", "B_1", "B_2", "B_3"], 
           "C": ["C_0", "C_1", "C_2", "C_3"] 
        },
        index=[0, 1, 2], 
  ) 
df2 = new dfd.DataFrame( 
       { 
          "A": ["A_4", "A_5", "A_6", "A_7"], 
          "B": ["B_4", "B_5", "B_6", "B_7"], 
          "C": ["C_4", "C_5", "C_6", "C_7"], 
       }, 
       index=[4, 5, 6], 
    ) 
df3 = new dfd.DataFrame( 
    { 
          "A": ["A_8", "A_9", "A_10", "A_11"], 
           "B": ["B_8", "B_9", "B_10", "B_11"], 
           "C": ["C_8", "C_9", "C_10", "C_11"]
       }, 
       index=[8, 9, 10], 
   )
table(df1)
table(df2)
table(df3)
```

使用 Node.js 中的`print`函数和浏览器打印每个数据帧，或者使用 Dnotebook 中的`table`函数，将会得到以下输出。

`df1`数据帧的输出如下:

![Figure 4.42 – First DataFrame (df1) to be concatenated
](img/B17076_4_42.jpg)

图 4.42–要连接的第一个数据帧(df1)

`df2`数据帧的输出如下:

![Figure 4.43 – Second DataFrame (df2) to be concatenated
](img/B17076_4_43.jpg)

图 4.43–要连接的第二个数据帧(df2)

最后，`df3`数据帧的输出如下:

![Figure 4.44 – Third DataFrame (df3) to be concatenated
](img/B17076_4_44.jpg)

图 4.44–要连接的第三个数据帧(df3)

现在，让我们使用`concat`函数组合这些数据帧，如以下代码所示:

```
df_frames = [df1, df2, df3]
combined_df = dfd.concat({df_list: df_frames, axis: 0})
table(combined_df)
```

这会产生以下输出:

![Figure 4.45 – Result of concatenating three DataFrames along the row axis (0) 
](img/B17076_4_45.jpg)

图 4.45–沿着行轴(0)连接三个数据帧的结果

这里可以看到`concat`函数只是简单的将每个数据帧(`df1`、`df2`、`df3`)沿着列轴组合起来；也就是说，它将它们堆叠在`df_list`中第一个数据帧的下方，以创建一个巨大的组合。

此外，指数看起来不同。这是因为，在内部，Danfo.js 为组合生成了新的索引。如果需要数字索引，那么可以使用`reset_index`函数，如下面的代码中的所示:

```
combined_df.reset_index(true)
table(combined_df)
```

这会产生以下输出:

![Figure 4.46 – Resetting the index of the combined DataFrames
](img/B17076_4_46.jpg)

图 4.46–重置组合数据帧的索引

现在，使用相同的数据帧沿着列轴串联会是什么样子呢？我们将在下一节中尝试这一点。

### 沿着列轴串联数据帧(1)

使用我们之前创建的相同数据帧，只需将`concat`代码中的`axis`更改为`1`，如以下代码所示:

```
df_frames = [df1, df2, df3]
combined_df = dfd.concat({df_list: df_frames, axis: 1})
table(combined_df)
```

打印数据帧会产生以下输出:

![Figure 4.47 – Result of applying concat to three DataFrames along the column axis (0)
](img/B17076_4_47.jpg)

图 4.47–沿列轴(0)对三个数据帧应用 concat 的结果

串联也适用于系列对象。我们将在下一节看一个例子。

### 沿指定轴串联系列

Series 也是 Danfo.js 数据结构，因此,`concat`函数也可以用在它们上面。这与连接数据帧的方式相同，我们将很快演示。

使用上一节中的数据帧，我们将创建一些 Series 对象，如下面的代码所示:

```
series_list = [df1['A'], df2['B'], df3['D']]
```

请注意，我们使用 DataFrame 子设置从数据帧中获取不同的列作为系列。现在，我们可以将这些序列组合成一个数组，然后将它传递给`concat`函数，如下面的代码所示:

```
series_list = [df1['A'], df2['B'], df3['D']]
combined_series = dfd.concat({df_list: series_list, axis: 1})
table(combined_series)
```

打印数据帧产生以下输出:

![Figure 4.48 – Result of applying concat to three Series along the row axis (0)
](img/B17076_4_48.jpg)

图 4.48–将 concat 应用于沿行轴(0)的三个序列的结果

将轴更改为 row (0)也可以工作，并返回一个包含大量缺失条目的数据帧，如下图所示:

![Figure 4.49 – Result of applying concat to three Series along the column axis (1)
](img/B17076_4_49.jpg)

图 4.49–沿列轴对三个系列应用 concat 的结果(1)

现在，您可能想知道为什么在结果组合中会有很多缺失的字段。这是因为当对象沿着指定的轴组合时，有时对象的位置/长度不会与第一个数据帧对齐。用`NaN`到完成填充，返回一致的长度。

在这一小节中，我们介绍了两个重要的函数(`merge`和`concat`)，它们可以帮助您在数据帧或系列上执行复杂的组合。在下一部分，我们将讨论一些不同但也很重要的东西，那就是**字符串/文本操作**。

# 系列数据存取器

Danfo.js 在各种访问器下提供了特定于数据类型的方法。**访问器**是只能在特定数据类型上应用/调用的 Series 对象中的名称空间。目前为字符串和日期-时间序列提供了两种访问器，在这一节中，我们将讨论每一种访问器，并提供一些示例。

### 字符串存取器

数据帧或带有`dtype`字符串的系列中的字符串列可以在`str`访问器下访问。在这样的对象上调用`str`访问器会公开许多用于操作数据的字符串函数。我们将在本节中给出一些例子。

假设我们有一个包含以下字段的系列:

```
data = ['lower boy', 'capitals', 'sentence', 'swApCaSe']
sf = new dfd.Series(data)
table(sf)
```

打印此系列会产生下图:

![Figure 4.50 – Result of applying concat to three Series along the column axis (1)
](img/B17076_4_50.jpg)

图 4.50–沿列轴对三个系列应用 concat 的结果(1)

从前面的输出中，我们可以看到序列(`sf`)包含文本，并且是字符串类型。您可以用`dtype`函数确认这一点，如以下代码所示:

```
console.log(sf.dtype)
```

输出如下所示:

```
string
```

现在我们已经有了 string 数据类型的 Series，我们可以在它上面调用`str`访问器并使用各种 JavaScript string 方法，例如`capitalize`、`split`、`len`、`join`、`trim`、`substring`、`slice`、`replace`等等，如下面的示例所示。

以下代码将`capitalize`函数应用于一个系列:

```
mod_sf = sf.str.capitalize() 
table(mod_sf)
```

打印此系列会产生以下输出:

![Figure 4.51 – Result of applying capitalize to a string Series
](img/B17076_4_51.jpg)

图 4.51–对字符串序列应用大写的结果

以下代码将`substring`函数应用于一个系列:

```
mod_sf = sf.str.substring(0,3) //returns a substring by start and end index
table(mod_sf)
```

打印此系列会产生以下输出:

![Figure 4.52 – Result of applying the substring function to a string Series
](img/B17076_4_52.jpg)

图 4.52-将 substring 函数应用于字符串序列的结果

以下代码将`replace`函数应用于一个系列:

```
mod_sf = sf.str.replace("lower", "002") //replaces a string with specified value
table(mod_sf)
```

打印该系列会导致以下输出:

![Figure 4.53 – Result of applying the replace function to a string Series
](img/B17076_4_53.jpg)

图 4.53–对字符串序列应用替换功能的结果

以下代码将`join`函数应用于一个序列:

```
mod_sf = sf.str.join("7777", "+") // joins specified value to Series
table(mod_sf)
```

打印该系列结果如下图所示:

![Figure 4.54 – Result of applying the join function to a string Series
](img/B17076_4_54.jpg)

图 4.54–将连接函数应用于字符串序列的结果

以下代码将`indexOf`函数应用于一个序列:

```
mod_sf = sf.str.indexOf("r") //Returns the index where the value is found else -1
table(mod_sf)
```

打印此系列会产生以下输出:

![Figure 4.55 – Result of applying the indexOf function to a string Series
](img/B17076_4_55.jpg)

图 4.55–将 indexOf 函数应用于字符串序列的结果

注意

通过`str`访问器有许多公开的字符串方法可用。你可以在 Danfo.js 文档中看到完整的列表([https://danfo . jsdata . org/API-reference/series # string-handling](https://danfo.jsdata.org/api-reference/series#string-handling))。

### 日期时间存取器

Danfo.js 在 Series 对象上公开的第二个访问器是日期-时间访问器。这可以在`dt`名称空间下访问。在进行数据转换时，从日期-时间列中处理和提取不同的信息(如日、月和年)是一个常见的过程，因为日期-时间原始格式几乎没有用处。

如果您的数据有一个日期-时间列，那么可以对它调用`dt`访问器，这反过来公开了各种可以用来提取信息的函数，比如年、月、月名、星期几、小时、秒和一天中的分钟。

让我们看一些在带有日期列的序列上使用`dt`访问器的例子。首先，我们将创建一个包含一些日期时间字段的序列:

```
timeColumn = ['12/13/2016 15:00:20', '10/20/2019 18:30:00', '1/1/2020 12:00:00', '1/30/2020 16:20:00', '11/12/2019 22:00:30'] 
sf = new dfd.Series(timeColumn, {columns: ["times"]})
table(sf)
```

打印此系列会产生以下输出:

![Figure 4.56 – Series with date-time fields
](img/B17076_4_56.jpg)

图 4.56–带有日期-时间字段的序列

现在我们有了一个带有日期字段的序列，我们可以提取一些信息，比如一天中的小时、年、月或星期几。我们需要做的第一件事是使用`dt`访问器将序列转换成 Danfo.js 的日期-时间格式，如下面的代码所示:

```
dateTime = sf['times'].dt  
```

`dateTime`变量现在公开了提取日期信息的不同方法。利用这一点，我们可以做到以下任何一点:

*   Get the hour of the day as a new Series:

    ```
    dateTime = sf.dt 
    hours = dateTime.hour()
    table(hours)
    ```

    这为我们提供了以下输出:

![Figure 4.57 – New Series showing the extracted hour of the day
](img/B17076_4_57.jpg)

图 4.57–显示一天中提取的小时的新系列

*   Get the year as a new Series:

    ```
    dateTime = sf.dt 
    years = dateTime.year()
    table(years)
    ```

    这为我们提供了以下输出:

![Figure 4.58 – New Series showing the extracted year
](img/B17076_4_58.jpg)

图 4.58–显示提取年份的新系列

*   Get the month as a new Series:

    ```
    dateTime = sf.dt 
    month_name = dateTime.month_name()
    table(month_name)
    ```

    这为我们提供了以下输出:

![Figure 4.59 – New Series showing the extracted name of the month
](img/B17076_4_59.jpg)

图 4.59–显示提取的月份名称的新系列

*   Get the day of the week as a new Series:

    ```
    dateTime = sf.dt  
    weekdays = dateTime.weekdays() 
    table(weekdays)
    ```

    这为我们提供了以下输出:

![Figure 4.60 – New Series showing the extracted day of the week
](img/B17076_4_60.jpg)

图 4.60–显示提取的一周中的某一天的新系列

由`dt`访问器公开的其他一些函数如下:

*   `Series.dt.month`:返回月份的整数，从 1(1 月)到 12(12 月)。
*   `Series.dt.day`:以整数形式返回星期几，从 0(星期一)到 6(星期日)。
*   `Series.dt.minutes`:以整数形式返回一天中的分钟。
*   `Series.dt.seconds`:以整数形式返回一天中的秒数。

祝贺您完成本节的学习！数据转换和聚集是数据分析的非常重要的方面。有了这些知识，您就可以适当地转换和整理您的数据集。

在下一节中，我们将向您展示如何使用 Danfo.js 计算数据集的描述性统计数据。

# 计算统计数据

Danfo.js 附带了一些重要的统计和数学函数。这些函数可用于生成整个数据帧以及单个序列的摘要或描述性统计数据。在数据集中，统计很重要，因为它们可以让我们更好地洞察数据。

在下面的小节中，我们将使用流行的 Titanic 数据集，您可以从下面的 GitHub 存储库下载该数据集:[https://GitHub . com/packt publishing/Building-Data-Driven-Applications-with-danfo . js/blob/main/chapter 03/Data/Titanic . CSV](https://github.com/PacktPublishing/Building-Data-Driven-Applications-with-Danfo.js/blob/main/Chapter03/data/titanic.csv)。

首先，让我们使用`read_csv`函数将数据集加载到 Dnotebook 中，如下面的代码所示:

```
var df //using var so df is available to all cells
load_csv("https://raw.githubusercontent.com/plotly/datasets/master/finance-charts-apple.csv")
.then((data)=>{
  df = data
})
```

前面的代码从指定的 URL 加载 Titanic 数据集，并将其保存在`df`变量中。

注意

我们在这里使用`load_csv`和`var`声明，因为我们在 Dnotebook 中工作。正如我们一直提到的，您不会在浏览器或 Node.js 脚本中使用这种方法。

现在，在一个新的单元格中，我们可以打印加载的数据集的头部:

```
table(df.head())
```

打印数据帧会产生以下输出:

![Figure 4.61 – The first five rows of the Titanic dataset
](img/B17076_4_61.jpg)

图 4.61–泰坦尼克号数据集的前五行

我们可以对整个数据调用的`describe`函数来快速获得所有列的描述统计信息，如下面的代码所示:

```
table(df.describe())
```

打印数据帧会产生以下输出:

![Figure 4.62 – Output of using the describe function on the Titanic dataset
](img/B17076_4_62.jpg)

图 4.62–在 Titanic 数据集上使用描述函数的输出

在前面的代码中，我们调用了`describe`函数，然后用`table`打印输出。`describe`函数只对数值数据类型有效，默认情况下，它只会自动选择属于`float32`或`int32`类型的列。

注意

默认情况下，所有统计和数学计算都会在执行计算之前删除`NaN`值。

`describe`功能为以下内容提供描述性统计:

*   `NaN`价值观。
*   **表示**:一列的平均值。
*   **标准差** ( **std** ):一组数值的变化量或离差量的度量。
*   **最小值** ( **min** ):一列中的最小值。
*   **中值**:一列中的中间值。
*   **最大值** ( **最大值**):一列中的最大值。
*   **方差**:平均值的值的分布度量。

## 按轴计算统计数据

`describe`函数虽然快速且易于应用，但当您需要计算特定轴的统计数据时，它并不十分有用。在这一节中，我们将介绍一些最流行的方法，并向您展示如何基于指定的轴计算统计数据。

可以在具有指定轴的数据帧上调用集中趋势，如均值、众数和中位数。这里`0`轴代表`rows`，而`1`轴代表`columns`。

在下面的代码中，我们计算了 Titanic 数据集中数值列的平均值、众数和中值:

```
df_nums = df.select_dtypes(['float32', "int32"]) //select all numeric dtype columns
console.log(df_nums.columns)
[AAPL.Open,AAPL.High,AAPL.Low,AAPL.Close,AAPL.Volume,AAPL.Adjusted,dn,mavg,up]
```

在前面的代码中，我们选择了所有的数字列，以便我们可以应用数学运算。接下来，我们将调用`mean`函数，默认情况下，该函数返回列轴的平均值(`1`):

```
col_mean = df_nums.mean()
table(col_mean)
```

打印数据帧导致以下输出:

![Figure 4.63 – Calling the mean function on numeric columns
](img/B17076_4_63.png)

图 4.63–对数字列调用均值函数

前面输出中显示的精度看起来有点太长了。我们可以将结果四舍五入到两位小数，使其更直观，如下面的代码所示:

```
col_mean = df_nums.mean().round(2)
table(col_mean)
```

打印数据帧会产生以下输出:

![Figure 4.64 – Calling the mean function on numeric columns and rounding values to two decimal places
](img/B17076_4_64.jpg)

图 4.64–在数字列上调用 mean 函数并将数值四舍五入到两位小数

当四舍五入到两位小数时，结果输出看起来更清晰。接下来，让我们跨行轴计算`mean`:

```
row_mean = df_nums.mean(axis=0)
table(row_mean)
```

这为我们提供了以下输出:

![Figure 4.65 – Calling the mean function on the row axis
](img/B17076_4_65.jpg)

图 4.65–在行轴上调用均值函数

在前面的输出中，您可以看到返回值带有数字标签。这是因为行轴最初有数字标签。

使用同样的想法，我们可以计算统计数据，如众数、中位数、标准差、方差、累积和、累积均值、绝对值等等。以下是 Danfo.js 中目前可用的统计函数:

*   `abs`:返回每个元素的绝对数值的序列/数据帧。
*   `count`:计算每一列或每一行的单元格数，不包括`NaN`值。
*   `cummax`:返回数据帧或数据系列的累积最大值。
*   `cummin`:返回一个数据帧或系列的累积最小值。
*   `cumprod`:返回一个数据帧或系列的累积积。
*   `cumsum`:返回数据帧或数据系列的累计和。
*   `describe`:生成描述性统计。
*   `max`:返回请求轴的最大值。
*   `mean`:返回所请求轴的平均值。
*   `median`:返回所请求轴的值的中值。
*   `min`:返回请求轴的最小值。
*   `mode`:返回所选轴上元素的模式。
*   `sum`:返回请求轴的值的总和。
*   `std`:返回请求轴的标准偏差。
*   `var`:返回请求轴上的无偏方差。
*   `nunique`: Counts the distinct elements over the requested axis.

    注意

    支持的功能列表可能会改变，并且会添加新的功能。因此，最好通过查看[https://danfo . jsdata . org/API-reference/data frame # computations-descriptive-stats](https://danfo.jsdata.org/api-reference/dataframe#computations-descriptive-stats)来跟踪新的数据。

描述性统计非常重要，在本节中，我们成功地介绍了一些重要的函数，它们可以帮助您在 Danfo.js 中有效地计算基于指定轴的统计。

# 总结

在本章中，我们成功地介绍了 Danfo.js 中可用的数据转换和整理函数。首先，我们向您介绍了用于替换值、填充缺失值和检测缺失值的各种整理函数，以及将自定义函数应用于数据集的应用和映射方法。这些功能和技术的知识可确保您具备构建数据驱动型产品所需的基础，并从您的数据中获得洞察力。

接下来，我们向您展示了如何使用 Danfo.js 中的各种合并和连接函数。最后，我们向您展示了如何计算数据集的描述性统计数据。

在下一章中，我们将更进一步，向您展示如何使用 Danfo.js 的内置绘图功能以及通过集成第三方绘图库来制作美丽而令人惊叹的图表/绘图。