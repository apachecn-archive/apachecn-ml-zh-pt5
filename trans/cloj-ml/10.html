<html><head/><body>



<title>Appendix A. References</title><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/><div><div><div><div><h1 class="title"><a id="appA"/>附录 a .参考文献</h1></div></div></div><div><div><div><div><h1 class="title"><a id="ch09lvl1sec62"/>第一章</h1></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">布林、谢尔盖和<a id="id859" class="indexterm"/>劳伦斯·佩奇。<em>剖析大规模超文本网络搜索引擎</em>。1998.</li></ul></div></div></div>





<title>Chapter 2</title><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/><div><div><div><div><h1 class="title"><a id="ch09lvl1sec63"/>第二章</h1></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">埃德加·安德森。《鸢尾中的物种问题》。密苏里植物园年鉴 23(3):457–509。1936.</li></ul></div></div>





<title>Chapter 3</title><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/><div><div><div><div><h1 class="title"><a id="ch09lvl1sec64"/>第三章</h1></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">名词（noun 的缩写）美国阿尔特曼。<em>核和最近邻非参数回归简介</em>。美国统计学家。1992.</li><li class="listitem" style="list-style-type: disc">J.r .昆兰。<em>归纳决策树</em>，<em>马赫</em>。<em>学习</em>。1，1(1986 年 3 月)。81–106.1986.</li><li class="listitem" style="list-style-type: disc">J.r .昆兰。<em> C4.5:机器学习的程序</em>。1993.</li><li class="listitem" style="list-style-type: disc">克劳德·香农《交流的数学理论》。贝尔系统技术期刊 27(3):379–423。1948.</li><li class="listitem" style="list-style-type: disc">基于树大小的悲观决策树修剪。继续。第 14 届机器学习国际会议。195–201.1997.</li></ul></div></div>





<title>Chapter 4</title><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/><div><div><div><div><h1 class="title"><a id="ch09lvl1sec65"/>第四章</h1></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">材料科学中的神经网络。ISIJ 国际机场 39(10):966–979。1999.</li><li class="listitem" style="list-style-type: disc">Balabina、Roman M .、Ravilya Z. Safievaa 和 Ekaterina I. Lomakinab。<em>基于汽油近红外光谱建立校正模型的小波神经网络方法</em>。化学计量学和智能实验室系统，第 93 卷，第 1 期。2008.</li><li class="listitem" style="list-style-type: disc">m .舒斯特和 K. K .帕利瓦尔。双向递归神经网络。<em> IEEE 信号处理汇刊</em>，<em>45:2673–81</em>，<em>1997 年 11 月</em>。</li><li class="listitem" style="list-style-type: disc">伊格尔、克里斯蒂安和迈克尔·胡斯肯。<em>改进的 Rprop 学习算法的实证评估</em>。神经计算<em/>50:105–123。2003.</li><li class="listitem" style="list-style-type: disc">布鲁姆黑德 D. S .和大卫.洛。<em>多变量函数插值和自适应网络</em>。复杂系统 2:321–355。1988.</li></ul></div></div>





<title>Chapter 5</title><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/><div><div><div><div><h1 class="title"><a id="ch09lvl1sec66"/>第五章</h1></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Fisher，R.A. <em>研究人员的统计方法</em>。奥利弗和博伊德(爱丁堡)。1925.</li><li class="listitem" style="list-style-type: disc">格雷厄姆保罗。<em>垃圾邮件计划</em>(<a class="ulink" href="http://www.paulgraham.com/spam.html">http://www.paulgraham.com/spam.html</a>)。2002.</li><li class="listitem" style="list-style-type: disc">格雷厄姆保罗。<em>更好的贝叶斯滤波</em>。(<a class="ulink" href="http://www.paulgraham.com/better.html">http://www.paulgraham.com/better.html</a>)。2003.</li></ul></div></div>





<title>Chapter 6</title><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/><div><div><div><div><h1 class="title"><a id="ch09lvl1sec67"/>第六章</h1></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Rosasco，l .，E. D. De Vito，A. Caponnetto，M. Piana 和 A. Verri。"损失函数<a id="id860" class="indexterm"/>都一样吗？"。神经计算 16(5):1063–1076。2004.</li><li class="listitem" style="list-style-type: disc">科尔特斯和 v .瓦普尼克。“支持向量网络”。机器学习 20 (3): 273。1995.</li><li class="listitem" style="list-style-type: disc">约翰·普拉特。<em>序贯最小优化:训练支持向量机的快速算法</em>。citeserx:10 . 1 . 1 . 43 . 4376。1998.</li></ul></div></div>





<title>Chapter 7</title><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/><div><div><div><div><h1 class="title"><a id="ch09lvl1sec68"/>第七章</h1></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">哈迪根 J. A .和 M. A. Wong。“算法 AS 136:一种 K 均值聚类算法”。皇家统计学会杂志，C 28 系列(1):100–108。JSTOR 2346830。1979.</li><li class="listitem" style="list-style-type: disc">罗尔夫·桑德伯格。<em>最大似然理论及其在观察指数族变量函数时产生的分布的应用</em>。论文。数理统计研究所。斯德哥尔摩大学。1971.</li><li class="listitem" style="list-style-type: disc">巴考、费尔南多、维克多·洛博和马可·派尼奥。<em>作为 K 均值聚类替代的自组织映射</em>。CS 2005，LNCS 3516，476–483。2005.</li><li class="listitem" style="list-style-type: disc">Jolliffe，I.T <em>。主成分分析，系列:统计学中的斯普林格系列。第二版。纽约斯普林格，2002 年。2002.</em></li></ul></div></div>





<title>Chapter 8</title><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/><div><div><div><div><h1 class="title"><a id="ch09lvl1sec69"/>第八章</h1></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">霍奇 V. J .和 j .奥斯汀。“异常值检测方法综述”。人工智能评论 22 (2): 85。2004.</li><li class="listitem" style="list-style-type: disc">蒙塔纳，M . B .洛佩兹和 J. L .德拉罗萨。“互联网上推荐代理的分类”。人工智能评论 19(4):285–330。2003.</li><li class="listitem" style="list-style-type: disc">莱米尔，丹尼尔，<a id="id861" class="indexterm"/>和安娜麦克拉克伦。<em>基于在线评级的协同过滤的斜率一预测值。</em>在暹罗的数据挖掘(SDM'05)。新港海滩。加利福尼亚。2005.</li></ul></div></div>





<title>Chapter 9</title><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/><div><div><div><div><h1 class="title"><a id="ch09lvl1sec70"/>第九章</h1></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">朱正涛、金尚均、伊、俞媛媛、加里·布拉德斯基、和昆勒·奥卢科通。“多核上机器学习的 Map-Reduce”。NIPS 2006。</li><li class="listitem" style="list-style-type: disc">Ranger，c .，R. Raghuraman，A. Penmetsa，G. Bradski 和 C. Kozyrakis。<em>针对多核和多处理器系统评估 MapReduce</em>。<em> </em> IEEE 第 13 届高性能计算机体系结构国际研讨会。13.2007.</li><li class="listitem" style="list-style-type: disc">罗卡钱德，l，o .梅蒙。决策树分类器的自顶向下归纳——综述。IEEE 系统、人和控制论汇刊。第 35 (4)部分:476–48 页。2005.</li></ul></div></div>
</body></html>