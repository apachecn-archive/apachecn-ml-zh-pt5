<html><head/><body>
<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Heterogeneous Ensemble Classifiers Using H2O</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">基于 H2O 的异构集成分类器</h1>
                
            
            
                
<p class="calibre2">在本章中，我们将介绍以下配方:</p>
<ul class="calibre10">
<li class="calibre11">使用异质集成分类器预测信用卡违约者</li>
</ul>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Introduction </title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">介绍</h1>
                
            
            
                
<p class="calibre2">在这一章中，我们将展示如何使用 H2O 构建异构集成分类器，它是一个开源、分布式、内存中的机器学习平台。在 H2O 有许多监督和非监督的算法。</p>
<p class="calibre2">在监督算法中，H2O 为我们提供了神经网络、随机森林(RF)、广义线性模型、梯度推进机、朴素贝叶斯分类器和 XGBoost。</p>
<p class="calibre2">H2O 还为我们提供了一种堆叠集成方法，旨在使用堆叠过程找到一组预测算法的最佳组合。H2O 的堆叠系综支持回归和分类。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Predicting credit card defaulters using heterogeneous ensemble classifiers</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">使用异质集成分类器预测信用卡违约者</h1>
                
            
            
                
<p class="calibre2">我们将以台湾的信用卡支付违约者数据为例。这是我们之前在<a href="6a5a73fc-dba9-4903-a54a-6c79a8ee57b4.xhtml" class="calibre9">第 3 章</a>、<em class="calibre13">重采样方法</em>中使用的数据集，用于构建逻辑回归模型。在这个食谱中，我们将使用不同的算法建立多个模型，最后，建立一个堆叠的集合模型。</p>
<p class="calibre2">此数据集包含台湾信用卡客户的信息。这包括与付款违约者、客户的人口统计因素、他们的信用数据和他们的付款历史有关的信息。GitHub 中提供了数据集。它也可以从它的主要来源，https://bit.ly/2EZX6IC 的 UCI ML 知识库获得。</p>
<p class="calibre2">在我们的示例中，我们将使用以下来自 H2O 的监督算法来构建我们的模型:</p>
<ul class="calibre10">
<li class="calibre11">广义线性模型</li>
<li class="calibre11">分布式随机森林</li>
<li class="calibre11">梯度推进机</li>
<li class="calibre11">堆叠系综</li>
</ul>
<p class="calibre2">我们将看到如何在 Python 中使用这些算法，并学习如何为每个算法设置一些超参数。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Getting ready</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">做好准备</h1>
                
            
            
                
<p class="calibre2">我们将使用 Google Colab 来构建我们的模型。在<a href="0d0517ac-d372-478f-ba6a-4ad4828b81a0.xhtml" class="calibre9">第十章</a>、<em class="calibre13">使用 H2O </em>、<em class="calibre13">、</em>的异构集成分类器中，我们在<em class="calibre13">还有更多</em>部分解释了如何使用 Google 协同实验室。</p>
<p class="calibre2">我们将从在 Google Colab 中安装 H2O 开始，如下所示:</p>
<pre class="calibre15"><strong class="calibre1">! pip install h2o</strong></pre>
<p class="calibre2">执行前面的命令将显示一些说明，最后一行显示以下消息(H2O 的版本号将根据可用的最新版本而有所不同):</p>
<pre class="calibre15"><strong class="calibre1">Successfully installed colorama-0.4.1 h2o-3.22.1.2</strong></pre>
<p class="calibre2">我们导入所有需要的库，如下所示:</p>
<pre class="calibre15">import pandas as pd<br class="title-page-name"/>import numpy as np<br class="title-page-name"/><br class="title-page-name"/>from sklearn.model_selection import train_test_split<br class="title-page-name"/>from sklearn.metrics import confusion_matrix, roc_curve, auc<br class="title-page-name"/>from sklearn import tree<br class="title-page-name"/><br class="title-page-name"/>import h2o<br class="title-page-name"/>from h2o.estimators.glm import H2OGeneralizedLinearEstimator<br class="title-page-name"/>from h2o.estimators.random_forest import H2ORandomForestEstimator<br class="title-page-name"/>from h2o.estimators.gbm import H2OGradientBoostingEstimator<br class="title-page-name"/>from h2o.grid.grid_search import H2OGridSearch<br class="title-page-name"/>from h2o.estimators.stackedensemble import H2OStackedEnsembleEstimator<br class="title-page-name"/><br class="title-page-name"/><br class="title-page-name"/>import seaborn as sns<br class="title-page-name"/>import matplotlib.pyplot as plt<br class="title-page-name"/>%matplotlib inline</pre>
<p class="calibre2">然后我们将初始化 H2O:</p>
<pre class="calibre15"># Initialize H2o<br class="title-page-name"/>h2o.init()</pre>
<p class="calibre2">成功初始化后，我们将看到下面截图中显示的信息。根据环境的不同，此信息可能会有所不同:</p>
<p class="CDPAlignCenter"><img class="aligncenter93" src="img/882ed571-c8ba-4490-a404-f16e26aabade.png"/></p>
<p class="calibre2">我们将从 Google Drive 中读取数据集。为此，我们首先需要安装驱动器:</p>
<pre class="calibre15">from google.colab import drive<br class="title-page-name"/>drive.mount('/content/drive')</pre>
<p class="calibre2">它将指示您转到一个 URL 来获取授权码。你需要点击网址，复制授权码，然后粘贴。成功安装后，您可以从 Google Drive 的相应文件夹中读取您的文件:</p>
<pre class="calibre15"># Reading dataset from Google drive<br class="title-page-name"/>df_creditcarddata = h2o.import_file("/content/drive/My Drive/Colab Notebooks/UCI_Credit_Card.csv")</pre>
<p class="calibre2">注意，使用<kbd class="calibre12">h2o.import_file</kbd>，我们创建了<kbd class="calibre12">h2o.frame.H2OFrame</kbd>。这类似于一个<kbd class="calibre12">pandas</kbd>数据框架。然而，在<kbd class="calibre12">pandas</kbd>数据帧的情况下，数据保存在内存中，而在这种情况下，数据位于 H2O 集群上。</p>
<p class="calibre2">你可以在 H2O 数据框架上运行类似的方法，就像你可以在熊猫上运行一样。例如，为了查看数据帧中的前 10 个观察值，可以使用以下命令:</p>
<pre class="calibre15">df_creditcarddata.head()</pre>
<p class="calibre2">要检查数据帧的尺寸，我们使用以下命令:</p>
<pre class="calibre15">df_creditcarddata.shape</pre>
<p class="calibre2">为了查看所有列名，我们运行以下语法:</p>
<pre class="calibre15">df_creditcarddata.columns</pre>
<p class="calibre2">在<kbd class="calibre12">pandas</kbd>数据框架中，我们使用<kbd class="calibre12">dtypes</kbd>来查看每一列的数据类型。在 H2o 数据框架中，我们将使用以下内容:</p>
<pre class="calibre15">df_creditcarddata.types</pre>
<p class="calibre2">这为我们提供了以下输出。注意分类变量显示为<kbd class="calibre12">'enum'</kbd>:</p>
<p class="CDPAlignCenter"><img class="aligncenter94" src="img/937331c5-ec80-4367-add7-ab7fd1c2be27.png"/></p>
<p class="calibre2">数据集中有我们的目标变量<kbd class="calibre12">default.payment.next.month</kbd>。这将告诉我们哪些客户已经或尚未拖欠付款。我们希望看到违约者和非违约者的分布情况:</p>
<pre class="calibre15">df_creditcarddata['default.payment.next.month'].table()</pre>
<p class="calibre2">这给了我们<kbd class="calibre12">default.payment.next.month</kbd>变量中每个类的计数:</p>
<p class="CDPAlignCenter"><img class="aligncenter95" src="img/4a2cdc5f-076e-4b13-bf8e-c0ef7bc4b80d.png"/></p>
<p class="calibre2">我们不需要<kbd class="calibre12">ID</kbd>列进行预测建模，所以我们将它从数据框架中移除:</p>
<pre class="calibre15">df_creditcarddata = df_creditcarddata.drop(["ID"], axis = 1) </pre>
<p class="calibre2">我们可以使用<kbd class="calibre12">hist()</kbd>方法查看数值变量的分布:</p>
<pre class="calibre15">import pylab as pl<br class="title-page-name"/>df_creditcarddata[['AGE','BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6', 'LIMIT_BAL']].as_data_frame().hist(figsize=(20,20))<br class="title-page-name"/>pl.show()</pre>
<p class="calibre2">下面的截图向我们展示了绘制的变量。这可以帮助我们分析每个变量:</p>
<p class="CDPAlignCenter"><img class="aligncenter96" src="img/23b6773e-bf76-460b-9529-95a123315127.png"/></p>
<p class="calibre2">为了扩展我们的分析，我们可以看到违约者和非违约者在性别、教育和婚姻状况方面的分布情况:</p>
<pre class="calibre15"># Defaulters by Gender<br class="title-page-name"/>columns = ["default.payment.next.month","SEX"]<br class="title-page-name"/>default_by_gender = df_creditcarddata.group_by(by=columns).count(na ="all")<br class="title-page-name"/>print(default_by_gender.get_frame())<br class="title-page-name"/><br class="title-page-name"/># Defaulters by education<br class="title-page-name"/>columns = ["default.payment.next.month","EDUCATION"]<br class="title-page-name"/>default_by_education = df_creditcarddata.group_by(by=columns).count(na ="all")<br class="title-page-name"/>print(default_by_education.get_frame())<br class="title-page-name"/><br class="title-page-name"/># Defaulters by MARRIAGE<br class="title-page-name"/>columns = ["default.payment.next.month","MARRIAGE"]<br class="title-page-name"/>default_by_marriage = df_creditcarddata.group_by(by=columns).count(na ="all")<br class="title-page-name"/>print(default_by_marriage.get_frame())</pre>
<p class="calibre2">在下面的截图中，我们可以看到不同类别的违约者的分布情况:</p>
<p class="CDPAlignCenter"><img class="aligncenter97" src="img/6bae3882-f108-4d74-8219-38c232dbe93f.png"/></p>
<p class="calibre2">我们现在将分类变量转换成因子:</p>
<pre class="calibre15"><strong class="calibre1"># Convert the categorical variables into factors</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">df_creditcarddata['SEX'] = df_creditcarddata['SEX'].asfactor()</strong><br class="title-page-name"/><strong class="calibre1">df_creditcarddata['EDUCATION'] = df_creditcarddata['EDUCATION'].asfactor()</strong><br class="title-page-name"/><strong class="calibre1">df_creditcarddata['MARRIAGE'] = df_creditcarddata['MARRIAGE'].asfactor()</strong><br class="title-page-name"/><strong class="calibre1">df_creditcarddata['PAY_0'] = df_creditcarddata['PAY_0'].asfactor()</strong><br class="title-page-name"/><strong class="calibre1">df_creditcarddata['PAY_2'] = df_creditcarddata['PAY_2'].asfactor()</strong><br class="title-page-name"/><strong class="calibre1">df_creditcarddata['PAY_3'] = df_creditcarddata['PAY_3'].asfactor()</strong><br class="title-page-name"/><strong class="calibre1">df_creditcarddata['PAY_4'] = df_creditcarddata['PAY_4'].asfactor()</strong><br class="title-page-name"/><strong class="calibre1">df_creditcarddata['PAY_5'] = df_creditcarddata['PAY_5'].asfactor()</strong><br class="title-page-name"/><strong class="calibre1">df_creditcarddata['PAY_6'] = df_creditcarddata['PAY_6'].asfactor()</strong></pre>
<p class="calibre2">我们还将二分目标变量<kbd class="calibre12">default.payment.next.month</kbd>编码为因子变量。转换后，我们用<kbd class="calibre12">levels()</kbd>方法检查目标变量的类:</p>
<pre class="calibre15"><strong class="calibre1"># Also, encode the binary response variable as a factor</strong><br class="title-page-name"/><strong class="calibre1">df_creditcarddata['default.payment.next.month'] = df_creditcarddata['default.payment.next.month'].asfactor() </strong><br class="title-page-name"/><strong class="calibre1">df_creditcarddata['default.payment.next.month'].levels()</strong></pre>
<p class="calibre2">然后，我们将定义预测变量和目标变量:</p>
<pre class="calibre15"><strong class="calibre1"># Define predictors manually</strong><br class="title-page-name"/><strong class="calibre1">predictors = ['LIMIT_BAL','SEX','EDUCATION','MARRIAGE','AGE','PAY_0','PAY_2','PAY_3',\</strong><br class="title-page-name"/><strong class="calibre1"> 'PAY_4','PAY_5','PAY_6','BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4',\</strong><br class="title-page-name"/><strong class="calibre1"> 'BILL_AMT5','BILL_AMT6','PAY_AMT1','PAY_AMT2','PAY_AMT3','PAY_AMT4','PAY_AMT5','PAY_AMT6']</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">target = 'default.payment.next.month'</strong></pre>
<p class="calibre2">然后，我们使用<kbd class="calibre12">split_frame()</kbd>方法分割数据帧:</p>
<pre class="calibre15"><strong class="calibre1">splits = df_creditcarddata.split_frame(ratios=[0.7], seed=1)</strong> </pre>
<p class="calibre2">下面的代码给出了两个分割输出:</p>
<pre class="calibre15"><strong class="calibre1">splits</strong></pre>
<p class="calibre2">在下面的屏幕截图中，我们可以看到以下两个分割:</p>
<p class="CDPAlignCenter"><img class="aligncenter98" src="img/0c3138ad-28b8-46f5-b7d6-9d1ef46803f4.png"/></p>
<p class="calibre2">我们将分割分为训练和测试子集:</p>
<pre class="calibre15">train = splits[0]<br class="title-page-name"/>test = splits[1] </pre>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>How to do it...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">怎么做...</h1>
                
            
            
                
<p class="calibre2">让我们继续使用本章前面提到的算法来训练我们的模型。我们将从训练我们的<strong class="calibre4">广义线性模型</strong> ( <strong class="calibre4"> GLM </strong>)模型开始。我们将建立三个 GLM 模型:</p>
<ul class="calibre10">
<li class="calibre11">具有参数默认值的 GLM 模型</li>
<li class="calibre11">具有λ搜索(正则化)的 GLM 模型</li>
<li class="calibre11">网格搜索下的 GLM 模型</li>
</ul>
<p class="calibre2">现在，我们将在下一节开始训练我们的模型。</p>
<ol class="calibre14">
<li class="calibre11">让我们训练我们的第一个模型:</li>
</ol>
<pre class="calibre18">GLM_default_settings = H2OGeneralizedLinearEstimator(family='binomial', \<br class="title-page-name"/>                                            model_id='GLM_default',nfolds = 10, \<br class="title-page-name"/>                                            fold_assignment = "Modulo", \<br class="title-page-name"/>                                            keep_cross_validation_predictions = True)</pre>
<p class="calibre20"><kbd class="calibre12">H2OGeneralizedLinearEstimator</kbd>符合广义线性模型。它接受一个响应变量和一组预测变量。</p>
<p class="calibre20"><kbd class="calibre12">H2OGeneralizedLinearEstimator</kbd>可以处理回归和分类任务。在回归问题的情况下，它返回一个<kbd class="calibre12">H2ORegressionModel</kbd>子类，而对于分类，它返回一个<kbd class="calibre12">H2OBinomialModel</kbd>子类。</p>
<ol start="2" class="calibre14">
<li class="calibre11">我们在<em class="calibre23">准备就绪</em>部分创建了预测变量和目标变量。将预测值和目标变量传递给模型:</li>
</ol>
<pre class="calibre18">GLM_default_settings.train(x = predictors, y = target, training_frame = train)</pre>
<ol start="3" class="calibre14">
<li class="calibre11">使用<kbd class="calibre12">lambda_search</kbd>参数训练 GLM 模型:</li>
</ol>
<pre class="calibre18">GLM_regularized = H2OGeneralizedLinearEstimator(family='binomial', model_id='GLM', \<br class="title-page-name"/>                                                lambda_search=True, nfolds = 10, \<br class="title-page-name"/>                                                fold_assignment = "Modulo", \<br class="title-page-name"/>                                                keep_cross_validation_predictions = True)<br class="title-page-name"/><br class="title-page-name"/>GLM_regularized.train(x = predictors, y = target, training_frame = train)</pre>
<p class="calibre20"><kbd class="calibre12">lambda_search</kbd>帮助 GLM 找到最佳正则化参数λ。<kbd class="calibre12">lambda_search</kbd>参数接受一个布尔值。当设置为<kbd class="calibre12">True</kbd>时，GLM 将首先拟合具有最高 lambda 值的模型，这被称为<strong class="calibre4">最大正则化</strong>。然后，它在每一步减少这个值，直到它达到最小λ。最终的最佳模型基于最佳λ值。</p>
<ol start="4" class="calibre14">
<li class="calibre11">使用带网格搜索的 GLM 训练模型:</li>
</ol>
<pre class="calibre18">hyper_parameters = { 'alpha': [0.001, 0.01, 0.05, 0.1, 1.0],<br class="title-page-name"/>                     'lambda': [0.001, 0.01, 0.1, 1] }<br class="title-page-name"/>search_criteria = { 'strategy': "RandomDiscrete", 'seed': 1,<br class="title-page-name"/>                    'stopping_metric': "AUTO",<br class="title-page-name"/>                    'stopping_rounds': 5 }<br class="title-page-name"/><br class="title-page-name"/>GLM_grid_search = H2OGridSearch(H2OGeneralizedLinearEstimator(family='binomial', \<br class="title-page-name"/>                  nfolds = 10, fold_assignment = "Modulo", \<br class="title-page-name"/>                  keep_cross_validation_predictions = True),\<br class="title-page-name"/>                  hyper_parameters, grid_id="GLM_grid", search_criteria=search_criteria)<br class="title-page-name"/><br class="title-page-name"/>GLM_grid_search.train(x= predictors,y= target, training_frame=train)</pre>
<ol start="5" class="calibre14">
<li class="calibre11">我们用<kbd class="calibre12">get_grid()</kbd>方法得到按<kbd class="calibre12">auc</kbd>值排序的网格结果:</li>
</ol>
<pre class="calibre18"># Get the grid results, sorted by validation AUC<br class="title-page-name"/>GLM_grid_sorted = GLM_grid_search.get_grid(sort_by='auc', decreasing=True)<br class="title-page-name"/>GLM_grid_sorted</pre>
<p class="calibre20">在下面的截图中，我们可以看到每个型号的<kbd class="calibre12">auc</kbd>分数，它由<kbd class="calibre12">alpha</kbd>和<kbd class="calibre12">lambda</kbd>参数的不同组合组成:</p>
<p class="CDPAlignCenter"><img class="aligncenter99" src="img/f4209530-ce0e-440d-ab7a-85f54f11e2e6.png"/></p>
<ol start="6" class="calibre14">
<li class="calibre11">我们可以在我们的训练数据和交叉验证数据上看到模型指标:</li>
</ol>
<pre class="calibre18"># Extract the best model from random grid search<br class="title-page-name"/>Best_GLM_model_from_Grid = GLM_grid_sorted.model_ids[0]<br class="title-page-name"/><br class="title-page-name"/># model performance<br class="title-page-name"/>Best_GLM_model_from_Grid = h2o.get_model(Best_GLM_model_from_Grid)<br class="title-page-name"/>print(Best_GLM_model_from_Grid)</pre>
<p class="calibre20">从前面的代码块中，您可以评估模型度量，包括<kbd class="calibre12">MSE</kbd>、<kbd class="calibre12">RMSE</kbd>、<kbd class="calibre12">Null</kbd>和<kbd class="calibre12">Residual Deviance</kbd>、<kbd class="calibre12">AUC</kbd>和<kbd class="calibre12">Gini</kbd>，以及<kbd class="calibre12">Confusion Matrix</kbd>。在稍后的阶段，我们将使用网格搜索中的最佳模型来构建堆叠系综。</p>
<p class="calibre20">让我们看下图并评估模型指标:</p>
<p class="CDPAlignCenter"><img class="aligncenter100" src="img/f2e1b50c-c083-4d8c-a17b-37ff57893a35.png"/></p>
<ol start="7" class="calibre14">
<li class="calibre11">使用随机森林训练模型。使用默认设置的随机森林的代码如下所示:</li>
</ol>
<pre class="calibre18"># Build a RF model with default settings<br class="title-page-name"/>RF_default_settings = H2ORandomForestEstimator(model_id = 'RF_D',\<br class="title-page-name"/>                                nfolds = 10, fold_assignment = "Modulo", \<br class="title-page-name"/>                                keep_cross_validation_predictions = True)<br class="title-page-name"/><br class="title-page-name"/># Use train() to build the model<br class="title-page-name"/>RF_default_settings.train(x = predictors, y = target, training_frame = train)</pre>
<ol start="8" class="calibre14">
<li class="calibre11">要获得模型的汇总输出，请使用以下代码:</li>
</ol>
<pre class="calibre18">RF_default_settings.summary()</pre>
<ol start="9" class="calibre14">
<li class="calibre11">使用网格搜索训练随机森林模型。如下面的代码块所示设置超参数:</li>
</ol>
<pre class="calibre18">hyper_params = {'sample_rate':[0.7, 0.9],<br class="title-page-name"/>                'col_sample_rate_per_tree': [0.8, 0.9],<br class="title-page-name"/>                'max_depth': [3, 5, 9],<br class="title-page-name"/>                'ntrees': [200, 300, 400]<br class="title-page-name"/>               }</pre>
<ol start="10" class="calibre14">
<li class="calibre11">使用<kbd class="calibre12">H2OGridSearch()</kbd>上的超参数通过<kbd class="calibre12">gridsearch</kbd>训练<kbd class="calibre12">RF</kbd>模型:</li>
</ol>
<pre class="calibre18">RF_grid_search = H2OGridSearch(H2ORandomForestEstimator(nfolds = 10, \<br class="title-page-name"/>                             fold_assignment = "Modulo", \<br class="title-page-name"/>                             keep_cross_validation_predictions = True, \<br class="title-page-name"/>                             stopping_metric = 'AUC',stopping_rounds = 5), \<br class="title-page-name"/>                             hyper_params = hyper_params, \<br class="title-page-name"/>                             grid_id= 'RF_gridsearch')<br class="title-page-name"/><br class="title-page-name"/># Use train() to start the grid search<br class="title-page-name"/>RF_grid_search.train(x = predictors, y = target, training_frame = train)</pre>
<ol start="11" class="calibre14">
<li class="calibre11">按 AUC 分数对结果进行排序，以查看哪个模型表现最佳:</li>
</ol>
<pre class="calibre18"># Sort the grid models<br class="title-page-name"/>RF_grid_sorted = RF_grid_search.get_grid(sort_by='auc', decreasing=True)<br class="title-page-name"/>print(RF_grid_sorted)</pre>
<ol start="12" class="calibre14">
<li class="calibre11">从网格搜索结果中提取最佳模型:</li>
</ol>
<pre class="calibre18">Best_RF_model_from_Grid = RF_grid_sorted.model_ids[0]<br class="title-page-name"/><br class="title-page-name"/># Model performance<br class="title-page-name"/>Best_RF_model_from_Grid = h2o.get_model(Best_RF_model_from_Grid) <br class="title-page-name"/>print(Best_RF_model_from_Grid)</pre>
<p class="calibre20">在下面的屏幕截图中，我们看到了培训数据和交叉验证数据上的网格模型的模型指标:</p>
<p class="CDPAlignCenter"><img class="aligncenter101" src="img/960c92f8-db18-427d-a08a-ee1a3750b8d7.png"/></p>
<ol start="13" class="calibre14">
<li class="calibre11">使用 GBM 训练模型。以下是使用默认设置训练 GBM 的方法:</li>
</ol>
<pre class="calibre18">GBM_default_settings = H2OGradientBoostingEstimator(model_id = 'GBM_default', \<br class="title-page-name"/>                       nfolds = 10, \<br class="title-page-name"/>                       fold_assignment = "Modulo", \<br class="title-page-name"/>                       keep_cross_validation_predictions = True)<br class="title-page-name"/><br class="title-page-name"/># Use train() to build the model<br class="title-page-name"/>GBM_default_settings.train(x = predictors, y = target, training_frame = train)</pre>
<ol start="14" class="calibre14">
<li class="calibre11">
<p class="calibre2">在 GBM 上使用网格搜索。要执行网格搜索，请按如下方式设置超参数:</p>
</li>
</ol>
<pre class="calibre18">hyper_params = {'learn_rate': [0.001,0.01, 0.1],<br class="title-page-name"/>                'sample_rate': [0.8, 0.9],<br class="title-page-name"/>                'col_sample_rate': [0.2, 0.5, 1],<br class="title-page-name"/>                'max_depth': [3, 5, 9]}</pre>
<ol start="15" class="calibre14">
<li class="calibre11">使用<kbd class="calibre12">H2OGridSearch()</kbd>上的超参数，通过网格搜索训练 GBM 模型:</li>
</ol>
<pre class="calibre18">GBM_grid_search = H2OGridSearch(H2OGradientBoostingEstimator(nfolds = 10, \<br class="title-page-name"/>                        fold_assignment = "Modulo", \<br class="title-page-name"/>                        keep_cross_validation_predictions = True,\<br class="title-page-name"/>                        stopping_metric = 'AUC', stopping_rounds = 5),<br class="title-page-name"/>                        hyper_params = hyper_params, grid_id= 'GBM_Grid')<br class="title-page-name"/><br class="title-page-name"/># Use train() to start the grid search<br class="title-page-name"/>GBM_grid_search.train(x = predictors, y = target, training_frame = train)</pre>
<ol start="16" class="calibre14">
<li class="calibre11">与早期模型一样，我们可以查看按 AUC 排序的结果:</li>
</ol>
<pre class="calibre18"># Sort and show the grid search results<br class="title-page-name"/>GBM_grid_sorted = GBM_grid_search.get_grid(sort_by='auc', decreasing=True)<br class="title-page-name"/>print(GBM_grid_sorted)</pre>
<ol start="17" class="calibre14">
<li class="calibre11">从网格搜索中提取最佳模型:</li>
</ol>
<pre class="calibre18">Best_GBM_model_from_Grid = GBM_grid_sorted.model_ids[0]<br class="title-page-name"/><br class="title-page-name"/>Best_GBM_model_from_Grid = h2o.get_model(Best_GBM_model_from_Grid) <br class="title-page-name"/>print(Best_GBM_model_from_Grid)</pre>
<p class="calibre20">我们可以使用<kbd class="calibre12">H2OStackedEnsembleEstimator</kbd>构建一个堆叠集合 ML 模型，该模型可以使用我们使用 H2O 算法构建的模型来提高预测性能。<kbd class="calibre12">H2OStackedEnsembleEstimator</kbd>帮助我们找到一组预测算法的最佳组合。</p>
<ol start="18" class="calibre14">
<li class="calibre11">从我们使用网格搜索构建的早期模型中创建一个最佳模型列表:</li>
</ol>
<pre class="calibre18"># list the best models from each grid<br class="title-page-name"/>all_models = [Best_GLM_model_from_Grid, Best_RF_model_from_Grid, Best_GBM_model_from_Grid]</pre>
<ol start="19" class="calibre14">
<li class="calibre11">使用<kbd class="calibre12">H2OStackedEnsembleEstimator</kbd>设置堆叠集合模型:</li>
</ol>
<pre class="calibre18"># Set up Stacked Ensemble<br class="title-page-name"/>ensemble = H2OStackedEnsembleEstimator(model_id = "ensemble", base_models = all_models, metalearner_algorithm = "deeplearning")<br class="title-page-name"/><br class="title-page-name"/># uses GLM as the default metalearner<br class="title-page-name"/>ensemble.train(y = target, training_frame = train)</pre>
<ol start="20" class="calibre14">
<li class="calibre11">根据测试数据评估整体性能:</li>
</ol>
<pre class="calibre18"># Eval ensemble performance on the test data
Ens_model = ensemble.model_performance(test)<br class="title-page-name"/>Ens_AUC = Ens_model.auc()</pre>
<div><div><ol start="21" class="calibre14">
<li class="calibre11">比较基础学员在<kbd class="calibre12">test</kbd>数据上的表现。以下代码测试了我们构建的所有 GLM 模型的模型性能:</li>
</ol>
</div>
</div>
<pre class="calibre18"># Checking the model performance for all GLM models built<br class="title-page-name"/>model_perf_GLM_default = GLM_default_settings.model_performance(test)<br class="title-page-name"/>model_perf_GLM_regularized = GLM_regularized.model_performance(test)<br class="title-page-name"/>model_perf_Best_GLM_model_from_Grid = Best_GLM_model_from_Grid.model_performance(test)</pre>
<div><div><div><p class="calibre20">以下代码测试了我们构建的所有随机森林模型的模型性能:</p>
<pre class="calibre18"># Checking the model performance for all RF models built<br class="title-page-name"/>model_perf_RF_default_settings = RF_default_settings.model_performance(test)<br class="title-page-name"/>model_perf_Best_RF_model_from_Grid = Best_RF_model_from_Grid.model_performance(test)</pre></div>
</div>
</div>
<p class="calibre20">以下代码测试了我们构建的所有 GBM 模型的模型性能:</p>
<pre class="calibre18"># Checking the model performance for all GBM models built<br class="title-page-name"/>model_perf_GBM_default_settings = GBM_default_settings.model_performance(test)<br class="title-page-name"/>model_perf_Best_GBM_model_from_Grid = Best_GBM_model_from_Grid.model_performance(test)</pre>
<div><ol start="22" class="calibre14">
<li class="calibre11">要从基础学员那里获得最佳 AUC，请执行以下命令:</li>
</ol>
<pre class="calibre18"># Best AUC from the base learner models<br class="title-page-name"/>best_auc = max(model_perf_GLM_default.auc(), model_perf_GLM_regularized.auc(), \<br class="title-page-name"/> model_perf_Best_GLM_model_from_Grid.auc(), \<br class="title-page-name"/> model_perf_RF_default_settings.auc(), \<br class="title-page-name"/> model_perf_Best_RF_model_from_Grid.auc(), \<br class="title-page-name"/> model_perf_GBM_default_settings.auc(), \<br class="title-page-name"/> model_perf_Best_GBM_model_from_Grid.auc())<br class="title-page-name"/><br class="title-page-name"/>print("Best AUC out of all the models performed: ", format(best_auc))</pre>
<ol start="23" class="calibre14">
<li class="calibre11">以下命令显示堆叠系综模型的 AUC:</li>
</ol>
<pre class="calibre18"># Eval ensemble performance on the test data<br class="title-page-name"/>Ensemble_model = ensemble.model_performance(test)<br class="title-page-name"/>Ensemble_model = Ensemble_model.auc()</pre></div>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>How it works...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">它是如何工作的...</h1>
                
            
            
                
<p class="calibre2">我们使用 Google Colab 来训练我们的模型。在 Google Colab 中安装了 H2O 之后，我们初始化了 H2O 实例。我们还导入了所需的库。</p>
<p class="calibre2">为了使用 H2O 的库，我们从<kbd class="calibre12">h2o.estimators</kbd>引入了<kbd class="calibre12">H2OGeneralizedLinearEstimator</kbd>、<kbd class="calibre12">H2ORandomForestEstimator</kbd>和<kbd class="calibre12">H2OGradientBoostingEstimator</kbd>。我们还导入了<kbd class="calibre12">H2OStackedEnsembleEstimator</kbd>来使用堆叠集合训练我们的模型。</p>
<p class="calibre2">我们安装了 Google Drive 并使用<kbd class="calibre12">h2o.import_file()</kbd>读取数据集。这创建了一个 H2O 数据帧，它非常类似于一个<kbd class="calibre12">pandas</kbd>数据帧。但是，数据不是保存在内存中，而是位于一个远程 H2O 集群中。</p>
<p class="calibre2">然后，我们在 H2O 数据框架上执行基本操作来分析我们的数据。我们看了一下维度、前几行和每列的数据类型。<kbd class="calibre12">shape</kbd>属性返回了一个包含行数和列数的元组。<kbd class="calibre12">head()</kbd>方法返回前 10 个观察值。<kbd class="calibre12">types</kbd>属性返回每一列的数据类型。</p>
<p>注意，H2O 数据帧中的分类变量被标记为<kbd class="calibre19">enum</kbd>。</p>
<p class="calibre2">我们的目标变量是<kbd class="calibre12">default.payment.next.month</kbd>。使用<kbd class="calibre12">table()</kbd>方法，我们看到了目标变量的两个类的分布。在这种情况下，<kbd class="calibre12">table()</kbd>方法返回了类<kbd class="calibre12">1</kbd>和<kbd class="calibre12">0</kbd>的计数。</p>
<p class="calibre2">我们不需要<kbd class="calibre12">ID</kbd>列，所以我们使用带有<kbd class="calibre12">axis=1</kbd>作为参数的<kbd class="calibre12">drop()</kbd>方法删除了它。使用<kbd class="calibre12">axis=1</kbd>，它删除了列。否则，<kbd class="calibre12">axis=0</kbd>的默认值将从索引中删除标签。</p>
<p class="calibre2">我们分析了数字变量的分布。您可以无限探索您的数据。我们还看到了我们的目标变量的两个类别在不同类别中的分布，如性别、教育和婚姻。</p>
<p class="calibre2">然后，我们用<kbd class="calibre12">asfactor()</kbd>方法将分类变量转换成因子类型。对目标变量也是如此。</p>
<p class="calibre2">我们创建了一个预测变量和目标变量的列表。我们用<kbd class="calibre12">split_frame()</kbd>方法将数据帧分成训练和测试子集。</p>
<p>我们将比率传递给<kbd class="calibre19">split_frame()</kbd>方法。在我们的例子中，我们将数据集分成 70%和 30%。但是，请注意，这并没有给出 70%-30%的精确划分。H2O 使用概率分割方法，而不是使用精确的比率来分割数据集。这是为了在大数据上提高拆分效率。</p>
<p class="calibre2">在我们将数据集分成训练和测试子集之后，我们继续训练我们的模型。我们使用 GLM、随机森林、一台<strong class="calibre4">梯度提升机</strong> ( <strong class="calibre4"> GBM </strong>)和堆叠系综来训练堆叠模型。</p>
<p class="calibre2">在<em class="calibre13">怎么做...</em>部分，在<em class="calibre13">步骤 1 </em>和<em class="calibre13">步骤 2 </em>中，我们展示了使用默认设置训练 GLM 模型的代码。我们使用交叉验证来训练我们的模型。</p>
<p class="calibre2">在<em class="calibre13">步骤 3 </em>中，我们用<kbd class="calibre12">lambda_search</kbd>训练了一个 GLM 模型，这有助于找到最优的正则化参数。</p>
<p class="calibre2">在<em class="calibre13">步骤 4 </em>中，我们使用网格搜索参数来训练我们的 GLM 模型。我们设置了超参数，并将其提供给<kbd class="calibre12">H2OGridSearch()</kbd>方法。这有助于我们跨模型搜索最佳参数。在<kbd class="calibre12">H2OGridSearch()</kbd>方法中，我们使用了<kbd class="calibre12">RandomDiscrete</kbd>搜索标准策略。</p>
<p>默认的搜索标准策略是笛卡尔的，它覆盖了超参数组合的整个空间。随机离散策略对所提供的超参数的所有组合进行随机搜索。</p>
<p class="calibre2">在<em class="calibre13">步骤 5 </em>中，使用<kbd class="calibre12">get_grid()</kbd>方法，我们查看了使用所提供参数的不同组合构建的每个模型的 AUC 分数。在<em class="calibre13">步骤 6 </em>中，我们从随机网格搜索中提取了<kbd class="calibre12">best</kbd>模型。我们还可以在最佳模型上使用<kbd class="calibre12">print()</kbd>方法，查看训练数据和交叉验证数据上的模型性能指标。</p>
<p class="calibre2">在<em class="calibre13">步骤 7 </em>中，我们使用默认设置训练了一个随机森林模型，并查看了步骤 8 中生成的模型的摘要。在<em class="calibre13">步骤 9 </em>和<em class="calibre13">步骤 10 </em>中，我们展示了使用网格搜索训练随机森林模型的代码。我们为各种可接受的超参数设置多个值，如<kbd class="calibre12">sample_rate</kbd>、<kbd class="calibre12">col_sample_rate_per_tree</kbd>、<kbd class="calibre12">max_depth</kbd>和<kbd class="calibre12">ntrees</kbd>。<kbd class="calibre12">sample_rate</kbd>指不替换的行抽样。它取值在<kbd class="calibre12">0</kbd>和<kbd class="calibre12">1</kbd>之间，表示数据的采样百分比。<kbd class="calibre12">col_sample_rate_per_tree</kbd>是对每棵树进行无替换的列采样。<kbd class="calibre12">max_depth</kbd>设置为指定每棵树应建造的最大深度。较深的树可能在训练数据上表现得更好，但是将花费更多的计算时间，并且可能过度拟合，并且不能对看不见的数据进行归纳。<kbd class="calibre12">ntrees</kbd>参数用于基于树的算法，指定在模型上构建的树的数量。</p>
<p class="calibre2">在<em class="calibre13">步骤 11 </em>和<em class="calibre13">步骤 12 </em>中，我们打印了网格搜索生成的每个模型的 AUC 分数，并从中提取了最佳模型。</p>
<p class="calibre2">我们还训练了 GBM 模型来适应我们的数据。在<em class="calibre13">步骤 13 </em>中，我们使用默认设置构建了 GBM。在<em class="calibre13">步骤 14 </em>中，我们为网格搜索设置超参数空间。我们在<em class="calibre13">步骤 15 </em>中使用了这个，在那里我们培训了我们的 GBM。在 GBM 中，我们为超参数设置值，如<kbd class="calibre12">learn_rate</kbd>、<kbd class="calibre12">sample_rate</kbd>、<kbd class="calibre12">col_sample_rate</kbd>、<kbd class="calibre12">max_depth</kbd>和<kbd class="calibre12">ntrees</kbd>。<kbd class="calibre12">learn_rate</kbd>参数用于指定 GBM 算法训练模型的速率。<kbd class="calibre12">learn_rate</kbd>参数值越低越好，有助于避免过拟合，但计算时间会很长。</p>
<p>在 H2O，<kbd class="calibre19">learn_rate</kbd>有 GBM 和 XGBoost 两种型号。</p>
<p class="calibre2"><em class="calibre13">第 16 步</em>向我们展示了网格搜索得到的每个模型的 AUC 分数。我们在<em class="calibre13">步骤 17 </em>中提取了最佳网格搜索 GBM。</p>
<p class="calibre2">在<em class="calibre13">步骤 18 </em>到<em class="calibre13">步骤 20 </em>中，我们使用来自 H2O 的<kbd class="calibre12">H2OStackedEnsembleEstimator</kbd>来训练我们的堆叠系综模型。我们根据测试数据评估了最终模型的性能。</p>
<p class="calibre2">在第 21 步中，我们评估了根据测试数据构建的所有 GLM 模型。我们对使用 RF 和 GBM 训练的所有模型进行了同样的操作。<em xmlns:epub="http://www.idpf.org/2007/ops" class="calibre13">第 22 步</em>给出了具有最大 AUC 分数的模型。在<em xmlns:epub="http://www.idpf.org/2007/ops" class="calibre13">步骤 23 </em>中，我们评估了测试数据上堆叠集成模型的 AUC 分数，以便比较堆叠集成模型与单个基础学习者的性能。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>There's more...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">还有更多...</h1>
                
            
            
                
<p class="calibre2">请注意，我们使用交叉验证来训练我们所有的模型。我们使用了<kbd class="calibre12">nfolds</kbd>选项来设置用于交叉验证的折叠数。在我们的例子中，我们使用了<kbd class="calibre12">nfolds=5</kbd>，但是我们也可以将其设置为更高的数字。</p>
<p>在你建立的每个模型中，折叠的数量需要是相同的。</p>
<p class="calibre2">指定了<kbd class="calibre12">nfolds</kbd>的值后，我们还可以为<kbd class="calibre12">fold_assignment</kbd>参数提供一个值。<kbd class="calibre12">fold_assignment</kbd>取<kbd class="calibre12">auto</kbd>、<kbd class="calibre12">random</kbd>、<kbd class="calibre12">modulo</kbd>、<kbd class="calibre12">stratified</kbd>等值。如果我们设置为<kbd class="calibre12">Auto</kbd>，算法自动选择一个选项；目前选择<kbd class="calibre12">Random</kbd>。当<kbd class="calibre12">fold_assignment</kbd>设置为<kbd class="calibre12">Random</kbd>时，它会将数据随机分成<kbd class="calibre12">nfolds</kbd>组。当<kbd class="calibre12">fold_assignment</kbd>被设置为<kbd class="calibre12">Modulo</kbd>时，它使用确定性方法将数据平均分割成不依赖于<kbd class="calibre12">seed</kbd>参数的<kbd class="calibre12">nfolds</kbd>。</p>
<p>当我们使用交叉验证方法构建模型时，确保您为所有模型指定一个<kbd class="calibre19">seed</kbd>值或使用<kbd class="calibre19">fold_assignment="Modulo"</kbd>。</p>
<p class="calibre2">在网格搜索中，我们使用了两个参数:<kbd class="calibre12">stopping_metric</kbd>和<kbd class="calibre12">stopping_rounds</kbd>。这些参数适用于 GBM 和随机森林算法，但不适用于 GLM。<kbd class="calibre12">stopping_metric</kbd>指定在指定提前停止时要考虑的指标，这可以通过将<kbd class="calibre12">stopping_rounds</kbd>设置为大于零的值来实现。</p>
<p class="calibre2">在我们的例子中，我们将<kbd class="calibre12">stopping_metric</kbd>设置为 AUC，将<kbd class="calibre12">stopping_rounds</kbd>设置为 5。这意味着，如果 AUC 在指定的回合数(在我们的例子中是五个回合)内没有改善，算法将在停止进一步训练之前测量 AUC。</p>
<p>如果指定了<kbd class="calibre19">stopping_metric</kbd>，也必须设置<kbd class="calibre19">stopping_rounds</kbd>。当<kbd class="calibre19">stopping_tolerance</kbd>也被设置时，如果模型的<kbd class="calibre19">stopping_metric</kbd>没有提高到<kbd class="calibre19">stopping_tolerance</kbd>值，模型将在达到<kbd class="calibre19">stopping_rounds</kbd>中提到的轮数后停止训练。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>See also</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">请参见</h1>
                
            
            
                
<p class="calibre2">http://docs.h2o.ai/提供 H2O 文档。</p>


            

            
        
    </body>

</html>
</body></html>