<html><head/><body>
<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Boosting Model Performance with Boosting</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">通过增强提高模型性能</h1>
                
            
            
                
<p class="calibre2">在本章中，我们将介绍以下配方:</p>
<ul class="calibre10">
<li class="calibre11">升压简介</li>
<li class="calibre11">使用 scikit-learn 实施 AdaBoost 进行疾病风险预测</li>
<li class="calibre11">使用 scikit-learn 实现疾病风险预测的梯度增强</li>
<li class="calibre11">使用 XGBoost 和 scikit-learn 实现玻璃识别的极端梯度增强</li>
</ul>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Introduction to boosting</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">升压简介</h1>
                
            
            
                
<p class="calibre2">boosting 算法是一种集成技术，它通过将一组弱学习者组合成一个强学习者来帮助提高模型性能和准确性。boosting 背后的思想是，预测器应该从以前的预测器所犯的错误中学习。</p>
<p class="calibre2">升压算法有两个关键特征:</p>
<ul class="calibre10">
<li class="calibre11">首先，它们经历多次迭代</li>
<li class="calibre11">第二，每一次迭代都集中在被之前的迭代错误分类的实例上</li>
</ul>
<p class="calibre2">当一个输入被一个假设错误分类时，它的权重在下一次迭代中被改变，以便下一个假设可以正确分类它。在训练数据上提供更好性能的那些将被给予更大的权重。这个过程通过多次迭代，将弱学习者转化为强学习者的集合，从而提高模型的性能。</p>
<p class="calibre2"/>
<p class="calibre2"/>
<p class="calibre2"/>
<p class="calibre2">在 bagging 中，没有任何引导样本依赖于任何其他引导，因此它们都是并行运行的。升压以顺序方式工作，不涉及自举采样。bagging 和 boosting 都是通过将不同模型的几个估计值合并成一个估计值来减少单个估计值的方差。然而，重要的是要注意，如果单个模型过度拟合，增强不会有很大帮助。如果模型过拟合，装袋将是一个更好的选择。另一方面，boosting 试图减少偏差，而 bagging 很少改善偏差。</p>
<p class="calibre2">本章将介绍<strong class="calibre4">自适应 boosting </strong> ( <strong class="calibre4"> AdaBoost </strong>)、梯度 Boosting、<strong class="calibre4"> e </strong> <strong class="calibre4"> xtreme 梯度 boosting </strong> ( <strong class="calibre4"> XGBoost </strong>)等不同的 Boosting 算法。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Implementing AdaBoost for disease risk prediction using scikit-learn</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">使用 scikit-learn 实施 AdaBoost 进行疾病风险预测</h1>
                
            
            
                
<p class="calibre2">AdaBoost 是最早用于二进制分类的 boosting 算法之一。它是由 Freund 和 Schapire 于 1996 年提出的。此后，在 AdaBoost 的基础上开发了许多其他基于 boosting 的算法。</p>
<div><div><div><div><div><div><div><div><p class="calibre2">自适应增强的另一种变体被称为<strong class="calibre4">AdaBoost-absent</strong>。AdaBoost-absent 允许每个基线分类器在其依赖特征丢失时放弃投票。</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<p class="calibre2">AdaBoost 侧重于将一组弱学习者组合成一个强学习者。AdaBoost 分类器的过程如下:</p>
<ol class="calibre14">
<li class="calibre11">最初，一个简短的决策树分类器适用于数据。决策树只能有一个单独的分支，称为<strong class="calibre1">决策树桩</strong>。评估整体误差。这是第一次迭代。</li>
<li class="calibre11">在第二次迭代中，任何被正确分类的数据将被赋予较低的权重，而被错误分类的类将被赋予较高的权重。</li>
<li class="calibre11">在第三次迭代中，另一个决策树桩将适合数据，并且权重将在下一次迭代中再次改变。</li>
<li class="calibre11">一旦这些迭代结束，在每次迭代中根据错误率自动计算每个分类器的权重，以得到强分类器。</li>
</ol>
<p class="calibre2">以下截图显示了 AdaBoost 的工作原理:</p>
<p class="CDPAlignCenter"><img src="img/659ca5ea-7b32-4ead-9a6f-6c082501bb48.png" class="calibre38"/></p>
<p class="CDPAlignLeft3">该算法背后的概念是将权重分配给训练示例，并选择具有最低加权误差的分类器。最后，它构造一个强分类器作为这些弱学习器的线性组合。</p>
<p class="calibre2">AdaBoost 的一般公式如下:</p>
<p class="CDPAlignCenter"><img class="fm-editor-equation65" src="img/6ad74a62-127d-4778-897c-2841ac0d91e3.png"/></p>
<p class="CDPAlignLeft3">这里，<strong class="calibre4"> F(x) </strong>代表强量词，<strong class="calibre4"> <img class="fm-editor-equation21" src="img/141fe725-e4a9-44d6-93f6-b61bfb296f09.png"/> </strong>代表权重，<strong class="calibre4"> f(x) </strong>代表弱量词。</p>
<p class="calibre2"/>
<p class="calibre2"/>
<div><div><div><p class="calibre2">AdaBoost 分类器采用各种参数。重要的解释如下:</p>
</div>
</div>
</div>
<ul class="calibre10">
<li class="calibre11"><kbd class="calibre12">base_estimator</kbd>:用于训练模型的学习算法。如果没有为此参数提供值，则基本估计值为<kbd class="calibre12">DecisionTreeClassifier (max_depth=1)</kbd>。</li>
<li class="calibre11"><kbd class="calibre12">n_estimators</kbd>:迭代训练的模型数量。</li>
<li class="calibre11"><kbd class="calibre12">learning_rate</kbd> : <strong class="calibre1"> </strong>各模型对权重的贡献。默认情况下，<kbd class="calibre12">learning_rate</kbd>的值为<kbd class="calibre12">1</kbd>。学习率值越低，模型的训练速度越慢，但性能得分可能会更高。</li>
</ul>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Getting ready</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">做好准备</h1>
                
            
            
                
<p class="calibre2">首先，导入<kbd class="calibre12">os</kbd>和<kbd class="calibre12">pandas</kbd>包，并根据您的要求设置您的工作目录:</p>
<pre class="calibre15"># import required packages<br class="title-page-name"/>import os<br class="title-page-name"/>import pandas as pd<br class="title-page-name"/>import numpy as np<br class="title-page-name"/><br class="title-page-name"/>from sklearn.ensemble import AdaBoostClassifier<br class="title-page-name"/>from sklearn.model_selection import GridSearchCV<br class="title-page-name"/>from sklearn.model_selection import train_test_split<br class="title-page-name"/>from sklearn.tree import DecisionTreeClassifier<br class="title-page-name"/><br class="title-page-name"/>from sklearn.metrics import roc_auc_score, roc_curve, auc<br class="title-page-name"/>from sklearn.model_selection import train_test_split<br class="title-page-name"/><br class="title-page-name"/># Set working directory as per your need<br class="title-page-name"/>os.chdir(".../.../Chapter 8")<br class="title-page-name"/>os.getcwd()</pre>
<p class="calibre2">从 GitHub 下载<kbd class="calibre12">breastcancer.csv</kbd>数据集，并将其复制到您的工作目录。读取数据集:</p>
<pre class="calibre15">df_breastcancer = pd.read_csv("breastcancer.csv")</pre>
<p class="calibre2"/>
<p class="calibre2">用<kbd class="calibre12">head()</kbd>函数看一下前几行:</p>
<pre class="calibre15">df_breastcancer.head(5)</pre>
<p class="calibre2">注意，<kbd class="calibre12">diagnosis</kbd>变量有 M 和 B 这样的值，分别代表恶性和良性。我们将对<kbd class="calibre12">diagnosis</kbd>变量执行标签编码，这样我们可以将 M 和 B 值转换成数值。</p>
<p class="calibre2">我们使用<kbd class="calibre12">head()</kbd>来查看变化:</p>
<pre class="calibre15"># import LabelEncoder from sklearn.preprocessing<br class="title-page-name"/>from sklearn.preprocessing import LabelEncoder<br class="title-page-name"/><br class="title-page-name"/>lb = LabelEncoder()<br class="title-page-name"/>df_breastcancer['diagnosis'] =lb.fit_transform(df_breastcancer['diagnosis']) <br class="title-page-name"/>df_breastcancer.head(5)</pre>
<p class="calibre2">然后，我们检查数据集是否有空值:</p>
<pre class="calibre15">df_breastcancer.isnull().sum()</pre>
<p class="calibre2">我们用<kbd class="calibre12">shape()</kbd>检查数据集的形状:</p>
<pre class="calibre15">df_breastcancer.shape</pre>
<p class="calibre2">我们现在将目标和特性集分开。我们还将数据集分成训练和测试子集:</p>
<pre class="calibre15"># Create feature &amp; response variables<br class="title-page-name"/># Drop the response var and id column as it'll not make any sense to the analysis<br class="title-page-name"/>X = df_breastcancer.iloc[:,2:31]<br class="title-page-name"/><br class="title-page-name"/># Target<br class="title-page-name"/>Y = df_breastcancer.iloc[:,0]<br class="title-page-name"/><br class="title-page-name"/># Create train &amp; test sets<br class="title-page-name"/>X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30, random_state=0, stratify= Y)</pre>
<p class="calibre2">现在，我们将继续使用<kbd class="calibre12">AdaBoost</kbd>算法构建我们的模型。</p>
<p>值得注意的是，由于随机分割和其他随机性因素，准确性和 AUC 评分可能会有所不同。</p>
<p class="calibre2"/>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>How to do it...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">怎么做...</h1>
                
            
            
                
<p class="calibre2">我们现在将看看如何使用 AdaBoost 来训练我们的模型:</p>
<ol class="calibre14">
<li class="calibre11">在我们构建第一个<kbd class="calibre12">AdaBoost</kbd>模型之前，让我们使用<kbd class="calibre12">DecisionTreeClassifier</kbd>来训练我们的模型:</li>
</ol>
<pre class="calibre18">dtree = DecisionTreeClassifier(max_depth=3, random_state=0)<br class="title-page-name"/>dtree.fit(X_train, Y_train)</pre>
<ol start="2" class="calibre14">
<li class="calibre11">我们可以用下面的代码在曲线 ( <strong xmlns:epub="http://www.idpf.org/2007/ops" class="calibre1"> AUC </strong>)下看到我们的精度和<strong xmlns:epub="http://www.idpf.org/2007/ops" class="calibre1">面积:</strong></li>
</ol>
<pre class="calibre18"># Mean accuracy<br class="title-page-name"/>print('The mean accuracy is: ',(dtree.score(X_test,Y_test))*100,'%')<br class="title-page-name"/><br class="title-page-name"/>#AUC score<br class="title-page-name"/>y_pred_dtree = dtree.predict_proba(X_test)<br class="title-page-name"/>fpr_dtree, tpr_dtree, thresholds = roc_curve(Y_test, y_pred_dtree[:,1])<br class="title-page-name"/>auc_dtree = auc(fpr_dtree, tpr_dtree)<br class="title-page-name"/>print ('AUC Value: ', auc_dtree)</pre>
<p class="calibre20">我们得到的准确度分数和 AUC 值分别为 91.81%和 0.91。注意，由于随机性，这些值对于不同的用户可能是不同的。</p>
<ol start="3" class="calibre14">
<li class="calibre11">现在，我们将使用 scikit-learn 库构建我们的 AdaBoost 模型。我们将使用<kbd class="calibre12">AdaBoostClassifier</kbd>来构建我们的<kbd class="calibre12">AdaBoost</kbd>模型。<kbd class="calibre12">AdaBoost</kbd>默认使用<kbd class="calibre12">dtree</kbd>作为基本分类器:</li>
</ol>
<pre class="calibre18">AdaBoost = AdaBoostClassifier(n_estimators=100, base_estimator=dtree, learning_rate=0.1, random_state=0)<br class="title-page-name"/>AdaBoost.fit(X_train, Y_train)</pre>
<ol start="4" class="calibre14">
<li class="calibre11">我们根据测试数据检查模型的准确性和 AUC 值:</li>
</ol>
<pre class="calibre18"># Mean accuracy<br class="title-page-name"/>print('The mean accuracy is: ',(AdaBoost.score(X_test,Y_test))*100,'%')<br class="title-page-name"/><br class="title-page-name"/>#AUC score<br class="title-page-name"/>y_pred_adaboost = AdaBoost.predict_proba(X_test)<br class="title-page-name"/>fpr_ab, tpr_ab, thresholds = roc_curve(Y_test, y_pred_adaboost[:,1])<br class="title-page-name"/>auc_adaboost = auc(fpr_ab, tpr_ab)<br class="title-page-name"/>print ('AUC Value: ', auc_adaboost)</pre>
<p class="calibre2"/>
<p class="calibre20">我们注意到，我们得到了 92.82%的准确度分数和 0.97 的 AUC 值。这两个指标都高于我们在<em class="calibre13">步骤 1 </em>中构建的决策树模型。</p>
<ol start="5" class="calibre14">
<li class="calibre11">然后，我们必须微调我们的超参数。我们将<kbd class="calibre12">n_estimators</kbd>设置为<kbd class="calibre12">100</kbd>，将<kbd class="calibre12">learning_rate</kbd>设置为<kbd class="calibre12">0.4</kbd>:</li>
</ol>
<pre class="calibre18"># Tuning the hyperparams<br class="title-page-name"/>AdaBoost_with_tuning = AdaBoostClassifier(n_estimators=100, base_estimator=dtree, learning_rate=0.4, random_state=0)<br class="title-page-name"/>AdaBoost_with_tuning.fit(X_train, Y_train)</pre>
<ol start="6" class="calibre14">
<li class="calibre11">现在，我们将根据测试数据检查新模型的准确性和 AUC 值:</li>
</ol>
<pre class="calibre18"># Mean accuracy<br class="title-page-name"/>print('The mean accuracy is: ',(AdaBoost_with_tuning.score(X_test,Y_test))*100,'%')<br class="title-page-name"/><br class="title-page-name"/>#AUC score<br class="title-page-name"/>y_pred_adaboost_tune = AdaBoost.predict_proba(X_test)<br class="title-page-name"/>fpr_ab_tune, tpr_ab_tune, thresholds = roc_curve(Y_test, y_pred_adaboost_tune[:,1])<br class="title-page-name"/>auc_adaboost_tune = auc(fpr_ab_tune, tpr_ab_tune)<br class="title-page-name"/>print ('AUC Value: ', auc_adaboost_tune)</pre>
<p class="calibre2">我们注意到准确性下降到 92.39%，但是我们得到了 0.98 的改进的 AUC 值。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>How it works...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">它是如何工作的...</h1>
                
            
            
                
<p class="calibre2">在<em class="calibre13">步骤 1 </em>中，我们使用<kbd class="calibre12">DecisionTreeClassifier</kbd>来构建我们的模型。在<em class="calibre13">步骤 2 </em>中，我们注意到我们的平均准确率和 AUC 得分分别为 91.81%和 0.91。我们的目标是使用<kbd class="calibre12">AdaBoost</kbd>算法来改进这一点。</p>
<p class="calibre2">注意，<kbd class="calibre12">AdaBoost</kbd>算法默认使用决策树作为基本分类器。在<em class="calibre13">步骤 3 </em>中，我们使用默认基础学习者<kbd class="calibre12">AdaBoost</kbd>来训练我们的模型。我们将<kbd class="calibre12">n_estimators</kbd>设置为<kbd class="calibre12">100</kbd>，将<kbd class="calibre12">learning_rate</kbd>设置为<kbd class="calibre12">0.1</kbd>。我们在<em class="calibre13">步骤 4 </em>中检查了我们的平均准确度和 AUC 值。我们注意到，我们在平均准确性和 AUC 方面有了相当大的提高，它们分别跃升至 93.57%和 0.977。</p>
<p class="calibre2">在<em class="calibre13">步骤 5 </em>中，我们为我们的<kbd class="calibre12">AdaBoost</kbd>算法微调了一些超参数，该算法使用决策树作为基本分类器。我们将<kbd class="calibre12">n_estimators</kbd>设置为<kbd class="calibre12">100</kbd>，将<kbd class="calibre12">learning_rate</kbd>设置为<kbd class="calibre12">0.4</kbd>。<em class="calibre13">第 6 步</em>给出了我们在<em class="calibre13">第 5 步</em>中构建的模型的精确度和 AUC 值。我们看到准确率下降到 93.56%，AUC 保持在 0.981。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>There's more...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">还有更多...</h1>
                
            
            
                
<p class="calibre2">在这里，我们将展示使用 AdaBoost 训练一个模型，用一个<strong class="calibre4">支持向量机</strong> ( <strong class="calibre4"> SVM </strong>)作为基础学习器。</p>
<p class="calibre2">默认情况下，AdaBoost 使用决策树作为基本学习器。我们也可以使用不同的基础学习者。在下面的例子中，我们使用了一个 SVM 作为我们使用<kbd class="calibre12">AdaBoost</kbd>算法的基础学习器。我们使用<kbd class="calibre12">SVC</kbd>和<kbd class="calibre12">rbf</kbd>作为内核:</p>
<pre class="calibre15">from sklearn.svm import SVC<br class="title-page-name"/><br class="title-page-name"/>Adaboost_with_svc_rbf = AdaBoostClassifier(n_estimators=100, base_estimator=SVC(probability=True, kernel='rbf'), learning_rate=1, random_state=0)<br class="title-page-name"/>Adaboost_with_svc_rbf.fit(X_train, Y_train)</pre>
<p class="calibre2">我们可以使用<strong class="calibre4">支持向量分类器</strong> ( <strong class="calibre4"> SVC </strong>)作为基本学习器来检查我们的 AdaBoost 模型的准确性和 AUC 值:</p>
<pre class="calibre15"># Mean accuracy<br class="title-page-name"/>print('The mean accuracy is: ',(Adaboost_with_svc_rbf.score(X_test,Y_test))*100,'%') <br class="title-page-name"/><br class="title-page-name"/>#AUC score<br class="title-page-name"/>y_pred_svc_rbf = Adaboost_with_svc_rbf.predict_proba(X_test)<br class="title-page-name"/>fpr_svc_rbf, tpr_svc_rbf, thresholds = roc_curve(Y_test, y_pred_svc_rbf[:,1])<br class="title-page-name"/>auc_svc_rbf = auc(fpr_svc_rbf, tpr_svc_rbf)<br class="title-page-name"/>print ('AUC Value: ', auc_svc_rbf)</pre>
<p class="calibre2">我们注意到准确性和 AUC 值分别下降到 62.57 和 0.92。</p>
<p class="calibre2">现在，我们将使用 SVC 重建 AdaBoost 模型。这一次，我们将使用线性内核:</p>
<pre class="calibre15">Adaboost_with_svc_linear =AdaBoostClassifier(n_estimators=100, base_estimator=SVC(probability=True, kernel='linear'), learning_rate=1, random_state=0)<br class="title-page-name"/>Adaboost_with_svc_linear.fit(X_train, Y_train)</pre>
<p class="calibre2">我们现在获得了 90.64%的平均准确度和 0.96 的相当不错的 AUC 值。</p>
<p class="calibre2">我们现在将使用以下代码绘制一个图表来比较每个模型的 AUC 值:</p>
<pre class="calibre15">import matplotlib.pyplot as plt<br class="title-page-name"/>% matplotlib inline<br class="title-page-name"/>plt.figure(figsize=(8,8))<br class="title-page-name"/><br class="title-page-name"/>plt.plot(fpr_dtree, tpr_dtree,label="Model1: Dtree, auc="+str(auc_dtree))<br class="title-page-name"/>plt.plot(fpr_ab, tpr_ab,label="Model2: Adaboost, auc="+str(auc_adaboost))<br class="title-page-name"/>plt.plot(fpr_ab_tune,tpr_ab_tune,label="Model3: Adaboost with Tuning, auc="+str(auc_adaboost_tune))<br class="title-page-name"/>plt.plot(fpr_svc_rbf, tpr_svc_rbf, label="Model4: Adaboost with SVC (RBF Kernel), auc="+str(auc_svc_rbf))<br class="title-page-name"/>plt.plot(fpr_svc_lin, tpr_svc_lin, label="Model5: Adaboost with SVC (Linear Kernel), auc="+str(auc_svc_linear))<br class="title-page-name"/><br class="title-page-name"/>plt.legend(loc=5)<br class="title-page-name"/>plt.show()</pre>
<p class="calibre2">这给了我们以下的情节:</p>
<p class="CDPAlignCenter"><img src="img/ccb24245-d84c-46b3-a7e0-46377e766863.png" class="calibre39"/></p>
<p class="calibre2">我们还可以使用以下代码绘制所有模型的精度:</p>
<pre class="calibre15">import matplotlib.pyplot as plt<br class="title-page-name"/>% matplotlib inline<br class="title-page-name"/>plt.figure(figsize=(8,8))<br class="title-page-name"/><br class="title-page-name"/>label = ['Decison Tree', 'Adaboost', 'Adaboost with Tuning', 'Adaboost with SVC (RBF)', 'Adaboost with SVC (Linear)']<br class="title-page-name"/><br class="title-page-name"/>values = [dtree.score(X_test,Y_test),<br class="title-page-name"/>        AdaBoost.score(X_test,Y_test),<br class="title-page-name"/>        AdaBoost_with_tuning.score(X_test,Y_test),<br class="title-page-name"/>        Adaboost_with_svc_rbf.score(X_test,Y_test),<br class="title-page-name"/>        Adaboost_with_svc_linear.score(X_test,Y_test)]<br class="title-page-name"/><br class="title-page-name"/>def plot_bar_accuracy():<br class="title-page-name"/>    # this is for plotting purpose<br class="title-page-name"/>    index = np.arange(len(label))<br class="title-page-name"/>    plt.bar(index, values)<br class="title-page-name"/>    plt.xlabel('Algorithms', fontsize=10)<br class="title-page-name"/>    plt.ylabel('Accuracy', fontsize=10)<br class="title-page-name"/>    plt.xticks(index, label, fontsize=10, rotation=90)<br class="title-page-name"/>    plt.title('Model Accuracies')<br class="title-page-name"/>    plt.show()<br class="title-page-name"/><br class="title-page-name"/>plot_bar_accuracy()</pre>
<p class="calibre2">这为我们提供了以下输出:</p>
<p class="CDPAlignCenter"><img src="img/3c274f0f-7286-4468-b1a2-07b246aa9cd5.png" class="calibre40"/></p>
<p class="calibre2"/>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>See also</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">请参见</h1>
                
            
            
                
<p class="calibre2">我们还可以将网格搜索与 AdaBoost 结合使用:</p>
<pre class="calibre15">#grid search using svm<br class="title-page-name"/>Adaboost_with_svc = AdaBoostClassifier(n_estimators=100, base_estimator=SVC(probability=True, kernel='linear'), learning_rate=1, algorithm= 'SAMME')<br class="title-page-name"/><br class="title-page-name"/>Ada_Grid = {'n_estimators': [10,30,40,100],<br class="title-page-name"/>           'learning_rate': [0.1, 0.2, 0.3]}<br class="title-page-name"/><br class="title-page-name"/>estimator = Adaboost_with_svc<br class="title-page-name"/>Adaboost_with_grid_search = GridSearchCV(estimator,Ada_Grid).fit(X_train, Y_train)<br class="title-page-name"/>print(Adaboost_with_grid_search.best_params_)<br class="title-page-name"/>print(Adaboost_with_grid_search.best_score_)</pre>
<p class="calibre2">在前面的代码中，我们执行了网格搜索，将<kbd class="calibre12">n_estimators</kbd>设置为<kbd class="calibre12">10</kbd>、<kbd class="calibre12">30</kbd>、<kbd class="calibre12">40</kbd>和<kbd class="calibre12">100</kbd>，将<kbd class="calibre12">learning_rate</kbd>设置为<kbd class="calibre12">0.1</kbd>、<kbd class="calibre12">0.2</kbd>和<kbd class="calibre12">0.3</kbd>。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Implementing a gradient boosting machine for disease risk prediction using scikit-learn</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">使用 scikit-learn 实现用于疾病风险预测的梯度增强机器</h1>
                
            
            
                
<p class="calibre2">梯度增强是一种基于增强原理工作的机器学习技术，其中弱学习器迭代地将他们的注意力转向在先前迭代中难以预测的错误观察，并创建弱学习器的集合，通常是决策树。</p>
<p class="calibre2">梯度增强按顺序训练模型，包括以下步骤:</p>
<ol class="calibre14">
<li class="calibre11">根据数据拟合模型</li>
<li class="calibre11">用残差拟合模型</li>
<li class="calibre11">创建新模型</li>
</ol>
<p class="calibre2">AdaBoost 模型通过使用分配给数据点的权重来识别误差，而梯度增强则通过计算损失函数中的梯度来识别误差。损失函数是模型如何能够拟合其被训练的数据的度量，并且通常取决于被解决的问题的类型。如果我们在讨论回归问题，可以使用均方差，而在分类问题中，可以使用对数损失。梯度下降程序用于在一次添加一棵树时最小化损失。模型中现有的树保持不变。</p>
<p class="calibre2"/>
<p class="calibre2">有一些超参数可以为此进行调整:</p>
<ul class="calibre10">
<li class="front-matter">
 
</li>
</ul>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Getting ready</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">做好准备</h1>
                
            
            
                
<p class="calibre2">我们将采用用于训练 AdaBoost 模型的相同数据集。在这个例子中，我们将看到如何使用梯度推进机器来训练我们的模型。我们还将研究一些超参数，可以通过调整来提高模型的性能。</p>
<p class="calibre2"/>
<p class="calibre2">首先，我们必须导入所有需要的库:</p>
<pre class="calibre15">import os<br class="title-page-name"/>import pandas as pd<br class="title-page-name"/>import numpy as np<br class="title-page-name"/><br class="title-page-name"/>from sklearn.model_selection import train_test_split<br class="title-page-name"/><br class="title-page-name"/>from sklearn.ensemble import GradientBoostingClassifier <br class="title-page-name"/>from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score<br class="title-page-name"/>from sklearn.preprocessing import MinMaxScaler<br class="title-page-name"/><br class="title-page-name"/>import matplotlib.pyplot as plt<br class="title-page-name"/>import itertools</pre>
<p class="calibre2">然后，我们读取数据并将目标变量编码为 1 和 0:</p>
<pre class="calibre15"># Read the Dataset<br class="title-page-name"/>df_breastcancer = pd.read_csv("breastcancer.csv")<br class="title-page-name"/><br class="title-page-name"/>from sklearn.preprocessing import LabelEncoder<br class="title-page-name"/>lb = LabelEncoder()<br class="title-page-name"/>df_breastcancer['diagnosis'] = lb.fit_transform(df_breastcancer['diagnosis']) <br class="title-page-name"/>df_breastcancer.head(5)</pre>
<p class="calibre2">然后，分离我们的目标和特征变量。我们将数据分成训练和测试子集:</p>
<pre class="calibre15"># create feature &amp; response variables<br class="title-page-name"/># drop the response var and id column as it'll not make any sense to the analysis<br class="title-page-name"/>X = df_breastcancer.iloc[:,2:31]<br class="title-page-name"/><br class="title-page-name"/># Target variable<br class="title-page-name"/>Y = df_breastcancer.iloc[:,0]<br class="title-page-name"/><br class="title-page-name"/># Create train &amp; test sets<br class="title-page-name"/>X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=0, stratify= Y)</pre>
<p>这与我们在<kbd class="calibre19">AdaBoost</kbd>示例的<em class="calibre23">准备好</em>部分使用的代码相同。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>How to do it...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">怎么做...</h1>
                
            
            
                
<p class="calibre2">我们现在将看看如何使用梯度推进机器来训练我们的模型:</p>
<ol class="calibre14">
<li class="calibre11">我们在上节<em class="calibre23">准备</em>中从<kbd class="calibre12">sklearn.ensemble</kbd>导入了<kbd class="calibre12">GradientBoostingClassifier</kbd>。我们使用<kbd class="calibre12">GradieBoostingClassfier</kbd>训练我们的模型:</li>
</ol>
<pre class="calibre18">GBM_model = GradientBoostingClassifier() <br class="title-page-name"/>GBM_model.fit(X_train, Y_train)</pre>
<ol start="2" class="calibre14">
<li class="calibre11">这里，我们必须将测试数据传递给<kbd class="calibre12">predict()</kbd>函数，以使用我们在<em class="calibre23">步骤 1 </em>中构建的模型进行预测:</li>
</ol>
<pre class="calibre18">Y_pred_gbm = GBM_model.predict(X_test)</pre>
<ol start="3" class="calibre14">
<li class="calibre11">现在，我们使用<kbd class="calibre12">classification_report</kbd>来查看以下指标:</li>
</ol>
<pre class="calibre18">print(classification_report(Y_test, Y_pred_gbm))</pre>
<p class="calibre20"><kbd class="calibre12">classification_report</kbd>给出了以下输出:</p>
<p class="CDPAlignCenter"><img src="img/ad04d7fa-7696-4168-bd2f-8bee27c56d4a.png" class="calibre42"/></p>
<ol start="4" class="calibre14">
<li class="calibre11">我们将使用<kbd class="calibre12">confusion_matrix()</kbd>来生成混淆矩阵。然后，我们将<kbd class="calibre12">confusion_matrix</kbd>的输出传递给我们预定义的函数，即<kbd class="calibre12">plot_confusion_matrix()</kbd>，以绘制矩阵:</li>
</ol>
<p class="CDPAlignCenter"><img src="img/905c7c1c-03c9-453b-b2d6-2931f578c79f.png" class="calibre43"/></p>
<ol start="5" class="calibre14">
<li class="calibre11">我们可以用<kbd class="calibre12">accuracy_score()</kbd>和<kbd class="calibre12">roc_auc_score()</kbd>检查测试的准确性和 AUC 值。</li>
</ol>
<p class="calibre2">注意<kbd class="calibre12">accuracy_score</kbd>和<kbd class="calibre12">roc_auc_score</kbd>已经从<kbd class="calibre12">sklearn.metrics</kbd>导入:</p>
<p class="CDPAlignCenter"><img src="img/e2061b05-4ac1-4159-a970-4e4c9f32c13c.png" class="calibre44"/></p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>How it works...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">它是如何工作的...</h1>
                
            
            
                
<p class="calibre2">在<em class="calibre13">步骤 1 </em>中，我们训练了一个梯度推进分类器模型。在<em class="calibre13">步骤 2 </em>中，我们使用<kbd class="calibre12">predict()</kbd>方法对我们的测试数据进行预测。</p>
<p class="calibre2">在<em class="calibre13">步骤 3 </em>中，我们使用<kbd class="calibre12">classification_report()</kbd>来查看各种度量，例如每个类的<kbd class="calibre12">precision</kbd>、<kbd class="calibre12">recall</kbd>和<kbd class="calibre12">f1-score</kbd>，以及每个度量的平均值。<kbd class="calibre12">classification_report()</kbd>报告总真阳性、假阴性、假阳性、每个标签的未加权平均值和每个标签的支持加权平均值的平均值。它还报告了多标签分类的样本平均值。</p>
<p class="calibre2"/>
<p>精度指的是分类器不将一个阴性实例标记为阳性实例的能力，而召回指的是分类器找到所有阳性实例的能力。f <sub class="calibre45"> 1 </sub>分数是精确度和召回率的加权调和平均值。最好的<kbd class="calibre19">f<sub class="calibre46">1</sub> score</kbd>是 1.0，最差是 0.0。支持度是每类的观察次数。</p>
<p class="calibre2">在<em class="calibre13">步骤 4 </em>中，我们使用<kbd class="calibre12">confusion_matrix()</kbd>生成混淆矩阵来查看真阳性、真阴性、假阳性和假阴性。</p>
<p class="calibre2">在<em class="calibre13">步骤 5 </em>中，我们使用<kbd class="calibre12">accuracy_score()</kbd>和<kbd class="calibre12">roc_auc_score()</kbd>函数查看了测试数据的准确性和 AUC 值。</p>
<p class="calibre2">在下一节中，我们将使用网格搜索来调优超参数，以找到最佳模型。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>There's more...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">还有更多...</h1>
                
            
            
                
<p class="calibre2">我们现在来看看如何微调梯度推进机器的超参数:</p>
<ol class="calibre14">
<li class="calibre11">首先，我们从<kbd class="calibre12">sklearn.model_selection</kbd>导入<kbd class="calibre12">GridSearchCV</kbd>:</li>
</ol>
<pre class="calibre18">from sklearn.model_selection import GridSearchCV</pre>
<ol start="2" class="calibre14">
<li class="calibre11">我们将网格参数设置为变量:</li>
</ol>
<pre class="calibre18">parameters = {<br class="title-page-name"/>    "n_estimators":[100,150,200],<br class="title-page-name"/>    "loss":["deviance"],<br class="title-page-name"/>    "learning_rate": [0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],<br class="title-page-name"/>    "min_samples_split":np.linspace(0.1, 0.5, 4),<br class="title-page-name"/>    "min_samples_leaf": np.linspace(0.1, 0.5, 4),<br class="title-page-name"/>    "max_depth":[3, 5, 8],<br class="title-page-name"/>    "max_features":["log2","sqrt"],<br class="title-page-name"/>    "criterion": ["friedman_mse", "mae"],<br class="title-page-name"/>    "subsample":[0.3, 0.6, 1.0]<br class="title-page-name"/>    }</pre>
<ol start="3" class="calibre14">
<li class="calibre11">我们使用<kbd class="calibre12">GridSeacrhCV</kbd>，它让我们将估计器与网格搜索相结合来调整超参数。<kbd class="calibre12">GridSeacrhCV</kbd>方法从网格值中选择最佳参数，并与估计器一起使用:</li>
</ol>
<pre class="calibre18">grid = GridSearchCV(GradientBoostingClassifier(), parameters, cv=3, n_jobs=-1) <br class="title-page-name"/>grid.fit(X_train, Y_train)</pre>
<ol start="4" class="calibre14">
<li class="calibre11">然后，我们可以查看最佳参数:</li>
</ol>
<pre class="calibre18">grid.best_estimator_</pre>
<p class="calibre20">看一下下面的截图:</p>
<p class="CDPAlignCenter"><img src="img/e01f81c8-036d-4083-b101-61505564fa5e.png" class="calibre47"/></p>
<ol start="5" class="calibre14">
<li class="calibre11">我们将测试数据传递给<kbd class="calibre12">predict</kbd>方法来获得预测:</li>
</ol>
<pre class="calibre18">grid_predictions = grid.predict(X_test)</pre>
<ol start="6" class="calibre14">
<li class="calibre11">同样，我们可以看到由<kbd class="calibre12">classification_report</kbd>提供的指标:</li>
</ol>
<pre class="calibre18">print(classification_report(Y_test, grid_predictions))</pre>
<p class="calibre20">这为我们提供了以下输出。我们注意到平均值<kbd class="calibre12">precision</kbd>和<kbd class="calibre12">f1-score</kbd>比前一种情况有所提高:</p>
<p class="CDPAlignCenter"><img src="img/ee2e913d-849e-4077-991b-93d071a4080f.png" class="calibre48"/></p>
<ol start="7" class="calibre14">
<li class="calibre11">现在，我们将看看混淆矩阵，并像之前一样绘制它:</li>
</ol>
<pre class="calibre18">cnf_matrix = confusion_matrix(Y_test, grid_predictions)<br class="title-page-name"/>plot_confusion_matrix(cnf_matrix,classes=[0,1])<br class="title-page-name"/></pre>
<p class="CDPAlignLeft1">从前面的代码中我们得到了下面的图:</p>
<p class="CDPAlignCenter"><img src="img/77d312c3-89a3-4a46-b046-920e8dcfd943.png" class="calibre49"/></p>
<ol start="8" class="calibre14">
<li class="calibre11">现在，我们将再次查看准确性和 AUC 值:</li>
</ol>
<p class="calibre2"> </p>
<pre class="calibre18">print("Accuracy score = {:0.2f}".format(accuracy_score(Y_test, grid_predictions)))<br class="title-page-name"/>print("Area under ROC curve = {:0.2f}".format(roc_auc_score(Y_test, grid_predictions)))</pre>
<p class="calibre20">我们注意到精确度保持不变，但是 AUC 从 0.96 提高到 0.97:</p>
<p class="CDPAlignCenter"><img src="img/8df0c134-5624-4f39-afce-466c64cbff69.png" class="calibre50"/></p>
<p class="calibre2"/>
<p class="calibre2"/>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Implementing the extreme gradient boosting method for glass identification using XGBoost with scikit-learn </title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">使用 XGBoost 和 scikit-learn 实现玻璃鉴定的极端梯度增强方法</h1>
                
            
            
                
<p class="calibre2">XGBoost 代表极端梯度增强。它是梯度推进机的一个变种，旨在提高性能和速度。Python 中的 XGBoost 库实现了梯度推进决策树算法。梯度推进这个名字来自于它的梯度下降算法，以尽量减少损失时，增加新的模型。XGBoost 可以处理回归和分类任务。</p>
<p class="calibre2">XGBoost 是那些参加 Kaggle 竞赛的算法中的首选算法，因为它在困难的机器学习问题中的性能和执行速度。</p>
<p class="calibre2">XGBoost 中使用的一些重要参数如下:</p>
<ul class="calibre10">
<li class="calibre11"><kbd class="calibre12">n_estimators</kbd> / <kbd class="calibre12">ntrees</kbd> : <strong class="calibre1"> </strong>指定要建造的树的数量。默认值为 50。</li>
<li class="calibre11"><kbd class="calibre12">max_depth</kbd> : <strong class="calibre1"> </strong>指定了树的最大深度。默认值为 6。较高的值将使模型更加复杂，并可能导致过度拟合。将该值设置为 0 表示没有限制。</li>
<li class="calibre11"><kbd class="calibre12">min_rows</kbd>:此<strong class="calibre1"> </strong>指定一片叶子的最小观察次数。默认值为 1。</li>
<li class="calibre11"><kbd class="calibre12">learn_rate</kbd>:指定缩小特征权重的学习率。在每个提升步骤之后收缩特征权重使得提升过程更加保守，并且防止过度拟合。范围是 0.0 到 1.0。默认值为 0.3。</li>
<li class="calibre11"><kbd xmlns:epub="http://www.idpf.org/2007/ops" class="calibre12">sample_rate</kbd> : <strong xmlns:epub="http://www.idpf.org/2007/ops" class="calibre1"> </strong>指定训练实例的行采样率(<em xmlns:epub="http://www.idpf.org/2007/ops" class="calibre23">x</em>T25】轴)。例如，将该值设置为 0.5 会告诉 XGBoost 随机收集一半的数据实例来增长树。默认值为 1，范围为 0.0 到 1.0。较高的值可以提高训练精度。</li>
<li class="calibre11"><kbd class="calibre12">col_sample_rate</kbd>:指定每一级中每个分割的列采样率(<em class="calibre23"> y 轴</em>)。默认值为 1.0，范围从 0 到 1.0。较高的值可以提高训练精度。</li>
</ul>
<p class="calibre2"/>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Getting ready...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">做好准备...</h1>
                
            
            
                
<p class="calibre2">你需要安装<kbd class="calibre12">XGBoost</kbd>库来继续这个食谱。您可以使用<kbd class="calibre12">pip</kbd>命令安装<kbd class="calibre12">XGBoost</kbd>库，如下所示:</p>
<pre class="calibre15"><strong class="calibre1">!pip install xgboost</strong></pre>
<p class="calibre2">导入所需的库:</p>
<pre class="calibre15"># Import required libraries<br class="title-page-name"/>import os<br class="title-page-name"/>import pandas as pd<br class="title-page-name"/>import numpy as np<br class="title-page-name"/><br class="title-page-name"/>from numpy import sort<br class="title-page-name"/><br class="title-page-name"/>from xgboost import XGBClassifier<br class="title-page-name"/>from xgboost import plot_tree<br class="title-page-name"/>from xgboost import plot_importance<br class="title-page-name"/><br class="title-page-name"/>from sklearn.feature_selection import SelectFromModel<br class="title-page-name"/>from sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold<br class="title-page-name"/><br class="title-page-name"/>import matplotlib.pyplot as plt<br class="title-page-name"/>from sklearn.metrics import accuracy_score, confusion_matrix<br class="title-page-name"/><br class="title-page-name"/>import itertools</pre>
<p class="calibre2">设置工作文件夹并读取数据:</p>
<pre class="calibre15">os.chdir("/.../Chapter 7")<br class="title-page-name"/>os.getcwd()<br class="title-page-name"/><br class="title-page-name"/>df_glassdata = pd.read_csv('glassdata.csv')<br class="title-page-name"/>df_glassdata.shape</pre>
<p class="calibre2">这些数据来自 UCI ML 知识库。列名已经根据以下链接中提供的数据描述进行了更改:<a href="https://bit.ly/2EZX6IC" class="calibre9">https://bit.ly/2EZX6IC</a>。</p>
<p class="calibre2">我们来看看数据:</p>
<pre class="calibre15">df_glassdata.head()</pre>
<p class="calibre2">我们将数据分为目标和特性集，并对其进行验证。注意，我们忽略了 ID 列:</p>
<pre class="calibre15"># split data into X and Y<br class="title-page-name"/>X = df_glassdata.iloc[:,1:10]<br class="title-page-name"/>Y = df_glassdata.iloc[:,10]<br class="title-page-name"/><br class="title-page-name"/>print(X.shape)<br class="title-page-name"/>print(Y.shape)</pre>
<p class="calibre2">我们确认没有缺失值:</p>
<pre class="calibre15">df_glassdata.isnull().sum()</pre>
<p class="calibre2">我们将数据集分成训练和测试子集:</p>
<pre class="calibre15"># Create train &amp; test sets<br class="title-page-name"/>X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30, random_state=0)</pre>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>How to do it...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">怎么做...</h1>
                
            
            
                
<p class="calibre2">现在，我们将继续构建我们的第一个 XGBoost 模型:</p>
<ol class="calibre14">
<li class="calibre11">首先，我们将训练数据放入 XGBoost 分类器:</li>
</ol>
<pre class="calibre18">xg_model = XGBClassifier()<br class="title-page-name"/>xg_model.fit(X_train, Y_train)</pre>
<ol start="2" class="calibre14">
<li class="calibre11">我们可以从训练好的模型中可视化出一个 XGBoost 决策树。可视化决策树可以提供对梯度推进过程的洞察:</li>
</ol>
<pre class="calibre18">plot_tree(xg_model, num_trees=0, rankdir='LR')<br class="title-page-name"/>fig = pyplot.gcf()<br class="title-page-name"/>fig.set_size_inches(30, 30)</pre>
<p class="calibre2"/>
<p class="calibre20">这为我们提供了以下输出:</p>
<p class="CDPAlignCenter"><img src="img/76e980da-6fd8-4498-9b40-d45f6a6996ac.png" class="calibre51"/></p>
<p class="calibre20">用<kbd class="calibre12">num_trees=0</kbd>，我们得到第一棵被提升的树。我们可以通过将索引值设置为<kbd class="calibre12">num_trees</kbd>参数来查看其他提升的树。</p>
<ol start="3" class="calibre14">
<li class="calibre11">我们在下面的例子中设定<kbd class="calibre12">num_trees=5</kbd>:</li>
</ol>
<pre class="calibre18">plot_tree(xg_model, num_trees=5, rankdir='LR')<br class="title-page-name"/>fig = pyplot.gcf()<br class="title-page-name"/>fig.set_size_inches(30, 30)</pre>
<p class="calibre20">下面的截图向我们展示了第六棵被提升的树:</p>
<p class="CDPAlignCenter"><img src="img/21e57f28-d9e9-47d4-8583-92582c2b6d1c.png" class="calibre52"/></p>
<p class="calibre2"/>
<p class="calibre2"/>
<p>你需要在你的系统上安装<kbd class="calibre19">graphviz</kbd>库来绘制被增强的树。</p>
<ol start="4" class="calibre14">
<li class="calibre11">我们现在将对我们的测试数据使用<kbd class="calibre12">predict()</kbd>来获得预测值。我们可以通过<kbd class="calibre12">accuracy_score()</kbd>看到我们的测试精度:</li>
</ol>
<pre class="calibre18">test_predictions = xg_model.predict(X_test)<br class="title-page-name"/>test_accuracy = accuracy_score(Y_test, test_predictions)<br class="title-page-name"/><br class="title-page-name"/>print("Test Accuracy: %.2f%%" % (test_accuracy * 100.0))</pre>
<p class="calibre20">通过执行这段代码，我们可以看到测试准确率为 69.23%。</p>
<ol start="5" class="calibre14">
<li class="calibre11">我们可以通过使用以下代码来查看我们的混淆矩阵:</li>
</ol>
<pre class="calibre18">confusion_matrix(Y_test, predictions)</pre>
<ol start="6" class="calibre14">
<li class="calibre11">然后我们可以使用一个预定义的函数<kbd class="calibre12">plot_confusion_matrix()</kbd>，它来自于<a href="https://scikit-learn.org" class="calibre9">https://scikit-learn.org</a>:</li>
</ol>
<pre class="calibre18">def plot_confusion_matrix(cm, classes,<br class="title-page-name"/>                          normalize=False,<br class="title-page-name"/>                          title='Confusion matrix',<br class="title-page-name"/>                          cmap=plt.cm.Blues):<br class="title-page-name"/>    plt.imshow(cm, interpolation='nearest', cmap=cmap)<br class="title-page-name"/>    plt.title(title)<br class="title-page-name"/>    plt.colorbar()<br class="title-page-name"/>    tick_marks = np.arange(len(classes))<br class="title-page-name"/>    plt.xticks(tick_marks, classes, rotation=45)<br class="title-page-name"/>    plt.yticks(tick_marks, classes)<br class="title-page-name"/><br class="title-page-name"/>    fmt = '.2f' if normalize else 'd'<br class="title-page-name"/>    thresh = cm.max() / 2.<br class="title-page-name"/>    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):<br class="title-page-name"/>        plt.text(j, i, format(cm[i, j], fmt),<br class="title-page-name"/>                 horizontalalignment="center",<br class="title-page-name"/>                 color="white" if cm[i, j] &gt; thresh else "black")<br class="title-page-name"/><br class="title-page-name"/>    plt.ylabel('True label')<br class="title-page-name"/>    plt.xlabel('Predicted label')<br class="title-page-name"/>    plt.tight_layout()</pre>
<ol start="7" class="calibre14">
<li class="calibre11">然后，我们查看目标变量的<kbd class="calibre12">unique</kbd>值，以设置目标变量的每个级别的名称:</li>
</ol>
<pre class="calibre18">Y.unique()</pre>
<p class="calibre20">在下面的代码块中，我们可以看到<kbd class="calibre12">target_names</kbd>值为<kbd class="calibre12">1</kbd>、<kbd class="calibre12">2</kbd>、<kbd class="calibre12">3</kbd>、<kbd class="calibre12">5</kbd>、<kbd class="calibre12">6</kbd>和<kbd class="calibre12">7</kbd>。我们相应地为目标变量的每个级别设置名称:</p>
<pre class="calibre18"># Set names to each level of our target variable<br class="title-page-name"/>target_names = [ '1', '2', '3', '5', '6', '7']<br class="title-page-name"/><br class="title-page-name"/># Pass Actual &amp; Predicted values to confusion_matrix()<br class="title-page-name"/>cm = confusion_matrix(Y_test, predictions)<br class="title-page-name"/><br class="title-page-name"/>plt.figure()<br class="title-page-name"/>plot_confusion_matrix(cm, classes=target_names)<br class="title-page-name"/>plt.show()</pre>
<p class="calibre20">我们现在可以看到混淆矩阵，如下图所示:</p>
<p class="CDPAlignCenter"><img src="img/94cf908f-30aa-49c6-ad21-e09a5d42b239.png" class="calibre53"/></p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>How it works...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">它是如何工作的...</h1>
                
            
            
                
<p class="calibre2">在<em class="calibre13">步骤 1 </em>中，我们将<kbd class="calibre12">XGBoostClassfier</kbd>与我们的训练数据相匹配。在<em class="calibre13">步骤 2 </em>和<em class="calibre13">步骤 3 </em>中，我们可视化了单个被增强的树。为此，我们使用了<kbd class="calibre12">plot_tree()</kbd>函数。我们将我们的<kbd class="calibre12">XGBoost</kbd>模型传递给<kbd class="calibre12">plot_tree()</kbd>，并通过设置<kbd class="calibre12">num_trees</kbd>参数来设置树的索引。<kbd class="calibre12">rankdir='LR'</kbd>参数从左到右绘制树。将<kbd class="calibre12">rankdir</kbd>设置为 UT 将绘制一棵垂直树。</p>
<p class="calibre2">在<em class="calibre13">步骤 4 </em>中，我们将测试子集传递给<kbd class="calibre12">predict()</kbd>以获得测试精度。<em class="calibre13">第 5 步</em>给了我们混淆矩阵。在<em class="calibre13">步骤 6 </em>中，我们从<a href="https://scikit-learn.org/stable/" class="calibre9">scikit-learn.org</a>那里获得了一个预定义的函数<kbd class="calibre12">plot_confusion_matrix()</kbd>。我们用这个函数来绘制我们的混淆矩阵。在<em class="calibre13">步骤 7 </em>中，我们查看了目标变量的唯一值，这样我们就可以为混淆矩阵图的每个类设置名称。然后我们绘制了混淆矩阵来评估我们的模型。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>There's more...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">还有更多...</h1>
                
            
            
                
<p class="calibre2">在这一节中，我们将看看如何检查特性的重要性，并基于此进行特性选择。我们还将看看如何使用交叉验证来评估 XGBoost 模型的性能。</p>
<p class="calibre2">我们可以用<kbd class="calibre12">model.feature_importances_</kbd>来检查特性的重要性:</p>
<pre class="calibre15">print(xg_model.feature_importances_)</pre>
<p class="calibre2">我们还可以使用<kbd class="calibre12">plot_importance()</kbd>来可视化特性的重要性:</p>
<p>注意，我们已经从<kbd class="calibre19">xgboost</kbd>库中导入了<kbd class="calibre19">plot_importance</kbd>。</p>
<pre class="calibre15">plot_importance(xg_model)</pre>
<p class="calibre2"/>
<p class="calibre2">执行上述代码后，我们会看到下面的图表，它按照重要性降序显示了特性的重要性:</p>
<p class="CDPAlignCenter"><img src="img/c9e25012-3c0d-4e66-b74a-1b944c24b59c.png" class="calibre54"/></p>
<p class="calibre2">使用<kbd class="calibre12">SelectFromModel</kbd>可将特征重要性用于特征选择。</p>
<p><kbd class="calibre19">SelectFromModel</kbd>类是从<kbd class="calibre19">sklearn.feature_selection</kbd>导入的。</p>
<p class="calibre2">在下面的例子中，<kbd class="calibre12">SelectFromModel</kbd>采用预训练的<kbd class="calibre12">XGBoost</kbd>模型，并从我们的数据集中提供一个具有所选特征的子集。它基于阈值来决定所选择的特征。</p>
<p class="calibre2">重要性大于或等于阈值的要素将被保留，而其他要素将被丢弃:</p>
<pre class="calibre15"># The threshold value to use for feature selection. <br class="title-page-name"/>feature_importance = sort(xg_model.feature_importances_)<br class="title-page-name"/><br class="title-page-name"/># select features using threshold<br class="title-page-name"/>for each_threshold in feature_importance:<br class="title-page-name"/>    selection = SelectFromModel(xg_model, threshold=each_threshold, prefit=True)<br class="title-page-name"/>    <br class="title-page-name"/>    # Reduce X_train only to the selected feature<br class="title-page-name"/>    selected_feature_X_train = selection.transform(X_train)<br class="title-page-name"/>    <br class="title-page-name"/>    # Train the model<br class="title-page-name"/>    selection_model = XGBClassifier()<br class="title-page-name"/>    selection_model.fit(selected_feature_X_train, Y_train)<br class="title-page-name"/>    <br class="title-page-name"/>    # Reduce X_test only to the selected feature<br class="title-page-name"/>    selected_feature_X_test = selection.transform(X_test)<br class="title-page-name"/>    <br class="title-page-name"/>    # Predict using the test value of the selected feature<br class="title-page-name"/>    predictions = selection_model.predict(selected_feature_X_test)<br class="title-page-name"/>    <br class="title-page-name"/>    accuracy = accuracy_score(Y_test, predictions)<br class="title-page-name"/>    print("Threshold=%.5f, Number of Features=%d, Model Accuracy: %.2f%%" % (each_threshold, selected_feature_X_train.shape[1],accuracy*100))</pre>
<p class="calibre2">从前面的代码中，我们可以看到以下输出:</p>
<p class="CDPAlignCenter"><img src="img/2ad16bc9-18cf-45ec-88ca-7fb8be176527.png" class="calibre55"/></p>
<div><div><div><p class="calibre2">我们注意到模型的性能随着所选特征的数量而波动。基于前面的输出，我们决定选择五个特征，这五个特征的准确率为 72%。此外，如果我们使用奥卡姆剃刀原理，我们可能会选择一个具有四个特征的更简单的模型，它给我们提供了略低的 71%的准确性。</p>
</div>
<p class="calibre2">我们还可以使用交叉验证来评估我们的模型。为了执行 k-fold 交叉验证，我们必须从<kbd class="calibre12">sklearn.model_selection</kbd>导入<kbd class="calibre12">KFold</kbd>类。</p>
<p class="calibre2">首先，我们创建<kbd class="calibre12">KFold</kbd>对象，并提及我们想要的分割数量:</p>
<pre class="calibre15">kfold = KFold(n_splits=40, random_state=0)<br class="title-page-name"/>xg_model_with_kfold = XGBClassifier()<br class="title-page-name"/><br class="title-page-name"/>cv_results = cross_val_score(xg_model_with_kfold, X_train, Y_train, cv=kfold, verbose=True)<br class="title-page-name"/>print("Mean Accuracy: %.2f%% Standard Deviation %.2f%%" % (cv_results.mean()*100, cv_results.std()*100))</pre></div>
</div>
<p class="calibre2">使用<kbd class="calibre12">cross_val_score()</kbd>，我们评估我们的模型，该模型为我们提供了均值和标准差分类精度。我们注意到我们得到了 77.92%的平均准确度和 22.33%的标准偏差。</p>
<p class="calibre2">在我们的例子中，我们有一个包含六个类的目标变量。</p>
<p class="calibre2">如果多类别分类任务有多个类别，则在执行交叉验证时，可以使用分层折叠:</p>
<pre class="calibre15">Stratfold = StratifiedKFold(n_splits=40, random_state=0)<br class="title-page-name"/>xg_model_with_stratfold = XGBClassifier()<br class="title-page-name"/><br class="title-page-name"/>sf_results = cross_val_score(xg_model_with_stratfold, X_train, Y_train, cv=Stratfold, verbose=True)<br class="title-page-name"/>print("Mean Accuracy: %.2f%% Standard Deviation %.2f%%" % (sf_results.mean()*100, sf_results.std()*100))</pre>
<p class="calibre2">使用<kbd class="calibre12">StratifiedKFold()</kbd>，我们获得了 81.18%的改进平均准确度和 21.37%的降低标准偏差。</p>
<p>注意<kbd class="calibre19">n_splits</kbd>不能大于每个类的成员数。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>See also</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">请参见</h1>
                
            
            
                
<ul class="calibre10">
<li class="calibre11">LightGBM 是微软开发的梯度推进框架的开源软件。它使用基于树的算法不同于其他<strong xmlns:epub="http://www.idpf.org/2007/ops" class="calibre1">梯度推进机</strong>(<strong xmlns:epub="http://www.idpf.org/2007/ops" class="calibre1">GBMs</strong>)【https://bit.ly/2QW53jH】T21</li>
</ul>


            

            
        
    </body>

</html>
</body></html>