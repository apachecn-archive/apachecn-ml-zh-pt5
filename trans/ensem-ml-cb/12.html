<html><head/><body>
<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Homogenous Ensemble for Multiclass Classification Using Keras</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">基于 Keras 的多类分类同质集成</h1>
                
            
            
                
<p class="calibre2">在这一章中，我们将介绍以下食谱:</p>
<ul class="calibre10">
<li class="calibre11">同类模型的集合来对时尚产品进行分类</li>
</ul>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Introduction</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">介绍</h1>
                
            
            
                
<p class="calibre2">在分类问题上已经进行了许多研究，以找出如何获得更好的分类精度。当要对大量的类进行预测时，这个问题会变得更加复杂。在多类分类的情况下，假设目标变量中的每个类都是相互独立的。多类分类技术包括训练一个或多个模型来对可以取两个以上类的目标变量进行分类。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>An ensemble of homogeneous models to classify fashion products</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">同类模型的集合来对时尚产品进行分类</h1>
                
            
            
                
<p class="calibre2">在这个例子中，我们将使用时尚 MNIST 数据集。该数据集包含 10 个类别的 60，000 张时尚产品图片。目标变量可分为十类:</p>
<ul class="calibre10">
<li class="calibre11">t 恤/上衣</li>
<li class="calibre11">裤子</li>
<li class="calibre11">套衫</li>
<li class="calibre11">连衣裙</li>
<li class="calibre11">外套</li>
<li class="calibre11">凉鞋</li>
<li class="calibre11">衬衫</li>
<li class="calibre11">运动鞋</li>
<li class="calibre11">包</li>
<li class="calibre11">踝靴</li>
</ul>
<p class="calibre2">每个图像都是 28 x 28 灰度图像。我们将继续读取数据，通过几次迭代建立几个同质模型，看看集成是否能提供更高的精度。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Getting ready</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">做好准备</h1>
                
            
            
                
<p class="calibre2">我们将使用 Google Colab 来训练我们的模型。Google Colab 自带 TensorFlow 安装，我们不用在系统中单独安装。</p>
<p class="calibre2">我们导入所需的库，如下所示:</p>
<pre class="calibre15">import numpy as np<br class="title-page-name"/>import pandas as pd<br class="title-page-name"/>import seaborn as sns<br class="title-page-name"/>import matplotlib.pyplot as plt<br class="title-page-name"/><br class="title-page-name"/>import tensorflow as tf<br class="title-page-name"/>from tensorflow import keras<br class="title-page-name"/>from sklearn.utils import resample<br class="title-page-name"/>from sklearn.metrics import accuracy_score<br class="title-page-name"/>from sklearn.metrics import confusion_matrix<br class="title-page-name"/>from sklearn.metrics import classification_report<br class="title-page-name"/>from scipy import stats</pre>
<p class="calibre2">我们从<kbd class="calibre12">tf.keras</kbd>提供的数据集中加载数据:</p>
<pre class="calibre15"># Load the fashion-mnist pre-shuffled train data and test data
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()</pre>
<p class="calibre2">我们检查训练和测试子集的维度:</p>
<pre class="calibre15"># Print training set shape <br class="title-page-name"/>print("x_train shape:", x_train.shape, "y_train shape:", y_train.shape)</pre>
<p class="calibre2">这为我们提供了以下输出:</p>
<p class="CDPAlignCenter"><img class="aligncenter124" src="img/c7c78596-8409-45b0-9b07-88787f16e63b.png"/></p>
<p class="calibre2">我们注意到目标变量中的唯一值:</p>
<pre class="calibre15">np.unique(y_train)</pre>
<p class="calibre2">我们可以看到，从 0 到 9 有 10 个类别:</p>
<p class="CDPAlignCenter"><img class="aligncenter125" src="img/adb643ea-43b7-4070-967a-1a60c4a811c5.png"/></p>
<p class="calibre2">我们可以快速浏览一下最初的一些观察结果，如下所示:</p>
<pre class="calibre15">fig=plt.figure(figsize=(16,8))<br class="title-page-name"/><br class="title-page-name"/># number of columns for images in plot<br class="title-page-name"/>columns=5 <br class="title-page-name"/><br class="title-page-name"/># number of rows for images in plot<br class="title-page-name"/>rows=3<br class="title-page-name"/><br class="title-page-name"/>for i in range (1,columns*rows+1):<br class="title-page-name"/>      fig.add_subplot(rows,columns,i)<br class="title-page-name"/>      plt.title("Actual Class: {}".\<br class="title-page-name"/>              format((y_train[i])),color='r',fontsize=16)<br class="title-page-name"/>      plt.imshow(x_train[i])<br class="title-page-name"/>plt.show()</pre>
<p class="calibre2"/>
<p class="calibre2">使用前面的代码，我们绘制了前 15 幅图像，以及相关联的标签:</p>
<p class="CDPAlignCenter"><img class="aligncenter126" src="img/3a825ef7-c292-420e-8539-a852303b3206.png"/></p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>How to do it...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">怎么做...</h1>
                
            
            
                
<p class="calibre2">我们现在将继续训练我们的模型:</p>
<ol class="calibre14">
<li class="calibre11">在下面的代码块中，我们将使用<kbd class="calibre12">tf.keras</kbd>通过几次迭代创建多个同质模型:</li>
</ol>
<pre class="calibre18">accuracy = pd.DataFrame( columns=["Accuracy","Precision","Recall"])<br class="title-page-name"/>predictions = np.zeros(shape=(10000,7))<br class="title-page-name"/>row_index = 0<br class="title-page-name"/>for i in range(7):<br class="title-page-name"/>        # bootstrap sampling <br class="title-page-name"/>        boot_train = resample(x_train,y_train,replace=True, n_samples=40000, random_state=None)<br class="title-page-name"/>        model = tf.keras.Sequential([<br class="title-page-name"/>            tf.keras.layers.Flatten(input_shape=(28, 28)),<br class="title-page-name"/>            tf.keras.layers.Dense(256, activation=tf.nn.relu),<br class="title-page-name"/>            tf.keras.layers.Dense(128, activation=tf.nn.relu),<br class="title-page-name"/>            tf.keras.layers.Dense(128, activation=tf.nn.relu),<br class="title-page-name"/>            tf.keras.layers.Dense(128, activation=tf.nn.relu),<br class="title-page-name"/>            tf.keras.layers.Dense(128, activation=tf.nn.relu),<br class="title-page-name"/>            tf.keras.layers.Dense(128, activation=tf.nn.relu),<br class="title-page-name"/>            tf.keras.layers.Dense(128, activation=tf.nn.relu),<br class="title-page-name"/>            tf.keras.layers.Dense(128, activation=tf.nn.relu),<br class="title-page-name"/>            tf.keras.layers.Dense(128, activation=tf.nn.relu),<br class="title-page-name"/>            tf.keras.layers.Dense(128, activation=tf.nn.relu),<br class="title-page-name"/>            tf.keras.layers.Dense(10, activation=tf.nn.softmax)])<br class="title-page-name"/>  <br class="title-page-name"/>        # compile the model<br class="title-page-name"/>        model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])<br class="title-page-name"/>  <br class="title-page-name"/>        # Train the model<br class="title-page-name"/>        model.fit(x_train,y_train,epochs=10,batch_size=64)<br class="title-page-name"/>  <br class="title-page-name"/>        # Evaluate accuracy<br class="title-page-name"/>        score = model.evaluate(x_test, y_test, batch_size=64)<br class="title-page-name"/>        accuracy.loc[row_index,"Accuracy"]=score[1]<br class="title-page-name"/>  <br class="title-page-name"/>        # Make predictions<br class="title-page-name"/>        model_pred= model.predict(x_test)<br class="title-page-name"/>        pred_classes =model_pred.argmax(axis=-1)<br class="title-page-name"/>        accuracy.loc[row_index, 'Precision'] = precision_score(y_test, pred_classes, average='weighted')<br class="title-page-name"/>        accuracy.loc[row_index, 'Recall'] = recall_score(y_test, pred_classes,average='weighted')<br class="title-page-name"/>  <br class="title-page-name"/>        # Save predictions to predictions array<br class="title-page-name"/>        predictions[:,i] = pred_classes<br class="title-page-name"/>  <br class="title-page-name"/>        print(score)<br class="title-page-name"/>        row_index+=1<br class="title-page-name"/><br class="title-page-name"/>        print("Iteration " + str(i+1)+ " Accuracy : " + "{0}".format(score[1]))</pre>
<p class="calibre2">我们提到了 7 次迭代和每次迭代中的 10 个时期。在下面的截图中，我们可以看到模型训练的进度:</p>
<p class="CDPAlignCenter"><img class="aligncenter127" src="img/facfdce9-3e8f-43c7-91ba-7b757885f4c1.png"/></p>
<ol start="2" class="calibre14">
<li class="calibre11">使用<em class="calibre23">步骤 1 </em>中的代码，我们对测试数据的每次迭代的准确度、精确度和召回率进行比较:</li>
</ol>
<div><div><div><div><pre class="calibre18">accuracy</pre></div>
</div>
</div>
</div>
<div><div><p class="outputarea">在下面的屏幕截图中，我们可以看到前面的三个指标在每次迭代中是如何变化的:</p>
<div><img class="aligncenter128" src="img/66b6e227-2ba8-4c36-bc2b-8232068e5a6e.png"/></div>
</div>
</div>
<ol start="3" class="calibre14">
<li class="calibre11">我们将形成一个数据框架，其中包含每次迭代中所有模型返回的预测:</li>
</ol>
<pre class="calibre18"># Create dataframe using prediction of each iteration
df_iteration = pd.DataFrame([predictions[:,0],\
                           predictions[:,1],\
                           predictions[:,2],\
                           predictions[:,3],\
                           predictions[:,4],\
                           predictions[:,5],\
                           predictions[:,6]])</pre>
<ol start="4" class="calibre14">
<li class="calibre11">我们将类型转换为整数:</li>
</ol>
<pre class="calibre18">df_iteration = df_iteration.astype('int64')</pre>
<ol start="5" class="calibre14">
<li class="calibre11">我们执行最大投票来识别每个观察的最预测的类。我们简单地使用<kbd class="calibre12">mode</kbd>来找出哪个类在一次观察中被预测的次数最多:</li>
</ol>
<pre class="calibre18"># find the mode for result<br class="title-page-name"/>mode = stats.mode(df_iteration)</pre>
<ol start="6" class="calibre14">
<li class="calibre11">我们计算测试数据的准确性:</li>
</ol>
<pre class="calibre18"># calculate the accuracy for test dataset<br class="title-page-name"/>print(accuracy_score( y_test, mode[0].T))</pre>
<ol start="7" class="calibre14">
<li class="calibre11">我们用所需的标签生成混淆矩阵:</li>
</ol>
<pre class="calibre18"># confusion matrix<br class="title-page-name"/>cm = confusion_matrix(y_test, mode[0].T, labels=[0, 1, 2, 3, 4, 5, 6, 7, 8])</pre>
<ol start="8" class="calibre14">
<li class="calibre11">我们绘制混淆矩阵:</li>
</ol>
<pre class="calibre18">ax= plt.subplot()<br class="title-page-name"/><br class="title-page-name"/># annot=True to annotate cells<br class="title-page-name"/>sns.heatmap(cm, annot=True, ax = ax, fmt='g', cmap='Blues')</pre>
<p class="calibre20">混淆矩阵图如下所示:</p>
<p class="CDPAlignCenter"><img class="aligncenter129" src="img/1e7a1a0d-f59b-4d09-b8fd-ccb1c8cf2eae.png"/></p>
<ol start="9" class="calibre14">
<li class="calibre11">我们创建一个包含所有迭代编号的数据帧:</li>
</ol>
<pre class="calibre18">accuracy["Models"]=["Model 1",\<br class="title-page-name"/>                   "Model 2",\<br class="title-page-name"/>                   "Model 3",\<br class="title-page-name"/>                   "Model 4",\<br class="title-page-name"/>                   "Model 5",\<br class="title-page-name"/>                   "Model 6",\<br class="title-page-name"/>                   "Model 7"]</pre>
<ol start="10" class="calibre14">
<li class="calibre11">然后，我们将准确度、精确度和召回率结合在一个表格中:</li>
</ol>
<pre class="calibre18">accuracy=accuracy.append(pd.DataFrame([[\<br class="title-page-name"/>                                        accuracy_score(y_test,\<br class="title-page-name"/>                                        mode[0].T),0,0,\<br class="title-page-name"/>                                        "Ensemble Model"]], \<br class="title-page-name"/>                                        columns=["Accuracy",\<br class="title-page-name"/>                                        "Precision","Recall",\<br class="title-page-name"/>                                        "Models"]))<br class="title-page-name"/><br class="title-page-name"/>accuracy.index=range(accuracy.shape[0])<br class="title-page-name"/><br class="title-page-name"/>accuracy.set_value(7, 'Precision', precision_score(y_test, mode[0].T, average='micro'))<br class="title-page-name"/>accuracy.set_value(7, 'Recall', recall_score(y_test, mode[0].T, average='micro'))</pre>
<p class="calibre20">在下面的屏幕截图中，我们可以看到保存每个模型和集合模型的指标的结构:</p>
<p class="CDPAlignCenter"><img class="aligncenter130" src="img/033e6f18-7e95-4b79-95c9-c433448cce9a.png"/></p>
<ol start="11" class="calibre14">
<li class="calibre11">我们绘制了每次迭代返回的精确度和最大投票的精确度:</li>
</ol>
<pre class="calibre18">plt.figure(figsize=(20,8))<br class="title-page-name"/>plt.plot(accuracy.Models,accuracy.Accuracy)<br class="title-page-name"/>plt.title("Accuracy across all Iterations and Ensemble")<br class="title-page-name"/>plt.ylabel("Accuracy")<br class="title-page-name"/>plt.show()</pre>
<p class="calibre20">这给了我们以下情节。我们注意到，与单个模型相比，最大投票法返回的精确度最高:</p>
<p class="CDPAlignCenter"><img class="aligncenter131" src="img/de750f3d-1583-4900-aa77-1e788d9ac40d.png"/></p>
<ol start="12" class="calibre14">
<li class="calibre11">我们还绘制了每个模型和集合的精度和召回率:</li>
</ol>
<pre class="calibre18">plt.figure(figsize=(20,8))<br class="title-page-name"/>plt.plot(accuracy.Models,accuracy.Accuracy,accuracy.Models,accuracy.Precision)<br class="title-page-name"/>plt.title("Metrics across all Iterations and models")<br class="title-page-name"/>plt.legend(["Accuracy","Precision"])<br class="title-page-name"/>plt.show()</pre>
<p class="calibre2"/>
<p class="calibre20">如下图所示:</p>
<p class="CDPAlignCenter"><img class="aligncenter132" src="img/2bb4181e-f699-495d-9bf5-d5aab4558174.png"/></p>
<p class="calibre2">从前面的截图中，我们注意到集成模型的精度和召回率都有所提高。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>How it works...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">它是如何工作的...</h1>
                
            
            
                
<p class="calibre2">在<em class="calibre13">准备好</em>部分，我们导入了我们需要的库。注意，我们已经导入了<kbd class="calibre12">TensorFlow</kbd>库。我们可以通过导入<kbd class="calibre12">tf.keras.datasets</kbd>模块直接访问数据集。该模块带有各种内置数据集，包括:</p>
<ul class="calibre10">
<li class="calibre11"><kbd class="calibre12">boston_housing</kbd>:波斯顿房价回归数据集</li>
<li class="calibre11"><kbd class="calibre12">cifar10</kbd> : CIFAR10 小图像分类数据集</li>
<li class="calibre11"><kbd class="calibre12">fashion_mnist</kbd>:时尚-MNIST 数据集</li>
<li class="calibre11"><kbd class="calibre12">imdb</kbd> : IMDB 情感分类数据集</li>
<li class="calibre11"><kbd class="calibre12">mnist</kbd> : MNIST 手写数字数据集</li>
<li class="calibre11"><kbd class="calibre12">reuters</kbd>:路透社主题分类数据集</li>
</ul>
<p class="calibre2">我们使用了本模块中的<kbd class="calibre12">fashion_mnist</kbd>数据集。我们加载了预混洗的训练和测试数据，并检查了训练和测试子集的形状。</p>
<p class="calibre2">我们注意到，在 G <em class="calibre13">设置</em> <em class="calibre13">就绪</em>部分，训练子集的形状是(60000，28，28)，这意味着我们有 60000 幅大小为 28 X 28 像素的图像。</p>
<p class="calibre2"/>
<p class="calibre2"/>
<p class="calibre2">我们用<kbd class="calibre12">unique()</kbd>方法检查了目标变量的不同水平。我们看到从 0 到 9 一共 10 节课。</p>
<p class="calibre2">我们还快速浏览了一些图片。我们定义了所需的列数和行数。运行一次迭代，我们用灰度绘制了带有<kbd class="calibre12">matplotlib.pyplot.imshow()</kbd>的图像。我们还使用<kbd class="calibre12">matplotlib.pyplot.title()</kbd>打印了每个图像的实际类别标签。</p>
<p class="calibre2">在<em class="calibre13">怎么做...</em>部分，在<em class="calibre13">步骤 1 </em>中，我们使用<kbd class="calibre12">tf.keras</kbd>模块创建了多个同质模型。在每次迭代中，我们使用<kbd class="calibre12">resample()</kbd>方法来创建引导样本。我们将<kbd class="calibre12">replace=True</kbd>传递给<kbd class="calibre12">resample()</kbd>方法，以确保我们有替换的样本。</p>
<p class="calibre2">在这一步中，我们还定义了模型架构。我们使用<kbd class="calibre12">tf.keras.layers</kbd>给模型添加了层。在每一层中，我们定义了单元的数量。</p>
<p>“模型架构”是指整个神经网络结构，包括称为层的单元组。这些层以链状结构排列。每一层都是前一层的功能。确定模型结构是神经网络的关键。</p>
<p class="calibre2">在我们的例子中，我们经历了几次迭代。我们设置迭代的次数。在每次迭代中，我们编译模型并使其适合我们的训练数据。我们对测试数据进行了预测，并在数据框架中获得了以下指标:</p>
<ul class="calibre10">
<li class="calibre11">准确(性)</li>
<li class="calibre11">精确</li>
<li class="calibre11">回忆</li>
</ul>
<p class="calibre2">我们使用<kbd class="calibre12">Rectified Linear Units (RELU)</kbd>作为隐藏层的激活函数。ReLU 由<kbd class="calibre12">f(x) = max{0, x}</kbd>表示。在神经网络中，ReLU 被推荐为默认的激活函数。</p>
<p>注意，在模型架构的最后一层，我们使用 softmax 作为激活函数。softmax 函数可视为 sigmoid 函数的推广。sigmoid 函数用于表示二分变量的概率分布，而 softmax 函数用于表示具有两个以上类别的目标变量的概率分布。当 softmax 函数用于多类分类时，它会为每个类返回一个介于 0 和 1 之间的概率值。所有概率之和将等于 1。</p>
<p class="calibre2">在<em class="calibre13">步骤 2 </em>中，我们检查了在<em class="calibre13">步骤 1 </em>中创建的精度数据帧的结构。我们注意到我们有三列，分别是准确度、精确度和召回率，并且每个迭代的度量都被捕获。在<em class="calibre13">步骤 3 </em>中，我们将数据帧中的数据类型转换为整数。</p>
<p class="calibre2">在<em class="calibre13">步骤 4 </em>中，我们使用<kbd class="calibre12">stats.mode()</kbd>对每个观察值进行了最大投票。因为我们运行了七次迭代，所以我们对每次观察都有七个预测。<kbd class="calibre12">stats.mode()</kbd>返回出现次数最多的预测。</p>
<p class="calibre2">在<em class="calibre13">步骤 5 </em>中，我们用最大投票预测检查了模型的准确性。在<em class="calibre13">步骤 6 </em>和<em class="calibre13">步骤 7 </em>中，我们生成了混淆矩阵来可视化正确的预测。图中的对角线元素是正确的预测，而非对角线元素是错误的分类。我们看到，与错误分类相比，正确分类的数量更多。</p>
<p class="calibre2">在<em class="calibre13">步骤 8 </em>和<em class="calibre13">步骤 9 </em>中，我们继续创建一个结构来保存性能指标(准确度、精确度和召回率)，以及每个迭代和集合的标签。我们使用这种结构来绘制性能指标的图表。</p>
<p class="calibre2">在<em class="calibre13">步骤 10 </em>中，我们绘制了每次迭代的精确度和最大投票预测。类似地，在<em class="calibre13">步骤 11 </em>中，我们绘制了每次迭代的精确度和召回率以及最大投票预测。</p>
<p class="calibre2">从我们在<em class="calibre13">步骤 10 </em>和<em class="calibre13">步骤 11 </em>中生成的图中，我们注意到了最大投票预测的准确度、精确度和召回率是如何提高的。</p>
<p class="calibre2">请参见</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>See also</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title"><kbd class="calibre12">tf.keras</kbd>模块为我们提供了 TensorFlow 特有的功能，比如快速执行、数据管道和估算器。你可以看看<kbd class="calibre12">tf.keras</kbd>模块为我们提供的各种选项。</h1>
                
            
            
                
<p class="calibre2">在我们的例子中，我们使用了由<kbd class="calibre12">tf.keras.optimizer</kbd>模块提供的内置优化器类。我们在示例中使用了<strong class="calibre4"> Adam </strong> <strong class="calibre4">优化器</strong>，但是也可以使用其他优化器，比如 Adadelta、Adagrad、Adamax、RMSprop 或 SGD。</p>
<p class="calibre2">In our example, we used the built-in optimizer classes provided by the <kbd class="calibre12">tf.keras.optimizer</kbd> module. We used the <strong class="calibre4">Adam</strong> <strong class="calibre4">optimizer</strong> in our example, but there are other optimizers you can use, such as Adadelta, Adagrad, Adamax, RMSprop, or SGD.</p>
<p class="calibre2"/>
<p class="calibre2">在今天，亚当优化器是最好的优化器之一。它是<strong class="calibre1">随机梯度下降</strong> ( <strong class="calibre1"> SGD </strong>)的扩展。SGD 考虑所有权重更新的单一学习率，并且学习率在模型训练过程中保持不变。Adam 算法考虑自适应学习率方法来计算每个参数的个体学习率。</p>
<p><kbd class="calibre12">tf.keras.losses</kbd>模块为我们提供了各种选项，以便我们选择损失函数。我们用了<kbd class="calibre12">sparse_categorical_crossentropy</kbd>。根据您的任务，您可能会选择其他选项，比如<kbd class="calibre12">binary_crossentropy</kbd>、<kbd class="calibre12">categorical_crossentropy</kbd>、<kbd class="calibre12">mean_squared_error</kbd>等等。</p>
<p class="calibre2">在多类分类的情况下，如果目标变量是 one-hot 编码的，使用<kbd class="calibre19">categorical_crossentropy</kbd>。如果目标变量中的类用整数表示，使用<kbd class="calibre19">sparse_categorical_crossentropy</kbd>。</p>
<p>您可以在<a href="https://www.tensorflow.org/api_docs/python/tf/keras" class="calibre9">https://www.tensorflow.org/api_docs/python/tf/keras</a>获得与<kbd class="calibre12">tf.keras</kbd>一起使用的其他超参数的更多详细信息。</p>
<p class="calibre2">You can get more detailed information about the other hyperparameters that can be used with <kbd class="calibre12">tf.keras</kbd> at <a href="https://www.tensorflow.org/api_docs/python/tf/keras" class="calibre9">https://www.tensorflow.org/api_docs/python/tf/keras</a>.</p>


            

            
        
    </body>

</html>
</body></html>