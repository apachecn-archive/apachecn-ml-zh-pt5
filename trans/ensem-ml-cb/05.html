<html><head/><body>
<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Bag the Models with Bagging</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">用袋子将模型装袋</h1>
                
            
            
                
<p class="CDPAlignLeft3">在本章中，我们将讨论以下配方:</p>
<ul class="calibre10">
<li class="calibre11">自举聚合</li>
<li class="calibre11">集成元估计量</li>
<li class="calibre11">装袋回归量</li>
</ul>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Introduction</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">介绍</h1>
                
            
            
                
<p class="calibre2">分类器的组合有助于大大减少误分类错误。许多研究证明，这种集成方法可以显著降低预测模型的方差。已经提出了几种技术来实现方差减小。例如，在许多情况下，自举聚集(bagging)分类树已经显示出比单个分类树具有更高的准确性。Bagging 可以应用于基于树的算法，以提高预测的准确性，尽管它也可以与基于树的方法之外的方法一起使用。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Bootstrap aggregation</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">自举聚合</h1>
                
            
            
                
<p class="calibre2"><strong class="calibre4"> Bootstrap aggregation </strong>，也称为<strong class="calibre4"> bagging </strong>，是 Leo Breiman 在 1994 年提出的一种强大的集成方法，用于防止过拟合。bagging 背后的概念是结合几个基础学习者的预测，以创建一个更准确的输出。</p>
<p class="calibre2">Breiman 表明，bagging 可以在<strong class="calibre4">不稳定的</strong>学习算法中成功实现预期的结果，其中训练数据的微小变化会导致预测的巨大变化。Breiman 证明了神经网络和决策树等算法是不稳定学习算法的例子。Bootstrap 聚合在小型数据集上非常有效。</p>
<p class="calibre2"/>
<p class="calibre2">装袋的一般过程有助于减少那些具有高方差的算法的方差。Bagging 还支持分类和回归问题。下图显示了引导聚合流的工作方式:</p>
<p class="CDPAlignCenter"><img class="aligncenter65" src="img/fa8702be-8271-4dba-9264-13e122c57947.png"/></p>
<p class="calibre2">使用具有训练数据集<em class="calibre13"> X </em> <strong class="calibre4">，</strong>的自举，我们生成 N 个自举样本<em class="calibre13"> X1 </em>，<em class="calibre13"> X2，.....，XN </em>。</p>
<p class="calibre2">对于每个引导样本，我们训练一个分类器<img class="fm-editor-equation60" src="img/0f7c18d2-774c-46a5-958b-e14bfac327eb.png"/>。组合分类器将对所有这些单独分类器的输出进行平均，如下所示:</p>
<p class="CDPAlignCenter"><img class="fm-editor-equation61" src="img/9332286b-1e5f-4fb6-839f-8afe04b73931.png"/></p>
<p class="calibre2">在上式中，<em class="calibre13"> N </em>代表样本数。</p>
<p class="calibre2">在 bagging 分类器中，投票用于进行最终预测。Breiman 提出的 bagging 分类器的伪代码如下:</p>
<p class="CDPAlignCenter"><img class="aligncenter66" src="img/542d5b93-e002-4f48-b9c6-f76f9909939b.png"/></p>
<p class="calibre2">在 bagging 回归器的情况下，最终预测是在每个 bootstrap 样本上建立的模型预测的平均值。以下伪代码描述了 bagging 回归器:</p>
<p class="CDPAlignCenter"><img class="aligncenter67" src="img/9a400a3a-8888-45de-8a81-161d00c22819.png"/></p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Getting ready</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">做好准备</h1>
                
            
            
                
<p class="calibre2">我们首先导入所需的库并读取我们的文件。我们使用<kbd class="calibre12">warnings</kbd>库中的<kbd class="calibre12">warnings.filterwarnings()</kbd>函数来抑制任何警告:</p>
<pre class="calibre18">import warnings<br class="title-page-name"/>warnings.filterwarnings('ignore')<br class="title-page-name"/><br class="title-page-name"/>import os<br class="title-page-name"/>import pandas as pd<br class="title-page-name"/>import numpy as np<br class="title-page-name"/><br class="title-page-name"/>from sklearn.model_selection import train_test_split<br class="title-page-name"/>from sklearn.linear_model import SGDRegressor<br class="title-page-name"/>from sklearn.metrics import mean_squared_error, r2_score<br class="title-page-name"/>from sklearn.utils import resample<br class="title-page-name"/><br class="title-page-name"/>import matplotlib.pyplot as plt<br class="title-page-name"/><br class="title-page-name"/></pre>
<p class="calibre2">我们现在已经设置了工作文件夹。从 GitHub 下载<kbd class="calibre12">autompg.csv</kbd>文件，并复制到你的工作文件夹，如下所示:</p>
<pre class="calibre18">os.chdir('.../.../Chapter 5')<br class="title-page-name"/>os.getcwd()</pre>
<p class="calibre2">我们用<kbd class="calibre12">read_csv()</kbd>读取数据，并在数据帧的名称前加上<kbd class="calibre12">df_</kbd>，这样更容易理解:</p>
<pre class="calibre18">df_autodata = pd.read_csv("autompg.csv")</pre>
<p class="calibre2">我们检查数据集是否有任何缺失值，如下所示:</p>
<pre class="calibre18"># The below syntax returns the column names which has any missing value<br class="title-page-name"/>columns_with_missing_values=df_autodata.columns[df_autodata.isnull().any()]<br class="title-page-name"/><br class="title-page-name"/># We pass the column names with missing values to the dataframe to count the number<br class="title-page-name"/># of missing values<br class="title-page-name"/>df_autodata[columns_with_missing_values].isnull().sum()</pre>
<p class="calibre2">我们注意到<kbd class="calibre12">horsepower</kbd>变量有六个缺失值。我们可以用下面的代码使用<kbd class="calibre12">horsepower</kbd>变量现有值的中值来填充缺失值:</p>
<pre class="calibre18">df_autodata['horsepower'].fillna(df_autodata['horsepower'].median(), inplace=True)</pre>
<p class="calibre2">我们注意到<kbd class="calibre12">carname</kbd>变量是一个标识符，在我们的建模练习中没有用，所以我们可以像下面这样删除它:</p>
<pre class="calibre18">df_autodata.drop(['carname'], axis=1, inplace=True)</pre>
<p class="calibre2">我们可以用<kbd class="calibre12">dataframe.head()</kbd>命令查看数据:</p>
<pre class="calibre18">df_autodata.head()</pre>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>How to do it...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">怎么做...</h1>
                
            
            
                
<p class="calibre2">在本节中，我们将了解如何使用引导示例构建模型:</p>
<ol class="calibre14">
<li class="calibre11">我们从创建引导示例开始。在<a href="6a5a73fc-dba9-4903-a54a-6c79a8ee57b4.xhtml" class="calibre9">第 3 章</a>、<em class="calibre23">重采样方法</em>中，我们编写了一个自定义函数<kbd class="calibre12">create_bootstrap_oob()</kbd>，用于创建引导和<strong class="calibre1">开箱</strong> ( <strong class="calibre1"> OOB </strong>)样本。</li>
</ol>
<p class="calibre20">在下面的代码块中，我们看到了如何创建引导和 OOB 示例:</p>
<pre class="calibre18">def create_bootstrap_oob(df):<br class="title-page-name"/>    global df_OOB<br class="title-page-name"/>    global df_bootstrap_sample <br class="title-page-name"/>    # creating the bootstrap sample<br class="title-page-name"/>    df_bootstrap_sample = resample(df, replace=True, n_samples=100)<br class="title-page-name"/>    <br class="title-page-name"/>    # creating the OOB sample <br class="title-page-name"/>    bootstrap_sample_index = tuple(df_bootstrap_sample.index)<br class="title-page-name"/>    bootstrap_df = df.index.isin(bootstrap_sample_index)<br class="title-page-name"/>    <br class="title-page-name"/>    df_OOB = df[~bootstrap_df]</pre>
<ol start="2" class="calibre14">
<li class="calibre11">我们使用 bootstrap 样本构建模型，并对所有模型的成本函数进行平均。我们在每个引导样本上使用<kbd class="calibre12">SGDRegressor()</kbd>。在下面的代码块中，我们重用之前编写的自定义函数<kbd class="calibre12">create_bootstrap_oob()</kbd>，来创建引导和 OOB 错误示例:</li>
</ol>
<pre class="calibre18">iteration=50<br class="title-page-name"/>mse_each_iterations = list()<br class="title-page-name"/>lm=SGDRegressor()<br class="title-page-name"/>total_mse=0<br class="title-page-name"/>average_mse= list()<br class="title-page-name"/><br class="title-page-name"/>for i in range(iteration):<br class="title-page-name"/>    create_bootstrap_oob(df_autodata)<br class="title-page-name"/><br class="title-page-name"/>    # Bootstrap sample features set<br class="title-page-name"/>    X_BS = df_bootstrap_sample.iloc[:,1:8] <br class="title-page-name"/><br class="title-page-name"/>    # bootstrap sample response variable<br class="title-page-name"/>    Y_BS = df_bootstrap_sample.iloc[:,0] <br class="title-page-name"/><br class="title-page-name"/>    X_OOB = df_OOB.iloc[:,1:8] #OOB sample features<br class="title-page-name"/>    Y_OOB = df_OOB.iloc[:,0] #OOB sample response variable <br class="title-page-name"/>    <br class="title-page-name"/>    # fit your model with bootstrap sample<br class="title-page-name"/>    lm=SGDRegressor()<br class="title-page-name"/>    lm.fit(X_BS, Y_BS)<br class="title-page-name"/>    <br class="title-page-name"/>    # test your model on out-of-bag sample <br class="title-page-name"/>    predictedvalues = lm.predict(X_OOB)<br class="title-page-name"/>    <br class="title-page-name"/>    # capture MSE for the predicted values against OOB actuals<br class="title-page-name"/>    mse = mean_squared_error(Y_OOB, predictedvalues)<br class="title-page-name"/>    <br class="title-page-name"/>    # create a list of mse values<br class="title-page-name"/>    mse_each_iterations.append(mse) </pre>
<ol start="3" class="calibre14">
<li class="calibre11">我们现在将绘制每个模型的 MSE:</li>
</ol>
<pre class="calibre18">import matplotlib.pyplot as plt<br class="title-page-name"/>f, ax= plt.subplots(figsize=(8,6))<br class="title-page-name"/><br class="title-page-name"/>plt.plot(mse_each_iterations, 'c--', label='MSE by Iteration')<br class="title-page-name"/><br class="title-page-name"/>plt.xlabel('Iterations')<br class="title-page-name"/>plt.ylabel('Mean Squared Error')<br class="title-page-name"/>plt.legend(loc=1)<br class="title-page-name"/>plt.show()</pre>
<p class="calibre20">该图将如下所示:</p>
<p class="CDPAlignCenter"><img class="aligncenter68" src="img/f8316674-8694-4913-9562-18dde46e30a7.png"/></p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>How it works...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">它是如何工作的...</h1>
                
            
            
                
<p class="calibre2">在<em class="calibre13">步骤 1 </em>中，我们执行了自定义函数代码来创建<kbd class="calibre12">create_bootstrap_oob()</kbd>函数，该函数为我们创建了引导程序和 OOB 样本。在<em class="calibre13">步骤 2 </em>中，我们执行了以下步骤:</p>
<ol class="calibre14">
<li class="calibre11">我们决定进行 50 次迭代，因此我们将变量<kbd class="calibre12">iteration</kbd>设置为<kbd class="calibre12">50</kbd>。</li>
<li class="calibre11">在每次迭代中，<kbd class="calibre12">create_bootstrap_oob()</kbd>函数返回两个 DataFrame 对象<kbd class="calibre12">df_bootstrap_sample</kbd>和<kbd class="calibre12">df_OOB</kbd>。</li>
<li class="calibre11">我们分别使用<kbd class="calibre12">df_bootstrap_sample</kbd>和<kbd class="calibre12">df_OOB</kbd>作为我们的自举样本和 OOB 样本。</li>
<li class="calibre11">我们将<kbd class="calibre12">df_bootstrap_sample</kbd>和<kbd class="calibre12">df_OOB</kbd>样本分成特征集和响应变量。</li>
<li class="calibre11">我们将<kbd class="calibre12">SGDRegressor()</kbd>与我们的 bootstrap 样本相匹配来构建我们的模型。</li>
<li class="calibre11">我们将 OOB 样本传递给模型来预测我们的值。</li>
</ol>
<ol start="7" class="calibre14">
<li class="calibre11">我们将预测值与 OOB 样本中的响应变量进行了比较。</li>
<li class="calibre11">我们计算了每次迭代的 MSE。</li>
</ol>
<p class="calibre2">在<em class="calibre13">步骤 3 </em>中，我们创建了一个图来显示从第 50 次迭代到每次迭代的 MSE。由于随机性，这个结果可能会有所不同。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>See also</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">请参见</h1>
                
            
            
                
<ul class="calibre10">
<li class="calibre11">利奥·布雷曼于 1994 年 9 月发表的《装袋预测》</li>
</ul>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Ensemble meta-estimators</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">集成元估计量</h1>
                
            
            
                
<p class="calibre2">bagging 分类器和 bagging 回归器是集合元估计器，它们分别在原始数据集的随机子集上拟合基本分类器和回归器模型。来自每个模型的预测被组合以创建最终预测。这些元估计量将随机化引入模型构建过程，并汇总结果。该聚集对数值目标变量的迭代求平均值，并执行多次投票以达到分类结果。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Bagging classifiers</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">袋装分类器</h1>
                
            
            
                
<p class="calibre2">Bagging 分类器在原始训练集的随机子集上训练每个分类器模型，并聚集预测，然后对分类结果执行多元投票。在下面的食谱中，我们将研究一个带有引导样本的装袋分类器的实现。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>How to do it...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">怎么做...</h1>
                
            
            
                
<ol class="calibre14">
<li class="calibre11">我们从<kbd class="calibre12">scikit-learn</kbd>库中导入<kbd class="calibre12">BaggingClassifier</kbd>和<kbd class="calibre12">DecisionTreeClassifier</kbd>。我们还导入其他所需的库，如下所示:</li>
</ol>
<pre class="calibre18">from sklearn.ensemble import BaggingClassifier<br class="title-page-name"/>from sklearn.tree import DecisionTreeClassifier<br class="title-page-name"/>from sklearn.model_selection import train_test_split</pre>
<p class="calibre2"/>
<ol start="2" class="calibre14">
<li class="calibre11">接下来，我们读出数据并查看尺寸:</li>
</ol>
<pre class="calibre18">df_winedata = pd.read_csv('winedata.csv')<br class="title-page-name"/>df_winedata.shape</pre>
<ol start="3" class="calibre14">
<li class="calibre11">我们将特征和响应集分开。我们还将数据分成训练和测试子集。</li>
</ol>
<pre class="calibre18">X = df_winedata.iloc[:,1:14]<br class="title-page-name"/>Y = df_winedata.iloc[:,0]<br class="title-page-name"/><br class="title-page-name"/>X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=1)</pre>
<ol start="4" class="calibre14">
<li class="calibre11">我们创建了一个<kbd class="calibre12">DecisionTreeClassifier</kbd>类的实例，并将其传递给<kbd class="calibre12">BaggingClassifier()</kbd>:</li>
</ol>
<pre class="calibre18">dt_model = DecisionTreeClassifier(criterion='entropy')<br class="title-page-name"/>bag_dt_model = BaggingClassifier(dt_model, max_features=1.0, n_estimators=5, \<br class="title-page-name"/>                                 random_state=1, bootstrap=True)</pre>
<p>注意，在前面的代码块中，我们声明了<kbd class="calibre19">bootstrap=True</kbd>。这是默认值，表示使用替换绘制样本。</p>
<ol start="5" class="calibre14">
<li class="calibre11">我们将模型拟合到训练数据，如下所示:</li>
</ol>
<pre class="calibre18">bag_dt_model.fit(X_train, Y_train)</pre>
<ol start="6" class="calibre14">
<li class="calibre11">我们可以在将测试数据传递给模型后看到分数:</li>
</ol>
<pre class="calibre18">bag_dt_model.score(X_test, Y_test)</pre>
<ol start="7" class="calibre14">
<li class="calibre11">我们使用<kbd class="calibre12">predict</kbd>函数预测响应变量，如下所示:</li>
</ol>
<pre class="calibre18">predictedvalues = bag_dt_model.predict(X_test)</pre>
<ol start="8" class="calibre14">
<li class="calibre11">我们现在将使用一个代码来绘制混淆矩阵。请注意，这段代码来自 scikit-learn.org。我们执行下面的代码来创建<kbd xmlns:epub="http://www.idpf.org/2007/ops" class="calibre12">plot_confusion_matrix()</kbd>函数:</li>
</ol>
<pre class="calibre18"># code from <br class="title-page-name"/># http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html<br class="title-page-name"/>def plot_confusion_matrix(cm, classes,<br class="title-page-name"/>                          normalize=False,<br class="title-page-name"/>                          title='Confusion matrix',<br class="title-page-name"/>                          cmap=plt.cm.Blues):<br class="title-page-name"/>    """<br class="title-page-name"/>    This function prints and plots the confusion matrix.<br class="title-page-name"/>    """<br class="title-page-name"/>    plt.imshow(cm, interpolation='nearest', cmap=cmap)<br class="title-page-name"/>    plt.title(title)<br class="title-page-name"/>    plt.colorbar()<br class="title-page-name"/>    tick_marks = np.arange(len(classes))<br class="title-page-name"/>    plt.xticks(tick_marks, classes, rotation=45)<br class="title-page-name"/>    plt.yticks(tick_marks, classes)<br class="title-page-name"/><br class="title-page-name"/>    thresh = cm.max() / 2.<br class="title-page-name"/>    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):<br class="title-page-name"/>        plt.text(j, i, cm[i, j],<br class="title-page-name"/>                 horizontalalignment="center",<br class="title-page-name"/>                 color="white" if cm[i, j] &gt; thresh else "black")<br class="title-page-name"/><br class="title-page-name"/>    plt.tight_layout()<br class="title-page-name"/>    plt.ylabel('Actuals')<br class="title-page-name"/>    plt.xlabel('Predicted')</pre>
<ol start="9" class="calibre14">
<li class="calibre11">我们使用前面的<kbd class="calibre12">plot_confusion_matrix()</kbd>函数来绘制混淆矩阵:</li>
</ol>
<pre class="calibre18"># This variable holds the class labels of our target variable<br class="title-page-name"/>target_names = [ '1', '2', '3']<br class="title-page-name"/><br class="title-page-name"/>import itertools<br class="title-page-name"/>from sklearn.metrics import confusion_matrix<br class="title-page-name"/><br class="title-page-name"/># Constructing the Confusion Matrix<br class="title-page-name"/>cm = confusion_matrix(Y_test, predictedvalues)<br class="title-page-name"/><br class="title-page-name"/># Plotting the confusion matrix<br class="title-page-name"/>plt.figure(figsize=(3,3))<br class="title-page-name"/>plot_confusion_matrix(cm, classes=target_names, normalize=False)<br class="title-page-name"/>plt.show()</pre>
<p class="calibre20">混淆矩阵图如下所示:</p>
<p class="CDPAlignCenter"><img class="aligncenter69" src="img/a6309b5b-fc95-44fc-94d1-6d5607f77a59.png"/></p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>How it works...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">它是如何工作的...</h1>
                
            
            
                
<p class="calibre2">在<em class="calibre13">步骤 1 </em>中，我们使用 bagging 分类器导入了所需的库来构建决策树分类器模型。在<em class="calibre13">步骤 2 </em>中，我们读取我们的数据集，即<kbd class="calibre12">winedata.csv</kbd>。在<em class="calibre13">步骤 3 </em>中，我们分离了我们的特征集和目标变量。我们还将数据分成训练和测试子集。在<em class="calibre13">步骤 4 </em>中，我们创建了一个决策树分类器模型，并将其传递给<kbd class="calibre12">BaggingClassifier()</kbd>。在<kbd class="calibre12">DecisionTreeClassifier()</kbd>中，<kbd class="calibre12">criterion</kbd>参数的默认值是<kbd class="calibre12">gini</kbd>，但是我们将其更改为<kbd class="calibre12">entropy</kbd>。然后，我们将决策树模型传递给<kbd class="calibre12">BaggingClassfier()</kbd>。在<kbd class="calibre12">BaggingClassfier()</kbd>中，我们有包括<kbd class="calibre12">n_estimators</kbd>和<kbd class="calibre12">bootstrap</kbd>的参数。<kbd class="calibre12">n_estimators</kbd>是集合中基本估计量的数量，默认值为<kbd class="calibre12">10</kbd>。<kbd class="calibre12">bootstrap</kbd>参数表示是否用替换抽取样品，默认设置为<kbd class="calibre12">True</kbd>。</p>
<div><div><p class="calibre2">在<em class="calibre13">步骤 5 </em>和<em class="calibre13">步骤</em> <em class="calibre13"> 6 </em>中，我们将我们的模型拟合到训练数据中，并查看测试集的分数。在<em class="calibre13">步骤 7 </em>中，我们调用了<kbd class="calibre12">predict()</kbd>方法并通过了测试特性集。在<em class="calibre13">步骤 8 </em>中，我们添加了来自<a href="http://scikit-learn.org" class="calibre9">http://scikit-learn.org</a>的<kbd class="calibre12">plot_confusion_matrix()</kbd>的代码，它将混淆矩阵作为其输入参数之一，并绘制混淆矩阵。在<em class="calibre13">步骤 9 </em>中，我们通过传递混淆矩阵来调用<kbd class="calibre12">plot_confusion_matrix()</kbd>函数，以生成混淆矩阵图。</p>
</div>
</div>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>There's more...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">还有更多...</h1>
                
            
            
                
<p class="calibre2">我们也可以使用<kbd class="calibre12">sklearn.model_selection</kbd>中的<kbd class="calibre12">GridSearchCV()</kbd>来网格搜索最佳参数，并在<kbd class="calibre12">BaggingClassifier</kbd>中使用它们:</p>
<ol class="calibre14">
<li class="calibre11">首先，我们导入所需的库:</li>
</ol>
<pre class="calibre18">from sklearn.model_selection import GridSearchCV</pre>
<ol start="2" class="calibre14">
<li class="calibre11">然后，我们设置参数值:</li>
</ol>
<pre class="calibre18">param_values = {'n_estimators': [10, 20, 25, 30], 'base_estimator__max_leaf_nodes':[5, 10, 15, 20], 'base_estimator__max_depth':[3, 4, 5]}</pre>
<ol start="3" class="calibre14">
<li class="calibre11">我们实例化我们的<kbd class="calibre12">DecisionTreeClassifier</kbd>类，并将其传递给<kbd class="calibre12">BaggingClassifier()</kbd>函数。请注意，我们将<kbd class="calibre12">oob_score</kbd>设置为<kbd class="calibre12">True</kbd>来评估基于 OOB 样本构建的模型:</li>
</ol>
<pre class="calibre18">dt_model = DecisionTreeClassifier()<br class="title-page-name"/>bag_dt_model_grid = BaggingClassifier(base_estimator=dt_model, oob_score=True, random_state=1) </pre>
<ol start="4" class="calibre14">
<li class="calibre11">我们使用<kbd class="calibre12">GridSearchCV()</kbd>来确定最佳参数:</li>
</ol>
<pre class="calibre18">bc_grid = GridSearchCV(estimator=bag_dt_model_grid, param_grid=param_values, cv=20, n_jobs=-1)<br class="title-page-name"/>bc_grid.fit(X_train, Y_train)<br class="title-page-name"/>best_params = bc_grid.best_params_<br class="title-page-name"/>print(best_params)</pre>
<p class="calibre20">前面的代码返回最佳参数:</p>
<p class="CDPAlignCenter"><img class="aligncenter70" src="img/11224b03-0e99-4ce4-beb7-7d3cd26242fb.png"/></p>
<ol start="5" class="calibre14">
<li class="calibre11">我们现在获取由<kbd class="calibre12">bc_grid.bestparams</kbd>返回的值，并使用<kbd class="calibre12">BaggingClassfier()</kbd>函数重建我们的决策树模型。我们为<kbd class="calibre12">max_leaf_nodes</kbd>传递<kbd class="calibre12">10</kbd>，为<kbd class="calibre12">max_depth</kbd>传递<kbd class="calibre12">3</kbd>，为<kbd class="calibre12">n_estimators</kbd>传递<kbd class="calibre12">20</kbd>:</li>
</ol>
<pre class="calibre18">best_dt_model = DecisionTreeClassifier(criterion='entropy', max_leaf_nodes=10, max_depth=3) <br class="title-page-name"/>final_bag_dt_model = BaggingClassifier(base_estimator=best_dt_model, n_estimators=150, bootstrap=True, random_state=1, oob_score=True)</pre>
<p class="calibre20">我们在前面的代码块中将<kbd class="calibre12">n_estimators</kbd>设置为<kbd class="calibre12">150</kbd>。<kbd class="calibre12">n_estimators</kbd>参数表示我们想要构建的树的数量。我们将最终模型与训练数据进行拟合，并使用测试特征集进行预测。</p>
<ol start="6" class="calibre14">
<li class="calibre11">然后，我们可以在下面的代码块中查看我们的 OOB 样本的准确性:</li>
</ol>
<pre class="calibre18">final_bag_dt_model.fit(X_train, Y_train)<br class="title-page-name"/>bag_predictedvalues = final_bag_dt_model.predict(X_test)<br class="title-page-name"/><br class="title-page-name"/># See the OOB accuracy<br class="title-page-name"/>acc_oob = final_bag_dt_model.oob_score_<br class="title-page-name"/>print(acc_oob)</pre>
<p class="calibre2">如果我们绘制我们的混淆矩阵，我们可以看到我们在错误分类的数量上有所改进。在前面的示例中，类别 2 的两个实例被错误地预测为类别 3，但是我们现在可以看到错误分类的数量已经减少到一个:</p>
<p class="CDPAlignCenter"><img class="aligncenter71" src="img/2ab6bb14-572f-47c8-a678-f7331a597e13.png"/></p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>See also</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">请参见</h1>
                
            
            
                
<ul class="calibre10">
<li class="calibre11">打包分类器的学习指南:<a href="https://bit.ly/2zaq8lS" class="calibre9">https://bit.ly/2zaq8lS</a></li>
</ul>
<p class="calibre2"/>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Bagging regressors</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">装袋回归量</h1>
                
            
            
                
<p class="calibre2">Bagging 回归元类似于 bagging 分类器。他们在原始训练集的随机子集上训练每个回归模型，并聚合预测。然后，因为目标变量是数字，所以聚合在迭代中求平均值。在下面的食谱中，我们将展示一个带有引导样本的装袋回归器的实现。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Getting ready</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">做好准备</h1>
                
            
            
                
<p class="calibre2">我们将分别从<kbd class="calibre12">sklearn.ensemble</kbd>和<kbd class="calibre12">sklearn.tree</kbd>导入所需的库<kbd class="calibre12">BaggingRegressor</kbd>和<kbd class="calibre12">DecisionTreeRegressor</kbd>:</p>
<pre class="calibre15">from sklearn.ensemble import BaggingRegressor<br class="title-page-name"/>from sklearn.tree import DecisionTreeRegressor</pre>
<p class="calibre2">我们读取数据集<kbd class="calibre12">bostonhousing.csv</kbd>，并查看数据帧的维度:</p>
<pre class="calibre15">df_housingdata = pd.read_csv('bostonhousing.csv')<br class="title-page-name"/>df_housingdata.shape</pre>
<p class="calibre2">我们现在继续创建我们的特性集和目标变量集。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>How to do it...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">怎么做...</h1>
                
            
            
                
<ol start="1" class="calibre14">
<li class="calibre11">我们首先分离我们的特征和响应集。我们还将在下面的代码块中把数据分成训练和测试子集:</li>
</ol>
<pre class="calibre18">X = df_housingdata.iloc[:,1:14]<br class="title-page-name"/>Y = df_housingdata.iloc[:,-1]<br class="title-page-name"/><br class="title-page-name"/>X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=1)</pre>
<ol start="2" class="calibre14">
<li class="calibre11">然后我们将创建一个<kbd class="calibre12">DecisionTreeClassifier</kbd>类的实例，并将其传递给<kbd class="calibre12">BaggingClassifier()</kbd>函数:</li>
</ol>
<pre class="calibre18">dt_model = DecisionTreeRegressor()<br class="title-page-name"/>bag_dt_model = BaggingRegressor(dt_model, max_features=1.0, n_estimators=5, bootstrap=True, random_state=1, )</pre>
<ol start="3" class="calibre14">
<li class="calibre11">我们将使我们的模型符合训练数据集，如下所示:</li>
</ol>
<pre class="calibre18">bag_dt_model.fit(X_train, Y_train)</pre>
<ol start="4" class="calibre14">
<li class="calibre11">我们可以在下面的代码块中看到模型得分:</li>
</ol>
<pre class="calibre18">bag_dt_model.score(X_test, Y_test)</pre>
<ol start="5" class="calibre14">
<li class="calibre11">我们使用<kbd class="calibre12">predict()</kbd>函数并通过测试数据集来预测我们的目标变量，如下所示:</li>
</ol>
<pre class="calibre18">predictedvalues = bag_dt_model.predict(X_test)</pre>
<ol start="6" class="calibre14">
<li class="calibre11">我们使用以下代码绘制目标变量的实际值和预测值的散点图:</li>
</ol>
<pre class="calibre18">#We can plot the actuals and the predicted values <br class="title-page-name"/>plt.figure(figsize=(4, 4))<br class="title-page-name"/>plt.scatter(Y_test, predictedvalues)<br class="title-page-name"/>plt.xlabel('Actual')<br class="title-page-name"/>plt.ylabel('Predicted')<br class="title-page-name"/>plt.tight_layout()</pre>
<p class="calibre20">执行前面的代码会得到下面的散点图:</p>
<p class="CDPAlignCenter"><img class="aligncenter72" src="img/efe7575b-b3c6-4059-8454-653ce7268e60.png"/></p>
<p><kbd class="calibre19">matplotlib.pyplot.tight_layout()</kbd>自动调整子情节参数以创建指定的填充。</p>
<p class="calibre2"/>
<ol start="7" class="calibre14">
<li class="calibre11">我们现在将以下代码中的<kbd class="calibre12">n_estimators</kbd>参数更改为 30，并重新执行从<em class="calibre23">步骤 3 </em>到<em class="calibre23">步骤 6 </em>的步骤:</li>
</ol>
<pre class="calibre18">bag_dt_model = BaggingRegressor(dt_model, max_features=1.0, n_estimators=30, bootstrap=True, random_state=1, )</pre>
<p class="calibre20">这给了我们以下分数:</p>
<p class="CDPAlignCenter"><img class="aligncenter73" src="img/bbf118f9-2223-46e4-9f14-575e7f0f64c9.png"/></p>
<ol start="8" class="calibre14">
<li class="calibre11">实际值与预测值的关系如下图所示。这向我们展示了，当我们将<kbd class="calibre12">n_estimator</kbd>参数的值从<kbd class="calibre12">5</kbd>更改为<kbd class="calibre12">30</kbd>时，预测的值比之前的情况更准确:</li>
</ol>
<p class="CDPAlignCenter"><img class="aligncenter74" src="img/62df9a66-8da7-4b7d-b9e9-8389e017f331.png"/></p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>How it works...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">它是如何工作的...</h1>
                
            
            
                
<p class="calibre2">在<em class="calibre13">步骤 1 </em>中，我们分离了特征和目标变量集。我们还将数据分成训练和测试子集。在<em class="calibre13">步骤 2 </em>中，我们创建了一个决策树回归器模型，并将其传递给<kbd class="calibre12">BaggingRegressor()</kbd>函数。注意，我们还将<kbd class="calibre12">n_estimator=5</kbd>参数传递给了<kbd class="calibre12">BaggingRegressor()</kbd>函数。如前所述，<kbd class="calibre12">n_estimator</kbd>是我们希望算法构建的森林中的树的数量。在<em class="calibre13">步骤 3 </em>中，我们训练了我们的模型。</p>
<p class="calibre2"/>
<p class="calibre2">在<em class="calibre13">步骤 4 </em>中，我们看了一下模型得分，是 0.71。在<em class="calibre13">步骤 5 </em>中，我们使用<kbd class="calibre12">predict()</kbd>函数来预测测试子集的目标变量。之后，在<em class="calibre13">步骤 6 </em>中，我们绘制了散点图来探究实际目标值和预测目标值之间的关系。</p>
<p class="calibre2">在<em class="calibre13">步骤 7 </em>中，我们将<kbd class="calibre12">n_estimator</kbd>参数的值从<kbd class="calibre12">5</kbd>更改为<kbd class="calibre12">30</kbd>，并重新构建我们的模型。这一次，我们注意到模型得分提高到 0.82。在<em class="calibre13">步骤 8 </em>中，我们绘制了实际值和预测值，发现实际值和预测值之间的相关性比我们之前使用<kbd class="calibre12">n_estimators=5</kbd>的模型好得多。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>See also</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">请参见</h1>
                
            
            
                
<ul class="calibre10">
<li class="calibre11">sci kit-bagging 回归元学习指南:<a href="https://bit.ly/2pZFmUh" class="calibre9">https://bit.ly/2pZFmUh</a></li>
<li class="calibre11">单一估计量与打包法:<a href="https://bit.ly/2q08db6" class="calibre9">https://bit.ly/2q08db6</a></li>
</ul>


            

            
        
    </body>

</html>
</body></html>