<html><head/><body>
<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Homogeneous Ensembles Using Keras</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">使用 Keras 的同质系综</h1>
                
            
            
                
<p class="calibre2">在本章中，我们将讨论以下主题:</p>
<ul class="calibre10">
<li class="calibre11">能量预测的均匀模式集合</li>
<li class="calibre11">用于手写数字分类的同质模型集成</li>
</ul>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Introduction</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">介绍</h1>
                
            
            
                
<p class="calibre2">在集成模型的情况下，每个基本分类器本身必须具有一定程度的多样性。这种多样性可以通过以下方式之一获得:</p>
<ul class="calibre10">
<li class="calibre11">通过各种重采样方法或训练数据的随机化来使用训练数据的不同子集</li>
<li class="calibre11">通过对不同的基础学习者使用不同的学习超参数</li>
<li class="calibre11">通过使用不同的学习算法</li>
</ul>
<p class="calibre2">在集成模型的情况下，不同的算法用于基础学习器，集成被称为<strong class="calibre4">异构集成方法</strong>。如果对训练集的不同分布的所有基本学习者使用相同的算法，则该集成被称为<strong class="calibre4">同质集成</strong>。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>An ensemble of homogeneous models for energy prediction</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">能量预测的均匀模式集合</h1>
                
            
            
                
<p class="calibre2">在下面的例子中，我们将使用 Keras API。Keras 是一个用于构建深度神经网络的开源高级框架。它写在 TensorFlow 或 Theano 之上，并在幕后使用它们进行计算。Keras 既可以在 CPU 上运行，也可以在 GPU 上运行。Keras 的默认设置旨在大多数情况下提供良好的结果。</p>
<p class="calibre2"/>
<p class="calibre2">Keras 的重点是模型的概念。Keras 支持两种类型的模型。模型的主要类型是一系列层，称为<strong class="calibre4">顺序</strong>。Keras 中的另一类模型是非顺序模型，称为<strong class="calibre4">模型</strong>。</p>
<p class="calibre2">要构建顺序模型，请执行以下步骤:</p>
<ol class="calibre14">
<li class="calibre11">使用<kbd class="calibre12">Sequential()</kbd>实例化顺序模型</li>
<li class="calibre11">使用<kbd class="calibre12">Dense</kbd>类一个接一个地添加图层</li>
<li class="calibre11">使用以下内容编译模型:<ul class="calibre41">
<li class="calibre11">强制损失函数</li>
<li class="calibre11">强制优化器</li>
<li class="calibre11">可选评估参数</li>
</ul>
</li>
<li class="calibre11">使用数据来拟合模型</li>
<li class="calibre11">评估模型</li>
</ol>
<p class="calibre2">以下是前面步骤的流程图:</p>
<p class="CDPAlignCenter"><img src="img/f89f4516-767a-4737-a6a6-dd1e6b30bd1d.png" class="calibre56"/></p>
<p class="calibre2">在下面的代码块中，我们可以看到一个简短的代码示例:</p>
<pre class="calibre18"># Instantiate a sequential model<br class="title-page-name"/>seqmodel = Sequential()<br class="title-page-name"/><br class="title-page-name"/># Add layers using the Dense class<br class="title-page-name"/>seqmodel.add(Dense8, activation='relu')<br class="title-page-name"/><br class="title-page-name"/># Compile the model<br class="title-page-name"/>seqmodel.compile(loss='binary_crossentropy, optimizer='adam', metric=['accuracy'])<br class="title-page-name"/><br class="title-page-name"/># Fit the model<br class="title-page-name"/>seqmodel.fit(X_train, Y_train, batch_size=10)</pre>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Getting ready</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">做好准备</h1>
                
            
            
                
<p class="calibre2">我们将从安装 Keras 开始。为了安装 Keras，您需要在系统中安装 Theano 或 TensorFlow。在这个例子中，我们将使用 TensorFlow 作为 Keras 的后端。</p>
<p class="calibre2">TensorFlow 有两个版本:CPU 版本和 GPU 版本。</p>
<p class="calibre2">要安装当前的纯 CPU 版本，请使用以下命令:</p>
<pre class="calibre15">pip install tensorflow</pre>
<p class="calibre2">如果您必须安装 GPU 包，请使用以下命令:</p>
<pre class="calibre15">pip install tensorflow-gpu</pre>
<p class="calibre2">安装 TensorFlow 后，您需要使用以下命令安装 Keras:</p>
<pre class="calibre15">sudo pip install keras</pre>
<p class="calibre2">为了升级已经安装的 Keras 库，请使用以下命令:</p>
<pre class="calibre15">sudo pip install --upgrade keras</pre>
<p class="calibre2">安装完库后，让我们导入所需的库:</p>
<pre class="calibre15">import os<br class="title-page-name"/>import pandas as pd<br class="title-page-name"/>import numpy as np<br class="title-page-name"/>from sklearn.model_selection import train_test_split<br class="title-page-name"/><br class="title-page-name"/>from sklearn.metrics import mean_squared_error<br class="title-page-name"/><br class="title-page-name"/>from keras.models import Sequential<br class="title-page-name"/>from keras.layers import Dense</pre>
<p class="calibre2">我们根据自己的需求设置工作目录:</p>
<pre class="calibre15">os.chdir("..../Chapter 9")<br class="title-page-name"/>os.getcwd()</pre>
<p class="calibre2">我们阅读了我们的<kbd class="calibre12">energydata.csv</kbd>数据集:</p>
<pre class="calibre15">df_energydata = pd.read_csv("energydata.csv")</pre>
<p class="calibre2">我们检查数据集中是否有空值:</p>
<pre class="calibre15">df_energydata.isnull().sum() </pre>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>How to do it...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">怎么做...</h1>
                
            
            
                
<p class="calibre2">我们现在将构建我们的<kbd class="calibre12">test</kbd>子集，并训练我们的神经网络模型:</p>
<ol class="calibre14">
<li class="calibre11">分离<kbd class="calibre12">test</kbd>子集以应用模型，从而进行预测:</li>
</ol>
<pre class="calibre18">df_traindata, df_testdata = train_test_split(df_energydata, test_size=0.3)</pre>
<ol start="2" class="calibre14">
<li class="calibre11">检查<kbd class="calibre12">train </kbd>和<kbd class="calibre12">test</kbd>子集的形状:</li>
</ol>
<pre class="calibre18">print(df_traindata.shape)<br class="title-page-name"/>print(df_testdata.shape)</pre>
<ol start="3" class="calibre14">
<li class="calibre11">取<kbd class="calibre12">test</kbd>子集并将其分成目标和特征变量:</li>
</ol>
<pre class="calibre18">X_test = df_testdata.iloc[:,3:27] <br class="title-page-name"/>Y_test = df_testdata.iloc[:,28] </pre>
<ol start="4" class="calibre14">
<li class="calibre11">通过检查<kbd class="calibre12">X_test</kbd>和<kbd class="calibre12">Y_test</kbd>的形状来验证之前的分割:</li>
</ol>
<pre class="calibre18">print(X_test.shape)<br class="title-page-name"/>print(Y_test.shape)</pre>
<ol start="5" class="calibre14">
<li class="calibre11">让我们使用 Keras 创建多个神经网络模型。我们使用<kbd class="calibre12">For...Loop</kbd>来构建多个模型:</li>
</ol>
<pre class="calibre18">ensemble = 20<br class="title-page-name"/>frac = 0.7<br class="title-page-name"/><br class="title-page-name"/>predictions_total = np.zeros(5921, dtype=float)<br class="title-page-name"/><br class="title-page-name"/>for i in range(ensemble):<br class="title-page-name"/>    print("number of iteration:", i)<br class="title-page-name"/>    print("predictions_total", predictions_total)<br class="title-page-name"/><br class="title-page-name"/>    # Sample randomly the train data<br class="title-page-name"/>    Traindata = df_traindata.sample(frac=frac)<br class="title-page-name"/>    X_train = Traindata.iloc[:,3:27] <br class="title-page-name"/>    Y_train = Traindata.iloc[:,28] <br class="title-page-name"/>    <br class="title-page-name"/><br class="title-page-name"/>    ############################################################<br class="title-page-name"/>    <br class="title-page-name"/>    model = Sequential()<br class="title-page-name"/>    # Adding the input layer and the first hidden layer<br class="title-page-name"/>    model.add(Dense(units=16, kernel_initializer = 'normal', activation = 'relu', input_dim = 24))<br class="title-page-name"/><br class="title-page-name"/>    # Adding the second hidden layer<br class="title-page-name"/>    model.add(Dense(units = 24, kernel_initializer = 'normal', activation = 'relu'))<br class="title-page-name"/>    <br class="title-page-name"/>    # Adding the third hidden layer<br class="title-page-name"/>    model.add(Dense(units = 32, kernel_initializer = 'normal', activation = 'relu'))<br class="title-page-name"/><br class="title-page-name"/>    # Adding the output layer<br class="title-page-name"/>    model.add(Dense(units = 1, kernel_initializer = 'normal', activation = 'relu'))<br class="title-page-name"/><br class="title-page-name"/>    # Compiling the ANN<br class="title-page-name"/>    adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.9, epsilon=None, decay=0.0)<br class="title-page-name"/>    model.compile(loss='mse', optimizer=adam, metrics=['mean_squared_error'])<br class="title-page-name"/>    # Fitting the ANN to the Training set<br class="title-page-name"/><br class="title-page-name"/>    model.fit(X_train, Y_train, batch_size = 16, epochs = 25)<br class="title-page-name"/><br class="title-page-name"/>    ############################################################<br class="title-page-name"/>    <br class="title-page-name"/>    # We use predict() to predict our values<br class="title-page-name"/>    model_predictions = model.predict(X_test)<br class="title-page-name"/>    <br class="title-page-name"/>    model_predictions = model_predictions.flatten()<br class="title-page-name"/>    print("TEST MSE for individual model: ", mean_squared_error(Y_test, model_predictions))<br class="title-page-name"/>    print("")<br class="title-page-name"/>    print(model_predictions)<br class="title-page-name"/>    print("")<br class="title-page-name"/><br class="title-page-name"/>predictions_total = np.add(predictions_total, model_predictions)</pre>
<ol start="6" class="calibre14">
<li class="calibre11">取预测值之和，除以迭代次数，得到平均预测值。我们使用平均预测值来计算集合的<strong class="calibre1">均方误差</strong> ( <strong class="calibre1"> MSE </strong>):</li>
</ol>
<pre class="calibre18">predictions_total = predictions_total/ensemble<br class="title-page-name"/>print("MSE after ensemble: ", mean_squared_error(np.array(Y_test), predictions_total))</pre>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>How it works...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">它是如何工作的...</h1>
                
            
            
                
<p class="calibre2">以下是整体同质模型工作流程的图示:</p>
<p class="CDPAlignCenter"><img src="img/e78d32ca-81b3-482a-9bd6-5ece7e724693.png" class="calibre33"/></p>
<p class="calibre2"/>
<p class="calibre2"/>
<p class="calibre2">在上图中，我们假设有 100 个训练样本。我们在 100 个训练样本上训练 100 个模型，并将它们应用于我们的测试样本。我们得到了 100 组预测，无论目标变量是数值变量还是我们正在计算分类问题的概率，我们都通过平均来集合这些预测。在类预测的情况下，我们会选择最大投票。</p>
<p class="calibre2">在<em class="calibre13">步骤 1 </em>中，我们分离了我们的训练样本和测试样本。这是我们在这个食谱中建立的所有模型中用于预测的同一个测试样本。在<em class="calibre13">步骤 2 </em>中，我们检查了<kbd class="calibre12">train</kbd>和<kbd class="calibre12">test</kbd>子集的形状。在<em class="calibre13">步骤 3 </em>中，我们将测试子集分成目标变量和预测变量，然后在<em class="calibre13">步骤 4 </em>中再次检查形状，以确保我们得到正确的分割。</p>
<p class="calibre2">在<em class="calibre13">步骤 5 </em>中，我们使用 Keras 库来构建我们的神经网络模型。我们初始化两个变量，<kbd class="calibre12">ensemble</kbd>和<kbd class="calibre12">frac</kbd>。我们使用了<kbd class="calibre12">ensemble</kbd>变量来运行一个<kbd class="calibre12">for</kbd>循环，重复一定次数(在我们的例子中，我们将其设置为<kbd class="calibre12">200</kbd>)。然后，我们使用<kbd class="calibre12">frac</kbd>变量来分配我们从训练子集中抽取的引导样本的数据比例。在我们的例子中，我们将<kbd class="calibre12">frac</kbd>设置为<kbd class="calibre12">0.8</kbd>。</p>
<p class="calibre2">在<em class="calibre13">步骤 5 </em>中，在<kbd class="calibre12">for...loop</kbd>迭代中，我们构建了多个神经网络模型，并将这些模型应用于我们的测试子集以获得预测。我们通过使用<kbd class="calibre12">add()</kbd>方法传递一系列层来创建顺序模型。在第一层中，我们使用<kbd class="calibre12">input_dim</kbd>参数指定输入维度。因为我们有 24 个输入维度，所以我们将<kbd class="calibre12">input_dim</kbd>设置为<kbd class="calibre12">24</kbd>。我们还提到了通过设置<kbd class="calibre12">Activation</kbd>参数在每个层中使用的<kbd class="calibre12">Activation</kbd>函数。</p>
<p class="calibre2">您也可以通过<kbd class="calibre12">Activation</kbd>层设置<kbd class="calibre12">Activation</kbd>功能，如下所示:</p>
<pre class="calibre15"># Example code to set activation function through the activation layer<br class="title-page-name"/><br class="title-page-name"/>from keras.layers import Activation, Dense <br class="title-page-name"/><br class="title-page-name"/>model.add(Dense(64)) <br class="title-page-name"/>model.add(Activation('tanh'))</pre>
<p class="calibre2">在这一步中，在我们构建模型之前，我们使用<kbd class="calibre12">compile</kbd>方法配置学习过程。<kbd class="calibre12">compile</kbd>方法以强制<kbd class="calibre12">loss function</kbd>、强制<kbd class="calibre12">optimizer</kbd>和可选<kbd class="calibre12">metrics</kbd>作为参数。</p>
<p class="calibre2"><kbd class="calibre12">optimizer</kbd>参数可以取值为<strong class="calibre4">随机梯度下降</strong> ( <strong class="calibre4"> SGD </strong>)、<kbd class="calibre12">RMSprop</kbd>、<kbd class="calibre12">Adagrad</kbd>、<kbd class="calibre12">Adadelta</kbd>、<kbd class="calibre12">Adam</kbd>、<kbd class="calibre12">Adamax</kbd>或<kbd class="calibre12">Nadam</kbd>。</p>
<p class="calibre2"><kbd xmlns:epub="http://www.idpf.org/2007/ops" class="calibre12">loss function</kbd>可以取值为<kbd xmlns:epub="http://www.idpf.org/2007/ops" class="calibre12">mean_squared_error</kbd>、<kbd xmlns:epub="http://www.idpf.org/2007/ops" class="calibre12">mean_absolute_error</kbd>、<kbd xmlns:epub="http://www.idpf.org/2007/ops" class="calibre12">mean_absolute_percentage_error</kbd>、<kbd xmlns:epub="http://www.idpf.org/2007/ops" class="calibre12">mean_squared_logarithmic_error</kbd>、<kbd xmlns:epub="http://www.idpf.org/2007/ops" class="calibre12">squared_hinge</kbd>、<kbd xmlns:epub="http://www.idpf.org/2007/ops" class="calibre12">categorical_hinge</kbd>或<kbd xmlns:epub="http://www.idpf.org/2007/ops" class="calibre12">binary_crossentropy</kbd>。更多详情请见 https://keras.io/losses/。</p>
<p class="calibre2">我们还使用<kbd class="calibre12">np.add()</kbd>方法将预测数组添加到一个名为<kbd class="calibre12">predictions_total</kbd>的数组变量中。</p>
<p class="calibre2">一旦我们在<em class="calibre13">步骤 5 </em>中完成了<kbd class="calibre12">for</kbd>循环中的所有迭代，我们将预测的总和除以迭代次数，迭代次数保存在<kbd class="calibre12">ensemble</kbd>变量中并设置为<kbd class="calibre12">200</kbd>，以获得平均预测。我们使用平均预测来计算集合结果的 MSE。</p>
<p class="calibre2">还有更多...</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>There's more...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">如果对计算要求高，可以使用 Google Colaboratory。Colaboratory 是一个免费的 Jupyter 笔记本环境，不需要设置，完全在云中运行。是支持免费 GPU 的免费云服务。您可以使用 Google Colab 来构建使用 TensorFlow、Keras、PyTorch 和 OpenCV 的深度学习应用程序。</h1>
                
            
            
                
<p class="calibre2">一旦你用<a href="https://colab.research.google.com/" class="calibre9">https://colab.research.google.com/</a>创建了你的账户，你就可以用你的凭证登录了。</p>
<p class="calibre2">登录后，您可以直接进入<kbd class="calibre12">File</kbd>菜单创建您的 Python 笔记本:</p>
<p class="calibre2"><img class="aligncenter87" src="img/931b17de-964b-4ef9-a5ca-fbefd119a528.png"/></p>
<p class="CDPAlignCenter">一旦你点击文件标签，你会看到新的 Python 3 笔记本；创建了一个支持 Python 3 的新笔记本。</p>
<p class="calibre2">您可以单击左上角的 Untitled0.ipynb 来重命名该文件:</p>
<p class="calibre2"><img class="aligncenter88" src="img/b6b14a5c-e286-4f02-93f5-b9c58805fef2.png"/></p>
<p class="CDPAlignCenter">转到编辑，然后转到笔记本设置。将弹出一个窗口，指示您可以拥有的不同设置:</p>
<p class="calibre2"><img class="aligncenter89" src="img/1c957538-b972-4980-a900-d69544ed9fda.png"/></p>
<p class="CDPAlignCenter">选择<strong class="calibre4">图形处理器</strong> ( <strong class="calibre4"> GPU </strong>)选项作为硬件加速器，如前面截图所示，以便使用免费的 GPU。</p>
<p class="calibre2">Google Colab 的一个优点是它可以在你自己的 Google Drive 上运行。您可以选择在 Google Drive 中创建自己的文件夹，或者使用默认的 Colab 笔记本文件夹。为了使用默认的 Google Colab 笔记本文件夹，请按照以下屏幕截图中所示的步骤操作:</p>
<p class="calibre2"><img class="aligncenter90" src="img/b21d3679-750f-4335-9a7f-74af17b93341.png"/></p>
<p class="CDPAlignCenter">要开始读取数据集，您可以将它们存储在 Google Drive 的文件夹中。</p>
<p class="calibre2">在您登录到 Google Colab 并创建了一个新的笔记本后，您必须通过在笔记本中执行以下代码来安装驱动器:</p>
<p class="calibre2">运行上述代码时，它会要求输入授权代码，如下所示:</p>
<pre class="calibre15">from google.colab import drive<br class="title-page-name"/><br class="title-page-name"/># This can be your folder path as per your drive<br class="title-page-name"/>drive.mount('/content/drive')</pre>
<p class="calibre2"><img class="aligncenter91" src="img/4cad1459-aa85-4a26-92a2-e1ba88e9d95e.png"/></p>
<p class="CDPAlignCenter">单击前面的 URL 获取授权码:</p>
<p class="calibre2"><img class="aligncenter92" src="img/e49f2e8c-79d1-4314-abf4-74b6df76ed6e.png"/></p>
<p class="CDPAlignCenter">将授权码粘贴到文本框中。每次你都会得到不同的授权码。授权后，驱动器被装载。</p>
<p class="calibre2">一旦安装了驱动器，就可以使用<kbd class="calibre12">pandas</kbd>读取<kbd class="calibre12">.csv</kbd>文件，正如我们在本章前面所展示的。如<em class="calibre13">如何做</em>部分所示，其余代码按原样运行。如果你使用 GPU，你会注意到计算性能的速度有了实质性的提高。</p>
<p class="calibre2">为了在 Google Colab 中安装额外的库，你需要运行带有！在它前面签名。例如，您可以运行<kbd class="calibre19">!pip install utils</kbd>在 Google Colab 实例中安装 utils。</p>
<p>请参见</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>See also</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">有多种激活功能可用于 Keras 库:</h1>
                
            
            
                
<p class="calibre2">Softmax 激活功能</p>
<ul class="calibre10">
<li class="calibre11">指数线性单位</li>
<li class="calibre11">标度指数线性单位</li>
<li class="calibre11">Softplus 激活功能</li>
<li class="calibre11">整流线性单元</li>
<li class="calibre11">双曲正切激活函数</li>
<li class="calibre11">Sigmoid 激活函数</li>
<li class="calibre11">线性激活函数</li>
<li class="calibre11">指数激活函数</li>
<li class="calibre11">Exponential activation function</li>
</ul>
<p class="calibre2"/>
<p class="calibre2">有关前述激活功能的更多信息，请访问<a href="https://keras.io/activations/" class="calibre9">https://keras.io/activations/</a>。</p>
<p class="calibre2">用于手写数字分类的同质模型集成</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>An ensemble of homogeneous models for handwritten digit classification</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">在本例中，我们将使用一个名为<strong class="calibre4">街景门牌号</strong> ( <strong class="calibre4"> SVHN </strong>)的数据集，该数据集来自【http://ufldl.stanford.edu/housenumbers/】的<a href="http://ufldl.stanford.edu/housenumbers/" class="calibre9"/>。GitHub 也以<kbd class="calibre12">.hd5f</kbd>格式提供数据集。</h1>
                
            
            
                
<p class="calibre2">该数据集是真实世界的数据集，从谷歌街景图像中的门牌号获得。</p>
<p class="calibre2">我们使用 Google Colab 来训练我们的模型。在第一阶段，我们使用 Keras 建立一个单一的模型。在第二阶段，我们集成多个同质模型并集成结果。</p>
<p class="calibre2">做好准备</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Getting ready</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">该数据集包含 60，000 个门牌号图像。每张图片的标号在 1 到 10 之间。数字 1 标记为 1，数字 9 标记为 9，数字 0 标记为 10。这些图像是以单个字符为中心的 32 x 32 的图像。在某些情况下，我们可以看到图像在视觉上模糊不清。</h1>
                
            
            
                
<p class="calibre2">我们导入所需的库:</p>
<p class="CDPAlignLeft3">我们安装谷歌硬盘:</p>
<pre class="calibre15">import os<br class="title-page-name"/>import matplotlib.pyplot as plt<br class="title-page-name"/>import numpy as np<br class="title-page-name"/>from numpy import array<br class="title-page-name"/><br class="title-page-name"/>from sklearn.metrics import accuracy_score<br class="title-page-name"/><br class="title-page-name"/>from keras.models import Sequential, load_model<br class="title-page-name"/>from keras.layers.core import Dense, Dropout, Activation<br class="title-page-name"/><br class="title-page-name"/></pre>
<p class="calibre2">现在，我们导入一个名为<kbd class="calibre12">h5py</kbd>的库来读取 HDF5 格式文件和我们的数据文件，这个文件名为<kbd class="calibre12">SVHN_single_grey.h5</kbd>:</p>
<pre class="calibre15">from google.colab import drive<br class="title-page-name"/>drive.mount('/content/drive')</pre>
<p class="calibre2">我们加载训练和测试子集并关闭文件:</p>
<pre class="calibre15">import h5py<br class="title-page-name"/><br class="title-page-name"/># Open the file as readonly<br class="title-page-name"/>h5f = h5py.File('/content/drive/My Drive/DLCP/SVHN_single_grey.h5', 'r')</pre>
<p class="calibre2">我们重塑我们的训练和测试子集。我们还将数据类型改为 float:</p>
<pre class="calibre15"># Load the training and test set<br class="title-page-name"/>x_train = h5f['X_train'][:]<br class="title-page-name"/>y_train = h5f['y_train'][:]<br class="title-page-name"/>x_test = h5f['X_test'][:]<br class="title-page-name"/>y_test = h5f['y_test'][:]<br class="title-page-name"/><br class="title-page-name"/># Close this file<br class="title-page-name"/>h5f.close()</pre>
<p class="calibre2">我们现在通过将数据除以 255.0 来标准化数据。这也将值的数据类型转换为浮点型:</p>
<pre class="calibre15">x_train = x_train.reshape(x_train.shape[0], 1024)<br class="title-page-name"/>x_test = x_test.reshape(x_test.shape[0], 1024)</pre>
<p class="calibre2">我们检查训练和测试子集的形状:</p>
<pre class="calibre15"># normalize inputs from 0-255 to 0-1<br class="title-page-name"/>x_train = x_train / 255.0<br class="title-page-name"/>x_test = x_test / 255.0</pre>
<p class="calibre2">我们看到<kbd class="calibre12">train</kbd>和<kbd class="calibre12">test</kbd>特征的形状以及我们的目标子集如下:</p>
<pre class="calibre15">print("X_train shape", x_train.shape)<br class="title-page-name"/>print("y_train shape", y_train.shape)<br class="title-page-name"/>print("X_test shape", x_test.shape)<br class="title-page-name"/>print("y_test shape", y_test.shape)</pre>
<p class="calibre2"><img src="img/cfdbb7d5-3001-4dc6-b046-01dde8bf8b48.png" class="calibre57"/></p>
<p class="CDPAlignCenter">我们想象一些图像。我们还在图像上打印标签:</p>
<p class="calibre2">前 10 幅图像如下所示:</p>
<pre class="calibre15"># Visualizing the 1st 10 images in our dataset<br class="title-page-name"/># along with the labels<br class="title-page-name"/>%matplotlib inline<br class="title-page-name"/>import matplotlib.pyplot as plt<br class="title-page-name"/>plt.figure(figsize=(10, 1))<br class="title-page-name"/>for i in range(10):<br class="title-page-name"/> plt.subplot(1, 10, i+1)<br class="title-page-name"/> plt.imshow(x_train[i].reshape(32,32), cmap="gray")<br class="title-page-name"/> plt.title(y_train[i], color='r')<br class="title-page-name"/> plt.axis("off")<br class="title-page-name"/>plt.show()</pre>
<p class="calibre2"><img src="img/ecbd6145-9449-460e-9e18-1cd953487adc.png" class="calibre33"/></p>
<p class="CDPAlignCenter">我们现在对目标变量执行一键编码。我们还将我们的<kbd class="calibre12">y_test</kbd>标签存储在另一个名为<kbd class="calibre12">y_test_actuals</kbd>的变量中，以备后用:</p>
<p class="calibre2">一键编码前后的形状如下:</p>
<pre class="calibre15"># Let us store the original y_test to another variable y_test_actuals<br class="title-page-name"/>y_test_actuals = y_test<br class="title-page-name"/><br class="title-page-name"/># one-hot encoding using keras' numpy-related utilities<br class="title-page-name"/>n_classes = 10<br class="title-page-name"/><br class="title-page-name"/>print("Before one-hot encoding:")<br class="title-page-name"/>print("Shape of Y_TRAIN before one-hot encoding: ", y_train.shape)<br class="title-page-name"/>print("Shape of Y_TEST before one-hot encoding: ", y_test.shape)<br class="title-page-name"/><br class="title-page-name"/>y_train = np_utils.to_categorical(y_train, n_classes)<br class="title-page-name"/>y_test = np_utils.to_categorical(y_test, n_classes)<br class="title-page-name"/><br class="title-page-name"/>print("After one-hot encoding:")<br class="title-page-name"/>print("Shape of Y_TRAIN after one-hot encoding: ", y_train.shape)<br class="title-page-name"/>print("Shape of Y_TRAIN after one-hot encoding: ", y_test.shape)</pre>
<p class="calibre2"><img src="img/81fa3c37-968c-4a24-8d35-a2a672133a44.png" class="aligncenter11"/></p>
<p class="CDPAlignCenter">怎么做...</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>How to do it...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">我们现在将使用 Keras 库构建一个模型:</h1>
                
            
            
                
<p class="calibre2">使用顺序模型构建线性层堆栈:</p>
<ol start="1" class="calibre14">
<li class="calibre11">编译模型:</li>
</ol>
<pre class="calibre18"># building a linear stack of layers with the sequential model<br class="title-page-name"/>model = Sequential()<br class="title-page-name"/>model.add(Dense(512, input_shape=(1024,)))<br class="title-page-name"/>model.add(Activation('relu')) <br class="title-page-name"/><br class="title-page-name"/>model.add(Dense(512))<br class="title-page-name"/>model.add(Activation('relu'))<br class="title-page-name"/><br class="title-page-name"/>model.add(Dense(10))<br class="title-page-name"/>model.add(Activation('softmax'))</pre>
<ol start="2" class="calibre14">
<li class="calibre11">将模型拟合到<kbd class="calibre12">train</kbd>数据，并用<kbd class="calibre12">test</kbd>数据进行验证:</li>
</ol>
<pre class="calibre18"># compiling the sequential model<br class="title-page-name"/>model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')</pre>
<ol start="3" class="calibre14">
<li class="calibre11">绘制每个时期的模型精度:</li>
</ol>
<pre class="calibre18"># training the model and saving metrics in history<br class="title-page-name"/>svhn_model = model.fit(x_train, y_train,<br class="title-page-name"/>          batch_size=128, epochs=100,<br class="title-page-name"/>          verbose=2,<br class="title-page-name"/>          validation_data=(x_test, y_test))</pre>
<ol start="4" class="calibre14">
<li class="calibre11">我们看到下面的模型精度图:</li>
</ol>
<pre class="calibre18"># plotting the metrics<br class="title-page-name"/>fig = plt.figure(figsize=(12,4))<br class="title-page-name"/><br class="title-page-name"/>#plt.subplot(2,1,1)<br class="title-page-name"/>plt.plot(svhn_model.history['acc'])<br class="title-page-name"/>plt.plot(svhn_model.history['val_acc'])<br class="title-page-name"/>plt.title('Model Accuracy')<br class="title-page-name"/>plt.ylabel('Accuracy')<br class="title-page-name"/>plt.xlabel('Epochs')<br class="title-page-name"/>plt.legend(['Train', 'Test'], loc='uppper left')<br class="title-page-name"/><br class="title-page-name"/>plt.tight_layout()</pre>
<p class="calibre20"><img src="img/a5b170b0-ef5f-41cc-9915-340b5d345445.png" class="calibre33"/></p>
<p class="CDPAlignCenter"><img src="img/a5b170b0-ef5f-41cc-9915-340b5d345445.png" class="calibre33"/></p>
<p class="calibre2">绘制每个时期的损失:</p>
<ol start="5" class="calibre14">
<li class="calibre11">我们看到下面的模型损耗图:</li>
</ol>
<pre class="calibre18"># plotting the metrics<br class="title-page-name"/>fig = plt.figure(figsize=(12,4))<br class="title-page-name"/><br class="title-page-name"/>plt.plot(svhn_model.history['loss'])<br class="title-page-name"/>plt.plot(svhn_model.history['val_loss'])<br class="title-page-name"/>plt.title('Model Loss')<br class="title-page-name"/>plt.ylabel('Loss')<br class="title-page-name"/>plt.xlabel('Epochs')<br class="title-page-name"/>plt.legend(['Train', 'Test'], loc='upper right')<br class="title-page-name"/><br class="title-page-name"/>plt.tight_layout()</pre>
<p class="calibre20"><img src="img/480f23ae-eb8f-43f0-ab1a-8f0f7347fa55.png" class="calibre58"/></p>
<p class="CDPAlignCenter">重复使用 scikit-learn 网站上的代码来绘制混淆矩阵:</p>
<ol start="6" class="calibre14">
<li class="calibre11">用数字和图形绘制混淆矩阵:</li>
</ol>
<pre class="calibre18"># code from http://scikit-learn.org<br class="title-page-name"/>def plot_confusion_matrix(cm, classes,<br class="title-page-name"/>normalize=False,<br class="title-page-name"/>title='Confusion matrix',<br class="title-page-name"/>cmap=plt.cm.Blues):<br class="title-page-name"/>"""<br class="title-page-name"/>This function prints and plots the confusion matrix.<br class="title-page-name"/>"""<br class="title-page-name"/>plt.imshow(cm, cmap=cmap)<br class="title-page-name"/>plt.title(title)<br class="title-page-name"/>plt.colorbar()<br class="title-page-name"/>tick_marks = np.arange(len(classes))<br class="title-page-name"/>plt.xticks(tick_marks, classes, rotation=45)<br class="title-page-name"/>plt.yticks(tick_marks, classes)<br class="title-page-name"/><br class="title-page-name"/>thresh = cm.max() / 2.<br class="title-page-name"/>for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):<br class="title-page-name"/>plt.text(j, i, cm[i, j],<br class="title-page-name"/>horizontalalignment="center",<br class="title-page-name"/>color="white" if cm[i, j] &gt; thresh else "black")<br class="title-page-name"/><br class="title-page-name"/>plt.ylabel('Actuals')<br class="title-page-name"/>plt.xlabel('Predicted')</pre>
<ol start="7" class="calibre14">
<li class="calibre11">混淆矩阵如下所示:</li>
</ol>
<pre class="calibre18">target_names = [ '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']<br class="title-page-name"/><br class="title-page-name"/># Formulating the Confusion Matrix<br class="title-page-name"/>import itertools<br class="title-page-name"/>from sklearn.metrics import confusion_matrix<br class="title-page-name"/><br class="title-page-name"/>cm = confusion_matrix(y_test_actuals, predicted_classes)<br class="title-page-name"/>print(cm)<br class="title-page-name"/><br class="title-page-name"/>plt.figure(figsize=(10,10))<br class="title-page-name"/>plot_confusion_matrix(cm, classes=target_names, normalize=False)<br class="title-page-name"/>plt.show()</pre>
<p class="calibre20"><img src="img/0744e47b-b9c7-464e-8753-4eed29c9d736.png" class="calibre59"/></p>
<p class="CDPAlignCenter"><img src="img/0744e47b-b9c7-464e-8753-4eed29c9d736.png" class="calibre59"/></p>
<p class="calibre2"/>
<p class="calibre2">我们现在来看看如何集成多个同质模型的结果。定义一个函数以使模型符合训练数据:</p>
<ol start="8" class="calibre14">
<li class="calibre11">编写一个函数来集合所有模型的预测:</li>
</ol>
<pre class="calibre18"># fit model on dataset<br class="title-page-name"/>def train_models(x_train, y_train):<br class="title-page-name"/>  # building a linear stack of layers with the sequential model<br class="title-page-name"/>  model = Sequential()<br class="title-page-name"/>  model.add(Dense(512, input_shape=(1024,)))<br class="title-page-name"/>  model.add(Activation('relu')) <br class="title-page-name"/>  model.add(Dropout(0.2))<br class="title-page-name"/><br class="title-page-name"/>  model.add(Dense(512))<br class="title-page-name"/>  model.add(Activation('relu'))<br class="title-page-name"/>  model.add(Dropout(0.2))<br class="title-page-name"/><br class="title-page-name"/>  model.add(Dense(10))<br class="title-page-name"/>  model.add(Activation('softmax'))<br class="title-page-name"/>  <br class="title-page-name"/>  # compiling the sequential model<br class="title-page-name"/>  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])<br class="title-page-name"/>  <br class="title-page-name"/>  # training the model and saving metrics in history<br class="title-page-name"/>  svhn_model = model.fit(x_train, y_train, batch_size=32, epochs=25)<br class="title-page-name"/>  <br class="title-page-name"/>  return model</pre>
<ol start="9" class="calibre14">
<li class="calibre11">Write a function to ensemble the predictions of all the models:</li>
</ol>
<pre class="calibre18"># make an ensemble prediction for multi-class classification<br class="title-page-name"/>def ensemble_predictions(models, x_test):<br class="title-page-name"/>  # make predictions<br class="title-page-name"/>  y_predicted = [model.predict(x_test) for model in models]<br class="title-page-name"/>  y_predicted = np.array(y_predicted)<br class="title-page-name"/>  <br class="title-page-name"/>  # sum predictions from all ensemble models<br class="title-page-name"/>  predicted_total = np.sum(y_predicted, axis=0)<br class="title-page-name"/>  <br class="title-page-name"/>  # argmax across classes<br class="title-page-name"/>  result = np.argmax(predicted_total, axis=1)<br class="title-page-name"/>  <br class="title-page-name"/>  return result</pre>
<div><kbd class="calibre19">numpy.argmax</kbd><strong class="calibre1"> </strong>returns indices of the max element of the array in a particular axis.</div>
<p class="calibre2">编写一个函数来评估模型，并获得每个模型的准确性分数:</p>
<ol start="10" class="calibre14">
<li class="calibre11">适合所有型号:</li>
</ol>
<pre class="calibre18"># evaluate a specific number of members in an ensemble<br class="title-page-name"/>def evaluate_models(models, no_of_models, x_test, y_test):<br class="title-page-name"/> # select a subset of members<br class="title-page-name"/> subset = models[:no_of_models]<br class="title-page-name"/> <br class="title-page-name"/> # make prediction<br class="title-page-name"/> y_predicted_ensemble = ensemble_predictions(subset, x_test)<br class="title-page-name"/> <br class="title-page-name"/> # calculate accuracy<br class="title-page-name"/> return accuracy_score(y_test_actuals, y_predicted_ensemble)</pre>
<ol start="11" class="calibre14">
<li class="calibre11">绘制每个历元的准确度分数:</li>
</ol>
<pre class="calibre18"># fit all models<br class="title-page-name"/>no_of_models = 50<br class="title-page-name"/><br class="title-page-name"/>models = [train_models(x_train, y_train) for _ in range(no_of_models)]<br class="title-page-name"/><br class="title-page-name"/># evaluate different numbers of ensembles<br class="title-page-name"/>all_scores = list()<br class="title-page-name"/>for i in range(1, no_of_models+1):<br class="title-page-name"/>  score = evaluate_models(models, i, x_test, y_test)<br class="title-page-name"/>  print("Accuracy Score of model ", i, " ", score)<br class="title-page-name"/>  all_scores.append(score)</pre>
<ol start="12" class="calibre14">
<li class="calibre11">它是如何工作的...</li>
</ol>
<pre class="calibre18"># plot score vs number of ensemble members<br class="title-page-name"/>x_axis = [i for i in range(1, no_of_models+1)]<br class="title-page-name"/>plt.plot(x_axis, all_scores)<br class="title-page-name"/>plt.show()</pre>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>How it works...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">在<em class="calibre13">步骤 1 </em>到<em class="calibre13">步骤 7 </em>中，我们构建了一个单一的神经网络模型，以了解如何使用带标签的图像数据集来训练我们的模型，并预测一个看不见的图像的实际标签。</h1>
                
            
            
                
<p class="calibre2">在<em class="calibre13">步骤 1 </em>中，我们使用 Keras 构建了一个线性层叠层，其中包含顺序模型。我们定义了三层:一个输入层、一个隐藏层和一个输出层。我们向输入层提供了<kbd class="calibre12">input_shape=1024</kbd>,因为我们有 32 x 32 的图像。我们在第一层和第二层使用了 relu 激活函数。因为我们的问题是一个多类分类问题，所以我们使用 softmax 作为输出层的激活函数。</p>
<p class="calibre2">在<em class="calibre13">第二步</em>中，我们用<kbd class="calibre12">loss='categorical_crossentropy'</kbd>和<kbd class="calibre12">optimizer='adam'</kbd>编译了模型。在<em class="calibre13">步骤 3 </em>中，我们将我们的模型与我们的训练数据相匹配，并在我们的测试数据上验证它。</p>
<p class="calibre2">在<em class="calibre13">步骤 4 </em>和<em class="calibre13">步骤 5 </em>中，我们绘制了每个时期的模型精度和损耗度量。</p>
<p class="calibre2">在<em class="calibre13">步骤 6 </em>和<em class="calibre13">步骤 7 </em>中，我们重用了 scikit-learn 网站上的一个<kbd class="calibre12">plot_confusion_matrix()</kbd>函数，以数字和视觉方式绘制我们的混淆矩阵。</p>
<p class="calibre2">从<em class="calibre13">步骤 8 </em>开始，我们集合了多个模型。我们编写了三个自定义函数:</p>
<p class="calibre2"><kbd class="calibre12">train_models()</kbd>:使用连续层来训练和编译我们的模型。</p>
<ul class="calibre10">
<li class="calibre11"><kbd class="calibre12">ensemble_predictions()</kbd>:集合预测，找出所有观测值的最大值。</li>
<li class="calibre11"><kbd class="calibre12">evaluate_models()</kbd>:计算每个模型的精度分数。</li>
<li class="calibre11">在<em class="calibre13">步骤 11 </em>中，我们拟合了所有的模型。我们将<kbd class="calibre12">no_of_models</kbd>变量设置为<kbd class="calibre12">50</kbd>。我们通过调用<kbd class="calibre12">train_models()</kbd>函数在循环中训练我们的模型。然后，我们将<kbd class="calibre12">x_train</kbd>和<kbd class="calibre12">y_train</kbd>传递给在每次迭代中构建的每个模型的<kbd class="calibre12">train_models()</kbd>函数。我们还调用了<kbd class="calibre12">evaluate_models()</kbd>，它返回了构建的每个模型的准确度分数。然后我们附加了所有的准确度分数。</li>
</ul>
<p class="calibre2">在<em class="calibre13">步骤 12 </em>中，我们绘制了所有模型的准确度分数。</p>
<p class="calibre2">In <em class="calibre13">Step 12</em>, we plotted the accuracy scores for all the models.</p>


            

            
        
    </body>

</html>
</body></html>