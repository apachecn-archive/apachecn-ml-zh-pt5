<html><head/><body>
<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>When in Doubt, Use Random Forests</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">如果有疑问，使用随机森林</h1>
                
            
            
                
<p class="CDPAlignLeft3">在本章中，我们将介绍以下配方:</p>
<ul class="calibre10">
<li class="calibre11">随机森林简介</li>
<li class="calibre11">使用 scikit-learn 实现预测信用卡违约的随机森林</li>
<li class="calibre11">使用 H2O 实现预测信用卡违约的随机森林</li>
</ul>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Introduction to random forests</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">随机森林简介</h1>
                
            
            
                
<p class="calibre2">随机森林是一种基于集成学习的监督机器学习算法。它用于回归和分类问题。随机森林背后的一般思想是构建多个决策树，并聚合它们以获得准确的结果。决策树是一种确定性算法，这意味着如果向它提供相同的数据，每次都会生成相同的树。他们有过度拟合的倾向，因为他们用给定的数据建立了可能的最佳树，但当提供了看不见的数据时，可能无法进行归纳。组成随机森林的所有决策树都是不同的，因为我们在数据的不同随机子集上构建每棵树。随机森林往往比单一决策树更准确，因为它最大限度地减少了过度拟合。</p>
<p class="calibre2">下图演示了从源样本进行的引导抽样。在每个样本上建立模型，然后将预测组合起来，以得出最终结果:</p>
<p class="CDPAlignCenter"><img class="aligncenter75" src="img/b7a368ae-ce16-47db-96c7-5ab98ab0b289.png"/></p>
<p class="calibre2">随机森林中的每棵树都使用以下步骤构建，其中 A 代表整个森林，A 代表单棵树，对于<em class="calibre13"> a = 1 </em>到<em class="calibre13"> A </em>:</p>
<ol class="calibre14">
<li class="calibre11">创建一个带有替换的引导样本，<em class="calibre23"> D </em>训练来自<em class="calibre23"> x </em>，<em class="calibre23"> y </em>标注这些<em class="calibre23"> X <sub class="calibre32"> a </sub> </em> <sub class="calibre32">，</sub> <em class="calibre23"> Y <sub class="calibre32"> a </sub> </em></li>
<li class="calibre11">在<em xmlns:epub="http://www.idpf.org/2007/ops" class="calibre23">X<sub class="calibre32">a</sub>T33】，<em xmlns:epub="http://www.idpf.org/2007/ops" class="calibre23">Y<sub class="calibre32">a</sub>T37】上训练树<em xmlns:epub="http://www.idpf.org/2007/ops" class="calibre23">f<sub class="calibre32">a</sub>T29】</em></em></em></li>
<li class="calibre11">对预测进行平均，或采用多数投票来得出最终预测</li>
</ol>
<p class="calibre2">在回归问题中，对测试实例的预测是通过对所有树的预测取平均值来进行的。这可以表示如下:</p>
<p class="CDPAlignCenter"><img class="fm-editor-equation62" src="img/b058aa6d-f242-48e0-ab2c-e20bca7feca3.png"/></p>
<p class="calibre2">这里，<em class="calibre13"> N </em>是随机森林中的总树数。<em class="calibre13"> a=1 </em>代表森林中的第一棵树，而森林中的最后一棵树是<em class="calibre13"> A </em>。<img class="fm-editor-equation63" src="img/b6820836-5f23-4996-b72c-86e17bcfbed3.png"/> ( <img class="fm-editor-equation64" src="img/d7f322ac-15d3-4190-bea7-6b3f7250eba4.png"/>)代表来自单个树的预测。</p>
<p class="calibre2">如果我们有一个分类问题，多数表决或最常见的答案被使用。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Implementing a random forest for predicting credit card defaults using scikit-learn</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">使用 scikit-learn 实现预测信用卡违约的随机森林</h1>
                
            
            
                
<p class="calibre2">scikit-learn 库通过提供两个估算器来实现随机森林:<kbd class="calibre12">RandomForestClassifier</kbd> <kbd class="calibre12"> </kbd>和<kbd class="calibre12">RandomForestRegressor</kbd>。它们采用各种参数，其中一些参数解释如下:</p>
<ul class="calibre10">
<li class="calibre11"><kbd class="calibre12"> n_estimators</kbd> : <strong class="calibre1"> </strong>该参数是算法在进行最大投票或平均预测之前构建的树的数量。一般来说，树的数量越多，预测的性能和准确性就越好，但是在计算方面也花费更多。</li>
<li class="calibre11"><kbd class="calibre12">max_features</kbd>:该参数是允许随机森林在单个树中尝试的最大功能数量。</li>
<li class="calibre11"><kbd class="calibre12">min_sample_leaf</kbd> : <strong class="calibre1"> </strong>该参数决定了分割一个内部节点所需的最少叶子数。</li>
<li class="calibre11"><kbd class="calibre12">n_jobs</kbd>:这个超参数告诉引擎，为了拟合模型和预测新实例，要并行运行多少个作业。如果它的值为<kbd class="calibre12">None</kbd>或<kbd class="calibre12">1</kbd>，那么它只运行一个作业。值<kbd class="calibre12">-1</kbd>意味着它将使用所有的处理器。</li>
<li class="calibre11"><kbd class="calibre12">random_state</kbd> : <strong class="calibre1"> </strong>当该参数有一个确定值<kbd class="calibre12">random_state</kbd>时，如果给定了相同的超参数和相同的训练数据，该参数将总是产生相同的结果。</li>
<li class="calibre11"><kbd class="calibre12">oob_score</kbd>:该参数也称为<strong class="calibre1"/><strong class="calibre1">抽样</strong>，是一种随机森林交叉验证方法。在这种采样方法中，大约有三分之一的数据不用于训练模型，而可用于评估其性能。这些样品被称为<strong class="calibre1">开箱</strong>样品<strong class="calibre1">样品</strong>。</li>
</ul>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Getting ready</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">做好准备</h1>
                
            
            
                
<p class="calibre2">在这个例子中，我们使用了一个来自 UCI ML 数据库的关于信用卡违约的数据集。该数据集包含以下信息:</p>
<ul class="calibre10">
<li class="calibre11">违约付款</li>
<li class="calibre11">人口因素</li>
<li class="calibre11">信用数据</li>
<li class="calibre11">付款历史</li>
<li class="calibre11">信用卡客户账单</li>
</ul>
<p class="calibre2">GitHub 文件夹中提供了数据和数据描述:</p>
<p class="calibre2">我们将从加载所需的库和读取数据集开始:</p>
<pre class="calibre15">import os<br class="title-page-name"/>import numpy as np<br class="title-page-name"/>import pandas as pd<br class="title-page-name"/>import matplotlib.pyplot as plt<br class="title-page-name"/>%matplotlib inline<br class="title-page-name"/>import seaborn as sns</pre>
<p class="calibre2">我们将工作文件夹设置如下:</p>
<pre class="calibre15"># Set your working directory according to your requirement<br class="title-page-name"/>os.chdir(".../Chapter 6/Random Forest")<br class="title-page-name"/>os.getcwd()</pre>
<p class="calibre2">现在让我们来读取数据。我们将以<kbd class="calibre12">df_</kbd>作为数据帧名称的前缀，以便于理解:</p>
<pre class="calibre15">df_creditcarddata = pd.read_csv("UCI_Credit_Card.csv")</pre>
<p class="calibre2">我们检查数据集的形状:</p>
<pre class="calibre15">df_creditcarddata.shape</pre>
<p class="calibre2">我们检查数据类型:</p>
<pre class="calibre15">df_creditcarddata.dtypes</pre>
<p class="calibre2">我们删除了<kbd class="calibre12">ID</kbd>列，因为这不是必需的:</p>
<pre class="calibre15">df_creditcarddata = df_creditcarddata.drop("ID", axis= 1) </pre>
<p class="calibre2"/>
<p class="calibre2">我们可以用各种方式探索我们的数据。让我们来看看几种不同的方法:</p>
<pre class="calibre15">selected_columns = df_creditcarddata[['AGE','BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6', 'LIMIT_BAL']]<br class="title-page-name"/><br class="title-page-name"/>selected_columns.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8);</pre>
<p>注意，我们在前面代码块的最后一行使用了分号。分号有助于隐藏 Matplotlib 生成的详细信息。<kbd class="calibre19">xlabelsize</kbd>和<kbd class="calibre19">ylabelsize</kbd>用于调整 x 轴和 y 轴的字体大小。</p>
<p class="calibre2">下图显示了数值变量的分布:</p>
<p class="CDPAlignCenter"><img src="img/9ea0dcfd-9bd1-47c3-9207-8d476ce78ee0.png" class="calibre33"/></p>
<p class="calibre2">我们现在将探讨按年龄组的付款默认值。我们存储<kbd class="calibre12">age</kbd>变量，并将存储的值存储在<kbd class="calibre12">df_creditcarddata</kbd>中的新变量<kbd class="calibre12">age_group</kbd>中:</p>
<pre class="calibre15">df_creditcarddata['agegroup'] = pd.cut(df_creditcarddata['AGE'], range(0, 100, 10), right=False)<br class="title-page-name"/>df_creditcarddata.head()</pre>
<p class="calibre2">然后，我们使用新的<kbd class="calibre12">age_group</kbd>变量来绘制每个年龄组的违约数量:</p>
<pre class="calibre15"># Default vs Age<br class="title-page-name"/>pd.crosstab(df_creditcarddata.age_group, \<br class="title-page-name"/>           df_creditcarddata["default.payment.next.month"]).plot(kind='bar',stacked=False, grid=True) <br class="title-page-name"/><br class="title-page-name"/>plt.title('Count of Defaults by AGE')<br class="title-page-name"/>plt.xlabel('AGE')<br class="title-page-name"/>plt.ylabel('# of Default')<br class="title-page-name"/>plt.legend(loc='upper left')</pre>
<p class="calibre2">下面的屏幕截图显示了每个年龄段的违约数量:</p>
<p class="CDPAlignCenter"><img src="img/a01f25a0-5db7-469d-b4b7-e1638ac2ed03.png" class="calibre34"/></p>
<p class="calibre2">我们可以从<kbd class="calibre12">df_creditcarddata</kbd>中删除<kbd class="calibre12">age_group</kbd>变量，因为我们不再需要它了:</p>
<pre class="calibre15">df_creditcarddata = df_creditcarddata.drop(columns = ['age_group'])<br class="title-page-name"/>df_creditcarddata.head()</pre>
<p class="calibre2">我们现在将根据帐户持有人的信用限额来查看付款违约情况:</p>
<pre class="calibre15">fig_facetgrid = sns.FacetGrid(df_creditcarddata, hue='default.payment.next.month', aspect=4)<br class="title-page-name"/>fig_facetgrid.map(sns.kdeplot, 'LIMIT_BAL', shade=True)<br class="title-page-name"/>max_limit_bal = df_creditcarddata['LIMIT_BAL'].max()<br class="title-page-name"/>fig_facetgrid.set(xlim=(0,max_limit_bal));<br class="title-page-name"/>fig_facetgrid.set(ylim=(0.0,0.000007));<br class="title-page-name"/>fig_facetgrid.set(title='Distribution of limit balance by default.payment')<br class="title-page-name"/>fig_facetgrid.add_legend()</pre>
<p class="calibre2">前面的代码给出了下面的情节:</p>
<p class="CDPAlignCenter"><img src="img/8ca04a04-c2dc-4bac-bbf1-55319d9dee18.png" class="calibre33"/></p>
<p class="calibre2">我们也可以给我们的一些变量分配标签，以使解释更好。我们为<kbd class="calibre12">Gender</kbd>、<kbd class="calibre12">Marriage</kbd>和<kbd class="calibre12">Education</kbd>变量分配标签。</p>
<p class="calibre2">我们还将<kbd class="calibre12">pay</kbd>变量的数据类型改为字符串:</p>
<pre class="calibre15">GenderMap = {2:'female', 1:'male'}<br class="title-page-name"/>MarriageMap = {1:'married', 2:'single', 3:'other', 0: 'other'}<br class="title-page-name"/>EducationMap = {1:'graduate school', 2:'university', 3:'high school', 4:'others', 5:'unknown', 6:'unknown', 0:'unknown'}<br class="title-page-name"/><br class="title-page-name"/>df_creditcarddata['SEX'] = df_creditcarddata.SEX.map(GenderMap)<br class="title-page-name"/>df_creditcarddata['MARRIAGE'] = df_creditcarddata.MARRIAGE.map(MarriageMap) <br class="title-page-name"/>df_creditcarddata['EDUCATION'] = df_creditcarddata.EDUCATION.map(EducationMap)<br class="title-page-name"/>df_creditcarddata['PAY_0'] = df_creditcarddata['PAY_0'].astype(str) <br class="title-page-name"/>df_creditcarddata['PAY_2'] = df_creditcarddata['PAY_2'].astype(str) <br class="title-page-name"/>df_creditcarddata['PAY_3'] = df_creditcarddata['PAY_3'].astype(str) <br class="title-page-name"/>df_creditcarddata['PAY_4'] = df_creditcarddata['PAY_4'].astype(str) <br class="title-page-name"/>df_creditcarddata['PAY_5'] = df_creditcarddata['PAY_5'].astype(str) <br class="title-page-name"/>df_creditcarddata['PAY_6'] = df_creditcarddata['PAY_6'].astype(str) </pre>
<p class="calibre2">本书提供的代码包中有更多的探索。我们现在继续训练我们的随机森林模型。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>How to do it...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">怎么做...</h1>
                
            
            
                
<p class="calibre2">我们现在将看看如何使用随机森林来训练我们的模型:</p>
<ol class="calibre14">
<li class="calibre11">我们从分割目标变量和特征变量开始:</li>
</ol>
<pre class="calibre18">predictor= df_creditcarddata.iloc[:, df_creditcarddata.columns != 'default.payment.next.month']<br class="title-page-name"/>target= df_creditcarddata.iloc[:, df_creditcarddata.columns == 'default.payment.next.month']</pre>
<ol start="2" class="calibre14">
<li class="calibre11">我们在我们的特征集中分离数值和非数值变量:</li>
</ol>
<pre class="calibre18"># save all categorical columns in list<br class="title-page-name"/>categorical_columns = [col for col in predictor.columns.values if predictor[col].dtype == 'object']<br class="title-page-name"/><br class="title-page-name"/># dataframe with categorical features<br class="title-page-name"/>df_categorical = predictor[categorical_columns]<br class="title-page-name"/><br class="title-page-name"/># dataframe with numerical features<br class="title-page-name"/>df_numeric = predictor.drop(categorical_columns, axis=1)</pre>
<ol start="3" class="calibre14">
<li class="calibre11">我们对分类变量进行虚拟编码:</li>
</ol>
<pre class="calibre18">dummy_code_cat_vars = pd.get_dummies(df_categorical,drop_first=True)</pre>
<ol start="4" class="calibre14">
<li class="calibre11">我们将伪代码变量连接到数据帧:</li>
</ol>
<pre class="calibre18">df_predictor = pd.concat([df_numeric, dummy_code_cat_vars], axis=1)<br class="title-page-name"/>df_predictor.head()</pre>
<ol start="5" class="calibre14">
<li class="calibre11">我们将数据集分成训练和测试子集:</li>
</ol>
<pre class="calibre18">from sklearn.model_selection import train_test_split<br class="title-page-name"/>X_train,X_test, y_train, y_test = train_test_split(df_predictor, target, test_size = 0.30, random_state=0)<br class="title-page-name"/>print("x_train ",X_train.shape)<br class="title-page-name"/>print("x_test ",X_test.shape)<br class="title-page-name"/>print("y_train ",y_train.shape)<br class="title-page-name"/>print("y_test ",y_test.shape)</pre>
<ol start="6" class="calibre14">
<li class="calibre11">我们用<kbd class="calibre12">StandardScaler()</kbd>来缩放特性:</li>
</ol>
<pre class="calibre18">from sklearn.preprocessing import StandardScaler<br class="title-page-name"/>scaler = StandardScaler()</pre>
<ol start="7" class="calibre14">
<li class="calibre11">我们可能会注意到列名已经被改成了数字。我们将列名和索引值赋回缩放后的数据帧:</li>
</ol>
<pre class="calibre18">X_train_scaled.columns = X_train.columns.values<br class="title-page-name"/>X_test_scaled.columns = X_test.columns.values<br class="title-page-name"/>X_train_scaled.index = X_train.index.values<br class="title-page-name"/>X_test_scaled.index = X_test.index.values<br class="title-page-name"/><br class="title-page-name"/>X_train = X_train_scaled<br class="title-page-name"/>X_test = X_test_scaled</pre>
<ol start="8" class="calibre14">
<li class="calibre11">我们从<kbd class="calibre12">sklearn.ensemble</kbd>进口<kbd class="calibre12">RandomForestClassifier()</kbd>。然后，我们将构建随机森林分类器模型:</li>
</ol>
<pre class="calibre18">from sklearn.ensemble import RandomForestClassifier<br class="title-page-name"/><br class="title-page-name"/>classifier = RandomForestClassifier(random_state = 0, n_estimators = 100,\<br class="title-page-name"/> criterion = 'entropy', max_leaf_nodes= 20,oob_score = True, n_jobs = -1 )<br class="title-page-name"/><br class="title-page-name"/># fit the model<br class="title-page-name"/>model_RF = classifier.fit(X_train, y_train)</pre>
<ol start="9" class="calibre14">
<li class="calibre11">之后，我们计算训练模型的准确性:</li>
</ol>
<pre class="calibre18">acc_random_forest = round(classifier.score(X_train, y_train) * 100, 2)<br class="title-page-name"/>print(round(acc_random_forest,2,), "%")</pre>
<ol start="10" class="calibre14">
<li class="calibre11">我们通过传递<kbd xmlns:epub="http://www.idpf.org/2007/ops" class="calibre12">y_test</kbd>和<kbd xmlns:epub="http://www.idpf.org/2007/ops" class="calibre12">y_pred_proba</kbd>到<kbd xmlns:epub="http://www.idpf.org/2007/ops" class="calibre12">roc_curve()</kbd>得到<strong xmlns:epub="http://www.idpf.org/2007/ops" class="calibre1">f</strong>T17】假阳性率 ( <strong xmlns:epub="http://www.idpf.org/2007/ops" class="calibre1"> FPR </strong>)和<strong xmlns:epub="http://www.idpf.org/2007/ops" class="calibre1"> t </strong> <strong xmlns:epub="http://www.idpf.org/2007/ops" class="calibre1">假阳性率</strong> ( <strong xmlns:epub="http://www.idpf.org/2007/ops" class="calibre1"> TPR </strong>)。我们还使用<kbd xmlns:epub="http://www.idpf.org/2007/ops" class="calibre12">roc_auc_score()</kbd>得到<kbd xmlns:epub="http://www.idpf.org/2007/ops" class="calibre12">auc </kbd>值。使用 FPR、TPR 和 AUC 值，我们绘制 ROC 曲线，并在图上标注 AUC 值:</li>
</ol>
<pre class="calibre18">from sklearn import metrics<br class="title-page-name"/><br class="title-page-name"/>y_pred_proba = model_RF.predict_proba(X_test)[::,1]<br class="title-page-name"/>fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)<br class="title-page-name"/>auc = metrics.roc_auc_score(y_test, y_pred_proba)<br class="title-page-name"/>plt.plot(fpr,tpr,label="AUC="+str(auc))<br class="title-page-name"/>plt.legend(loc=4)<br class="title-page-name"/>plt.show()</pre>
<p class="calibre20">下图显示了标有 AUC 值的 ROC 曲线:</p>
<p class="CDPAlignCenter"><img class="aligncenter76" src="img/43c5f4c5-d916-4f76-a3b4-8bf301a6926f.png"/></p>
<ol start="11" class="calibre14">
<li class="calibre11">我们还可以评估其他分数，如下所示:</li>
</ol>
<pre class="calibre18"># predict the model<br class="title-page-name"/>y_pred_RF = model_RF.predict(X_test)<br class="title-page-name"/><br class="title-page-name"/># evaluate other scores<br class="title-page-name"/>evaluation_scores = pd.Series({'Model': " Random Forest Classifier ",<br class="title-page-name"/>'ROC Score' : metrics.roc_auc_score(y_test, y_pred_RF),<br class="title-page-name"/>'Precision Score': metrics.precision_score(y_test, y_pred_RF),<br class="title-page-name"/>'Recall Score': metrics.recall_score(y_test, y_pred_RF),<br class="title-page-name"/>'Accuracy Score': metrics.accuracy_score(y_test, y_pred_RF),<br class="title-page-name"/>'Kappa Score':metrics.cohen_kappa_score(y_test, y_pred_RF)})<br class="title-page-name"/><br class="title-page-name"/>print(evaluation_scores)</pre>
<p class="calibre20">上述代码产生以下评估分数:</p>
<p class="CDPAlignCenter"><img class="aligncenter77" src="img/dac2941b-1804-4d74-977b-f9878a69d72a.png"/></p>
<ol start="12" class="calibre14">
<li class="calibre11">我们还可以基于目标变量的类别评估一些统计数据，在本例中是<kbd class="calibre12">0</kbd>或<kbd class="calibre12">1</kbd>:</li>
</ol>
<pre class="calibre18">from sklearn.metrics import classification_report<br class="title-page-name"/>print(classification_report(y_test, y_pred_RF))</pre>
<p class="calibre20"><kbd class="calibre12">sklearn.metrics</kbd>中的<kbd class="calibre12">classification_report</kbd>根据目标变量的每个类别给出了以下分数:</p>
<p class="CDPAlignCenter"><img class="aligncenter78" src="img/eb489a75-2234-4f49-86ce-191e94fd501c.png"/></p>
<p class="calibre2"/>
<ol start="13" class="calibre14">
<li class="calibre11">我们可以根据特征重要性绘制前 10 个变量，以了解哪些变量对模型很重要:</li>
</ol>
<pre class="calibre18">feature_importances = pd.Series(classifier.feature_importances_, index=X_train.columns)<br class="title-page-name"/>feature_importances.nlargest(10).plot(kind='barh') #top 10 features</pre>
<p class="calibre20">以下截图显示了前 10 个变量及其相对重要性:</p>
<p class="CDPAlignCenter"><img src="img/152d22d8-51d0-4861-9e34-66ac936652a2.png" class="calibre35"/></p>
<p class="calibre2">我们可以改变超参数，看看模型如何表现得更好。我们还可以对超参数值的组合进行网格搜索，以微调我们的模型。</p>
<p class="calibre2"/>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>How it works...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">它是如何工作的...</h1>
                
            
            
                
<p class="calibre2">在<em class="calibre13">步骤 1 </em>中，我们分割了目标和特征变量。在<em class="calibre13">步骤 2 </em>中，在我们的特性集中，我们分离了数字和非数字变量。在<em class="calibre13">步骤 3 </em>和<em class="calibre13">步骤 4 </em>中，我们将非数字变量转换为虚拟编码变量，并将它们添加回数据帧。在<em class="calibre13">步骤 5 </em>中，我们将数据集分成训练和测试子集，在<em class="calibre13">步骤 6 </em>中，我们从<kbd class="calibre12">sklearn.preprocessing</kbd>导入<kbd class="calibre12">StandardScaler()</kbd>并对我们的特征应用相同的比例。</p>
<p class="calibre2">在执行了<em class="calibre13">步骤 6 </em>中的命令后，我们注意到列名已经变成了序列号。出于这个原因，在<em class="calibre13">步骤 7 </em>中，我们将列名和索引值赋回缩放后的数据帧。在<em class="calibre13">步骤 8 </em>中，我们从<kbd class="calibre12">sklearn.ensemble</kbd>导入了<kbd class="calibre12">RandomForestClassifier()</kbd>，并构建了我们的第一个随机森林分类器模型。之后，在<em class="calibre13">第 9 步</em>和<em class="calibre13">第 10 步</em>中，我们使用我们的模型来计算我们的训练模型的准确性，并分别绘制 ROC 曲线。我们还用 AUC 值标注了 ROC 曲线。</p>
<p class="calibre2">在<em class="calibre13">步骤 11 </em>中，我们评估了其他分数，包括 kappa 值、精确度、召回率和准确度。</p>
<p class="calibre2">在<em class="calibre13">第 12 步</em>中，我们还根据目标变量的每一类评估了这些分数，在本例中，目标变量是<kbd class="calibre12">0</kbd>或<kbd class="calibre12">1</kbd>，使用<kbd class="calibre12">sklearn.metrics</kbd>中的<kbd class="calibre12">classification_report</kbd>。在那里，<kbd class="calibre12">classification_report()</kbd>为我们提供了每个类的精度、召回率和 f1 值等指标，以及每个指标的平均值。</p>
<p class="calibre2"><kbd class="calibre12">classification_report()</kbd>报告平均值，包括平均总真阳性、假阴性和假阳性，平均每个标签的未加权平均值，以及平均每个标签的支持加权平均值。它还报告多标签分类的样本平均值。</p>
<p class="calibre2">最后，在<em class="calibre13">步骤 13 </em>中，我们查看了前 10 项功能的相对可变重要性。这有助于选择特征以构建具有正确特征的模型。</p>
<p>有各种可用的特征选择方法，例如平均变量、重要性、Boruta、递归特征选择和使用 RF 的变量选择。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>There's more...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">还有更多...</h1>
                
            
            
                
<p class="calibre2">隔离森林是另一种建立在决策树基础上的算法，用于异常和离群点检测。该算法基于异常数据点很少的假设。</p>
<p class="calibre2">该算法的工作方式与随机森林略有不同。它创建一组决策树，然后计算隔离树中的观察所需的路径长度。这个想法是，孤立的观察或异常更容易分离，因为区分它们与正常情况所需的条件更少。因此，异常将具有比正常观察更短的路径，并且因此将更靠近树根。当几个决策树被创建时，分数被平均，这给了我们一个好主意，哪些观察是真正异常的。因此，隔离林用于异常值和异常检测。</p>
<div><div><div><p class="calibre2">此外，隔离林不利用任何距离或密度测量来检测异常。与基于距离和基于密度的方法相比，这显著降低了计算成本。</p>
</div>
</div>
</div>
<p class="calibre2">在 scikit-learn 中，<kbd class="calibre12">sklearn.ensemble.IsolationForest</kbd>提供了隔离森林算法的实现。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>See also</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">请参见</h1>
                
            
            
                
<ul class="calibre10">
<li class="calibre11">隔离森林算法的 scikit-learn 实现可以在这里找到:<a href="https://bit.ly/2DCjGGF" class="calibre9">https://bit.ly/2DCjGGF</a></li>
</ul>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Implementing random forest for predicting credit card defaults using H2O</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">使用 H2O 实现预测信用卡违约的随机森林</h1>
                
            
            
                
<p class="calibre2">H2O 是一个开源的分布式机器学习平台，允许你在大型数据集上建立机器学习模型。H2O 支持监督和非监督算法，速度极快，可扩展，易于实现。H2O 的 REST API 允许我们从外部程序(如 R 和 Python)访问它的所有功能。Python 中的 H2O 被设计成非常类似于 scikit-learn。在写这本书的时候，H2O 的最新版本是 H2O v3。</p>
<p class="calibre2">H2O 之所以给企业带来快如闪电的机器学习，有以下解释:</p>
<p>“H2O 的核心代码是用 Java 写的。在 H2O 内部，分布式键/值存储用于跨所有节点和机器访问和引用数据、模型、对象等。这些算法是在 H2O 的分布式 Map/Reduce 框架之上实现的，并利用 Java fork/join 框架实现多线程。数据被并行读取，分布在整个集群中，并以压缩的方式以列格式存储在内存中。H2O 的数据解析器具有内置智能，可以猜测传入数据集的模式，并支持以各种格式从多个来源接收数据”</p>
<p>-来自 h2o.ai</p>
<p class="calibre2">H2O 为我们提供了分布式随机森林，这是一个用于分类和回归任务的强大工具。这会生成多个树，而不是单个树。在分布式随机森林中，我们使用分类和回归模型的平均预测来得出最终结果。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Getting ready</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">做好准备</h1>
                
            
            
                
<p class="calibre2">Java 是 H2O 运行的必备软件。确保在 Jupyter 中使用以下命令安装了 Java:</p>
<pre class="calibre15"><strong class="calibre1">! apt-get install default-jre</strong><br class="title-page-name"/><strong class="calibre1">! java -version</strong></pre>
<p class="calibre2">你现在需要安装 H2O。要从 Jupyter 安装它，请使用以下命令:</p>
<pre class="calibre15"><strong class="calibre1">! pip install h2o</strong></pre>
<p class="calibre2">导入所需的库:</p>
<pre class="calibre15">import h2o<br class="title-page-name"/>import seaborn as sns<br class="title-page-name"/>import numpy as np<br class="title-page-name"/>import pandas as pd<br class="title-page-name"/>import seaborn<br class="title-page-name"/>import matplotlib.pyplot as plt<br class="title-page-name"/>%matplotlib inline<br class="title-page-name"/><br class="title-page-name"/>from h2o.estimators.random_forest import H2ORandomForestEstimator<br class="title-page-name"/>from sklearn import metrics</pre>
<p class="calibre2">要使用 H2O，我们需要初始化一个实例并连接到它。我们可以这样做:</p>
<pre class="calibre15">h2o.init()</pre>
<p class="calibre2">默认情况下，前面的命令尝试连接到实例。如果失败，它将尝试启动一个实例，然后连接到该实例。一旦连接到实例，我们将看到该实例的详细信息，如下所示:</p>
<p class="CDPAlignCenter"><img src="img/845d5994-fe6f-4d56-abfe-db1c235d5142.png" class="calibre36"/></p>
<p class="calibre2">我们将数据读入<kbd class="calibre12">pandas</kbd>数据帧:</p>
<pre class="calibre15">df_creditcarddata = pd.read_csv("UCI_Credit_Card.csv")</pre>
<p class="calibre2">我们使用<kbd class="calibre12">h2o.H2OFrame()</kbd>将我们的<kbd class="calibre12">pandas</kbd>数据帧更改为 H2O 数据帧。我们将<kbd class="calibre12">df_creditcarddata</kbd> H2O 数据帧命名为:</p>
<pre class="calibre15">hf_creditcarddata = h2o.H2OFrame(df_creditcarddata)</pre>
<p class="calibre2">检查 H2O 数据框中的数据是否正确加载，如下所示:</p>
<pre class="calibre15">hf_creditcarddata.head()</pre>
<p class="calibre2">我们可以用<kbd class="calibre12">describe()</kbd>方法看到汇总统计:</p>
<pre class="calibre15">hf_creditcarddata.describe()</pre>
<p class="calibre2"/>
<p class="calibre2">我们删除了 ID 列，因为我们的模型构建练习不需要它:</p>
<pre class="calibre15">hf_creditcarddata = hf_creditcarddata.drop(["ID"], axis = 1) </pre>
<p class="calibre2">我们现在将继续探索我们的数据并构建我们的模型。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>How to do it...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">怎么做...</h1>
                
            
            
                
<p class="calibre2">在前一节中，我们已经对我们的数据进行了各种探索。我们探索数据的方式没有限制。在这一节中，我们将学习更多的技巧:</p>
<ol start="1" class="calibre14">
<li class="calibre11">我们检查每个特征变量与目标变量的相关性:</li>
</ol>
<pre class="calibre18">df_creditcarddata.drop(['default.payment.next.month'], \<br class="title-page-name"/>     axis = 1).corrwith(df_creditcarddata['default.payment.next.month']).\<br class="title-page-name"/>     plot.bar(figsize=(20,10), \<br class="title-page-name"/>     title = 'Correlation with Response variable', \<br class="title-page-name"/>     fontsize = 15, rot = 45, grid = True)</pre>
<p class="calibre20">下图显示了每个特征如何与目标变量相关联:</p>
<p class="CDPAlignCenter"><img src="img/fac4a15a-c60d-4fca-9ae4-01edb2638f15.png" class="calibre33"/></p>
<ol start="2" class="calibre14">
<li class="calibre11">我们检查 H2O 数据框架中的数据类型。注意，对于<kbd class="calibre12">pandas</kbd>数据帧，我们使用了<kbd class="calibre12">dtypes</kbd>。对于 H2O 数据框架，我们使用类型:</li>
</ol>
<pre class="calibre18">hf_creditcarddata.types</pre>
<ol start="3" class="calibre14">
<li class="calibre11">我们注意到它们都是整数数据类型。我们将把它们转换成因素类型，这在本质上是绝对的:</li>
</ol>
<pre class="calibre18">hf_creditcarddata['SEX'] = hf_creditcarddata['SEX'].asfactor()<br class="title-page-name"/>hf_creditcarddata['EDUCATION'] = hf_creditcarddata['EDUCATION'].asfactor()<br class="title-page-name"/>hf_creditcarddata['MARRIAGE'] = hf_creditcarddata['MARRIAGE'].asfactor()<br class="title-page-name"/>hf_creditcarddata['PAY_0'] = hf_creditcarddata['PAY_0'].asfactor()<br class="title-page-name"/>hf_creditcarddata['PAY_2'] = hf_creditcarddata['PAY_2'].asfactor()<br class="title-page-name"/>hf_creditcarddata['PAY_3'] = hf_creditcarddata['PAY_3'].asfactor()<br class="title-page-name"/>hf_creditcarddata['PAY_4'] = hf_creditcarddata['PAY_4'].asfactor()<br class="title-page-name"/>hf_creditcarddata['PAY_5'] = hf_creditcarddata['PAY_5'].asfactor()<br class="title-page-name"/>hf_creditcarddata['PAY_6'] = hf_creditcarddata['PAY_6'].asfactor()</pre>
<p class="calibre20">我们可以用<kbd class="calibre12">hf_creditcarddata.types</kbd>检查数据类型，看看数据类型转换是否已经发生。</p>
<ol start="4" class="calibre14">
<li class="calibre11">我们将二进制目标变量编码为因子类型变量:</li>
</ol>
<pre class="calibre18">hf_creditcarddata['default.payment.next.month'] = \<br class="title-page-name"/>             hf_creditcarddata['default.payment.next.month'].asfactor() <br class="title-page-name"/>hf_creditcarddata['default.payment.next.month'].levels() </pre>
<ol start="5" class="calibre14">
<li class="calibre11">我们选择特征和<kbd class="calibre12">target</kbd>变量:</li>
</ol>
<pre class="calibre18">predictors = ['LIMIT_BAL','SEX','EDUCATION','MARRIAGE','AGE','PAY_0','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6','BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6','PAY_AMT1','PAY_AMT2','PAY_AMT3','PAY_AMT4','PAY_AMT5','PAY_AMT6']<br class="title-page-name"/><br class="title-page-name"/>target = 'default.payment.next.month'</pre>
<ol start="6" class="calibre14">
<li class="calibre11">我们现在将 H2O 数据帧分成训练和测试子集。我们使用 70%的数据来训练模型，剩下的 30%用于验证:</li>
</ol>
<pre class="calibre18">splits = hf_creditcarddata.split_frame(ratios=[0.7], seed=123) <br class="title-page-name"/>train = splits[0]<br class="title-page-name"/>test = splits[1] </pre>
<p class="calibre2"/>
<p class="calibre2"/>
<p class="calibre2"/>
<p class="calibre2"/>
<ol start="7" class="calibre14">
<li class="calibre11">我们用默认设置构建我们的随机森林模型。您可以使用以下命令检查测试数据的模型性能:</li>
</ol>
<pre class="calibre18">from h2o.estimators.random_forest import H2ORandomForestEstimator<br class="title-page-name"/><br class="title-page-name"/>RF_D = H2ORandomForestEstimator(model_id = 'RF_D',seed = 123)<br class="title-page-name"/>RF_D.train(x = predictors, y = target, training_frame = train)<br class="title-page-name"/><br class="title-page-name"/>print(RF_D.model_performance(test))</pre>
<p class="calibre20">这为我们提供了以下性能指标:</p>
<p class="CDPAlignCenter"><img class="aligncenter79" src="img/1b237e8e-a899-4125-8590-a66ef4baa7a0.png"/></p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>How it works...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">它是如何工作的...</h1>
                
            
            
                
<p class="calibre2">在<em class="calibre13">准备</em>部分，我们安装了 JRE 和 H2O。我们用<kbd class="calibre12">h2o.init()</kbd>初始化并连接到一个 H2O 实例。然后，我们使用<kbd class="calibre12">pandas</kbd>读取数据，并将其转换为 H2O 数据帧。我们在 H2O 数据框架上使用了<kbd class="calibre12">head()</kbd>和<kbd class="calibre12">describe()</kbd>方法，就像我们在<kbd class="calibre12">pandas</kbd>数据框架上使用它们一样。然后我们从 H2O 数据框架中删除了<kbd class="calibre12">ID</kbd>列。</p>
<p class="calibre2">在<em class="calibre13">准备就绪</em>部分完成这些数据探索后，我们继续下一步。在<em class="calibre13">步骤 1 中，</em>我们检查了每个特征与<kbd class="calibre12">target</kbd>变量的相关性。在<em class="calibre13">步骤 2 </em>中，我们使用了<kbd class="calibre12">h2o</kbd>数据帧并检查了数据类型。</p>
<p class="calibre2"/>
<p>注意，对于<kbd class="calibre19">pandas</kbd>数据帧，我们使用了<kbd class="calibre19">dtypes</kbd>，而对于<kbd class="calibre19">h2o </kbd>数据帧，我们使用了<kbd class="calibre19">types</kbd>。</p>
<p class="calibre2">在<em class="calibre13">步骤 3 </em>中，我们使用<kbd class="calibre12">asfactor()</kbd>将数字变量转换为分类类型。我们对应该是分类类型但却显示为数字的变量执行了此操作。</p>
<p>在前面的例子中，我们在一个<kbd class="calibre19">pandas</kbd>数据帧上使用了<kbd class="calibre19">astype()</kbd>方法。对于 H2O 数据框架，我们使用了<kbd class="calibre19">asfactor()</kbd>方法。</p>
<p class="calibre2">在<em class="calibre13">步骤 4 </em>中，我们在<kbd class="calibre12">target</kbd>变量上使用了<kbd class="calibre12">asfactor()</kbd>将其转换为分类变量。</p>
<p class="calibre2">在<em class="calibre13">步骤 5 </em>中，我们分离了我们的特征和<kbd class="calibre12">target</kbd>变量。在<em class="calibre13">步骤</em> 6 中，我们在 H2O 数据帧上使用<kbd class="calibre12">split_frame()</kbd>将 H2O 数据帧分成训练和测试子集。我们使用<kbd class="calibre12">ratios</kbd>参数，并将其设置为<kbd class="calibre12">split_frame()</kbd>的<kbd class="calibre12">ratios=[0.7]</kbd>，将 70%的数据分配给训练集，30%的数据分配给测试集。</p>
<p class="calibre2">在<em class="calibre13">第 7 步</em>中，我们从<kbd class="calibre12">h2o.estimators.random_forest</kbd>导入了<kbd class="calibre12">H2ORandomForestEstimator</kbd>。我们传递了<kbd class="calibre12">model_id</kbd>，然后引用它来调用<kbd class="calibre12">train()</kbd>函数，并传递预测器和<kbd class="calibre12">target</kbd>变量。然后，我们通过将测试子集传递给<kbd class="calibre12">model_performance()</kbd>来查看性能指标。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>There's more...</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">还有更多...</h1>
                
            
            
                
<p class="calibre2">在前面的例子中，我们有一个 AUC 为<kbd class="calibre12">0.76</kbd>和 log loss 为<kbd class="calibre12">0.44</kbd>:</p>
<ol class="calibre14">
<li class="calibre11">我们可以通过将<kbd class="calibre12">nfolds</kbd>作为参数传递给<kbd class="calibre12">H2ORandomForestEstimator()</kbd>来应用交叉验证:</li>
</ol>
<pre class="calibre18">RF_cv = H2ORandomForestEstimator(model_id = 'RF_cv', <br class="title-page-name"/>                                 seed = 12345, <br class="title-page-name"/>                                 ntrees = 500, <br class="title-page-name"/>                                 sample_rate = 0.9, <br class="title-page-name"/>                                 col_sample_rate_per_tree = 0.9, <br class="title-page-name"/>                                 nfolds = 10)<br class="title-page-name"/>                                            <br class="title-page-name"/>RF_cv.train(x = predictors, y = target, training_frame = train)<br class="title-page-name"/>print(RF_cv.model_performance(test))</pre>
<p class="calibre20">我们注意到 AUC 略微提高到<kbd class="calibre12">0.77</kbd>，原木损失下降到<kbd class="calibre12">0.43</kbd>:</p>
<p class="CDPAlignCenter"><img class="aligncenter80" src="img/ee005306-9054-40e0-b54f-eb0931b04b2d.png"/></p>
<p class="calibre2"/>
<ol start="2" class="calibre14">
<li class="calibre11">我们还可以应用网格搜索从给定的选项中提取最佳模型。我们将选项设置如下:</li>
</ol>
<pre class="calibre18">search_criteria = {'strategy': "RandomDiscrete"}<br class="title-page-name"/><br class="title-page-name"/>hyper_params = {'sample_rate': [0.5, 0.6, 0.7],\<br class="title-page-name"/>                'col_sample_rate_per_tree': [0.7, 0.8, 0.9],\<br class="title-page-name"/>                'max_depth': [3, 5, 7]}</pre>
<ol start="3" class="calibre14">
<li class="calibre11">我们使用前面的搜索参数构建模型:</li>
</ol>
<pre class="calibre18">from h2o.grid.grid_search import H2OGridSearch<br class="title-page-name"/><br class="title-page-name"/>RF_Grid = H2OGridSearch(<br class="title-page-name"/>                    H2ORandomForestEstimator(<br class="title-page-name"/>                        model_id = 'RF_Grid', <br class="title-page-name"/>                        ntrees = 200, <br class="title-page-name"/>                        nfolds = 10,<br class="title-page-name"/>                        stopping_metric = 'AUC', <br class="title-page-name"/>                        stopping_rounds = 25), <br class="title-page-name"/>                    search_criteria = search_criteria, # full grid search<br class="title-page-name"/>                    hyper_params = hyper_params)<br class="title-page-name"/>RF_Grid.train(x = predictors, y = target, training_frame = train)</pre>
<ol start="4" class="calibre14">
<li class="calibre11">我们现在按 AUC 降序排列所有模型，然后选择 AUC 最高的第一个模型:</li>
</ol>
<pre class="calibre18">RF_Grid_sorted = RF_Grid.get_grid(sort_by='auc',decreasing=True)<br class="title-page-name"/>print(RF_Grid_sorted)<br class="title-page-name"/><br class="title-page-name"/>best_RF_model = RF_Grid_sorted.model_ids[0]<br class="title-page-name"/>best_RF_from_RF_Grid = h2o.get_model(best_RF_model)</pre>
<ol start="5" class="calibre14">
<li class="calibre11">我们为测试数据应用最佳模型:</li>
</ol>
<pre class="calibre18">best_RF_from_RF_Grid.model_performance(test)</pre>
<ol start="6" class="calibre14">
<li class="calibre11">我们可以从迄今为止已经实现的最佳模型中绘制出变量重要性:</li>
</ol>
<ol start="6" class="calibre14"/>
<pre class="calibre18">best_RF_from_RF_G<br class="title-page-name"/>rid.varimp_plot()</pre>
<p class="calibre20">这给了我们以下的情节:</p>
<p class="CDPAlignCenter"><img src="img/1014ef94-8e46-46df-af56-802e3ba9589f.png" class="calibre37"/></p>
<p class="calibre2"/>
<p class="calibre2"/>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>See also</title>
    <meta content="urn:uuid:64b74aae-7be0-4e73-89f3-687dd4470606" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">请参见</h1>
                
            
            
                
<p class="calibre2">您可能希望研究极度随机化的树，它们的实现略有不同，但有时比随机森林的性能更好。</p>
<div><div><div><div><div><div><div><div><p class="calibre2">在集成方法中，每个模型在数据集子集和用于训练的特征向量子集方面进行不同的学习。这些子集是随机选取的。极度随机化的树在计算分割和所选特征子集的方式上具有很高的随机性。与随机森林不同，在随机森林中，分裂阈值是随机选择的，在极度随机化的树中，使用区别阈值作为分裂规则。由于这个原因，整体的总体方差减小，并且总体性能可能更好。</p>
<p class="calibre2">极度随机化树的 scikit-learn 实现可以在以下链接找到:【https://bit.ly/2zWsNNS<a xmlns:epub="http://www.idpf.org/2007/ops" href="https://bit.ly/2zWsNNS" class="calibre9"/><a xmlns:epub="http://www.idpf.org/2007/ops" href="https://bit.ly/2zWsNNS" class="calibre9">。H2O 也支持极度随机化的树。</a></p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>


            

            
        
    </body>

</html>
</body></html>