<html><head/><body>



<title>Chapter 2. Tools and Techniques</title><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/><div><div><div><div><h1 class="title"><a id="ch02"/>第二章。工具和技术</h1></div></div></div><p>Python 配备了一个用于机器学习任务的大型包库。</p><p>我们将在本章中查看的软件包如下:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">IPython 控制台</li><li class="listitem" style="list-style-type: disc">NumPy，它是一个扩展，增加了对多维数组、矩阵和高级数学函数的支持</li><li class="listitem" style="list-style-type: disc">SciPy 是一个科学公式、常数和数学函数的库</li><li class="listitem" style="list-style-type: disc">Matplotlib，用于创建地块</li><li class="listitem" style="list-style-type: disc">Scikit-learn，这是一个用于机器学习任务(如分类、回归和聚类)的库</li></ul></div><p>这里的空间只够让你感受一下这些庞大库的<em>风味</em>，一项重要的技能是能够找到并理解各种软件包的参考资料。不可能在一个教程风格的文档中呈现所有不同的功能，重要的是能够找到绕过有时是密集的 API 参考的方法。需要记住的一点是，这些包中的大部分是由开源社区放在一起的。它们不像商业产品那样是单一的结构，因此，理解各种不同的包分类法可能会令人困惑。然而，开源软件方法的多样性，以及想法不断被贡献的事实，给了它一个重要的优势。</p><p>然而，开源软件不断发展的质量也有其不利的一面，尤其是对于 ML 应用。例如，Python 机器学习用户社区很不愿意从 Python 2 迁移到 Python 3。因为 Python 3 打破了向后兼容性；重要的是，就其数值处理而言，更新相关包不是一个简单的过程。在写作的时候，所有重要的(对我来说很重要！)包，以及本书中使用的所有包，都适用于 Python 2.7 或 3x。Python 的主要发行版都有 Python 3 版本，包集略有不同。</p><div><div><div><div><h1 class="title"><a id="ch02lvl1sec11"/>用于机器学习的 Python</h1></div></div></div><p>Python 是一种通用编程语言。它是一种解释型语言，可以从控制台交互运行。它不需要像 C++或 Java 这样的编译器，所以开发时间<a id="id81" class="indexterm"/>往往会更短。它可以免费下载，可以安装在许多不同的操作系统上，包括 UNIX、Windows 和 Macintosh。它在科学和数学应用中特别受欢迎。与 C++和 Java 等语言相比，Python 相对容易学习，类似的任务使用更少的代码行。</p><p>Python 不是机器学习的唯一平台，但肯定是使用最多的平台之一。它的主要替代品之一是<strong> R </strong>。与 Python 一样，它是开源的，虽然它在应用机器<a id="id82" class="indexterm"/>学习方面很受欢迎，但它缺乏 Python 的大型开发社区。r 是机器学习和统计分析的专用工具。Python 是一种通用的、广泛使用的编程语言，它也为机器学习应用程序提供了优秀的库。</p><p>另一个替代方案是<strong> Matlab </strong>。不像 R <a id="id83" class="indexterm"/>和 Python，它是一个商业产品。正如所料，它包含了一个完美的用户界面和详尽的文档。然而，和 R 一样，它缺乏 Python 的通用性。Python 是一种非常有用的语言，与其他平台相比，你学习它的努力将会带来更大的回报。它还拥有优秀的网络库、web 开发库和微控制器编程库。这些应用程序可以补充或增强你在机器学习方面的工作，完全没有笨拙的集成和学习或记忆不同语言细节的痛苦。</p></div></div>





<title>IPython console</title><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/><div><div><div><div><h1 class="title"><a id="ch02lvl1sec12"/> IPython 控制台</h1></div></div></div><p>随着版本 4 的发布，<code class="literal">Ipython</code>包已经<a id="id84" class="indexterm"/>有了一些重大的变化。它以前是一个整体封装结构，现在已被分成多个子封装。几个 IPython 项目已经分裂成他们自己独立的项目。大多数库<a id="id85" class="indexterm"/>已经被转移到<strong> Jupyter </strong>项目中(<a class="ulink" href="http://jupyter.org">jupyter.org</a>)。</p><p>IPython 的核心是 IPython 控制台:一个强大的交互式解释器，允许您以非常快速和直观的方式测试您的想法。不必在每次想要测试代码片段时都创建、保存和运行文件，只需在控制台中键入即可。IPython 的一个强大特性是，它解耦了大多数计算平台所基于的传统读取-评估-打印循环。IPython 将 evaluate 阶段放在自己的进程中:一个内核(不要与机器学习算法中使用的内核函数混淆)。重要的是，不止一个客户端可以访问内核。这意味着您可以运行许多文件中的代码并访问它们，例如，从控制台运行一个方法。此外，内核和客户机不需要在同一台机器上。这对分布式和网络化计算有着强大的影响。</p><p>IPython 控制台增加了命令行特性，比如 tab 补全和<code class="literal">%magic</code>命令，它们复制了终端命令。如果您使用的不是已经安装了 IPython 的 Python 发行版，您可以通过在 Python 命令行中键入<code class="literal">ipython</code>来启动 IPython。在 IPython 控制台中键入<code class="literal">%quickref</code>会给你一个命令列表和它们的<a id="id86" class="indexterm"/>功能。</p><p>还应该提到 IPython 笔记本。这款笔记本已经并入了另一个名为 Jupyter(【jupyter.org】)的项目。这个 web <a id="id87" class="indexterm"/>应用程序是一个用 40 多种语言进行数值计算的强大平台。该笔记本允许您共享和协作实时代码，并发布丰富的图形和文本。</p></div>





<title>Installing the SciPy stack</title><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/><div><div><div><div><h1 class="title"><a id="ch02lvl1sec13"/>安装 SciPy 堆栈</h1></div></div></div><p>SciPy 栈由 Python 和最常用的科学、数学和 ML 库组成。(访问:<a class="ulink" href="http://scipy.org">scipy.org</a>)。这些包括<strong> NumPy </strong>、<strong> Matplotlib </strong>、<a id="id90" class="indexterm"/> SciPy 库本身以及 IPython。这些包可以单独安装在现有的 Python 系统上，或者作为一个完整的发行版(<strong> distro </strong>)。如果你的电脑上没有安装 Python，最简单的入门方法是使用发行版。主要的 Python <a id="id93" class="indexterm"/>发行版适用于大多数平台，它们在一个包中包含了您需要的一切。单独安装所有的包及其依赖项确实需要一些时间，但是如果您的机器上已经安装了配置好的 Python，这可能是一个选项。</p><p>大多数发行版都为您提供了所需的所有工具，而且许多都附带了强大的开发环境。最好的两个<a id="id94" class="indexterm"/>是<strong>蟒蛇</strong>(<a class="ulink" href="http://www.continuum.io/downloads">www.continuum.io/downloads</a>)和<strong>天蓬</strong>(<a class="ulink" href="http://www.enthought.com/products/canopy/">http://www.enthought.com/products/canopy/</a>)。都有<a id="id95" class="indexterm"/>免费版和商业版。作为参考，我将使用 Python 的 Anaconda 发行版。</p><p>安装主要发行版通常是一件相当轻松的任务。</p><div><div><h3 class="title"><a id="tip02"/>提示</h3><p>请注意，并非所有的发行版都包含相同的 Python 模块集，您可能需要安装模块，或者重新安装模块的正确版本。</p></div></div></div>





<title>NumPY</title><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/><div><div><div><div><h1 class="title"><a id="ch02lvl1sec14"/> NumPY</h1></div></div></div><p>我们应该知道在 Python 中有一个表示数据的类型层次结构。根是不可变的对象<a id="id96" class="indexterm"/>，比如整数、浮点数和布尔值。在此基础上，我们有了序列类型。这些是由非负整数索引的有序对象集。它们是包含字符串、列表和元组的迭代对象。序列类型有一组常见的操作，例如返回一个元素(<em> s[i] </em>)或一个切片(<em> s[i:j] </em>)，以及查找长度(<em> len(s) </em>)或 sum ( <em> sum(s) </em>)。最后，我们有映射类型。这些是由另一个键对象集合索引的对象集合。映射对象是无序的，通过数字、字符串或其他对象进行索引。内置的 Python 映射类型是字典。</p><p>NumPy 通过提供另外两个对象来构建这些数据对象:一个 N 维数组对象(<code class="literal">ndarray</code>)和一个通用函数对象(<code class="literal">ufunc</code>)。<code class="literal">ufunc</code>对象提供了对<code class="literal">ndarray</code>对象的逐元素操作，允许类型转换和数组广播。类型转换是将一种数据类型转换为另一种数据类型的过程，广播描述了在算术运算过程中如何处理不同大小的数组。有线性代数(<code class="literal">linalg</code>)、随机数生成(<code class="literal">random</code>)、离散傅立叶变换(<code class="literal">fft</code>)和单元测试(<code class="literal">testing</code>)的子包。</p><p>NumPy 使用一个<code class="literal">dtype</code>对象来描述数据的各个方面。这包括数据的类型，如 float、integer 等，数据类型中的字节数(如果数据是结构化的)，以及字段的名称和任何子数组的形状。NumPy 有几个新的数据类型，包括:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">8、16、32 和 64 位<code class="literal">int</code>值</li><li class="listitem" style="list-style-type: disc">16、32 和 64 位浮点值</li><li class="listitem" style="list-style-type: disc">64 位和 128 位复杂类型</li><li class="listitem" style="list-style-type: disc"><code class="literal">Ndarray</code>结构化数组类型</li></ul></div><p>我们可以使用<code class="literal">np.cast</code>对象在类型之间转换。这是一个简单的字典，根据目标转换类型进行键控，其值是执行转换的适当函数。这里我们将一个整数转换成一个浮点数 32:</p><p><em> f= np.cast['f'] (2) </em></p><p>NumPy 数组可以通过多种方式创建，例如从其他 Python 数据结构转换，使用内置的数组创建对象如<code class="literal">arange()</code>、<code class="literal">ones()</code>和<code class="literal">zeros()</code>，或者从文件如<code class="literal">.csv</code>或<code class="literal">.html</code>转换。</p><p><code class="literal">Indexing</code>和<code class="literal">slicingNumPy</code>基于序列中使用的切片和索引技术。您应该已经熟悉 Python 中使用<code class="literal">[i:j:k]</code>语法的切片序列，比如列表和元组，其中<code class="literal">i</code>是开始索引，<code class="literal">j</code>是结束，<code class="literal">k</code>是步骤。NumPy 将选择元组的概念扩展到 N 维。</p><p>启动 Python 控制台并键入以下命令:</p><div><pre class="programlisting">
<strong>import numpy as np</strong>
<strong>a=np.arange(60).reshape(3,4,5)</strong>
<strong>print(a)</strong>
</pre></div><p>您将观察到以下情况:</p><div><img src="img/B05198_2_10.jpg" alt="NumPY"/></div><p>这将打印 3 乘 4 乘 5 数组前面的<a id="id97" class="indexterm"/>。您应该知道，我们可以使用像<code class="literal">a[2,3,4]</code>这样的符号来访问数组中的每一项。这将返回<code class="literal">59</code>。请记住，索引从 0 开始。</p><p>我们可以使用切片技术来返回数组的切片。</p><p>下图显示了<code class="literal">A[1:2:]</code>阵列:</p><div><img src="img/B05198_2_14.jpg" alt="NumPY"/></div><p>使用椭圆(…)，我们可以选取任何剩余的未指定尺寸。例如，<code class="literal">a[...,1]</code>相当于<code class="literal">a[:,:,1]</code>:</p><div><img src="img/B05198_2_11.jpg" alt="NumPY"/></div><p>您也可以使用负数从轴的末端开始计数:</p><div><img src="img/B05198_2_15.jpg" alt="NumPY"/></div><p>通过切片，我们正在创建视图；原始数组保持不变，视图保留对原始数组的引用<a id="id98" class="indexterm"/>。这意味着当我们创建一个片时，即使我们把它赋给一个新的变量，如果我们改变了原来的数组，这些改变也会反映在新的数组中。下图说明了这一点:</p><div><img src="img/B05198_2_16.jpg" alt="NumPY"/></div><p>这里，<strong> a </strong>和<strong> b </strong>指的是同一个数组。当我们在<code class="literal">a</code>中赋值时，这也反映在<code class="literal">b</code>中。为了复制一个数组而不是简单地引用它，我们使用了标准库中<a id="id99" class="indexterm"/>包<code class="literal">copy</code>中的深度<code class="literal">copy()</code>函数:</p><div><pre class="programlisting">
<strong>import copy</strong>
<strong>c=copy.deepcopy(a)</strong>
</pre></div><p>在这里，我们创建了一个新的独立数组，<code class="literal">c</code>。在数组<code class="literal">a</code>中所做的任何改变都不会反映在数组<code class="literal">c</code>中。</p><div><div><div><div><h2 class="title"><a id="ch02lvl2sec10"/>构造和转换数组</h2></div></div></div><p>这种切片功能<a id="id100" class="indexterm"/>也可以和几个 NumPy 类一起使用，作为构造数组的有效方法。例如，<code class="literal">numpy.mgrid</code>对象创建了一个<a id="id101" class="indexterm"/> <code class="literal">meshgrid</code>对象，在某些情况下，它提供了一个比<code class="literal">arange()</code>更方便的选择。它的主要目的是为指定的 N 维体积构建一个坐标数组。请参考下图作为示例:</p><div><img src="img/B05198_2_17.jpg" alt="Constructing and transforming arrays"/></div><p>有时，我们需要以其他方式操作我们的数据结构。其中包括:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>concatenating</strong>: By using the <code class="literal">np.r_</code> and <code class="literal">np.c_</code> functions, we can concatenate along one or two axes using the slicing constructs. Here is an example:<div><img src="img/B05198_2_18.jpg" alt="Constructing and transforming arrays"/></div><p>这里我们使用了复数<strong> 5j </strong>作为步长，Python <a id="id102" class="indexterm"/>将其解释为点的数量，以在指定范围(这里是<strong> -1 </strong>到<strong> 1 </strong>)之间拟合<a id="id103" class="indexterm"/>。</p></li><li class="listitem" style="list-style-type: disc"><strong>newaxis</strong>: This object expands the dimensions of an array:<div><img src="img/B05198_2_19.jpg" alt="Constructing and transforming arrays"/></div><p>这在第一维度上创建了一个额外的轴。以下内容在第二维中创建新轴:</p><div><img src="img/B05198_2_20.jpg" alt="Constructing and transforming arrays"/></div><p>您也可以使用布尔运算符进行过滤:</p><div><pre class="programlisting">
<strong>a[a&lt;5]</strong>
<strong>Out[]: array([0, 1, 2, 3, 4])</strong>
</pre></div></li><li class="listitem" style="list-style-type: disc">Find the sum of a given axis:<div><img src="img/B05198_2_21.jpg" alt="Constructing and transforming arrays"/></div><p>这里我们用轴 2 求和。</p></li></ul></div></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec11"/>数学运算</h2></div></div></div><p>正如您所期望的，您可以在 NumPy 数组上执行数学运算，如加、减、乘以及三角函数。不同形状阵列上的算术<a id="id105" class="indexterm"/>运算可以通过称为<strong>广播</strong>的过程来执行。当<a id="id106" class="indexterm"/>在两个数组上操作时，NumPy 从尾部维度开始按元素比较它们的形状。如果两个尺寸相同，或者其中一个尺寸为 1，则这两个尺寸是相容的。如果不满足这些条件，则抛出<code class="literal">ValueError</code>异常。</p><p>这些都是使用<code class="literal">ufunc</code>对象在后台完成的。该对象在<code class="literal">ndarrays</code>上逐个元素地操作。它们本质上是包装器，为标量函数提供一致的接口，以允许它们使用 NumPy 数组。超过 60 个<code class="literal">ufunc</code>对象涵盖了各种操作和类型。当您使用<code class="literal">+</code>操作符执行诸如添加两个数组的操作时，会自动调用<code class="literal">ufunc</code>对象。</p><p>让我们看看一些额外的数学特征:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>Vectors</strong>: We can<a id="id107" class="indexterm"/> also create our own vectorized versions of scalar<a id="id108" class="indexterm"/> functions using the <code class="literal">np.vectorize()</code> function. It takes a Python <code class="literal">scalar</code> function or method as a parameter and returns a vectorized version of this function:<div><pre class="programlisting">
<strong>def myfunc(a,b):</strong>
<strong>def myfunc(a,b):</strong>
<strong>if a &gt; b:</strong>
<strong>        return a-b</strong>
<strong>    else:</strong>
<strong>        return a + b</strong>
<strong>vfunc=np.vectorize(myfunc)</strong>
</pre></div><p>我们将观察到以下输出:</p><div><img src="img/B05198_2_22.jpg" alt="Mathematical operations"/></div></li><li class="listitem" style="list-style-type: disc"><strong>Polynomial functions</strong>: The <code class="literal">poly1d</code> class allows us to deal with polynomial functions in a natural way. It <a id="id109" class="indexterm"/>accepts as a parameter an array of coefficients in decreasing powers. For example, the polynomial, <em>2x<sup>2</sup></em> + <em>3x + 4</em>, can be entered by the following:<div><img src="img/B05198_2_23.jpg" alt="Mathematical operations"/></div><p>我们可以看到它以人类可读的方式打印出了<a id="id110" class="indexterm"/>多项式。我们可以对多项式执行各种操作，例如在一个点上求值:</p><div><img src="img/B05198_2_24.jpg" alt="Mathematical operations"/></div></li><li class="listitem" style="list-style-type: disc">找到根源:<div> <img src="img/B05198_2_25.jpg" alt="Mathematical operations"/> </div></li></ul></div><p>我们可以使用<code class="literal">asarray(p)</code>给多项式的系数一个数组，这样它就可以用在所有接受数组的函数中。</p><p>正如我们将看到的，基于 NumPy 构建的包<a id="id111" class="indexterm"/>为我们提供了一个强大而灵活的机器学习框架。</p></div></div>





<title>Matplotlib</title><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/><div><div><div><div><h1 class="title">Matplotlib</h1></div></div></div><p>Matplotlib，或者更重要的是它的子包<code class="literal">PyPlot</code>，是用 Python 可视化二维数据的必备工具。我在这里只简单地提一下，因为随着我们对例子的学习，它的用法会变得很明显。它的工作原理与 Matlab 类似，具有命令式功能。每个<code class="literal">PyPlot</code>函数对一个<code class="literal">PyPlot</code>实例做一些改变。<code class="literal">PyPlot</code>的核心是<code class="literal">plot</code>方法。最简单的实现是传递 plot 列表或 1D 数组。如果只有一个参数被传递给 plot，它假定它是一个由<em> y </em>值组成的序列，它将自动生成<em> x </em>值。更常见的是，我们为坐标<em> x </em>和<em> y </em>传递 plot 两个 1D 数组或列表。<code class="literal">plot</code>方法也可以接受一个参数来指示线条属性，比如线条宽度、颜色和样式。这里有一个例子:</p><div><pre class="programlisting">
<strong>import numpy as np</strong>
<strong>import matplotlib.pyplot as plt</strong>

<strong>x = np.arange(0., 5., 0.2)</strong>
<strong>plt.plot(x, x**4, 'r', x, x*90, 'bs', x, x**3, 'g^')</strong>
<strong>plt.show()</strong>
</pre></div><p>这段代码以不同的样式打印了三行<a id="id113" class="indexterm"/>:一条红线、蓝色方块和绿色三角形。注意，我们可以传递多对坐标数组来绘制多条线。如需线条样式的完整列表，请键入<code class="literal">help(plt.plot)</code>函数。</p><p>Pyplot 和 Matlab 一样，将绘图命令应用于当前轴。使用<code class="literal">subplot</code>命令可以创建多个轴。这里有一个例子:</p><div><pre class="programlisting">
<strong>x1 = np.arange(0., 5., 0.2)</strong>
<strong>x2 = np.arange(0., 5., 0.1)</strong>

<strong>plt.figure(1)</strong>
<strong>plt.subplot(211)</strong>
<strong>plt.plot(x1, x1**4, 'r', x1, x1*90, 'bs', x1, x1**3, 'g^',linewidth=2.0)</strong>

<strong>plt.subplot(212)</strong>
<strong>plt.plot(x2,np.cos(2*np.pi*x2), 'k')</strong>
<strong>plt.show()</strong>
</pre></div><p>上述代码的输出如下:</p><div><img src="img/B05198_2_26.jpg" alt="Matplotlib"/></div><p>另一个有用的图是直方图。<code class="literal">hist()</code>对象接受输入值的数组或数组序列。第二个参数是箱的数量。在本例中，我们将分布划分为 10 个箱。当设置为<code class="literal">1</code>或<code class="literal">true</code>时，归一化参数将计数归一化为<a id="id114" class="indexterm"/>形式的概率密度。还要注意，在这段代码中，我们标记了<em> x </em>和<em> y </em>轴，并在坐标给出的位置显示了一个标题和一些文本:</p><div><pre class="programlisting">
<strong>mu, sigma = 100, 15</strong>
<strong>x = mu + sigma * np.random.randn(1000)</strong>
<strong>n, bins, patches = plt.hist(x, 10, normed=1, facecolor='g')</strong>
<strong>plt.xlabel('Frequency')</strong>
<strong>plt.ylabel('Probability')</strong>
<strong>plt.title('Histogram Example')</strong>
<strong>plt.text(40,.028, 'mean=100 std.dev.=15')</strong>
<strong>plt.axis([40, 160, 0, 0.03])</strong>
<strong>plt.grid(True)</strong>
<strong>plt.show()</strong>
</pre></div><p>这段代码的输出如下所示:</p><div><img src="img/B05198_2_27.jpg" alt="Matplotlib"/></div><p>我们要看的最后一个 2D 图是散点图。<code class="literal">scatter</code>对象接受两个相同长度的序列对象(如数组)和可选参数来表示颜色和样式<a id="id115" class="indexterm"/>属性。让我们来看看这段代码:</p><div><pre class="programlisting">
<strong>N = 100</strong>
<strong>x = np.random.rand(N)</strong>
<strong>y = np.random.rand(N)</strong>
<strong>#colors = np.random.rand(N)</strong>
<strong>colors=('r','b','g')</strong>
<strong>area = np.pi * (10 * np.random.rand(N))**2  # 0 to 10 point radiuses</strong>
<strong>plt.scatter(x, y, s=area, c=colors, alpha=0.5)</strong>
<strong>plt.show()</strong>
</pre></div><p>我们将观察到以下输出:</p><div><img src="img/B05198_2_28.jpg" alt="Matplotlib"/></div><p>Matplotlib 也有一个强大的工具箱用于渲染 3D 绘图。以下代码演示是 3D 折线图、散点图和曲面图的简单示例。3D 图的创建方式与 2D 图非常相似。这里，我们用<code class="literal">gca</code>函数获取当前轴，并将<a id="id116" class="indexterm"/>投影参数设置为 3D。所有的绘图方法工作起来都很像 2D 的对应方法，除了它们现在为 z 轴获取第三组输入值:</p><div><pre class="programlisting">
<strong>import matplotlib as mpl</strong>
<strong>from mpl_toolkits.mplot3d import Axes3D</strong>
<strong>import numpy as np</strong>
<strong>import matplotlib.pyplot as plt</strong>
<strong>from matplotlib import cm</strong>

<strong>mpl.rcParams['legend.fontsize'] = 10</strong>

<strong>fig = plt.figure()</strong>
<strong>ax = fig.gca(projection='3d')</strong>
<strong>theta = np.linspace(-3 * np.pi, 6 * np.pi, 100)</strong>
<strong>z = np.linspace(-2, 2, 100)</strong>
<strong>r = z**2 + 1</strong>
<strong>x = r * np.sin(theta)</strong>
<strong>y = r * np.cos(theta)</strong>
<strong>ax.plot(x, y, z)</strong>

<strong>theta2 = np.linspace(-3 * np.pi, 6 * np.pi, 20)</strong>
<strong>z2 = np.linspace(-2, 2, 20)</strong>
<strong>r2=z2**2 +1</strong>
<strong>x2 = r2 * np.sin(theta2)</strong>
<strong>y2 = r2 * np.cos(theta2)</strong>

<strong>ax.scatter(x2,y2,z2, c= 'r')</strong>
<strong>x3 = np.arange(-5, 5, 0.25)</strong>
<strong>y3 = np.arange(-5, 5, 0.25)</strong>
<strong>x3, y3 = np.meshgrid(x3, y3)</strong>
<strong>R = np.sqrt(x3**2 + y3**2)</strong>
<strong>z3 = np.sin(R)</strong>
<strong>surf = ax.plot_surface(x3,y3,z3, rstride=1, cstride=1, cmap=cm.Greys_r,</strong>
<strong>                       linewidth=0, antialiased=False)</strong>
<strong>ax.set_zlim(-2, 2)</strong>
<strong>plt.show()</strong>
</pre></div><p>我们将观察<a id="id117" class="indexterm"/>这个输出:</p><div><img src="img/B05198_2_29.jpg" alt="Matplotlib"/></div></div>





<title>Pandas</title><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/><div><div><div><div><h1 class="title"><a id="ch02lvl1sec16"/>熊猫</h1></div></div></div><p><strong> Pandas </strong>库通过引入几个有用的数据结构和功能来读取和处理数据，从而在 NumPy 上构建了<a id="id118" class="indexterm"/>。Pandas 是一个很好的通用数据管理工具。它可以轻松处理常见任务，例如处理缺失数据、操作形状和大小、在数据格式和结构之间转换以及从不同来源导入数据。</p><p>Pandas 引入的主要数据结构有:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">系列</li><li class="listitem" style="list-style-type: disc">数据框架</li><li class="listitem" style="list-style-type: disc">面板</li></ul></div><p>数据帧可能是应用最广泛的。它是一个二维结构，实际上是一个从 NumPy 数组、列表、字典或序列创建的表。您也可以通过读取文件来创建数据帧。</p><p>大概了解熊猫的最好方法是浏览一个典型的使用案例。假设我们的任务是发现日最高温度是如何随时间变化的。在这个例子中，我们将使用塔斯马尼亚霍巴特气象站的历史天气观测数据<a id="id120" class="indexterm"/>。下载下面的 ZIP 文件，并将其内容解压到 Python 工作目录中名为<strong> data </strong>的文件夹中:</p><p><a class="ulink" href="http://davejulian.net/mlbook/data">http://davejulian.net/mlbook/data</a></p><p>我们做的第一件事是从它创建一个数据帧:</p><div><pre class="programlisting">
<strong>import pandas as pd</strong>
<strong>df=pd.read_csv('data/sampleData.csv')</strong>
</pre></div><p>检查数据中的前几行:</p><div><pre class="programlisting">df.head()</pre></div><p>我们可以看到，每一行的产品代码和站号都是相同的，这些信息是多余的。此外，我们不需要累计最高温度的天数，因此我们也将它们删除:</p><div><pre class="programlisting">
<strong>del df['Bureau of Meteorology station number']</strong>
<strong>del df['Product code']</strong>
<strong>del df['Days of accumulation of maximum temperature']</strong>
</pre></div><p>让我们通过缩短列标签来使我们的数据更容易阅读:</p><div><pre class="programlisting">
<strong>df=df.rename(columns={'Maximum temperature (Degree C)':'maxtemp'})</strong>
</pre></div><p>我们只对高质量的数据感兴趣，所以我们只包括在质量列中有<em> Y </em>的记录:</p><div><pre class="programlisting">
<strong>df=df[(df.Quality=='Y')]</strong>
</pre></div><p>我们可以得到数据的统计摘要:</p><div><pre class="programlisting">
<strong>df.describe()</strong>
</pre></div><div><img src="img/B05198_2_12.jpg" alt="Pandas"/></div><p>如果我们<a id="id121" class="indexterm"/>导入<code class="literal">matplotlib.pyplot</code>包，我们可以将数据图形化:</p><div><pre class="programlisting">
<strong>import matplotlib.pyplot as plt</strong>
<strong>plt.plot(df.Year, df.maxtemp)</strong>
</pre></div><div><img src="img/B05198_2_30.jpg" alt="Pandas"/></div><p>请注意，PyPlot 正确地格式化了日期轴，并通过连接任一侧的两个已知点来处理缺失的数据。我们可以使用以下方法将 DataFrame 转换为 NumPy 数组:</p><div><pre class="programlisting">
<strong>ndarray = df.values</strong>
</pre></div><p>如果 DataFrame 包含混合的数据类型，那么这个函数会将它们转换为最小公分母类型，这意味着将选择容纳所有值的类型。例如，如果 DataFrame 由 float16 和 float32 类型混合组成，则值将被转换为 float 32。</p><p>Pandas DataFrame 是一个查看和操作简单文本和数字数据的好对象。然而，熊猫可能不是更复杂的数字处理<a id="id122" class="indexterm"/>的合适工具，比如计算点积，或者寻找线性系统的解。对于数值应用程序，我们通常使用 NumPy 类。</p></div>





<title>SciPy</title><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/><div><div><div><div><h1 class="title">SciPy</h1></div></div></div><p>SciPy 为 NumPy 增加了一个层，在 NumPy 更纯粹的数学结构之上包装了常见的科学和统计应用程序。SciPy 提供了操作和可视化数据的高级功能，在交互式使用 Python 时尤其有用。SciPy 被组织成涵盖不同科学计算应用的子包。与 ML 及其功能最相关的包<a id="id124" class="indexterm"/>列表如下:</p><div><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>包裹</p>
</th><th style="text-align: left" valign="bottom">
<p>描述</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p><code class="literal">cluster</code></p>
</td><td style="text-align: left" valign="top">
<p>这包含两个<a id="id125" class="indexterm"/>子包:</p>
<p><code class="literal">cluster.vq</code>用于 K-means 聚类和矢量量化。</p>
<p><code class="literal">cluster.hierachy</code>用于层次聚类和聚集聚类，这对于距离矩阵、计算聚类的统计数据以及用树状图可视化聚类非常有用。</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">constants</code></p>
</td><td style="text-align: left" valign="top">
<p>这些是物理和<a id="id126" class="indexterm"/>数学常数，如<em> pi </em>和<em> e </em>。</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">integrate</code></p>
</td><td style="text-align: left" valign="top">
<p>这些是微分方程解算器</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">interpolate</code></p>
</td><td style="text-align: left" valign="top">
<p>这些<a id="id128" class="indexterm"/>是用于在已知点范围内创建新数据点的插值函数。</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">io</code></p>
</td><td style="text-align: left" valign="top">
<p>这指的是用于创建字符串、二进制或原始数据流的输入和输出函数，以及从文件中读取和写入。</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">optimize</code></p>
</td><td style="text-align: left" valign="top">
<p>这里指的是优化和<a id="id130" class="indexterm"/>寻根。</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">linalg</code></p>
</td><td style="text-align: left" valign="top">
<p>这里指的是基本矩阵计算、解<a id="id131" class="indexterm"/>线性系统、求行列式和范数、分解等线性代数例程。</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">ndimage</code></p>
</td><td style="text-align: left" valign="top">
<p>这是 N 维<a id="id132" class="indexterm"/>图像处理。</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">odr</code></p>
</td><td style="text-align: left" valign="top">
<p>这就是<a id="id133" class="indexterm"/>正交距离回归。</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">stats</code></p>
</td><td style="text-align: left" valign="top">
<p>这是指<a id="id134" class="indexterm"/>统计分布和函数。</p>
</td></tr></tbody></table></div><p>许多 NumPy 模块与 SciPy 包中的模块具有相同的名称和相似的功能。在很大程度上，SciPy 引入了它的 NumPy 等价物并扩展了它的功能。但是，请注意，与 NumPy 中的函数相比，SciPy 模块中一些同名的函数可能具有<a id="id135" class="indexterm"/>稍微不同的功能。还应该提到的是，许多 SciPy 类在 scikit-learn 包中有方便的包装器，有时使用它们会更容易。</p><p>这些包中的每一个都需要显式导入；这里有一个例子:</p><div><pre class="programlisting">
<strong>import scipy.cluster</strong>
</pre></div><p>您可以从<a id="id136" class="indexterm"/> SciPy 网站(<a class="ulink" href="http://scipy.org">scipy.org</a>)或从控制台获取文档，例如<code class="literal">help(sicpy.cluster)</code>。</p><p>正如我们所见，在许多不同的 ML 设置中，一个共同的任务是优化。在上一章中，我们研究了单纯形算法的数学。下面是使用 SciPy 的实现。我们记得单纯形优化了一组线性方程。我们研究的问题如下:</p><p>最大化<em>x<sub>1</sub></em>+<em>x<sub>2</sub></em>在以下约束范围内:<em>2x<sub>1</sub></em>+<em>x<sub>2</sub>≤4</em>和<em>x<sub>1</sub></em>+<em>2x<sub>2</sub>≤3</em></p><p><code class="literal">linprog</code>对象可能是解决这个问题的最简单的对象。这是一个最小化算法，所以我们颠倒了目标的符号。</p><p>从<code class="literal">scipy.optimize</code>导入<code class="literal">linprog</code>:</p><div><pre class="programlisting">
<strong>objective=[-1,-1]</strong>
<strong>con1=[[2,1],[1,2]]</strong>
<strong>con2=[4,3]</strong>
<strong>res=linprog(objective,con1,con2)</strong>
<strong>print(res)</strong>
</pre></div><p>您将看到以下输出:</p><div><img src="img/B05198_2_13.jpg" alt="SciPy"/></div><p>还有一个<code class="literal">optimisation.minimize</code>对象，适合稍微复杂一点的问题。该对象将求解器作为参数。目前大约有十几个可用的解算器，如果您需要更具体的解算器，您可以编写自己的解算器。最常用且适用于大多数问题的<a id="id137" class="indexterm"/>是<strong> nelder-mead </strong>解算器。这个特定的解算器使用<a id="id138" class="indexterm"/>一个<strong>下坡单纯形</strong>算法，这基本上是一个启发式搜索，用位于<a id="id139" class="indexterm"/>剩余点的质心的一个点替换每个具有高误差的测试点。它重复这个过程，直到它收敛到一个最小值。</p><p>在这个例子中，我们使用<a id="id140" class="indexterm"/> <strong> Rosenbrock </strong>函数作为我们的测试问题。这是一个非凸函数，常用于测试优化问题。这个函数的全局最小值在一个长的抛物线谷上，这使得算法在一个大的、相对平坦的谷中寻找最小值具有挑战性。我们将看到更多这种功能:</p><div><pre class="programlisting">
<strong>import numpy as np</strong>
<strong>from scipy.optimize import minimize</strong>
<strong>def rosen(x):</strong>
<strong>    return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0)</strong>

<strong>def nMin(funct,x0):</strong>

<strong>    return(minimize(rosen, x0, method='nelder-mead', options={'xtol':</strong>
<strong>        1e-8, 'disp': True}))</strong>

<strong>x0 = np.array([1.3, 0.7, 0.8, 1.9, 1.2])</strong>

<strong>nMin(rosen,x0)</strong>
</pre></div><p>上述代码的输出如下:</p><div><img src="img/B05198_2_32.jpg" alt="SciPy"/></div><p>minimize 函数有两个强制参数。这些是目标函数和 x0 的初始值。最小化函数还为求解器方法提供了一个可选参数，在本例中，我们使用了<code class="literal">nelder-mead</code>方法。这些选项是一组特定于求解器的键-值对，用字典<a id="id141" class="indexterm"/>表示。这里，<code class="literal">xtol</code>是收敛可接受的相对误差，<code class="literal">disp</code>设置为打印消息。另一个对机器学习应用极其有用的包是<code class="literal">scipy.linalg</code>。这个软件包增加了执行诸如矩阵求逆、计算特征值和矩阵分解等任务的能力。</p></div>





<title>Scikit-learn</title><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/><div><div><div><div><h1 class="title"><a id="ch02lvl1sec18"/> Scikit-learn</h1></div></div></div><p>这包括用于最常见的机器学习任务的算法<a id="id142" class="indexterm"/>，例如分类、回归、聚类、降维、模型选择和预处理。</p><p>Scikit-learn 提供了几个真实世界的数据集供我们练习。让我们来看看其中的一个——虹膜数据集:</p><div><pre class="programlisting">
<strong>from sklearn import datasets</strong>
<strong>iris = datasets.load_iris()</strong>
<strong>iris_X = iris.data</strong>
<strong>iris_y = iris.target</strong>
<strong>iris_X.shape</strong>
<strong>(150, 4)</strong>
</pre></div><p>该数据集包含三种类型的鸢尾(Setosa、Versicolor 和 Virginica)的 150 个样本，每种样本具有四个特征。我们可以得到数据集的描述:</p><div><pre class="programlisting">
<strong>iris.DESCR</strong>
</pre></div><p>我们可以看到，这四个属性或特征是萼片宽度、萼片长度、花瓣长度和以厘米为单位的花瓣宽度。每个样本都与三个类别中的一个相关联。Setosa，Versicolor 和 Virginica。这些分别用 0、1 和 2 表示。</p><p>让我们用这些数据来看一个简单的分类问题。我们想根据鸢尾的特征来预测它的类型:萼片和花瓣的长度和宽度。通常，scikit-learn 使用估计器来实现一个<code class="literal">fit(X, y)</code>方法和一个<code class="literal">predict(X)</code>方法，前者用于训练一个分类器，后者用于在给定未标记的观察值<code class="literal">X</code>的情况下，返回预测的标签<code class="literal">y</code>。<code class="literal">fit()</code>和<code class="literal">predict()</code>方法通常采用类似 2D 数组的对象。</p><p>这里，我们将使用<strong> K 最近邻(K-NN) </strong>技术来解决这个分类问题。K-NN 背后的<a id="id143" class="indexterm"/>原理比较简单。我们根据最近邻的分类对未标记的样本进行分类。每个数据点根据其最近邻居的少数<em> k </em>的多数类别被分配类别成员。K-NN 是<a id="id144" class="indexterm"/>基于实例的学习的一个例子，其中分类不是根据一个内置的模型来完成的，而是参考一个标记的测试集。K-NN 算法被称为非一般化算法，因为它只是记住所有的训练数据，并将其与每个新样本进行比较。尽管，或者可能是因为，它表面上的简单，K-NN 是一种非常好的解决各种分类和回归问题的技术。</p><p><strong> Sklearn </strong>中有两个<a id="id145" class="indexterm"/>不同的 K-NN 分类器。<strong> KNeighborsClassifier </strong>要求用户指定<em> k </em>，最近邻居的数量。<strong>半径邻居分类器</strong>根据<a id="id146" class="indexterm"/>每个训练点固定半径内的邻居数量<em> r </em>进行学习。KNeighborsClassifier 是比较常用的一种。<em> k </em>的最佳值在很大程度上取决于数据。通常，较大的<em> k </em>值用于噪声数据。分类边界的权衡变得不那么明显。如果数据不是均匀采样的，那么 RadiusNeighborsClassifier 可能是更好的选择。由于邻居的数量是基于半径的，<em> k </em>对于每个点都是不同的。在稀疏区域，<em> k </em>将低于高样本密度区域:</p><div><pre class="programlisting">
<strong>from sklearn.neighbors import KNeighborsClassifier as knn</strong>
<strong>from sklearn import datasets</strong>
<strong>import numpy as np</strong>
<strong>import matplotlib.pyplot as plt</strong>
<strong>from matplotlib.colors import ListedColormap</strong>

<strong>def knnDemo(X,y, n):</strong>

<strong>    #cresates the the classifier and fits it to the data</strong>
<strong>    res=0.05</strong>
<strong>    k1 = knn(n_neighbors=n,p=2,metric='minkowski')</strong>
<strong>    k1.fit(X,y)</strong>

<strong>    #sets up the grid</strong>
<strong>    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1</strong>
<strong>    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1</strong>
<strong>    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, res),np.arange(x2_min, x2_max, res))</strong>

<strong>    #makes the prediction</strong>
<strong>    Z = k1.predict(np.array([xx1.ravel(), xx2.ravel()]).T)</strong>
<strong>    Z = Z.reshape(xx1.shape)</strong>

<strong>    #creates the color map</strong>
<strong>    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])</strong>
<strong>    cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])</strong>

<strong>    #Plots the decision surface</strong>
<strong>    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap_light)</strong>
<strong>    plt.xlim(xx1.min(), xx1.max())</strong>
<strong>    plt.ylim(xx2.min(), xx2.max())</strong>

<strong>    #plots the samples</strong>
<strong>    for idx, cl in enumerate(np.unique(y)):</strong>
<strong>        plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)</strong>

<strong>    plt.show()</strong>

<strong>iris = datasets.load_iris()</strong>
<strong>X1 = iris.data[:, 0:3:2]</strong>
<strong>X2 = iris.data[:, 0:2]</strong>
<strong>X3 = iris.data[:,1:3]</strong>
<strong>y = iris.target</strong>
<strong>knnDemo(X2,y,15)</strong>
</pre></div><p>以下是前面命令的<a id="id147" class="indexterm"/>输出:</p><div><img src="img/B05198_02_02.jpg" alt="Scikit-learn"/></div><p>现在让我们用 Sklearn 看看回归问题。最简单的解决方案是最小化误差平方和。这由<code class="literal">LinearRegression</code>对象执行。这个对象有一个<code class="literal">fit()</code>方法，它采用两个向量:<em> X </em>，特征向量，和<em> y </em>，目标向量:</p><div><pre class="programlisting">
<strong>from sklearn import linear_model</strong>
<strong>clf = linear_model.LinearRegression()</strong>
<strong>clf.fit ([[0, 0], [1, 1], [2, 2]], [0, 1, 2])</strong>
<strong>clf.coef_</strong>
<strong>array([ 0.5,  0.5])</strong>
</pre></div><p><code class="literal">LinearRegression</code>对象有四个可选参数:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">fit_intercept</code>:一个布尔值，如果设置为<code class="literal">false</code>，将假设数据居中，<a id="id148" class="indexterm"/>模型在其计算中不使用截距。默认值为<code class="literal">true</code>。</li><li class="listitem" style="list-style-type: disc"><code class="literal">normalize</code>:如果<code class="literal">true</code>，回归前将<em> X </em>归一化为零均值和单位方差。这有时很有用，因为它可以使系数的解释更加明确。默认为<code class="literal">false</code>。</li><li class="listitem" style="list-style-type: disc"><code class="literal">copy_X</code>:默认为<code class="literal">true</code>。如果设置为<code class="literal">false</code>，将允许<em> X </em>被覆盖。</li><li class="listitem" style="list-style-type: disc"><code class="literal">n_jobs</code>:用于计算的作业数量。默认为<code class="literal">1</code>。这可以用来加速多个 CPU 上的大型问题的计算。</li></ul></div><p>其输出具有以下属性:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">coef_</code>:线性回归问题的估计系数数组。如果 y 是多维的，即有多个目标变量，那么<code class="literal">coef_</code>将是一个形式为(<code class="literal">n_targets</code>、<code class="literal">n_features</code>)的 2D 数组。如果只传递了一个目标变量，那么<code class="literal">coef_</code>将是一个长度为(<code class="literal">n_features</code>)的 1D 数组。</li><li class="listitem" style="list-style-type: disc"><code class="literal">intercept_</code>:这是线性模型中截距或独立项的数组。</li></ul></div><p>对于<strong>普通最小二乘法</strong>到<a id="id149" class="indexterm"/>工作，我们假设特征是独立的。当这些项相关时，矩阵<em> X </em>可以接近奇点。这意味着估计对输入数据的微小变化变得高度敏感。这被称为<a id="id150" class="indexterm"/>多重共线性<strong>并导致巨大的差异和最终的不稳定性。我们稍后会更详细地讨论这一点，但现在，让我们来看一个算法，它在某种程度上解决了这些问题。</strong></p><p>岭回归不仅解决了多重共线性问题，还解决了输入变量的数量大大超过样本数量的情况。对象使用了 L2 正则化。直观上，我们可以理解为在权重向量的极值上增加一个惩罚。这有时被称为<strong>收缩</strong>，因为<a id="id151" class="indexterm"/>它使平均重量变小。这往往会使模型更加稳定，因为它降低了对极值的敏感性。</p><p>Sklearn 对象<code class="literal">linear_model.ridge</code>添加了一个正则化参数<code class="literal">alpha</code>。通常，<code class="literal">alpha</code>的小正值会提高模型的稳定性。它可以是浮点型，也可以是数组。如果是一个数组，则假定该数组对应于特定的目标，因此，它必须与目标的大小相同。我们可以用下面的简单函数来尝试一下:</p><div><pre class="programlisting">
<strong>from sklearn.linear_model import Ridge</strong>
<strong>import numpy as np</strong>

<strong>def ridgeReg(alpha):</strong>

<strong>    n_samples, n_features = 10, 5</strong>
<strong>    y = np.random.randn(n_samples)</strong>
<strong>    X = np.random.randn(n_samples, n_features)</strong>
<strong>    clf = Ridge(.001)</strong>
<strong>    res=clf.fit(X, y)</strong>
<strong>    return(res)</strong>
<strong>res= ridgeReg(0.001)</strong>
<strong>print (res.coef_)</strong>
<strong>print (res.intercept_)</strong>
</pre></div><p>现在让我们看看一些用于降维的 scikit-learn 算法。这对机器学习很重要，因为它减少了模型必须考虑的输入变量或特征的数量。这使得模型更有效率，也使得结果更容易解释。它还可以通过减少过度拟合来提高模型的泛化能力。</p><p>当然，重要的是不要丢弃会降低模型准确性的信息。确定什么是冗余的或不相关的是降维算法的主要功能。基本上有两种方法:特征提取和特征选择。特征选择试图找到原始特征变量的子集。另一方面，特征提取通过组合相关变量来创建新的特征变量。</p><p>我们先来看看大概最<a id="id154" class="indexterm"/>常见的特征提取算法，也就是<strong>主成分分析</strong>或者<strong> PCA </strong>。这使用正交变换将一组相关变量转换成一组不相关变量。重要信息、向量的长度以及它们之间的角度不会改变。该信息在内积中定义，并在正交变换中保留。PCA 以这样一种方式构造特征向量，即第一分量尽可能多地解释数据中的可变性。随后的组成部分说明了可变性的减少。这意味着，对于许多模型，我们可以只选择前几个主成分，直到我们满意地认为它们可以解释实验规范所要求的数据可变性。</p><p>可能是最通用的核函数，也是在大多数情况下给出好结果的核函数，是<strong>径向基函数</strong> ( <strong> RBF </strong>)。rbf 核取一个参数<code class="literal">gamma</code>，它可以被松散地<a id="id155" class="indexterm"/>解释为每个样本的影响范围的倒数。低 gamma 值意味着每个样本对模型选择的样本具有较大的影响半径。<code class="literal">KernalPCA fit_transform</code>方法获取训练向量，使其适合模型，然后将其转换为其主分量。让我们来看看这些命令:</p><div><pre class="programlisting">
<strong>import numpy as np</strong>
<strong>import matplotlib.pyplot as plt</strong>
<strong>from sklearn.decomposition import KernelPCA</strong>
<strong>from sklearn.datasets import make_circles</strong>
<strong>np.random.seed(0)</strong>
<strong>X, y = make_circles(n_samples=400, factor=.3, noise=.05)</strong>
<strong>kpca = KernelPCA(kernel='rbf', gamma=10)</strong>
<strong>X_kpca = kpca.fit_transform(X)</strong>
<strong>plt.figure()</strong>
<strong>plt.subplot(2, 2, 1, aspect='equal')</strong>
<strong>plt.title("Original space")</strong>
<strong>reds = y == 0</strong>
<strong>blues = y == 1</strong>
<strong>plt.plot(X[reds, 0], X[reds, 1], "ro")</strong>
<strong>plt.plot(X[blues, 0], X[blues, 1], "bo")</strong>
<strong>plt.xlabel("$x_1$")</strong>
<strong>plt.ylabel("$x_2$")</strong>
<strong>plt.subplot(2, 2, 3, aspect='equal')</strong>
<strong>plt.plot(X_kpca[reds, 0], X_kpca[reds, 1], "ro")</strong>
<strong>plt.plot(X_kpca[blues, 0], X_kpca[blues, 1], "bo")</strong>
<strong>plt.title("Projection by KPCA")</strong>
<strong>plt.xlabel("1st principal component in space induced by $\phi$")</strong>
<strong>plt.ylabel("2nd component")</strong>
<strong>plt.subplots_adjust(0.02, 0.10, 0.98, 0.94, 0.04, 0.35)</strong>
<strong>plt.show()</strong>
<strong>#print('gamma= %0.2f' %gamma)</strong>
</pre></div><p>正如我们所见，监督学习算法成功的一个主要障碍是从训练数据到测试数据的转换。已标记的训练集可能具有新的未标记数据中不存在的独特特征。我们已经看到，我们可以训练我们的模型在训练数据上非常精确，但是这种精度可能不会转化为我们的未标记的测试数据。过度拟合是监督学习中的一个重要问题，有许多技术可以用来最小化它。评估模型在训练集上的估计性能的一种方法是使用交叉验证。让我们使用支持向量机在我们的虹膜数据上尝试一下。我们需要做的第一件事是将数据分成训练集和测试集。<code class="literal">train_test_split</code>方法采用两种数据结构:数据本身和目标。它们可以是 NumPy 数组、Pandas 数据帧列表或 SciPy 矩阵。如您所料，目标需要与数据长度相同。<code class="literal">test_size</code>参数可以是一个介于<code class="literal">0</code>和<code class="literal">1</code>之间的浮点数，表示包含在分割中的数据比例，也可以是一个表示测试样本数量的整数。这里，我们使用了一个<code class="literal">test_size</code>对象作为<code class="literal">.3</code>，表示我们拿出了 40%的数据进行测试。</p><p>在这个例子中，我们<a id="id156" class="indexterm"/>使用<code class="literal">svm.SVC</code>类和<code class="literal">.score</code>方法返回预测标签的测试数据的平均准确度:</p><div><pre class="programlisting">
<strong>from sklearn.cross_validation import train_test_split</strong>
<strong>from sklearn import datasets</strong>
<strong>from sklearn import svm</strong>
<strong>from sklearn import cross_validation</strong>
<strong>iris = datasets.load_iris()</strong>
<strong>X_train, X_test, y_train, y_test = train_test_split (iris.data, iris.target, test_size=0.4, random_state=0)</strong>
<strong>clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)</strong>
<strong>scores=cross_validation.cross_val_score(clf, X_train, y_train, cv=5)</strong>
<strong>print("Accuracy: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))</strong>
</pre></div><p>您将看到以下输出:</p><div><img src="img/B05198_2_33.jpg" alt="Scikit-learn"/></div><p>支持向量机有一个必须手动设置的<code class="literal">penalty</code>参数，我们很可能会多次运行 SVC 并调整该参数，直到我们获得最佳拟合。然而，这样做会将训练集的信息泄露给测试集，因此我们可能仍然会遇到<a id="id157" class="indexterm"/>过度拟合的问题。对于任何具有必须手动设置的参数的估计器来说，这都是一个问题，我们将在<a class="link" href="ch04.html" title="Chapter 4. Models – Learning from Information">第 4 章</a>、<em>模型——从信息中学习</em>中进一步探讨这个问题。</p></div>





<title>Summary</title><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/><div><div><div><div><h1 class="title"><a id="ch02lvl1sec19"/>总结</h1></div></div></div><p>我们已经看到了一套基本的机器学习工具，以及它们在简单数据集上使用的一些迹象。你可能开始想知道这些工具如何应用于现实世界的问题。我们讨论的每个库之间有相当多的重叠。许多人执行相同的任务，但以不同的方式添加或执行相同的功能。为每个问题选择哪个库不一定是决定性的决定。没有最好的图书馆；只有首选的库，这因人而异，当然也因应用程序的具体情况而异。</p><p>在下一章，我们将研究机器学习中最重要的，也是经常被忽视的一个方面，那就是数据。</p></div>
</body></html>