

# 十二、模型服务和监控

在本章中，我们将思考在生产中服务和监控**机器学习** ( **ML** )模型的需求，并探索为模型的用户或消费者服务 ML 模型的不同方式。然后，我们将重温 [*第 11 章*](B16572_11_Final_JM_ePub.xhtml#_idTextAnchor206) 、*监控您的 ML 系统的关键原则*中的**可解释的监控框架**，并将其实现为我们一直在解决的使用 MLOps 预测天气的业务用例。一个可解释的监控框架的实现需要亲自动手。我们将推断部署的 API，并使用**漂移**(例如数据漂移、特性漂移和模型漂移)来监控和分析推断数据，以测量 ML 系统的性能。最后，我们将着眼于管理 ML 系统的几个概念，以实现 ML 系统的稳健性能，从而推动持续学习和交付。

让我们从反思生产中监控 ML 的必要性开始。然后，我们将继续探讨本章中的以下主题:

*   服务、监控和维护生产中的模型
*   探索服务 ML 模型的不同模式
*   实现可解释的监控框架
*   管理您的 ML 系统

# 服务、监控和维护生产中的模型

部署一个模型或一个 ML 系统而不监控它是没有意义的。监控性能是管理信息系统最重要的方面之一。监控使我们能够以定性和定量的方式分析和规划 ML 系统为利益相关者提供的业务影响。为了实现最大的业务影响，ML 系统的用户需要以最方便的方式得到服务。之后，他们就可以消费 ML 系统，产生价值。在前面的章节中，我们开发并部署了一个 ML 模型来预测港口的天气状况，作为我们为实际实现而解决的业务用例的一部分。在本章中，我们将重温我们在 [*第 11 章*](B16572_11_Final_JM_ePub.xhtml#_idTextAnchor206) 、*监控您的 ML 系统的关键原则*中讨论的可解释的监控框架，并在我们的业务用例中实现它。在*图 12.1* 中，我们可以看到**可说明的监控**框架及其部分组件，以绿色突出显示:

![Figure 12.1 – Components of the Explainable Monitoring framework to be implemented
](img/image0011.jpg)

图 12.1–要实现的可解释监控框架的组件

我们将对这些区域实现可解释的监控:*数据完整性*，*模型漂移*，*应用程序性能*，*偏差和威胁检测*，*本地和全局解释*，*警报和动作*，*模型 QA 和控制*，以及*模型审计和报告*。在我们的用例中，这些组件对于理解可解释监控的实现是最重要的。我们将省略*数据切片*，因为我们在人口统计或数据样本方面没有太多变化(例如，性别、年龄组等)。通过使用来自其他组件的信息，我们可以评估模型的性能及其公平性。在本章中，我们将实现**监视器**和**分析**模块的组件:*数据完整性*、*模型漂移*、*应用程序性能*、*偏差和威胁检测*以及*局部和全局解释*。其余的组件实现将在 [*第 13 章*](B16572_13_Final_JM_ePub.xhtml#_idTextAnchor234) 、*管理继续学习的 ML 系统*中介绍。在我们继续执行流程之前，让我们看一下如何为用户提供模型。

# 探索服务 ML 模型的不同模式

在这一节中，我们将考虑如何为用户(人类和机器)提供一个模型，以有效地消费 ML 服务。模型服务是一个关键的领域，一个 ML 系统需要在这个领域取得成功以实现它的商业影响，因为在这个领域的任何滞后或错误在服务用户方面都是昂贵的。健壮性、可用性和便利性是服务于 ML 模型时要记住的关键因素。让我们看一下服务于 ML 模型的一些方式:这可以通过批处理服务或者按需模式(例如，当为了获得预测而按需进行查询时)。在按需模式下，模型可以提供给机器或人类用户。下面是一个向用户提供模型的示例:

![Figure 12.2 – Serving a model to users
](img/image002.jpg)

图 12.2–为用户提供模型

在一个典型的场景中(在按需模式下)，一个模型作为一种服务供用户消费，如图*图 12.2* 所示。然后，机器或人员上的外部应用程序使用他们的数据向预测或 ML 服务进行查询。当接收到请求时，ML 服务使用负载平衡器将请求路由到 ML 应用内的可用资源(例如容器或应用)。负载平衡器还管理 ML 服务中的资源，以便按需编排和生成新的容器或资源。负载平衡将查询从用户重定向到 ML 应用程序内的容器中运行的模型，以获得预测。在获得预测时，负载平衡会回复到机器上的外部应用程序，或者发出请求的人，或者模型预测中的查询。以这种方式，ML 服务能够服务于它的用户。ML 系统与模型存储库或注册库相协调，以保持自己用最新的或性能最好的模型进行更新，从而以最好的方式为用户服务。与用户进行查询的典型场景相比，还有另一个用例，其中模型作为批处理服务提供。

## 为模型提供批量服务

批量处理或服务适用于大量或批量的输入数据(即不是单个观察值，而是一组观察值)。在有大量数据需要推断的情况下，模型通常以批处理模式提供。这方面的一个例子是当模型用于一次性处理产品或服务的所有消费者或用户的数据时。或者，可能需要处理来自工厂的固定时间表的一批数据，以检测机器中的异常。与按需模式相比，批处理模式更节省资源，通常在可以承受一定延迟时使用:

![Figure 12.3 – Batch Inference 
](img/image0031.jpg)

图 12.3-批量推断

批处理的一个关键优势是，与基于 REST API 的服务不同，批处理服务可能需要更轻或更少的基础设施。与部署在线 REST 服务相比，编写批处理作业对数据科学家来说更容易。这是因为数据科学家只是需要在机器上训练一个模型或者反序列化一个训练好的模型，对一批数据进行批量推断。批量推断的结果可以存储在数据库中，而不是向用户或消费者发送响应。然而，一个主要的缺点是高延迟，而且不是实时的。通常，批处理服务可以一次处理数百或数千个要素。可以使用一系列测试来确定最佳批量，以达到用例可接受的延迟。典型的批量大小可以是 32、64、128 或 518 的 2 次方。批量推理可以定期调度，并且可以服务于延迟不是问题的许多用例。下面讨论一个这样的例子。

现实世界的例子

一个真实的例子是一家银行从批量文本文档中提取信息。一家银行每天会从其合作机构收到数千份文档。人工代理不可能通读所有文档并在文档中列出的操作中突出任何危险信号。批量推理用于从银行收到的所有文档中一次性提取名称实体和红色标记。批量推断或服务的结果随后被存储在数据库中。

## 将模型提供给人类用户

在处理来自人类用户的请求之前，检查用户是否有足够的权限使用模型是很重要的。此外，在大多数情况下，了解提出请求的上下文是有帮助的。收集请求的上下文将使模型能够产生更好的预测。在收集了上下文之后，我们可以将它转换成模型可读的输入，并推断模型以获得预测。

在实践中，以下是为人类用户提供按需模型的关键步骤:

1.  验证或授权请求。
2.  分析和收集上下文信息(例如，历史数据、用户体验数据或用户的任何其他个人数据)。
3.  将任何上下文信息转换成模型可读的输入或模式。
4.  使用输入数据(请求和上下文信息)推断模型，以进行预测或获得输出。
5.  根据上下文解释输出。
6.  Relay the output to the user.

    现实世界的例子

    考虑一个聊天机器人服务人类客户预订机票。它执行上下文推理来服务人类用户。

## 为机器提供模型

我们可以基于用例，使用`REST` API 或流服务来为机器或外部应用提供服务。通常，机器推理数据需求是预先确定的或者在标准模式内。REST API 或流服务形式的定义良好的拓扑和数据模式将起作用。对机器或人类的按需服务因情况而异，因为在某些情况下，需求可能会变化(例如，在一天中对服务用户的需求可能较高的特定时间，如下午)。为了处理来自服务的高需求，自动伸缩(在云上)可以帮助按需产生更多资源，并杀死任何空闲资源以释放更多资源。然而，自动扩展并不是一个一站式的扩展解决方案，因为它本身无法处理突然或特殊的需求高峰:

![Figure 12.4 – Message Broker for on-demand serving
](img/image004.jpg)

图 12.4–按需服务的消息代理

在*图 12.4* 中显示的方法在处理大批量需求高峰时具有资源效率。为了处理突然的峰值，Apache Kafka 或 Spark 这样的消息代理会很有用。消息代理运行进程来写入和读取队列:一个进程将消息写入队列，另一个进程从该队列读取消息。接受服务的模型定期连接到消息代理，以处理来自队列的成批输入数据，从而为批中的每个元素做出预测。处理输入数据批次并生成预测后，预测将被写入输出队列，然后根据用户的请求将其推送给用户。

现实世界的例子

考虑一家拥有数百万用户的社交媒体公司。该公司为推荐系统使用单个或公共 ML 模型来向用户推荐新闻订阅源文章或帖子。因为服务于许多用户的请求量很大，所以它不能依赖于基于 REST API 的 ML 系统(因为它是同步的)。流式解决方案更好，因为它为公司服务用户提供了异步推理。当用户登录到他们在机器(例如社交媒体公司服务器)上托管的应用程序或帐户时，在他们的机器上运行的应用程序通过流服务推断 ML 模型(即推荐系统),以获得对用户新闻订阅源的推荐。同样，成千上万的其他用户同时登录。流媒体服务可以无缝地服务于所有这些用户。注意，这在使用 REST API 服务时是不可能的。通过为推荐系统模型使用流媒体服务，这家社交媒体公司能够实时为其大量用户提供服务，避免明显的滞后。

# 实现可解释的监控框架

为了实现可解释的监控框架，就实现假设的用例而言，有必要回顾一下到目前为止已经讨论过的内容。以下是我们为用例实现所做工作的回顾，包括问题和解决方案:

*   **问题背景**:你是一名数据科学家，与另外三名数据科学家在一个小团队中工作，为一家位于芬兰图尔库港的货运公司工作。90%进口到芬兰的货物通过货运到达全国各地的各个港口。对于货运来说，天气条件和物流有时会很有挑战性。多雨的条件会扭曲港口的运作和物流，从而影响供应链运作。提前预测降雨条件使我们能够优化人力资源、物流和运输资源等资源，以实现港口供应链的高效运作。从业务角度来看，提前预测降雨条件可使港口通过对供应链运营的人力资源、物流和运输资源进行高效规划和调度，从而将运营成本降低约 20%。
*   **任务或解决方案**:作为一名数据科学家，你的任务是开发一个 ML 驱动的解决方案，提前 4 小时预测芬兰图尔库港的天气情况。这将使港口能够优化其资源，从而节省高达 20%的成本。首先，我们为您提供了一个图尔库港 10 年的历史天气数据集(该数据集可以在本书的 Git 资源库中找到)。你的任务是建立一个持续学习驱动的 ML 解决方案来优化图尔库港的运营。

到目前为止，我们已经开发了 ML 模型，并将它们部署为 Kubernetes 集群中的 REST API 端点，位于[http://20 . 82 . 202 . 164:80/API/v1/service/weather-prod-service/score](http://20.82.202.164:80/api/v1/service/weather-prod-service/score)(端点的地址会有所不同)。

接下来，我们将为这个端点复制一个真实的推理场景。为此，我们将使用我们在 [*第 4 章*](B16572_04_Final_JM_ePub.xhtml#_idTextAnchor074) 、*机器学习管道*、在*数据摄取和特征工程*部分拆分和注册的测试数据集。转到 Azure ML 工作区，从**数据集**部分或连接到工作区的 Blob 存储中下载`test_data.csv`数据集(注册为`test_dataset`)，如*图 12.5* 所示:

![Figure 12.5 – Downloading the validation dataset (which was previously split and registered)
](img/image0051.jpg)

图 12.5–下载验证数据集(之前已分割并注册)

准备好用 REST API 端点或 ML 服务来推断`test_data.csv`数据。转到`12_Model_Serving_Monitoring`文件夹，将下载的数据集(`test_data.csv`)放入该文件夹。接下来，访问`inference.` `py`文件:

```py
import json
import requests
import pandas as pd
data = pd.read_csv('test_data.csv')
data = data.drop(columns=['Timestamp', 'Location', 'Future_weather_condition'])

url = 'http://20.82.202.164:80/api/v1/service/weather-prod-service/score'
headers = {'Content-Type':'application/json'}

for I in range(len(data)):
            inference_data = data.values[i].tolist()
            inference_data = json.dumps(""dat"": [inference_data]})
            r = requests.post(url, data=inference_data, headers=headers)
            print(str(i)+str(r.content))
```

在前面的代码中，我们执行以下步骤:

1.  在`inference.py`文件中，首先导入必要的库，比如`json`、`requests`和`pandas`。
2.  接下来，导入数据集(`test_data.csv`)用于推断端点。
3.  删除不必要的列进行推断，例如`Timestamp`、`Location`和`Future_weather_condition`(我们将通过查询端点来预测最后一列)。
4.  接下来，指向端点的 URL(您可以通过导航到 **Azure ML Workspace** | **端点** | **天气-产品-服务** | **消费**来找到它)。为了简单起见，因为我们没有为服务设置认证或密钥，所以我们有没有密钥或认证的头应用程序/JSON。
5.  最后，我们将通过用端点推断数组中的每个元素来遍历数据数组。要运行该脚本，只需用您的端点替换`'url'`，然后在终端中(从文件夹位置)运行以下命令来执行该脚本:

    ```py
    >> python3 inference.py
    ```

运行脚本将花费大约 10-15 分钟来推断推断数据的所有元素。在此之后，我们可以监控推断并分析推断数据的结果。让我们从数据完整性开始对此进行监控和分析。

## 监控您的 ML 系统

**监视器**模块专用于监视生产中的应用(即服务于 ML 模型)。动作监视器模块具有以下三种功能:

*   Data integrity:

    -注册目标数据集

    -创建数据漂移监视器

    -执行数据漂移分析

    -执行特征漂移分析

*   模型漂移
*   应用程序性能

接下来让我们更详细地了解一下这些功能。

### 数据完整性

为了监控推断数据的数据完整性，我们需要监控数据漂移和特征漂移，以查看输入数据中是否有任何异常变化或任何新模式:

*   **数据漂移**:这是当独立变量的属性改变时。例如，由于季节性、新产品的增加或消费者需求或习惯的变化，数据可能会发生变化，就像新冠肺炎疫情那样。
*   **特征漂移**:当特征属性随时间变化时，这就是。例如，由于季节或季节性的变化，温度也在变化，也就是说，在夏天，温度比冬天或秋天的温度要高。

为了监控漂移，我们将测量基线数据集与目标数据集之间的差异。第一步是定义基线数据集和目标数据集。这取决于不同的用例；我们将使用以下数据集作为基准数据集和目标数据集:

*   **基线数据集**:这个是训练数据集。
*   **目标数据集**:这是推理数据集。

我们将使用以前用于训练模型的训练数据集作为基线数据集。这是因为推理中使用的模型非常了解训练数据集中的模式。训练数据集是比较推断数据如何随时间变化的理想选择。我们将把推理期间收集的所有推理数据编译成推理数据集，并比较这两个数据集(即基线数据集和目标数据集)，以测量目标数据集的数据和特征漂移。

### 注册目标数据集

训练数据集在*数据摄取和特征工程*部分的 [*第 4 章*](B16572_04_Final_JM_ePub.xhtml#_idTextAnchor074) 、*机器学习管道*中注册。我们需要在 Azure ML 工作区的**数据集**部分注册推理数据集。

推断数据是使用`azureml.monitoring`SDK(`modelDataCollector`函数)的结果。通过使用评分文件中的`modelDataCollector`功能启用监控功能(在`score.py`中，正如我们在 [*第 6 章*](B16572_06_Final_JM_ePub.xhtml#_idTextAnchor124) 、*部署您的 ML 系统的关键原则*中所做的那样)，我们将推理数据以时间序列数据集的形式存储在 Blob 存储中。在连接到 Azure ML 工作空间的 Blob 存储中，推理数据存储在`modeldata`容器中。在`modeldata`容器中，推理数据(包括输入和输出)以 CSV 文件的形式存储在文件夹中。这些按每年、每月和每天(推断数据记录在生产中的时间)进行组织。在分区文件夹中，推理数据存储在名为`inputs.csv`和`outputs.csv`的 CSV 文件中。我们需要注册这些`input.csv`文件来监控数据漂移和特征漂移。按照以下步骤注册`input.csv`文件:

1.  Go to the **Datasets** section and click on **Create dataset**. Then, select the **From datastore** option, as shown in *Figure 12.6*:![Figure 12.6 – Registering the inference dataset 
    ](img/image006.jpg)

    图 12.6–注册推理数据集

2.  Name the dataset (for example, `Inputs-Inference-Dataset`), select the dataset type as **Tabular**, and write an appropriate description in the **Description** field name by describing the purpose of your dataset. Click on **Next** to specify the datastore selection. Select the **modeldata** datastore, as shown in *Figure 12.7*:![Figure 12.7 – Datastore selection (the Inputs-Inference-data registration)
    ](img/image0071.jpg)

    图 12.7-数据存储选择(输入-推理-数据注册)

3.  After selecting the `input.csv` file. You can find this in the folder of your `support vectorclassifier model`, which is inside the folder with your service name (for example, `prod-webservice`). Then, go into the subfolders (the default, inputs, and folders structured with dates), and go to the folder of your current date to find the `input.csv` file. Select the `input.csv` file, as shown in *Figure 12.8*:![Figure 12.8 – Selecting path of the input.csv file (the Inputs-Inference-data registration)
    ](img/image008.jpg)

    图 12.8-选择 input.csv 文件的路径(输入-推理-数据注册)

4.  After selecting the `input.csv` file, click on the `/**/inputs*.csv` (as shown in *Figure 12.9*). This is an important step that will refer to all of the `input.csv` files in the `inputs` folder dynamically. Without referencing all of the `input.csv` files, we will confine the path to only one `input.csv` file (which was selected previously in *Figure 12.8*). By referring to all of the `input.csv` files, we will compile all of the input data (the `inputs.csv` files) into the target dataset (for example, `Inputs-Inference-Data`):![Figure 12.9 – Referencing the path to dynamically access all the input.csv files 
    ](img/image0091.jpg)

    图 12.9–引用路径以动态访问所有 input.csv 文件

5.  Click on the **Next** button to advance to **Settings and preview**:![Figure 12.10 – Settings and preview (the inference dataset registration)
    ](img/image010.jpg)

    图 12.10–设置和预览(推理数据集注册)

    如*图 12.10* 所示，我们可以配置设置并预览数据集。通过选择**列标题**下拉菜单，然后选择**合并所有文件的标题**，指向正确的列名。检查正确的列名(例如，**温度 _ 摄氏度**和**湿度**)。选择适当的列名后，点击**下一个**按钮上的前进到下一个窗口。通过选择您想要监控的所有列以及它们的数据类型来选择正确的模式，如图*图 12.11* 所示:

    ![Figure 12.11 – Schema selection (the inference dataset registration)
    ](img/image0111.jpg)

    图 12.11-模式选择(推理数据集注册)

    确保您在**$ AML _ DC _ scoring _ Timestamp**列中选择了**时间戳**和**日期**属性，因为它们包含推理的时间戳。这一步很重要。只有时序格式数据集可用于计算漂移(通过 Azure 漂移模型)；否则，我们无法计算漂移。通过选择所有列选择正确的模式后，单击下一个按钮**，确认所有必要的细节(如数据集的名称、数据集版本、路径等)。**

6.  点击**创建**按钮创建数据集。成功创建数据集后，您可以在 Azure ML 工作区的**数据集**部分查看数据集。转到**数据集**部分，确认您的数据集已经创建。识别并单击您创建的数据集。点击后，您将能够查看您注册的推理数据集的详细信息，如图*图 12.12* 所示:

![Figure 12.12 – Viewing the registered inference dataset 
](img/image012.jpg)

图 12.12–查看注册的推理数据集

您可以在*图 12.12* 中看到您注册的数据集的所有基本属性。值得注意的是，相对路径是动态的，它指向引用所有的`input.csv`文件。引用所有输入文件的结果显示在`input.csv`中。随着每天在 Blob 存储中的数据存储中创建新的`input.csv`文件，文件将不断增加。恭喜你登记了推断数据。接下来，我们将配置数据漂移监控器。

### 创建数据漂移监控器

为了监控数据漂移和特性漂移，我们将使用 Azure ML 工作区的内置漂移监控特性，作为 Azure ML 工作区上`Data Drift Monitor`特性的一部分:

1.  Go to your workspace and access the **Datasets** section. Then, select **Dataset Monitors** (it is in preview mode at the moment, as this feature is still being tested). Click on **Create**, as shown in *Figure 12.13*:![Figure 12.13 – Creating the data drift monitor
    ](img/image0131.jpg)

    图 12.13–创建数据漂移监视器

2.  选择**创建**按钮后，系统会提示您创建一个新的数据漂移监视器。选择您选择的目标数据集。
3.  In the *Registering the target dataset* section, we registered the `inputs.csv` files as `Input-InferenceData`. Select your inference dataset as the target dataset, as shown in *Figure 12.14*:![Figure 12.14 – Select target dataset 
    ](img/image014.jpg)

    图 12.14–选择目标数据集

4.  After selecting your target dataset, you will be prompted to point to your baseline dataset, which should be your training dataset (it was used to train your deployed ML model). Select your baseline dataset, as shown in *Figure 12.15*:![Figure 12.15 – Select base dataset and configuring the monitor settings 
    ](img/image0151.jpg)

    图 12.15–选择基线数据集并配置监视器设置

5.  选择基线数据集后，系统会提示您设置监控设置，例如数据漂移监控的名称(例如`weather-Data-Drift`)、运行数据漂移作业的计算目标、数据漂移作业的频率(例如一天一次)以及监控漂移的阈值(例如 60)。当数据漂移超过设定的阈值时，您还会被要求发送您选择的电子邮件来接收通知。
6.  After configuring the settings, create a data drift monitor. Go to your newly created data drift (in the **Datasets** section, click on **Dataset Monitors** to view your drift monitors), as shown in *Figure 12.16*:![Figure 12.16 – Data drift overview (it is currently empty)
    ](img/image016.jpg)

    图 12.16–数据漂移概述(目前为空)

    当你访问你的数据漂移监视器，你会看到没有数据。这是因为我们还没有计算任何漂移。为了计算漂移，我们需要一个计算资源。

7.  Go to the **Compute** section, access the **Compute clusters** tab, and create a new compute resource (for example, **drift-compute – Standard_DS_V2 machine**), as shown in *Figure 12.17*:![Figure 12.17 – Creating a compute cluster to compute data drift
    ](img/image0171.jpg)

    图 12.17–创建计算集群以计算数据漂移

8.  创建计算集群后，返回到数据漂移监视器(例如，**天气数据漂移**)。接下来，我们将计算数据漂移。
9.  Click on **Analyze existing data** and submit a run to analyze any existing inference data, as shown in *Figure 12.18*:![Figure 12.18 – Submitting run to analyze any data drift
    ](img/image018.jpg)

    图 12.18-提交运行以分析任何数据漂移

10.  Select the start and end dates and the compute target (which was created previously, that is, **drift-compute**). Then, click on **Submit** to run drift computation. It will usually take around 10 minutes to analyze and compute data drift. You can track the progress of your runs in the **Experiments** section of your Azure ML workspace.

    **数据漂移分析**:成功完成运行后，已经计算出数据漂移。使用漂移概述，如图*图 12.19* 所示，我们可以监控和分析您的 ML 模型在生产中的性能。我们可以按特征查看数据漂移幅度和漂移分布:

![Figure 12.19 – Data Drift magnitude trend
](img/image019.jpg)

图 12.19–数据漂移幅度趋势

Azure ML 服务测量模型漂移的方式是，它使用一个单独的漂移模型(由 Azure 维护)，该模型查看基线并比较推断数据。这种比较产生数据变化的简单统计百分比或程度。

在*图 12.19* 中，**漂移量趋势**表示我们已经对模型进行了 3 天的推断(即 **03/23/21** 、 **04/03/21** 和 **04/04/21** )。

分析表明，这三种情况下的数据漂移都在 70%的阈值以下(这是红线，表示阈值)。 **03/23/21** 上的数据漂移在 50%左右；在 **04/03/21** 上，在 44%左右；而在 **04/04/21** 上则是 40%。这给了我们一个进入模型的推断数据的变化趋势的概念。同样，我们可以监控特征漂移。

*   **特性漂移分析**:您可以通过向下滚动到**特性细节**部分并选择您选择的特性来评估单个特性及其漂移。例如，我们可以看到**温度 _C** 随时间的分布特性，如图*图 12.20* 所示:

![Figure 12.20 – Feature drift trend (Temperature_C)
](img/image020.jpg)

图 12.20–特性漂移趋势(温度℃)

为了监控特性随时间的变化，我们可以为特性选择一些度量标准。诸如**平均值**、**最小值**、**最大值**、**欧几里德距离**或**瓦瑟斯坦距离**的度量可用于分析特征漂移。选择您选择的指标(例如，**平均值**)。我们选择了**平均值**度量来评估温度漂移，如图*图 12.20* 所示。随着时间的推移，**平均值**度量从 14 变为 8；这显示了**温度 C** 特性中的漂移变化。这种变化是预料之中的，因为季节变化会引起气温的变化。我们还可以监控特征分布的变化，如图*图 12.21* 所示:

![Figure 12.21 – The Feature distribution trend 
](img/image021.jpg)

图 12.21–特征分布趋势

如果漂移是剧烈的或异常的，我们需要检查推断到系统中的输入数据的质量。对特征漂移的洞察使我们能够理解不断变化的数据和我们周围的世界。同样，我们可以监控模型漂移，以根据变化的数据和世界了解模型性能。

### 模型漂移

监控模型漂移使我们能够检查模型在生产中的性能。模型漂移是因变量的属性发生变化的地方。举个例子，在我们的例子中，这是天气的分类结果(即下雨或不下雨)。正如我们在*创建数据漂移监控器*部分设置数据漂移一样，我们也可以设置一个模型漂移监控器来监控模型输出。以下是设置模型漂移的高级步骤:

1.  注册一个新的数据集(例如，`Outputs.csv`文件)。可以从**数据集**部分创建**输出**数据集。创建输出推理数据集时，选择重要的列(例如，**Future _ Weather _ Condition**)，并通过选择时间戳为**的列，将数据集更改为表格和时序格式(漂移只能在时序数据中计算)。**
2.  从**数据集**部分创建一个新监视器(例如模型漂移监视器)，点击**数据集监视器**。选择要监控的特征(例如，**未来天气状况**)并设置想要监控的阈值。
3.  在总览图中分析模型漂移(如图*图 12.22* ):

![ Figure 12.22 – Submitting run to analyze the data drift
](img/image022.jpg)

图 12.22–提交运行以分析数据漂移

如果您的模型漂移超过了设定的阈值，那么这可能表明您应该重新训练或训练您的模型比较结果，以简单的统计百分比或一定程度的数据变化。当数据漂移超过阈值(例如 70%)时，我们可以通过电子邮件通知管理员或产品所有者，或者采取措施，例如部署另一个模型或重新训练现有模型。使用智能行动，我们可以管理 ML 系统以产生最大价值。我们将在下一章探讨管理 ML 系统的方法( [*第 13 章*](B16572_13_Final_JM_ePub.xhtml#_idTextAnchor234) ，*为持续学习管理 ML 系统*)。到目前为止，我们已经实现了设置数据漂移、特征漂移和模型漂移。接下来，让我们监控 ML 系统的应用程序性能。

### 应用程序性能

您已经以 REST API 端点的形式部署了 ML 服务，用户可以使用它。我们可以使用 Azure Application Insights(由 Azure Monitor 支持)来监控这些端点。要监控我们的应用性能，请访问应用洞察仪表板，如*图 12.23* 所示。转到 Azure ML 服务工作区中的**端点**部分，并选择部署 ML 模型的 REST API 端点。点击 **Application Insights url** 访问连接到 REST API 端点的 Application Insights 端点:

![Figure 12.23 – Application Insights Overview
](img/image023.jpg)

图 12.23–应用洞察概述

从**应用洞察概述**部分，我们可以监控和分析您的 ML 服务的关键应用性能信息。此外，我们可以从**概述**部分监控失败的请求、服务器响应时间、服务器请求和可用性等信息，如图*图 12.24* 所示:

![Figure 12.24 – Application Insights Overview 
](img/image024.jpg)

图 12.24–应用洞察概述

基于这些指标和这些信息，我们可以监控应用程序的性能。理想情况下，我们不应该有任何失败的请求或很长的服务器响应时间。为了更深入地了解应用性能，我们可以访问应用仪表板(通过单击屏幕顶部的按钮)，如图*图 12.25* 所示:

![Figure 12.25 – Application dashboard with a more detailed performance assessment 
](img/image025.jpg)

图 12.25–具有更详细性能评估的应用仪表板

从应用仪表板中，我们可以更详细地监控应用性能。例如，我们可以监控应用程序的使用情况、可靠性和其他信息。在使用方面，**唯一会话和用户**是监控应用程序能够服务的唯一用户数量的关键信息。此外，**平均可用性**信息对于评估我们用户的服务可用性非常有用。有了这些信息，我们就可以在需要更多资源为用户服务时做出扩展决策。

我们可以通过评估失败请求的数量、服务器异常和依赖性失败等信息来监控应用程序的可靠性。我们可以使用平均服务器响应时间和 CPU 利用率等信息来监控响应能力。理想情况下，应用程序不应有任何故障，如果有任何故障，我们可以通过访问**事务搜索**或日志来更深入地查看应用程序日志，如图*图 12.26* 所示:

![Figure 12.26 – Accessing the logs to understand any errors or failures
](img/image026.jpg)

图 12.26-访问日志以了解任何错误或故障

我们可以仔细查看应用程序的日志，以了解任何故障或错误，从而调试应用程序并维护应用程序的正常运行。一个实用的 ML 应用程序可以让用户满意并产生最大的商业影响。因此，监控应用程序有助于发现潜在的故障并维护应用程序，从而以最有效的方式为用户服务。

## 分析您的 ML 系统

实时监控和分析生产中的 ML 系统是了解 ML 系统性能并确保其稳健性以产生最大商业价值的关键。人类在分析模型性能和检测微妙的异常和威胁方面起着关键作用。我们可以分析模型性能，以检测任何偏见或威胁，并理解为什么模型以某种模式做出决策。我们可以通过应用高级技术来做到这一点，如数据切片、对抗性攻击预防技术，或者通过理解本地和全球的解释。

### 数据切片

对于我们的用例，我们将省略数据切片，因为我们在人口统计或数据样本(例如，性别、年龄组等)方面没有太多变化。为了衡量模型的公平性，我们将关注偏差检测。

### 偏见和威胁检测

为了确定生产中的模型偏差，我们可以使用偏差-方差权衡方法。这使得监控和分析模型偏差或任何可能的威胁变得简单。不言而喻，可能有更好的方法来监测偏差，但这里的想法是保持简单，因为有时，简单更好，更有效。

我们模型的平均预测值和我们试图预测的正确值之间的差异就是偏差。方差是给定数据点或告知我们数据分布的值的模型估计的可变性。对已部署模型的推断数据进行偏差和方差分析显示偏差为 20.1，方差为 1.23(您可以在[https://machine learning mastery . com/calculate-the-bias-variance-trade-off/](https://machinelearningmastery.com/calculate-the-bias-variance-trade-off/)上阅读更多关于偏差和方差分析的信息)。这意味着我们的模型具有高偏差和低方差；因此，用推断数据训练或重新训练我们的模型来平衡偏差-方差可能是一个好主意。

### 本地和全球解释

本地和全球的解释对车型的表现提供了不同的视角。局部解释为特定或单独的输入提供了模型预测的理由，而全局解释提供了对模型预测过程的洞察，独立于任何特定的输入。我们之前在*图 12.19* 中探索监测漂移时，已经看到了全局解释。我们可以进一步调查特征分布，如图*图 12.21* 所示，详细了解局部解释。

分析您的 ML 系统的公平性、偏见以及局部和全局解释，为我们提供了对模型性能的关键见解，我们可以使用这些信息来管理我们的 ML 系统。

# 管理您的 ML 系统

系统治理的很大一部分涉及质量保证和控制、模型审计和报告，以具有端到端的可跟踪性和对法规的遵从性。ML 系统的效率(即，它产生期望或预期结果的能力)依赖于它实现最大商业价值的管理方式。到目前为止，我们已经监控和分析了我们部署的推理数据模型:

![Figure 12.27 – Components of governing your ML system 
](img/image027.jpg)

图 12.27-管理您的 ML 系统的组成部分

可以通过使用基于监控和警报而采取的智能行动来确定 ML 系统的功效。在下一章中，我们将从警报和动作、模型 QA 和控制以及模型审计和报告的角度来探讨 ML 系统治理。

# 总结

在这一章中，我们学习了为用户提供 ML 模型并监控它们以实现最大商业价值的关键原则。我们探索了为模型的用户或消费者提供 ML 模型的不同方法，并为一个假设的业务用例实现了可解释的监控框架，并部署了一个模型。我们亲自实现了一个可解释的监控框架来测量 ML 系统的性能。最后，我们讨论了管理最大似然系统的必要性，以确保最大似然系统的稳健性能。

在下一章，也是最后一章，我们将进一步探索 ML 系统的治理和持续学习的概念！