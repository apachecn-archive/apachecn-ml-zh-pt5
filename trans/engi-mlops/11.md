

# 九、测试和保护您的 ML 解决方案

在本章中，我们将深入探讨**机器学习** ( **ML** )解决方案测试和安全方面。您可以期望获得各种类型测试的入门知识，以测试您的 ML 解决方案的健壮性和可伸缩性，以及保护您的 ML 解决方案所需的知识。我们将研究对 ML 解决方案的多种攻击以及保护您的 ML 解决方案的方法。

在这一章中，我们将通过一些例子来学习，我们将对之前工作的天气预报业务用例进行负载测试和安全性测试。我们将首先思考测试和保护您的 ML 解决方案的必要性，然后继续探讨本章中的其他主题:

*   了解测试和保护您的 ML 应用程序的需求
*   通过设计测试您的 ML 解决方案
*   通过设计保护您的 ML 解决方案

# 了解测试和保护您的 ML 应用程序的需求

越来越多地采用数据驱动和基于 ML 的解决方案导致企业不得不处理不断增长的工作负载，使他们面临额外的复杂性和漏洞。

网络安全是人工智能开发者和采用者最担忧的风险。根据德勤发布的一项调查([https://www2 . Deloitte . com/us/en/insights/focus/cognitive-technologies/state-of-ai-and-intelligent-automation-in-business-survey . html](https://www2.deloitte.com/us/en/insights/focus/cognitive-technologies/state-of-ai-and-intelligent-automation-in-business-survey.html))，2020 年 7 月，62%的采纳者将网络安全风险视为重大或极端威胁，但只有 39%的人表示他们准备好应对这些风险。

在这一节中，我们将研究保护基于 ML 的系统和解决方案的需求。我们将思考 ML 系统的一些更广泛的挑战，如偏见、伦理和可解释性。我们还将研究在 ML 生命周期的每个阶段存在的一些挑战，这些挑战与使用 ML 测试和安全性设计指南的机密性、完整性和可用性相关。

# 通过设计测试您的 ML 解决方案

除了执行常规的软件开发测试，如单元测试、集成测试、系统测试和验收测试，ML 解决方案还需要额外的测试，因为涉及到数据和 ML 模型。数据和模型都随时间动态变化。这里有一些通过设计进行测试的概念；将它们应用到您的用例中可以确保最终产生健壮的 ML 解决方案。

## 数据测试

测试数据的目标是确保数据质量足够高，可用于 ML 模型训练。数据质量越好，为特定任务训练的模型就越好。那么我们如何评估数据的质量呢？这可以通过检查数据的以下五个因素来实现:

*   准确(性)
*   完整性(无缺失值)
*   一致性(就预期的数据格式和数量而言)
*   相关性(数据应满足预期的需要和要求)
*   及时性(最新数据)

基于这些因素，如果公司能够在接收或创建数据集时管理每个数据集的数据质量，数据质量就有保证。以下是您的团队或公司可以用来保证数据质量的一些步骤:

1.  **细致的数据编目和传入数据的控制**:数据编目(以要求的格式或模式记录和存储数据)和控制功能的结合可以确保传入数据的高质量。数据编目和控制可以通过监控数据因素来完成，如数据格式和模式、值分布和异常、完整性和一致性，这些因素有助于提供良好的输入数据质量。
2.  **小心管理数据管道以避免重复数据**:当重复数据由不同的人使用相同的逻辑从相同的数据源制造时，管理血统、真实性和数据完整性会变得复杂。这会在多个系统或数据库中产生级联效应。最好尽可能避免重复数据。
3.  **具有强制完整性的数据治理**:在当今世界，维护数据完整性变得至关重要。对于一个组织来说，没有实现数据完整性的心态可能会付出高昂的代价。数据最终可能变得不完整、延迟或过时，从而导致严重的数据质量问题。
4.  **维护端到端的可追溯性和沿袭**:数据沿袭和可追溯性可以通过元数据和数据本身的巧妙使用来实现。使用这两者，我们可以记录关键信息，例如每个数据集的唯一键、为每个记录添加时间戳以及记录数据更改。确保数据沿袭和端到端的可追溯性能够给我们重现模型和调试错误和管道的可能性。

## 模型测试

模型测试需要涵盖如下服务器问题:

*   评估 ML 模型的准确性或关键指标
*   随机数据点测试
*   测试任务中可接受的损失或性能
*   使用真实数据进行模型稳健性的单元测试

这些测试可以分为两个阶段:培训前和培训后。在工作流程中促进这些测试可以为生产产生健壮的模型。让我们看看设计可以完成哪些训练前和训练后测试。

## 培训前测试

在我们进入培训阶段之前，可以进行测试来找出缺陷。这些缺陷可能存在于数据、管道或参数中。*图 9.1* 建议运行训练前和训练后测试，作为开发高质量模型的工作流程的一部分:

![Figure 9.1 – Proposed workflow for developing high-quality models
](img/B16572_09_01.jpg)

图 9.1-开发高质量模型的建议工作流程

以下是一些使用训练前测试来检测和避免训练前缺陷的方法:

*   通过处理任何数据泄漏、边缘情况并优化以使管道节省时间和资源，消除数据管道债务
*   确保模型输出的形状与数据集中的标注相匹配
*   检查输出范围以确保它们符合我们的预期(例如检查分类模型的输出是类概率总和为 1 的分布)
*   检查训练和验证数据集的标签泄漏
*   确保 ETL 管道以所需的格式输出或获取数据

预训练测试不需要参数来运行，但是在运行模型训练之前，它们在捕捉错误方面非常有用。

## 培训后测试

培训后测试使我们能够调查模型性能和模型预测背后的逻辑，并在将模型部署到生产之前预见模型中任何可能的缺陷。训练后测试使我们能够检测模型性能和功能中的缺陷。培训后测试包括模型性能评估测试、不变性测试和最低功能测试。以下是一篇关于训练后测试的更多见解的推荐阅读:*超越准确性:NLP 模型的行为测试与清单*([https://homes . cs . Washington . edu/~ marcotcr/ACL 20 _ check list . pdf](https://homes.cs.washington.edu/~marcotcr/acl20_checklist.pdf))

部署和推理测试

部署测试包括测试**连续集成/连续交付** ( **CI/CD** )管道交付、集成测试以及测试部署成功。测试部署的模型是至关重要的，这就是推理测试的用武之地，它对部署的模型进行压力或负载测试，并测试它在实时数据上的性能。

在下一节中，我们将对一个先前部署的模型进行负载测试(一个用例)。

# 实践部署和推理测试(一个业务用例)

当您准备好您的服务(API 或 ML)并准备将其提供给用户，但您不知道它实际上可以处理多少用户，以及当许多用户同时访问它时它将如何反应，这就是负载测试对基准测试您的服务可以服务多少用户以及验证服务是否可以满足业务需求非常有用的地方。

我们将对之前部署的服务执行负载测试(在第 7 章 ，*构建健壮的 CI 和 CD 管道*)。`Locust.io`将用于负载测试。`locust.io`是一个开源的负载测试工具。为此，我们将安装`locust`(使用`pip`)并使用 locust.io SDK 管理一个 Python 脚本来测试一个端点。让我们从安装`locust`开始:

1.  安装`locust`:转到您的终端并执行以下命令:

    ```
    pip, locust will be installed – it takes around a minute to install. After installation is successful it's time to curate the Python script using the locust.io SDK to test an endpoint.
    ```

2.  Curate the `load_test.py` script: Go to your favorite IDE and start curating the script or follow the steps in the premade script. To access the premade script go to the *Engineering MLOps* repository cloned previously, access the `09_Testing_Security` folder, and go to the `load_test.py` file. Let's demystify the code in `load_test.py` – firstly, the needed libraries are imported as follows:

    ```
    import time
    import json
    from locust import HttpUser, task, between
    ```

    我们导入了`time`、`json`和`locust`库，然后从`locust`导入了以下所需的函数:`HttpUser`(可以访问不同端点的用户代理)、`task`和`between`。

3.  使用样本测试数据创建一个`test_data`变量，以在负载测试期间推断 ML 模型。定义我们将在负载测试中用于 API 调用的【T8:

    ```
    test_data = json.dumps({"data": [[8.75, 0.83, 70, 259, 15.82, 1016.51, 1.0]]}) headers = {'Content-Type': 'application/json'}
    ```

4.  Next, we will implement the core functionality of the load test as part of the `MLServiceUser` class (you can name it whatever you want) by extending `HttpUser`. `HttpUser` is the user agent that can visit different endpoints:

    ```
    class MLServiceUser(HttpUser):
        wait_time = between(1, 5)
        @task
        def test_weather_predictions(self):
            self.client.post("", data=test_data, headers=headers)
    ```

    我们使用`between()`函数创建了一个`wait_time`变量，它指定了完成一个端点的测试和切换到下一个端点的测试之间的时间。因此，我们在`between(1,5)`函数中将`wait_time`指定为`1`到`5`秒。下一部分是定义测试端点的任务的关键。

    为此，我们使用一个`@task`包装器或装饰器来开始定义我们的任务，使用一个定制函数来测试我们选择的端点。定义一个定制函数`def` `test_weather_predictions()`，并使用`test_data`和先前定义的头向端点发出一个`post`请求。现在，我们开始运行负载测试！

5.  Run the `locust.io` server: Go to your terminal and change to the location where you have the `load_test.py` file (such as in the `09_Testing_Security` folder of the cloned repository used in this book), then run the following command to spin up a `locust.io` server:

    ```
    Locust -f load_test-py
    ```

    执行前面的命令将启动端口`8089`的`locust`服务器。我们可以在由`locust.io`呈现的 web 界面上执行负载测试。要访问 web 服务，请打开您选择的浏览器并转到以下网址:`http://0.0.0.0:8089/`，如图*图 9.2* 所示:

    ![Figure 9.2 – Access the Locust.io web service
    ](img/B16572_09_02.jpg)

    图 9.2–访问 Locust.io web 服务

6.  运行负载测试:打开 web 服务会提示您指定选项，比如用户数量、生成率和主机(要测试的端点)。根据您的要求指定要模拟的用户数量和生成速率(每秒将生成多少用户),以验证您的终端是否能够满足您的业务/用户需求，例如，50 个用户和 50 个生成速率。
7.  最后，输入您希望进行负载测试的端点或主机，并点击**Start swarm**开始执行负载测试。在 [*第 7 章*](B16572_07_Final_JM_ePub.xhtml#_idTextAnchor143)*构建健壮的 CI 和 CD 管道*中，我们部署了一个端点。建议测试部署的端点。
8.  转到您的 Azure ML 工作区，访问**端点**部分，访问名为 **dev-webservice** 的已部署端点，并将端点 web 地址复制并粘贴到主机文本框中。
9.  Next, click **Start** **swarming** to start load testing the endpoint. This will start the load test and open a new page where you can monitor your load tests in real time as shown in *Figure 9.3*:![Figure 9.3 – Monitor the load test in real time
    ](img/B16572_09_03.jpg)

    图 9.3–实时监控负载测试

10.  Analyzing load testing results: You can monitor statistics, charts, failures, and exceptions in real time. For instance, in *Figure 9.3* we are monitoring the load test for the `POST` request with test data. The number of requests made (**77459**), the number of fails (**0**), the average response time (**75ms**), and other information can be monitored. It is important to check that there are no failures and that the average response time is within the range to serve your business/user needs with efficiency or no major speed breaker.

    如果没有失败的请求，并且平均响应时间在要求的范围内，那么您的端点已经通过了负载测试，可以为用户提供服务了。在负载测试之后或期间，您可以查看负载测试性能图表，其中包含关键信息，如每秒的总请求数、响应时间以及随时间推移的用户数。我们可以实时查看这些信息，如图*图 9.4* 和*图 9.5* 所示:

![Figure 9.4 – Charts showing the total requests per second and response times
](img/B16572_09_04.jpg)

图 9.4-显示每秒请求总数和响应时间的图表

在*图 9.4* 中，我们可以注意到，当`locust.io`的模拟用户发出请求时，每秒的请求数在 18-22 之间，在某些情况下，以毫秒为单位的响应时间从 70 到 500 不等，最小值和最大值之间有 430 毫秒的差异。平均请求时间为 75 毫秒(如*图 9.3* 所示)。

请注意，对于给定的用例，这种性能可能是也可能不是理想的，这取决于您的业务或用户需求。期望更稳定的响应时间；例如，对于稳定的性能，最小和最大响应时间之间不超过 50 毫秒的响应时间差异可能是优选的。为了实现这样的性能，建议在适当的高端基础设施上部署您的模型，例如，GPU 或高端 CPU，这不同于在 Azure 容器实例中的 CPU 上的部署。同样，在*图 9.5* 中，我们可以看到响应时间与用户数量的关系:

![Figure 9.5 – Charts showing the total requests per second and the number of users
](img/B16572_09_05.jpg)

图 9.5-显示每秒总请求数和用户数的图表

我们可以看到每秒产生的用户数是 50，正如前面提到的(在*图 9.2* )。随着时间的推移，产卵率是恒定的，响应时间在 70-500 毫秒之间变化，平均响应时间为 75 毫秒。

1.  记录或下载结果:负载测试成功执行后，您可以使用测试报告记录或向相关的风险承担者(QA/产品经理)展示负载测试的结果。要下载或访问测试报告，请进入`.csv`文件，如图*图 9.6* 所示:

![Figure 9.6 – Download the test results
](img/B16572_09_06.jpg)

图 9.6-下载测试结果

根据需要下载进一步检验所需的统计数据或故障报告，注意点击**下载报告**可以查看完整的测试报告，如图*图 9.7* 所示:

![Figure 9.7 – Download the test results
](img/B16572_09_07.jpg)

图 9.7-下载测试结果

全面的测试报告提供了关键信息，如端点推断的平均请求时间以及最小和最大请求时间，这些信息也以可视化图表的形式呈现，如图*图 9.7* 所示。您也可以下载这份完整的报告，向各自的利益相关方展示。

恭喜您，已经执行了实际负载测试，以验证您的端点并检查您的 ML 服务是否能够高效地满足您的业务或用户需求。

# 通过设计保护您的 ML 解决方案

由于越来越多地采用人工智能来提供智能应用，保护您的 ML 应用比以往任何时候都更加重要。设计和开发不考虑安全性的 ML 系统可能会使系统暴露给黑客，从而导致操纵、数据泄露和不合规，因此成本高昂。鲁棒性和安全性在确保人工智能系统值得信赖方面发挥着重要作用。为了构建值得信赖的 ML 应用程序，牢记安全性是至关重要的。

*图 9.8* 显示了通过设计创建安全 ML 应用的框架。该框架解决了 ML 生命周期中的关键领域，确保了这些特定阶段的机密性、完整性和可用性。让我们思考 ML 生命周期的每个领域，并解决每个领域中的机密性、完整性和可用性问题:

![Figure 9.8 – Framework for securing the ML life cycle by design
](img/B16572_09_08.jpg)

图 9.8-通过设计确保 ML 生命周期的框架

让我们思考一下 ML 生命周期的每个领域，并在查看不同类型的攻击时解决每个领域的机密性、完整性和可用性问题。

## 攻击类型

我们将探讨一些最常见的对 ML 系统的攻击。在高层次上，黑客的攻击可以分为四类:投毒、输入攻击和规避、逆向工程和后门攻击。让我们看看攻击者是如何通过这些攻击渗透到 ML 系统中的。

### 中毒

黑客或攻击者试图在中毒攻击中损害 AI 模型。中毒攻击可能发生在任何阶段(训练、部署或实时推理)。它们通常出现在训练和推理中。让我们看看中毒攻击是如何以三种典型方式实现的:

*   **数据集中毒**:训练数据集包含模型被训练的知识。一个攻击者可以通过渗透训练数据集来操纵这些知识。在这里，攻击者将错误标记或不正确的数据引入到训练数据集中，从而扭曲了整个学习过程。这是毒害模型的直接方式。在数据收集和管理阶段，训练数据集可能会中毒，并且很难注意到或检测到它，因为训练数据集可能来自多个来源，可能很大，并且攻击者可能会渗透到数据分布中。
*   **算法中毒**发生在攻击者干预用于训练模型的算法时。它可以简单到渗透超参数或摆弄算法的架构。例如，让我们以联合学习(旨在保护个人数据的隐私)为例，其中模型训练是在私人数据的多个子集上进行的(例如来自多个医院的医疗保健数据，同时保护患者的机密信息)。从每个子集导出多个模型，然后组合形成最终模型。在此期间，攻击者可以操纵数据的任何子集，并影响最终得到的模型。攻击者还可以从虚假数据创建虚假模型，并将其与通过对私有数据的多个子集进行训练而产生的模型连接起来，以产生偏离有效执行任务的最终模型，或者服务于攻击者的动机。
*   **模型中毒**发生在攻击者用替代的模型替换已部署的模型的时候。这种攻击与典型的网络攻击相同，其中包含模型的电子文件可能被修改或替换。

### 输入攻击和规避

当攻击者在中修改对 ML 系统的输入，从而导致系统故障(或给出错误预测)时，输入或规避攻击发生。这些扰动或变化可能难以察觉，因为这些变化非常细微或微小。

例如，对于计算机视觉算法来说，输入攻击很常见。这可以通过改变输入图像中的几个像素来实现。结果，系统可能以不应该的方式识别图像，或者做出错误的预测。这种微小的变化可以有效地操纵预测，导致系统采取错误的行动。因此，当输出被操纵时，ML 系统的行为是正常的。

ML 系统非常容易受到输入攻击。因此，使用异常检测器来监控传入的数据可以非常方便地避免传入数据中的这种扰动。不考虑输入数据，大多数分类模型从它们的训练中选择有效的类。保护 ML 系统的另一种方式是通过用代理二进制模型预处理输入，例如，在将该图像发送到最终图像分类器之前，该代理二进制模型告诉你输入图像是人还是动物。

### 逆向工程

对于一个人工智能系统的用户来说，它可以是一个黑盒或者是不透明的。在人工智能系统中，接受输入来生成输出而不揭示内部发生了什么是很常见的(就逻辑和算法而言)。训练数据集有效地包含了所有经过训练的系统的知识，通常也是保密的。理论上，这使得局外人无法预测为什么会产生特定的输出，或者 AI 系统内部在算法、训练数据或逻辑方面发生了什么。然而，在某些情况下，这些系统可能容易被逆向工程。攻击者或黑客在逆向工程攻击中的目标是复制作为服务部署的原始模型，并将其用于他们的优势。

在 2020 年 2 月发表的一篇题为*针对循环神经网络*([https://arxiv.org/pdf/2002.00123.pdf](https://arxiv.org/pdf/2002.00123.pdf))的模型提取攻击的论文中，研究人员对用公开可用的学术数据集训练的 RNN 和 LSTM 进行了模型提取攻击实验。研究人员通过模型提取攻击有效地再现了 ML 系统的功能。他们证明了具有高准确性的模型提取攻击可以被有效地提取，主要是通过从目标模型复制或配置损失函数或架构。

在另一个例子中，马克斯·普朗克信息学研究所的研究人员在 2018 年展示了他们如何通过使用一系列输入输出查询从不透明的模型中推断信息。

### 后门攻击

在后门攻击中，攻击可以在训练或推断阶段将他们选择的模式嵌入模型中，并使用预先确定的输入来推断部署的模型，以产生意外的输出或对 ML 系统的触发。因此，后门攻击可能发生在训练和推理阶段，而规避和中毒攻击可能发生在训练或推理的单一阶段。

在后门攻击中，毒药攻击可以用作攻击的一部分，在某些情况下，学生模型可以使用迁移学习从教师模型学习侵入一些后门。

后门攻击会导致完整性挑战，尤其是在训练阶段，如果攻击者设法使用毒药攻击来渗透训练数据并触发对模型或系统的更新。此外，后门攻击可以旨在降低性能，耗尽或重定向可能导致系统故障的资源，或者试图引入 AI 系统的特殊行为和输出。

# 摘要

在这一章中，我们学习了测试和安全性设计的关键原则。我们探索了测试 ML 解决方案的各种方法，以确保其安全性。为了获得全面的理解和实践经验，我们对之前部署的 ML 模型进行了负载测试(从 [*第 7 章*](B16572_07_Final_JM_ePub.xhtml#_idTextAnchor143) ，*构建健壮的 CI 和 CD 管道*)以预测天气。这样，您就可以准备好处理各种测试和安全场景了。

在下一章，我们将深入研究在生产中部署和维护健壮的 ML 服务的秘密。这将使您能够在生产中部署健壮的 ML 解决方案。我们来深入探讨一下。