<html><head/><body>


	
		<title>B16572_07_Final_JM_ePub</title>
		
	
	
		<div><h1 id="_idParaDest-124">第 7 章:构建强大的 CI/CD 管道</h1>
			<p><a id="_idTextAnchor144"/>在本章中，您将了解 MLOps 管道中的连续操作。您将在本章中学习的原则是在业务环境中推动持续部署的关键。为了获得全面的理解和第一手经验，我们将同时浏览概念和实际操作。我们将为测试环境建立一个 CI/CD 管道，同时了解<strong class="bold">持续集成</strong> ( <strong class="bold"> CI </strong>)和<strong class="bold">持续部署</strong> ( <strong class="bold"> CD </strong>)的组件、管道测试以及触发器的版本和类型。这将使您具备自动部署<strong class="bold">机器学习</strong> ( <strong class="bold"> ML </strong>)模型管道的技能，以适应业务的持续学习能力。让我们首先看看为什么我们在 MLOps 中需要 CI/CD。我们将继续探讨以下其他主题:</p>
			<ul>
				<li><a id="_idTextAnchor145"/>m lops 中的持续集成、交付和部署</li>
				<li>设置 CI/CD 管道和测试环境(使用 Azure DevOps)</li>
				<li>流水线执行和测试</li>
				<li>管道执行触发器</li>
			</ul>
			<h1 id="_idParaDest-125"><a id="_idTextAnchor146"/>m lops 中的持续集成、交付和部署</h1>
			<p><strong class="bold">自动化</strong>是 MLOps 工作流程中<a id="_idIndexMarker519"/> CI/CD 的<a id="_idIndexMarker517"/>主要<a id="_idIndexMarker518"/>原因。支持向 ML 服务连续交付的目标是维护模型的数据和源代码版本，支持触发器并行执行必要的工作，构建工件，并发布生产部署。一些云供应商正在推广 DevOps 服务，以监控生产中的 ML 服务和模型，并与云上的其他服务进行协调。使用 CI 和 CD，我们可以实现持续学习，这对于 ML 系统的成功至关重要。如果没有持续的学习，ML 系统就会被视为失败的概念验证。</p>
			<p class="author-quote">只有部署了持续学习能力的模型才能带来商业价值。</p>
			<p>为了学习在生产中部署具有持续学习能力的模型，我们将探索 CI、CD 和持续交付方法。</p>
			<p>正如<a id="_idIndexMarker521"/>你<a id="_idIndexMarker522"/>可以<a id="_idIndexMarker523"/>看到<em class="italic">图 7.1 </em>中的<a id="_idIndexMarker524"/>一样，CI 是 CD 和连续交付的关键。让我们<a id="_idIndexMarker525"/>看看<a id="_idIndexMarker526"/>这三者是如何相互联系的:</p>
			<div><div><img src="img/B16572_07_01.jpg" alt="Figure 7.1 – Continuous integration, delivery, and deployment pipelines&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 7.1–持续集成、交付和部署管道</p>
			<h2 id="_idParaDest-126"><a id="_idTextAnchor147"/>持续集成</h2>
			<p>CI 旨在<a id="_idIndexMarker527"/>将应用程序(ML 管道和应用程序)与开发人员实时同步。开发人员在提交或合并中的更改通过动态创建应用程序构建并针对该构建执行自动化测试来验证。CI 强调自动化测试，当新的提交被合并到 master 或 main 分支时，重点检查应用程序的健壮性(如果它没有被破坏或被窃听)。每当对主分支进行新的提交时，就会创建一个新的构建，并使用自动化测试对其进行健壮性测试。通过自动化这个过程，我们可以避免软件的延迟交付和其他集成挑战，这些挑战会让用户为发布等待数天。自动化和测试是 CI 的核心。</p>
			<h2 id="_idParaDest-127"><a id="_idTextAnchor148"/>连续交货</h2>
			<p>持续交付从 CI 中扩展出<a id="_idIndexMarker529"/>，以确保新的变更或发布被部署并有效地带给用户；自动化测试和发布过程有助于这一点。自动化测试和发布流程使开发人员和产品经理只需点击一个按钮即可部署变更，从而在流程的任何阶段实现无缝控制和监督功能。在连续交付过程中，通常，在将构建部署到生产中之前，人工代理(来自 QA 团队)会参与批准构建(通过或失败)(如连续交付管道中的<em class="italic">图 7.1 </em>所示)。在一个典型的连续交付管道中，一个构建在被部署到阶段之前要经过初步的验收测试，在这个阶段，一个人工代理使用冒烟测试和其他合适的测试来监督性能。</p>
			<p>一旦通过了冒烟测试，人工代理就通过了要在生产中部署的构建。自动化构建和发布过程并让人工代理参与到该过程中可以确保生产的高质量，并且我们可以避免一些全自动化管道可能忽略的缺陷。使用连续交付，企业可以完全控制它的发布过程，并且小批量地发布一个新的构建版本(在遇到阻塞或错误的情况下很容易排除故障),或者在必要的时间框架内(每天、每周或每月)发布一个完整的版本。</p>
			<h2 id="_idParaDest-128"><a id="_idTextAnchor149"/>持续部署</h2>
			<p>CD 实现了完全自动化，比连续交付更进了一步。与连续交付不同，构建和发布到生产的所有阶段都是完全自动化的，没有任何人工干预。在这样的自动化管道中，只有失败的测试才能阻止新的变更被部署到生产中。持续部署减轻了团队维护发布渠道的压力，并加速了直接面向客户的部署，通过与客户的反馈循环实现了持续学习。</p>
			<p>有了这样的自动化，开发者不再有发布日。这减轻了他们的压力，他们可以专注于构建软件，而不用担心测试和发布管理。开发人员可以在方便的时候构建、测试和部署软件，并且可以在几分钟内投入使用，而不是等待发布日或人工批准，这可能会将软件发布延迟几天甚至几周。持续部署可确保完全自动化，为用户部署和提供强大的<a id="_idIndexMarker530"/>可扩展软件。</p>
			<h1 id="_idParaDest-129"><a id="_idTextAnchor150"/>设置 CI/CD 管道和测试环境(使用 Azure DevOps)</h1>
			<p>在<a id="_idIndexMarker531"/>之前的<a id="_idIndexMarker532"/>部分，我们<a id="_idIndexMarker533"/>经历了<a id="_idIndexMarker534"/>CI、持续交付、持续部署的理论，现在是时候在实践中看到了。使用 Azure DevOps，我们将为业务问题(天气预测)建立一个我们自己的简单 CI/CD 管道，这是我们之前一直在做的(在<a href="B16572_06_Final_JM_ePub.xhtml#_idTextAnchor124"> <em class="italic">第 6 章</em> </a>，<em class="italic">部署您的 ML 系统的关键原则</em>，在动手部署部分(针对业务问题))。</p>
			<p>Azure DevOps 是微软提供的一项服务，旨在促进源代码管理(版本控制)、项目管理、CI、持续交付和持续部署(自动化构建、测试和发布功能)。它还支持软件应用程序的生命周期管理。我们将使用 Azure DevOps 进行实践培训，因为它与 Azure ML 服务无缝集成，我们之前在<a href="B16572_06_Final_JM_ePub.xhtml#_idTextAnchor124"><em class="italic">C</em><em class="italic">hapter 6</em></a>中一直在使用该服务。您将体验到两种服务的集成和同步，从而轻松进行部署。让我们开始吧。</p>
			<p>转到您的 Azure DevOps 项目，<code>Learn_MLOps</code>。转到克隆的存储库并访问<code>07_CICD_Pipeline</code>文件夹。我们将使用这些文件(在名为<code>07_CICD_Pipeline</code>的文件夹中)作为驱动程序来构建一个发布管道:</p>
			<pre>Learn_MLOps
├──07_CICD_Pipeline
│   ├── AciDeploymentconfig.yml
    ├── AksDeploymentconfig.yml
    └── InferenceConfig.yml
    └── myenv.yml
    └── score.py</pre>
			<p>我们将在两个<a id="_idIndexMarker535"/>部署目标上部署先前训练的 ML 模型(来自<a href="B16572_04_Final_JM_ePub.xhtml#_idTextAnchor074"> <em class="italic">第四章</em> </a>，<em class="italic">机器学习管道</em>):一个是<code>AciDeployment.yml</code>文件，包含 ACI 部署目标的配置，<code>AksDeployment.yml</code>文件包含 AKS 集群的配置。<code>InferenceConfig.yml</code>指向<code>score.py</code>、<code>myenv.yml</code>等推理工件。</p>
			<p>在<code>score.py</code>中定义的函数<a id="_idIndexMarker537"/>将<a id="_idIndexMarker538"/>用于预处理<a id="_idIndexMarker539"/>输入的数据，并使用 ML 模型推断<a id="_idIndexMarker540"/>预处理后的数据以进行预测。<code>myenv.yml</code>文件是推理环境的配置，例如 Python 版本和要在环境中安装的包。这些文件将被用作驱动程序，以促进发布渠道。现在您已经熟悉了这些文件，让我们开始使用服务主体连接 Azure ML 服务和 Azure DevOps 项目。</p>
			<h2 id="_idParaDest-130"><a id="_idTextAnchor151"/>创建服务主体</h2>
			<p>我们需要同步 Azure ML 服务和 Azure DevOps，以便促进两个服务之间的 CI。之前(在<a href="B16572_04_Final_JM_ePub.xhtml#_idTextAnchor074"> <em class="italic">第 4 章</em> </a>，<em class="italic">机器学习管道</em>)我们已经使用 Azure ML 服务开发和管理了我们的 ML 模型，并且我们使用了<code>Learn_MLOps</code>工作空间。现在，我们将使用服务主体连接 Azure ML 工作空间(名为<code>Learn_MLOps</code>)和 Azure DevOps 项目(名为<code>Learn_MLOps</code>)。</p>
			<p>服务主体是为应用程序间通信创建的身份；它是一个访问 Azure 资源的连接自动化工具。服务主体还负责应用程序的网络和连接方面。执行以下步骤为管道设置服务主体:</p>
			<ol>
				<li>Go to <strong class="bold">Project Settings</strong> (on the bottom left of your screen) and select <strong class="bold">Service connections</strong>. Click the <strong class="bold">New service connection</strong> option/button to reveal the New service connection window, as shown in <em class="italic">Figure 7.2</em>:<div><img src="img/B16572_07_02.jpg" alt="Figure 7.2 – New service principal connection&#13;&#10;"/></div><p class="figure-caption">图 7.2–新服务主体连接</p></li>
				<li>选择<strong class="bold"> Azure 资源管理器</strong>作为连接类型，然后点击<strong class="bold">下一步</strong>继续。选择<strong class="bold">服务主体(自动)</strong>并进入创建服务主体的最后一步。</li>
				<li>You will be prompted to create a new service connection. Set the scope as <strong class="bold">Machine Learning Workspace</strong> and point to the <strong class="bold">Subscription</strong>, <strong class="bold">Resource group</strong> and <strong class="bold">Machine Learning Workspace</strong> as shown in <em class="italic">Figure 7.3:</em><div><img src="img/B16572_07_03.jpg" alt="Figure 7.3 – Final step in creating a service principal&#13;&#10;"/></div><p class="figure-caption">图 7.3–创建服务主体的最后一步</p></li>
				<li>在<code>mlops_sp</code>中命名<a id="_idIndexMarker542"/>服务负责人，如图<em class="italic">图 7.3 </em>所示。最后，勾选复选框(<strong class="bold">授予所有管道</strong>的访问权限)，点击<strong class="bold">保存</strong>创建服务主体。</li>
			</ol>
			<p>这样，具有给定名称(例如，<code>mlops_sp</code>)的服务主体就可以用于编排 CI/CD 管道了。接下来，我们将安装用于管道的扩展。</p>
			<h2 id="_idParaDest-131"><a id="_idTextAnchor152"/>安装扩展以连接到 Azure ML 工作区</h2>
			<p>微软已经<a id="_idIndexMarker543"/>开发了一个扩展<a id="_idIndexMarker544"/>叫做<strong class="bold">机器学习</strong>。它可以在 Azure DevOps 市场上获得。它用于编排来自我们期望的 Azure ML 工作空间的模型和工件。它允许我们将模型从工作区部署到我们想要的部署目标，比如 ACI 或 AKS。我们将安装 ML 扩展并使用它来编排 CI/CD 管道。执行以下步骤安装扩展:</p>
			<ol>
				<li value="1">Go to the Marketplace to look for the <strong class="bold">Machine Learning</strong> extension. To go to the Marketplace, click on the bag icon in the top right of your screen, as shown in <em class="italic">Figure 7.4</em>:<div><img src="img/B16572_07_04.jpg" alt="Figure 7.4 – Finding the Azure DevOps Marketplace&#13;&#10;"/></div><p class="figure-caption">图 7.4–寻找 Azure DevOps 市场</p><p>进入市场后，您将看到多个扩展可以添加到您的 Azure DevOps 项目中。接下来，我们将搜索<strong class="bold">机器学习</strong>扩展。</p></li>
				<li>搜索<strong class="bold">机器学习</strong>扩展，免费安装扩展。点击<strong class="bold">松开</strong>按钮安装接长件，如图<em class="italic">图 7.5 </em>所示:</li>
			</ol>
			<div><div><img src="img/B16572_07_05.jpg" alt="Figure 7.5 – Installing the Machine Learning extension&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 7.5–安装机器学习扩展</p>
			<p>点击<strong class="bold">获得自由</strong>按钮，将安装<strong class="bold">机器学习</strong>扩展。成功安装后，您可以使用<strong class="bold">机器学习</strong>扩展来编排 CI/CD 管道中的<a id="_idIndexMarker545"/>作业。有了这些先决条件，您就可以配置连续部署或连续交付管道了。</p>
			<h2 id="_idParaDest-132"><a id="_idTextAnchor153"/>为测试环境建立持续集成和部署管道</h2>
			<p>在此<a id="_idIndexMarker546"/>部分，我们将<a id="_idIndexMarker547"/>为准备<a id="_idIndexMarker549"/>环境(也称为测试环境)配置<a id="_idIndexMarker548"/>CI/CD 管道。我们将利用这一渠道来促进持续学习和自动化部署。先从<strong class="bold">管道</strong> &gt; &gt; <strong class="bold">发布</strong>开始，如图<em class="italic">图 7.6 </em>所示:</p>
			<div><div><img src="img/B16572_07_06.jpg" alt="Figure 7.6 – Setting up your CI/CD pipeline  &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 7.6–设置 CI/CD 管道</p>
			<p>在<code>Port Weather ML Pipeline</code>中创建新的管道。接下来，我们将开始连接<a id="_idIndexMarker550"/>必需的工件<a id="_idIndexMarker551"/>以启用<a id="_idIndexMarker552"/>管道，例如包含代码的存储库<a id="_idIndexMarker553"/>和包含要部署的模型的 Azure ML 工作空间。</p>
			<h2 id="_idParaDest-133"><a id="_idTextAnchor154"/>将工件连接至管道</h2>
			<p>连接到您的 Azure DevOps <a id="_idIndexMarker554"/>存储库。Azure DevOps <a id="_idIndexMarker555"/>存储库作为中央代码存储库来编排 Azure DevOps 上的部署和操作。因此，让我们将存储库(<code>Learn_MLOps</code>)连接到发布管道:</p>
			<ol>
				<li value="1">As shown in <em class="italic">Figure 7.7</em>, go to the <code>Learn_MLOps</code>) to connect with the release pipeline:<div><img src="img/B16572_07_07.jpg" alt="Figure 7.7 – Connecting the Azure DevOps repository as an artifact  &#13;&#10;"/></div><p class="figure-caption">图 7.7–将 Azure DevOps 存储库作为工件进行连接</p></li>
				<li>在<strong class="bold">工件</strong>部分选择默认分支(例如<code>Learn_MLOps</code>)和图标。</li>
				<li>Connect to your Azure ML workspace. To connect your Azure ML workspace to the release pipeline, go to the <code>scaler</code> artifact previously registered in <a href="B16572_04_Final_JM_ePub.xhtml#_idTextAnchor074"><em class="italic">Chapter 4</em></a>, <em class="italic">Machine Learning Pipelines,</em> to scale the incoming data using the standard:<div><img src="img/B16572_07_08.jpg" alt="Figure 7.8 – Connecting the scaler as an artifact &#13;&#10;"/></div><p class="figure-caption">图 7.8–将定标器作为工件进行连接</p></li>
				<li>选择<code>model_scaler</code>工件后，点击<code>model_scaler</code>工件，将<a id="_idIndexMarker558"/>工件添加到发布<a id="_idIndexMarker559"/>管道中，您将能够在发布管道工件的<code>support_vector_classifier</code>模型中看到模型名称(<code>model_scaler</code>)和模型图标。首先点击<code>mlops_sp</code>，选择之前在<em class="italic">第 4 章</em>、<em class="italic">机器学习管道</em>中训练过的<code>support_vector_classifier</code>模型。点击<strong class="bold">添加</strong>按钮，将模型工件添加到管道中:</li>
			</ol>
			<div><div><img src="img/B16572_07_09.jpg" alt="Figure 7.9 – Connected artifacts&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 7.9–连接的工件</p>
			<p><a id="_idIndexMarker560"/>添加<code>support_vector_classifier</code>模型后，<a id="_idIndexMarker561"/>将可以在<strong class="bold">工件</strong>部分看到该模型的名称(<code>support_vector_classifier</code>和一个模型图标，如图<em class="italic">图 7.9 </em>所示。</p>
			<p>恭喜你！我们将所有三个期望的工件(<code>Learn_MLOps</code>、<code>scaler</code>和<strong class="bold">support _ vector _ classifier</strong>)连接到发布管道。我们可以使用这些工件来编排管道中的部署。接下来，准备配置试运行/测试环境！</p>
			<h2 id="_idParaDest-134"><a id="_idTextAnchor155"/>设置测试环境</h2>
			<p>让我们为管道中的测试环境设置一个<a id="_idIndexMarker562"/>持续集成和持续部署管道。在这一阶段，我们测试服务的健壮性，并执行各种测试来验证服务的生产就绪性:</p>
			<ol>
				<li value="1">To get started, click on the <code>DEV</code> <code>TEST</code>. We will name the stage <code>DEV</code> <code>TEST</code> as this will be our development and testing environment. Ideally, both DEV and TEST are different stages, but for simplicity and avoiding repetitive implementation, we will merge them both. See the following <em class="italic">Figure 7.10</em>:<div><img src="img/B16572_07_10.jpg" alt="Figure 7.10 – Setting up the DEV TEST stage&#13;&#10;"/></div><p class="figure-caption">图 7.10–设置开发测试阶段</p></li>
				<li>After naming <a id="_idIndexMarker563"/>the stage, save the stage by clicking the <strong class="bold">Save</strong> button at the top. Every stage is a composition of a series of steps or jobs to check the robustness of the stage. Next, we will configure the jobs within the <strong class="bold">DEV TEST</strong> stage. A CI/CD job, in simple terms, is a process or script to execute or test deployments (for example, a job to deploy a model on the Kubernetes cluster). To configure jobs, click <a id="_idIndexMarker564"/>on the <strong class="bold">1 job, 0 task</strong> link in the <strong class="bold">DEV TEST</strong> stage, as shown in <em class="italic">Figure 7.11</em>:  <div><img src="img/B16572_07_11.jpg" alt="Figure 7.11 – Configuring DEV TEST jobs&#13;&#10;"/></div><p class="figure-caption">图 7.11–配置开发测试作业</p><p>在<a id="_idIndexMarker565"/>点击<strong class="bold">开发测试</strong>阶段中的<strong class="bold"> 1 作业，0 任务</strong>链接后，您将必须添加代理作业。</p></li>
				<li>Add a task to the agent job by clicking <code>AzureML model deploy</code>, as shown in <em class="italic">Figure 7.12</em>:<div><img src="img/B16572_07_12.jpg" alt="Figure 7.12 – Adding a job – AzureML Model Deploy&#13;&#10;"/></div><p class="figure-caption">图 7.12–添加作业–azure ml 模型部署</p><p>添加<code>inferenceconfig</code>文件后。</p></li>
				<li>接下来，将提示您输入部署信息。如<em class="italic">图 7.13 </em>所示，指向您的 Azure ML 工作区(例如<code>mlops_ws</code>)，并将<code>Model Source</code>选项设置为<strong class="bold">模型工件</strong>(因为我们在训练和打包模型时使用了之前生成的模型工件):</li>
			</ol>
			<div><div><img src="img/B16572_07_13.jpg" alt="Figure 7.13 – Adding a job – Azure ML Model Deploy&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 7.13–添加作业–Azure ML 模型部署</p>
			<p>接下来，我们将看看<code>inferenceConfig</code>文件及其功能。以下片段摘自<code>inferenceConfig.yml</code>中的<a id="_idIndexMarker567"/>(在存储库中)。以下是<code>inferenceConfig.yml</code>的快照:</p>
			<p><code>inferenceConfig.yml</code></p>
			<pre>entryScript: score.py
runtime: python
condaFile: myenv.yml</pre>
			<p>它代表了我们将在其中部署模型的定制环境的设置。它指向<code>score.py</code>文件(之前在<a href="B16572_06_Final_JM_ePub.xhtml#_idTextAnchor124"> <em class="italic">第 6 章</em> </a>、<em class="italic">部署您的 ML 系统的关键原则</em>中创建)和<code>conda</code>文件<code>myenv.yml</code>，后者定义了<code>conda</code>环境(要安装的包和依赖项)。这里有一张<code>myenv.yml</code>的快照:</p>
			<p><code>myenv.yml</code></p>
			<pre>name: project_environment
dependencies:
  # The python interpreter version.
  # Currently Azure ML only supports 3.5.2 and later.
- python=3.6.2
- pip:
  - numpy
  - onnxruntime
  - joblib
  - azureml-core~=1.10.0
  - azureml-defaults~=1.10.0
  - scikit-learn==0.20.3
  - inference-schema
  - inference-schema[numpy-support]
  - azureml-monitoring
channels:
- anaconda
- conda-forge</pre>
			<p><code>score.py</code>和<code>myenv.yml</code>文件都捆绑在<code>inferenceConfig.yml</code>文件中，方便 ML 模型的部署和推理。继续选择您的推理配置文件(<code>inferenceConfig.yml</code>，如图<em class="italic">图 7.14 </em>所示:</p>
			<div><div><img src="img/B16572_07_14.jpg" alt="Figure 7.14 – Selecting your inference configuration file&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 7.14–选择您的推理配置文件</p>
			<p>指向 Azure DevOps 存储库中的<code>inferenceConfig.yml</code>文件后，部署的基本<a id="_idIndexMarker569"/>配置就完成了。最后，我们将通过指向 ACI 的<code>AciDeploymentConfig.yml</code>来配置部署信息:</p>
			<p><code>AciDeploymentConfig.yml</code></p>
			<pre>computeType: ACI
containerResourceRequirements:
    cpu: 1
    memoryInGB: 1
authEnabled: False
sslEnabled: False
appInsightsEnabled: True</pre>
			<p>它包含用于调配部署所需计算的基础架构定义，如 CPU 单位、内存(GB)以及其他身份验证或安全定义。让我们选择这个部署配置文件来为登台<a id="_idIndexMarker570"/>环境设置发布管道，如图<em class="italic">图 7.15 </em>所示:</p>
			<div><div><img src="img/B16572_07_15.jpg" alt="Figure 7.15 – Adding deployment information&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 7.15–添加部署信息</p>
			<p>添加部署配置文件后，通过单击屏幕右上角的<strong class="bold">保存</strong>按钮保存作业，然后转到<strong class="bold">管道</strong> &gt; &gt; <strong class="bold">发布</strong>(在屏幕左侧)查看您的管道是否成功设置。让我们从这里继续测试管道。</p>
			<h1 id="_idParaDest-135"><a id="_idTextAnchor156"/>管道执行和测试</h1>
			<p>现在是<a id="_idIndexMarker571"/>时间<a id="_idIndexMarker572"/>来测试您的管道，为此我们将创建一个发布，并验证管道发布是否已成功执行。以下步骤将帮助您测试管道:</p>
			<ol>
				<li value="1">点击<strong class="bold">创建发布</strong>按钮，执行在您的管道上配置的作业。屏幕右侧将出现一个弹出窗口(如图<em class="italic">图 7.16 </em>所示)，用于查看和选择要在您的暂存环境中部署的工件。</li>
				<li> Select the artifacts (<code>_scaler</code> and <code>_support-vector-classifier</code>) and select their versions. For simplicity, version 1 is recommended for both. <p>如果您想要选择您的模型或缩放器的另一个版本，请确保在<code>score.py</code>文件中更改您的模型和缩放器的路径(即，在<code>scaler</code>和<code>model</code>路径<code>model-scaler/{version number}/modelscaler.pkl</code>和<code>support-vector-classifier/ {version number} /svc.onnx</code>中插入适当的版本号)。如果您选择<a id="_idIndexMarker573"/>版本 1，您不必担心更改<code>score.py</code>文件中的<a id="_idIndexMarker574"/>代码，因为路径包含版本 1。</p></li>
				<li>After selecting artifacts and needed versions (version 1 is recommended), click on the <strong class="bold">Create</strong> button to create the release for your selected artifacts:<div><img src="img/B16572_07_16.jpg" alt="Figure 7.16 – Creating a release&#13;&#10;"/></div><p class="figure-caption">图 7.16–创建发布</p></li>
				<li>Now the release pipeline (the CI/CD pipeline) is triggered to execute. All the steps defined in the pipeline will execute, such as downloading the artifacts, provisioning the ACI compute instance for deployment, and deploying the web service. Upon successful execution, you'll be notified with a green <a id="_idIndexMarker575"/>tick-mark <a id="_idIndexMarker576"/>on your release, as shown in <em class="italic">Figure 7.17</em>: <div><img src="img/B16572_07_17.jpg" alt="Figure 7.17 – Monitoring releases&#13;&#10;"/></div><p class="figure-caption">图 7.17–监控释放</p></li>
				<li>You can monitor all your releases in the <code>scaler</code> and <code>_support-vector-classifier</code>) have been deployed as a web service on ACI, as shown in <em class="italic">Figure 7.18</em>: <div><img src="img/B16572_07_18.jpg" alt="Figure 7.18 – Successful jobs in a release (test environment)&#13;&#10;"/></div><p class="figure-caption">图 7.18–发布中的成功作业(测试环境)</p></li>
				<li>最后，进入<a id="_idIndexMarker577"/>并检查您的 Azure ML 工作区(从<a id="_idIndexMarker578"/>的<strong class="bold">端点</strong>部分)以查看部署的 web 服务，如图<em class="italic">图 7.19 </em>所示:</li>
			</ol>
			<div><div><img src="img/B16572_07_19.jpg" alt="Figure 7.19 – Web service deployed on the Azure ML workspace&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 7.19–部署在 Azure ML 工作空间上的 Web 服务</p>
			<p>我们已经在测试环境中成功地部署了一个 web 服务。我们可以看到 REST 端点和服务名<strong class="bold"> devtest-webservice </strong>。这使我们成功地完成了测试环境的 CI/CD 管道的构建和测试。可以使用触发器来驱动<a id="_idIndexMarker579"/>管道，在下一节中，我们将了解什么是<a id="_idIndexMarker580"/>触发器，以及我们如何使用它们来构建最佳 CI/CD 管道。</p>
			<h1 id="_idParaDest-136"><a id="_idTextAnchor157"/>管道执行触发器</h1>
			<p>在有效的 CI/CD 管道中，流程执行<a id="_idIndexMarker581"/>应该可以通过多个事件或触发器来实现。选择仅通过常规事件来触发管道，例如代码库或推或拉请求，可能是系统的障碍或限制。拥有使用多个事件触发管道过程的选项增强了 CI/CD 管道的灵活性和功能性。让我们来看一些可以为 CI/CD 渠道<a id="_idIndexMarker582"/>流程增值的触发器类型:</p>
			<ul>
				<li><strong class="bold">Artifactory triggers</strong><p>工件<a id="_idIndexMarker583"/>在流水线和开发过程的不同阶段生成<a id="_idIndexMarker584"/>。可以触发生成的工件，例如经过训练的模型、元数据、上传的 Docker 图像或任何已经上传的文件，来执行 CI/CD 管道中的某个流程。拥有这样的选项可以为 CI/CD 管道提供更大的灵活性和功能性。</p></li>
				<li><strong class="bold">Docker Hub triggers</strong><p>每次<a id="_idIndexMarker585"/>您将新的<a id="_idIndexMarker586"/> Docker 映像推送到您选择的 Docker Hub 存储库时，CI/CD 管道中的一个触发器就会根据需要执行。例如，当你上传一个新的 Docker 映像到 Docker Hub(或者 Azure Container Registry)时，管道被触发来将 Docker 映像部署为一个 web 服务。</p></li>
				<li><strong class="bold">Schedule triggers</strong><p>流水线<a id="_idIndexMarker587"/>过程可以按照特定的时间表被触发<a id="_idIndexMarker588"/>。这种类型的触发器对于计划的清理或 cron 作业或任何其他需要按照时间间隔运行的工作流非常有用；比如每天 12 点 ML 模型再训练的一个触发器。</p></li>
				<li><code>retrain</code>在开发者的平台上，可以触发管道来重新训练现有的部署模型。使用 API 调用可以简化这些触发器。</li>
				<li><strong class="bold">Git triggers</strong><p>Git 触发器<a id="_idIndexMarker591"/>通常用于触发<a id="_idIndexMarker592"/>管道执行，例如当新代码被提交到分支或者新的拉请求被发出时。当对存储库进行更改时，可以根据需求在管道中触发某些流程。</p></li>
			</ul>
			<p>Azure DevOps 提供多种触发选项(以上全部)。现在，让我们根据对存储库的 Git 提交设置一个 Git 触发器:</p>
			<ol>
				<li value="1">转到<code>Edit</code>(在屏幕右上角<a id="_idIndexMarker593"/>)编辑现有管道。</li>
				<li>点击存储库工件(名为<code>_Learn_MLOps</code>)，如图<em class="italic">图 7.20 </em>所示，并启用(通过点击拨动开关)持续部署触发器。</li>
				<li>Add a branch filter by including the develop branch. This will trigger the pipeline to execute when changes or commits are made to the develop branch of the repository. For the test or staging stage, configure a Git trigger for the develop branch only (not the master or another branch). For production we can configure a Git trigger for the master branch. This way, we can separate the Git trigger branches for the test and production stages:<div><img src="img/B16572_07_20.jpg" alt="Figure 7.20 – Enabling a Git trigger for the test environment &#13;&#10;"/></div><p class="figure-caption">图 7.20–为测试环境启用 Git 触发器</p></li>
				<li>点击<a id="_idIndexMarker594"/>顶部的<strong class="bold">保存</strong>按钮，配置 Git 触发器。恭喜你！您已经成功地为您的测试环境设置了一个连续部署 Git 触发器。每当存储库的开发分支有变更时，管道将被触发，以在测试(<strong class="bold"> DEV TEST </strong>)环境中部署 web 服务。</li>
			</ol>
			<h1 id="_idParaDest-137"><a id="_idTextAnchor158"/>总结</h1>
			<p>在本章中，我们学习了 MLOps 中持续运营的关键原则，主要是持续集成、交付和部署。我们已经通过使用 Azure DevOps 执行设置 CI/CD 管道和测试环境的实际实现了解了这一点。我们测试了管道的执行健壮性，最后研究了一些触发器来增强管道的功能，并为测试环境设置了一个 Git 触发器。本章为 MLOps 中的持续运营奠定了基础，并为您提供了在任何给定的云场景中自动部署 ML 模型的技能，以及与您的业务相适应的持续学习能力。</p>
			<p>在下一章中，我们将探讨 API、微服务以及它们为基于 MLOps 的解决方案提供了什么。</p>
		</div>
	

</body></html>