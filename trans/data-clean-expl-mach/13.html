<html><head/><body>









<title>Section 4 – Modeling Dichotomous and Multiclass Targets with Supervised Learning</title>







<div><div><div/>

</div>

<div><h1 id="_idParaDest-126"><a id="_idTextAnchor125"/>第 4 节–用监督学习对二分目标和多类目标建模</h1>

<p>有许多高性能的算法用于预测分类目标。在这一部分，我们将研究最流行的分类算法。我们也将考虑为什么我们可能选择一个算法而不是其他任何算法，给定我们的数据和领域知识的属性。</p>

<p>我们关注分类模型的欠拟合和过拟合，就像我们在前一部分关注回归模型一样。当特征和目标之间的关系很复杂时，我们需要使用一种算法来捕捉这种复杂性。但是，过度拟合通常存在不小的风险。我们将在这一部分的章节中讨论不过度拟合的复杂性建模策略。这通常涉及逻辑回归模型的某种形式的正则化、决策树的树深度限制，以及使用支持向量分类调整边界违规的容限。</p>

<p>如果我们试图在不过度拟合的情况下模拟复杂性，我们必须准备好花费大量时间进行超参数调整。在这几章中，我们肯定会花相当多的时间在这上面。与此相关，我们也非常擅长交叉验证以及生成和解释评估指标。我们将在接下来的五章中的每一章讨论准确度、精密度、灵敏度和特异性。我们也会非常习惯于盯着一个混乱的矩阵。</p>

<p>我们还将研究如何将这些算法扩展到多类目标。这对于 k-最近邻和决策树是直接的，但是需要扩展到逻辑回归和支持向量回归的算法。我们在这几章里会讲到。</p>

<p>本节包括以下章节:</p>

<ul>

<li><a href="B17978_10_ePub.xhtml#_idTextAnchor126"> <em class="italic">第十章</em> </a>，<em class="italic">逻辑回归</em></li>

<li><a href="B17978_11_ePub.xhtml#_idTextAnchor135"> <em class="italic">第十一章</em></a><em class="italic">决策树和随机森林分类</em></li>

<li><a href="B17978_12_ePub.xhtml#_idTextAnchor144"> <em class="italic">第十二章</em> </a>，<em class="italic">K-最近邻分类</em></li>

<li><a href="B17978_13_ePub.xhtml#_idTextAnchor152"> <em class="italic">第十三章</em></a><em class="italic">支持向量机分类</em></li>

<li><a href="B17978_14_ePub.xhtml#_idTextAnchor162"> <em class="italic">第十四章</em> </a>，<em class="italic">朴素贝叶斯分类</em></li>

</ul>

</div>

<div><div/>

</div>

</div>



</body></html>