<title>Chapter 6: Preparing for Model Evaluation</title>

# *第六章*:模型评估准备

在开始运行模型之前，仔细考虑如何评估模型的性能是一个好主意。一种常见的技术是将数据分成训练数据集和测试数据集。我们在过程的相对早期这样做，以避免所谓的数据泄漏；也就是说，根据为模型评估而留出的数据进行分析。在本章中，我们将探讨创建训练数据集的方法，包括如何确保训练数据具有代表性。我们将研究交叉验证策略，例如 **K-fold** ，它解决了使用静态训练/测试分割的一些限制。我们也将开始更仔细地评估模型的性能。

你可能想知道为什么我们在详细讨论任何算法之前讨论模型评估。这是因为有实际的考虑。我们倾向于在具有相似目的的算法中使用相同的度量和评估技术。我们在评估分类模型时检查准确性和敏感性，在检查回归模型时检查平均绝对误差和 R 平方。我们对所有监督学习模型进行交叉验证。因此，我们将在接下来的章节中多次重复这里介绍的策略。当稍后重新介绍这些概念时，您甚至会发现自己又回到了这些页面。

除了这些实际的考虑之外，当我们不把数据提取、数据清理、探索性分析、特征工程和预处理、模型规范和模型评估看作是离散的、连续的任务时，我们的建模工作就会改进。如果你建立机器学习模型的时间只有 6 个月或超过 30 年，你可能会意识到这种严格的排序与我们作为数据科学家的工作流程不一致。我们总是在为模型验证做准备，并且总是在清理数据。这是好事。当我们整合这些任务时，我们做得更好；当我们在选择特征时继续询问我们的数据清理，当我们在计算精度或均方根误差后回头看二元相关性或散点图时。

我们还将花相当多的时间来构建这些概念的可视化。处理分类问题时，最好养成查看混淆矩阵和累积精度分布图的习惯，处理连续目标时，最好养成查看残差图的习惯。这也将在随后的章节中很好地为我们服务。

具体来说，在本章中，我们将讨论以下主题:

*   测量二元分类的准确度、灵敏度、特异性和精确度
*   检查二元分类的 CAP、ROC 和精度-灵敏度曲线
*   评估多类模型
*   评估回归模型
*   使用 K 倍交叉验证
*   用管道预处理数据

# 技术要求

在本章中，除了 scikit-learn 库之外，我们还将使用`feature_engine`和`matplotlib`库。你可以使用`pip`来安装这些软件包。本章的代码文件可以在本书的 GitHub 资源库中找到，网址是[https://GitHub . com/packt publishing/Data-Cleaning-and-Exploration-with-Machine-Learning](https://github.com/PacktPublishing/Data-Cleaning-and-Exploration-with-Machine-Learning)。

# 测量二元分类的准确度、灵敏度、特异性和精确度

当评估一个分类模型时，我们通常想知道我们正确的频率。在二元目标的情况下——目标有两个可能的分类值——我们计算**准确度**,作为我们预测正确分类的次数与观察总数的比率。

但是，取决于分类问题，准确性可能不是最重要的性能度量。也许我们愿意接受一个可以识别更多真阳性的模型的更多假阳性，即使这意味着更低的准确性。对于预测乳腺癌、安全漏洞或桥梁结构损坏可能性的模型来说，这可能是真的。在这些情况下，我们可能会强调**敏感性**(识别阳性病例的倾向)而非准确性。

另一方面，我们可能希望有一个模型能够高度可靠地识别阴性病例，即使这意味着它不能很好地识别阳性病例。**特异性**是由模型识别的所有阴性百分比的度量。

**精度**，即实际上是阳性的预测阳性的百分比，是另一个重要的衡量标准。对于某些应用，限制假阳性是很重要的，即使我们不得不容忍较低的灵敏度。苹果种植者使用图像识别来识别坏苹果，可能更喜欢高精度的模型而不是更灵敏的模型，不想不必要地丢弃苹果。

通过查看混淆矩阵,可以更清楚地了解这一点:

![Figure 6.1 – Confusion matrix

](img/B17978_06_001.jpg)

图 6.1-混淆矩阵

混淆矩阵帮助我们概念化准确性、敏感性、特异性和精确性。准确度是我们的预测正确的观测值的百分比。这可以更精确地表述如下:

![](img/B17978_06_0011.jpg)

灵敏度是我们正确预测阳性的次数除以阳性的次数。再次查看混淆矩阵并确认实际正值可以是**预测正值** ( **TP** )或**预测负值** ( **FN** )可能会有所帮助。灵敏度也称为**召回**或**真阳性率**:

![](img/B17978_06_002.jpg)

特异性是我们正确预测一个**负值** ( **TN** )的次数除以实际负值的次数( **TN + FP** )。特异性也被称为真阴性率**:**

**![](img/B17978_06_003.jpg)

精度是我们正确预测一个**正值** ( **TP** )的次数除以预测的正值次数:

![](img/B17978_06_004.jpg)

当存在类别不平衡时，诸如准确性和敏感性之类的度量可以给出我们模型的性能的非常不同的估计。一个极端的例子可以说明这一点。黑猩猩有时会在白蚁丘里放一根棍子，希望能抓到几只白蚁。这只是偶尔成功。我不是灵长类动物学家，但我们也许可以把一次成功的捕鱼尝试建模为所用棍子的大小、一年中的时间和黑猩猩的年龄的函数。在我们的测试数据中，钓鱼尝试的成功率只有 2%。(此数据为本次演示所补。)

让我们也说，我们建立了一个成功的白蚁钓鱼的分类模型，其灵敏度为 50%。因此，如果在我们的测试数据中有 100 次钓鱼尝试，我们只能正确预测两次成功尝试中的一次。还有一个假阳性，当打捞失败时，我们的模型预测成功打捞。这给了我们以下混淆矩阵:

![Figure 6.2 – Successful termite fishing confusion matrix

](img/B17978_06_0021.jpg)

图 6.2-成功的白蚁钓鱼混淆矩阵

请注意，我们获得了 98%的非常高的精度，即(97+1) / 100。我们得到高精度和低灵敏度，因为大部分的捕鱼尝试是负面的，这很容易预测。一个仅仅预测失败的模型也总是有 98%的准确率。

现在，让我们用真实数据来看看这些模型评估方法。我们可以用一个 **k 近邻** ( **KNN** )模型进行实验，以预测学士学位的获得程度，而则评估其准确性、敏感性、特异性和精确度:

1.  我们将首先加载用于编码和标准化数据的库，以及用于创建训练和测试数据帧的库。我们还将加载 scikit-learn 的 KNN 分类器和`metrics`库:

    ```
    import pandas as pd import numpy as np from feature_engine.encoding import OneHotEncoder from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from sklearn.neighbors import KNeighborsClassifier import sklearn.metrics as skmet import matplotlib.pyplot as plt
    ```

2.  现在，我们可以创建训练和测试数据帧，编码并缩放数据:

    ```
    nls97compba = pd.read_csv("data/nls97compba.csv") feature_cols = ['satverbal','satmath','gpaoverall',   'parentincome','gender'] X_train, X_test, y_train, y_test =  \   train_test_split(nls97compba[feature_cols],\   nls97compba[['completedba']], test_size=0.3, random_state=0) ohe = OneHotEncoder(drop_last=True, variables=['gender']) ohe.fit(X_train) X_train_enc, X_test_enc = \   ohe.transform(X_train), ohe.transform(X_test) scaler = StandardScaler() standcols = X_train_enc.iloc[:,:-1].columns scaler.fit(X_train_enc[standcols]) X_train_enc = \   pd.DataFrame(scaler.transform(X_train_enc[standcols]),   columns=standcols, index=X_train_enc.index).\   join(X_train_enc[['gender_Female']]) X_test_enc = \   pd.DataFrame(scaler.transform(X_test_enc[standcols]),   columns=standcols, index=X_test_enc.index).\   join(X_test_enc[['gender_Female']])
    ```

3.  让我们创建一个 KNN 分类模型。我们不会太担心我们如何指定它，因为我们只想在这一部分关注评估方法。我们将使用`feature_cols`中列出的所有特性，我们使用 KNN 分类器的预测方法从测试数据中生成预测:

    ```
    knn = KNeighborsClassifier(n_neighbors = 5) knn.fit(X_train_enc, y_train.values.ravel()) pred = knn.predict(X_test_enc)
    ```

4.  我们可以使用 scikit-learn 来绘制混淆矩阵。我们将把测试数据中的实际值(`y_test`)和预测值传递给`confusion_matrix`方法:

    ```
    cm = skmet.confusion_matrix(y_test, pred, labels=knn.classes_) cmplot = skmet.ConfusionMatrixDisplay(   confusion_matrix=cm,    display_labels=['Negative', 'Positive']) cmplot.plot() cmplot.ax_.set(title='Confusion Matrix',    xlabel='Predicted Value', ylabel='Actual Value')
    ```

这产生了下面的图:

![Figure 6.3 – Confusion matrix of actual and predicted values

](img/B17978_06_0031.jpg)

图 6.3–实际值和预测值的混淆矩阵

1.  我们可以也只是返回真阴性，假阳性，假阴性，真阳性计数:

    ```
    tn, fp, fn, tp = skmet.confusion_matrix(   y_test.values.ravel(), pred).ravel() tn, fp, fn, tp (53, 63, 31, 126)
    ```

2.  我们现在已经有了计算准确度、灵敏度、特异性和精确度所需的东西:

    ```
    accuracy = (tp + tn) / pred.shape[0] accuracy 0.6556776556776557 sensitivity = tp / (tp + fn) sensitivity 0.802547770700637 specificity = tn / (tn+fp) specificity 0.45689655172413796 precision = tp / (tp + fp) precision 0.6666666666666666
    ```

这个模型精度相对较低，但灵敏度稍好；也就是说，它在识别测试数据中已经完成学士学位的人方面做得比正确识别学位完成者和未完成者更好。如果我们回头看混淆矩阵，我们会看到有相当数量的假阳性，因为我们的模型预测测试数据中有 63 个人会有学士学位，而他们没有。

1.  我们也可以使用 scikit-learn 简便的方法直接生成这些统计数据:

    ```
    skmet.accuracy_score(y_test.values.ravel(), pred) 0.6556776556776557 skmet.recall_score(y_test.values.ravel(), pred) 0.802547770700637 skmet.precision_score(y_test.values.ravel(), pred) 0.6666666666666666
    ```

只是为了比较，让我们尝试一个随机森林分类器，看看我们是否能得到更好的结果。

1.  让我们将一个随机森林分类器与相同的数据相匹配，并再次调用`confusion_matrix`:

    ```
    rfc = RandomForestClassifier(n_estimators=100,    max_depth=2, n_jobs=-1, random_state=0) rfc.fit(X_train_enc, y_train.values.ravel()) pred = rfc.predict(X_test_enc) tn, fp, fn, tp = skmet.confusion_matrix(   y_test.values.ravel(), pred).ravel() tn, fp, fn, tp (49, 67, 17, 140) accuracy = (tp + tn) / pred.shape[0] accuracy 0.6923076923076923 sensitivity = tp / (tp + fn) sensitivity 0.89171974522293 specificity = tn / (tn+fp) specificity 0.4224137931034483 precision = tp / (tp + fp) precision 0.6763285024154589
    ```

与第一种模式相比，第二种模式让我们获得了更少的假阴性和更多的真阳性。当测试数据中的个人已经完成学士学位时，预测没有学士学位的可能性较小，而当个人已经完成学士学位时，预测学士学位的可能性较大。较低的 FP 和较高的 TP 的主要影响是显著较高的灵敏度。与第一个模型的 80%相比，第二个模型在 89%的时间里识别出实际阳性。

我们在本节中讨论的测量方法——准确度、灵敏度、特异性和精确度——在我们评估分类模型时都值得考虑。但是很难很好地理解我们有时面临的权衡，例如在精确度和灵敏度之间。在构建分类模型时，数据科学家依靠几种标准的可视化来提高我们对这些权衡的感觉。我们将在下一节研究这些可视化。

# 检查二元分类的 CAP、ROC 和精度-灵敏度曲线

有几种方法可以可视化二元分类模型的性能。一个相对直接的可视化是**累积准确度分布图** ( **CAP** )，它显示了我们的模型识别类内或阳性病例的能力。它在 *X* 轴上显示累积病例，在 *Y* 轴上显示累积阳性结果。帽曲线是一个很好的方法，可以看出我们的模型在区分课堂观察方面做得有多好。(在讨论二元分类模型时，我会互换使用术语*类内*和*正*。)

**接收器工作特性** ( **ROC** )曲线说明了当我们调整对正值进行分类的阈值时，模型灵敏度(能够识别正值)和假阳性率之间的权衡。类似地，当我们调整阈值时，精度-灵敏度曲线显示了我们正面预测的可靠性(它们的精度)和灵敏度(我们的模型识别正面实际值的能力)之间的关系。

## 构造帽曲线

让我们从学士学位完成 KNN 模型的 CAP 曲线开始。让我们将它与决策树模型进行比较。同样，我们在这里不会做太多的特性选择。前一章详细介绍了特性选择。

除了我们模型的曲线之外，CAP 曲线还有一个**随机模型**和一个**完美模型**的图，以供比较。随机模型除了正值的总体分布之外，不提供任何信息。完美模型精确预测正值。为了说明这些图是如何绘制的，我们将从一个假设的例子开始。想象一下，你抽取了一副洗得很好的扑克牌中的前六张。您创建一个表，在一列中显示累积牌总数，在下一列中显示红牌数。它可能看起来像这样:

![Figure 6.4 – Sample of playing cards 

](img/B17978_06_0041.jpg)

图 6.4–扑克牌样本

我们可以根据我们对红牌数量的了解来绘制一个随机模型。随机模型只有两个点，(0，0)和(6，3)，但这就是我们所需要的。

完美的模型图需要更多的解释。如果我们的模型完美地预测了红牌，并且我们按照预测降序排序，我们将得到*图 6.5* 。在红卡用完之前，累积的类别计数与牌的数量相匹配，在本例中为 3。使用完美的模型绘制的累计类内总数图有两个斜率；等于 1，直到达到类内总数，之后等于 0:

![Figure 6.5 – Sample of playing cards

](img/B17978_06_005.jpg)

图 6.5–扑克牌样本

我们现在已经知道足够绘制随机模型和完美模型。完美的模型会有三点:(0，0)，(类内计数，类内计数)，和(卡片数，类内计数)。在这种情况下，课堂计数为`3`，卡片数量为`6`:

```
numobs = 6
```

```
inclasscnt = 3
```

```
plt.yticks([1,2,3])
```

```
plt.plot([0, numobs], [0, inclasscnt], c = 'b', label = 'Random Model')
```

```
plt.plot([0, inclasscnt, numobs], [0, inclasscnt, inclasscnt], c = 'grey', linewidth = 2, label = 'Perfect Model')
```

```
plt.title("Cumulative Accuracy Profile")
```

```
plt.xlabel("Total Cards")
```

```
plt.ylabel("In-class (Red) Cards")
```

此产生以下情节:

![Figure 6.6 – CAP with playing card data

](img/B17978_06_006.jpg)

图 6.6–带有扑克牌数据的帽子

理解完美模型优于随机模型的一个方法是考虑随机模型在中点会预测多少张红牌，即 3 张。在这一点上，随机模型将预测 1.5 张红牌。然而，完美的模型会预测 3。(请记住，我们已经根据预测按降序对卡片进行了排序。)

已经用虚构的数据构建了随机和完美模型的图，让我们用我们的学士学位完成数据来尝试一下:

1.  首先，我们必须导入与上一节相同的模块:

    ```
    import pandas as pd import numpy as np from feature_engine.encoding import OneHotEncoder from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from sklearn.neighbors import KNeighborsClassifier from sklearn.ensemble import RandomForestClassifier import sklearn.metrics as skmet import matplotlib.pyplot as plt import seaborn as sb
    ```

2.  然后，我们加载、编码和缩放 NLS 学士学位数据:

    ```
    nls97compba = pd.read_csv("data/nls97compba.csv") feature_cols = ['satverbal','satmath','gpaoverall',   'parentincome','gender'] X_train, X_test, y_train, y_test =  \   train_test_split(nls97compba[feature_cols],\   nls97compba[['completedba']], test_size=0.3, random_state=0) ohe = OneHotEncoder(drop_last=True, variables=['gender']) ohe.fit(X_train) X_train_enc, X_test_enc = \   ohe.transform(X_train), ohe.transform(X_test) scaler = StandardScaler() standcols = X_train_enc.iloc[:,:-1].columns scaler.fit(X_train_enc[standcols]) X_train_enc = \   pd.DataFrame(scaler.transform(X_train_enc[standcols]),   columns=standcols, index=X_train_enc.index).\   join(X_train_enc[['gender_Female']]) X_test_enc = \   pd.DataFrame(scaler.transform(X_test_enc[standcols]),   columns=standcols, index=X_test_enc.index).\   join(X_test_enc[['gender_Female']])
    ```

3.  接下来，我们创建`KNeighborsClassifier`和`RandomForestClassifier`实例:

    ```
    knn = KNeighborsClassifier(n_neighbors = 5) rfc = RandomForestClassifier(n_estimators=100, max_depth=2,    n_jobs=-1, random_state=0)
    ```

我们现在准备开始绘制我们的帽曲线。我们将从绘制一个随机模型开始，然后是一个完美的模型。这两个模型分别不使用任何信息(除了正值的总体分布)和提供完美信息。

1.  我们统计测试数据中的观察值的数量和正值的数量。我们将使用(0，0)和(观察次数，课内计数)来绘制随机模型线。对于完美的模型，我们将绘制一条从(0，0)到(类内计数，类内计数)的线，因为该模型可以完美地区分类内值(它永远不会出错)。它在那个点的右边是平的，因为没有更多的正值可以寻找。

我们将在中点画一条垂直线，在与随机模型线相交的地方画一条水平线。这在以后会更有用:

```
numobs = y_test.shape[0]
inclasscnt = y_test.iloc[:,0].sum()
plt.plot([0, numobs], [0, inclasscnt], c = 'b', label = 'Random Model')
plt.plot([0, inclasscnt, numobs], [0, inclasscnt, inclasscnt], c = 'grey', linewidth = 2, label = 'Perfect Model')
plt.axvline(numobs/2, color='black', linestyle='dashed', linewidth=1)
plt.axhline(numobs/2, color='black', linestyle='dashed', linewidth=1)
plt.title("Cumulative Accuracy Profile")
plt.xlabel("Total Observations")
plt.ylabel("In-class Observations")
plt.legend()
```

这会产生以下情节:

![Figure 6.7 – CAP with just random and perfect models

](img/B17978_06_007.jpg)

图 6.7–仅随机和完美模型的 CAP

1.  接下来，我们定义一个函数，为我们传递给它的模型绘制一个 CAP 曲线。我们将使用`predict_proba`方法得到一个数组，其概率为测试数据中的每个观察值都是在班的(在本例中，已经完成了学士学位)。然后，我们将创建一个包含这些概率和实际目标值的数据框架，按概率逆序排序，并计算正实际目标值的累计值。

我们还将获得中间观察点的累计值，并在该点画一条水平线。最后，我们将绘制一条线，该线有一个从 0 到观察次数的数组作为 *x* 值，运行的类内总数作为 *y* 值:

```
def addplot(model, X, Xtest, y, modelname, linecolor):
  model.fit(X, y.values.ravel())
  probs = model.predict_proba(Xtest)[:, 1]

  probdf = pd.DataFrame(zip(probs, y_test.values.ravel()),
    columns=(['prob','inclass']))
  probdf.loc[-1] = [0,0]
  probdf = probdf.sort_values(['prob','inclass'],
    ascending=False).\
    assign(inclasscum = lambda x: x.inclass.cumsum())
  inclassmidpoint = \
    probdf.iloc[int(probdf.shape[0]/2)].inclasscum
  plt.axhline(inclassmidpoint, color=linecolor,
    linestyle='dashed', linewidth=1)
  plt.plot(np.arange(0, probdf.shape[0]),
    probdf.inclasscum, c = linecolor,
    label = modelname, linewidth = 4)
```

1.  现在，让我们使用相同的数据运行 KNN 和随机森林分类器模型的函数:

    ```
    addplot(knn, X_train_enc, X_test_enc, y_train,   'KNN', 'red') addplot(rfc, X_train_enc, X_test_enc, y_train,   'Random Forest', 'green') plt.legend()
    ```

这更新了我们之前的情节:

![Figure 6.8 – CAP updated with KNN and random forest models

](img/B17978_06_008.jpg)

图 6.8–用 KNN 和随机森林模型更新的 CAP

不出所料，CAP 曲线显示我们的 KNN 和随机森林模型比随机猜测要好，但不如完美模型好。问题是，分别好多少和差多少。水平线给了我们一些概念。一个完美的模型应该从 138 个观察值中正确识别出 138 个正值。(回想一下，观察值是这样排序的，即最有可能为正的观察值排在最前面。)随机模型将识别 70(线未示出)，而 KNN 和随机森林模型将分别识别 102 和 103。我们的两个模型在辨别正值方面分别是完美模型的 74%和 75%。70%到 80%之间的任何东西都被认为是好的模型；高于这一比例就很好，低于这一比例就很差。

## 绘制受试者工作特性(ROC)曲线

ROC 曲线说明了调整阈值时假阳性率和真阳性率(也称为灵敏度)之间的权衡。在进一步讨论之前，我们应该讨论一下假阳性率。它是我们的模型错误地识别为阳性的实际阴性(真阴性加上假阳性)的百分比:

![](img/B17978_06_0051.jpg)

在这里，您可以看到假阳性率与特异性之间的关系，这在本章开始时已经讨论过。差就是分子。特异性是我们的模型正确识别为阴性的实际阴性的百分比:

![](img/B17978_06_0061.jpg)

我们还可以将假阳性率与灵敏度进行比较，灵敏度是我们的模型正确识别为阳性的实际阳性(真阳性加上假阴性)的百分比:

![](img/B17978_06_0071.jpg)

我们通常面临灵敏度和假阳性率之间的权衡。我们希望我们的模型能够识别大部分的实际阳性，但我们不希望有问题的高假阳性率。什么是*高*取决于你的背景。

区分阴性和阳性病例越困难，灵敏度和假阳性率之间的权衡就越棘手。当我们绘制预测概率时，我们可以通过我们的学士学位完成模型看到这一点:

1.  首先，让我们再次拟合我们的随机森林分类器，并生成预测和预测概率。我们会看到，这个模型在预测概率大于`0.500` :

    ```
    rfc.fit(X_train_enc, y_train.values.ravel()) pred = rfc.predict(X_test_enc) pred_probs = rfc.predict_proba(X_test_enc)[:, 1] probdf = pd.DataFrame(zip(   pred_probs, pred, y_test.values.ravel()),   columns=(['prob','pred','actual'])) probdf.groupby(['pred'])['prob'].agg(['min','max'])                 min             max pred              0.000           0.305           0.500 1.000           0.502           0.883
    ```

    时，预测这个人完成学士学位
2.  将这些概率的分布与实际的类值进行比较是有帮助的。我们可以用密度图做到这一点:

    ```
    sb.kdeplot(probdf.loc[probdf.actual==1].prob,    shade=True, color='red',   label="Completed BA") sb.kdeplot(probdf.loc[probdf.actual==0].prob,     shade=True, color='green',   label="Did Not Complete") plt.axvline(0.5, color='black', linestyle='dashed', linewidth=1) plt.axvline(0.65, color='black', linestyle='dashed', linewidth=1) plt.title("Predicted Probability Distribution") plt.legend(loc="upper left")
    ```

此产生以下图形:

![Figure 6.9 – Density plot of in-class and out-of-class observations

](img/B17978_06_009.jpg)

图 6.9–课内和课外观察的密度图

在这里，我们可以看到，我们的模型在区分实际的正值和负值方面有些困难，因为有相当多的类内和类外重叠。阈值 0.500(左侧虚线)会给我们带来很多假阳性，因为很大一部分课外观察(那些没有完成学士学位的人)预测的概率大于 0.500。如果我们将阈值移得更高，比如 0.650，我们会得到更多的假阴性，因为许多类内观察的概率低于 0.65。

1.  根据测试数据和随机森林模型很容易构建 ROC 曲线。`roc_curve`方法返回不同阈值(`ths`)下的假阳性率(`fpr`)和灵敏度(真阳性率，`tpr`)。

首先，让我们按阈值分别画出假阳性率和灵敏度线:

```
fpr, tpr, ths = skmet.roc_curve(y_test, pred_probs)
ths = ths[1:]
fpr = fpr[1:]
tpr = tpr[1:]
fig, ax = plt.subplots()
ax.plot(ths, fpr, label="False Positive Rate")
ax.plot(ths, tpr, label="Sensitivity")
ax.set_title('False Positive Rate and Sensitivity by Threshold')
ax.set_xlabel('Threshold')
ax.set_ylabel('False Positive Rate and Sensitivity')
ax.legend()
```

这会产生以下情节:

![Figure 6.10 – False positive rate and sensitivity lines

](img/B17978_06_010.jpg)

图 6.10-假阳性率和灵敏度线

在这里，我们可以看到，提高阈值会提高(降低)我们的假阳性率，但也会降低我们的灵敏度。

1.  现在，让我们绘制相关的 ROC 曲线，该曲线绘制了每个阈值的假阳性率与灵敏度的关系:

    ```
    fig, ax = plt.subplots() ax.plot(fpr, tpr, linewidth=4, color="black") ax.set_title('ROC curve') ax.set_xlabel('False Positive Rate') ax.set_ylabel('Sensitivity')
    ```

这会产生以下情节:

![Figure 6.11 – ROC curve with false positive rate and sensitivity

](img/B17978_06_011.jpg)

图 6.11–假阳性率和灵敏度的 ROC 曲线

ROC 曲线表明假阳性率和灵敏度之间的权衡非常陡峭，直到假阳性率大约为 0.5 或更高。让我们看看用于随机森林模型预测的阈值 0.5 意味着什么。

1.  让我们从阈值数组中选择一个接近 0.5 的指数，以及一个接近 0.4 和 0.6 的指数进行比较。然后，我们将为这些指标的假阳性率画垂直线，为这些指标的敏感度值画水平线:

    ```
    tholdind = np.where((ths>0.499) & (ths<0.501))[0][0] tholdindlow = np.where((ths>0.397) & (ths<0.404))[0][0] tholdindhigh = np.where((ths>0.599) & (ths<0.601))[0][0] plt.vlines((fpr[tholdindlow],fpr[tholdind],   fpr[tholdindhigh]), 0, 1, linestyles ="dashed",    colors =["green","blue","purple"]) plt.hlines((tpr[tholdindlow],tpr[tholdind],   tpr[tholdindhigh]), 0, 1, linestyles ="dashed",    colors =["green","blue","purple"])
    ```

本更新我们的剧情:

![Figure 6.12 – ROC curve with lines for thresholds

](img/B17978_06_012.jpg)

图 6.12–阈值的 ROC 曲线

这说明了在用于预测的 0.5 阈值(蓝色虚线)下假阳性率和灵敏度之间的权衡。ROC 曲线在阈值高于 0.5 时具有非常小的斜率，例如阈值为 0.6 时(绿色虚线)。因此，将阈值从 0.6 降低到 0.5 会导致较低的假阳性率(从 0.8 以上降低到 0.6 以下)，但灵敏度不会降低太多。然而，通过将阈值从 0.5 降低到 0.4(从蓝色到紫色线)来提高(降低)假阳性率会导致灵敏度显著变差。它从将近 90%下降到刚刚超过 70%。

## 绘制精度-灵敏度曲线

调整阈值时，检查精度和灵敏度之间的关系通常很有帮助。请记住，精度告诉我们，当我们预测一个正值时，我们的正确率是多少:

![](img/B17978_06_0081.jpg)

我们可以通过增加将一个值分类为正数的阈值来提高精度。然而，这可能意味着灵敏度的降低。当我们提高预测正值的正确率(精确度)时，我们将减少能够识别的正值的数量(敏感度)。精确度-灵敏度曲线，通常称为精确度-召回曲线，说明了这种权衡。

在绘制精度-灵敏度曲线之前，让我们来看看相对于阈值绘制的单独的精度和灵敏度曲线:

1.  我们可以用`precision_recall_curve`方法得到精度-灵敏度曲线的点。我们在最高阈值时移除一些不可思议，这有时会发生:

    ```
    prec, sens, ths = skmet.precision_recall_curve(y_test, pred_probs) prec = prec[1:-10] sens = sens[1:-10] ths  = ths[:-10] fig, ax = plt.subplots() ax.plot(ths, prec, label='Precision') ax.plot(ths, sens, label='Sensitivity') ax.set_title('Precision and Sensitivity by Threshold') ax.set_xlabel('Threshold') ax.set_ylabel('Precision and Sensitivity') ax.set_xlim(0.3,0.9) ax.legend()
    ```

这会产生以下情节:

![Figure 6.13 – Precision and sensitivity lines

](img/B17978_06_013.jpg)

图 6.13-精度和灵敏度线

这里，我们可以看到，阈值高于 0.5 时，灵敏度下降得更快。这种下降并没有给我们带来超过 0.6 阈值的更高精度。

1.  现在，让我们绘制灵敏度与精度的关系图，以查看精度-灵敏度曲线:

    ```
    fig, ax = plt.subplots() ax.plot(sens, prec) ax.set_title('Precision-Sensitivity Curve') ax.set_xlabel('Sensitivity') ax.set_ylabel('Precision') plt.yticks(np.arange(0.2, 0.9, 0.2))
    ```

这会产生以下情节:

![Figure 6.14 – Precision-sensitivity curve

](img/B17978_06_014.jpg)

图 6.14-精度-灵敏度曲线

精度-灵敏度曲线反映了这样一个事实，即灵敏度对阈值的响应比该特定模型的精度更敏感。这意味着我们可以将阈值降低到 0.5 以下，以获得更高的灵敏度，而不会显著降低精度。

注意

阈值的选择在一定程度上是一个判断和领域知识的问题，并且主要是当我们有显著的阶级不平衡时的一个问题。但是，在第十章[](B17978_10_ePub.xhtml#_idTextAnchor126)**、逻辑回归*中我们将探讨如何计算一个最优阈值。*

 *这一节以及上一节演示了如何评估二元分类模型。他们表明，模型评估不仅仅是一个竖起大拇指和竖起大拇指的过程。这更像是在做蛋糕时品尝面糊。我们对我们的模型规范做出良好的初始假设，并使用模型评估过程进行改进。这通常涉及准确性、敏感性、特异性和精确性之间的权衡，以及抵制一刀切建议的建模决策。这些决定在很大程度上依赖于领域，是专业判断的问题。

本节中的讨论以及大多数技术同样适用于多类建模。我们将在下一节讨论评估多类模型。

# 评估多类模型

我们用来评估二元分类模型的所有相同的原则适用于多类模型评估。计算混淆矩阵同样重要，尽管解释起来要困难一些。我们还需要检查一些竞争性的度量标准，比如精度和灵敏度。这也比用二元分类法更混乱。

我们将再次使用 NLS 学位完成数据。在这种情况下，我们将改变目标，从是否完成学士学位改为完成高中学业、完成学士学位和完成研究生学位:

1.  我们将从加载必要的库开始。这些是我们在前两节中使用的相同的库:

    ```
    import pandas as pd import numpy as np from feature_engine.encoding import OneHotEncoder from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from sklearn.neighbors import KNeighborsClassifier import sklearn.metrics as skmet import matplotlib.pyplot as plt
    ```

2.  接下来，我们将加载 NLS 学位程度数据，创建培训和测试数据框架，并对数据进行编码和缩放:

    ```
    nls97degreelevel = pd.read_csv("data/nls97degreelevel.csv") feature_cols = ['satverbal','satmath','gpaoverall',   'parentincome','gender'] X_train, X_test, y_train, y_test =  \   train_test_split(nls97degreelevel[feature_cols],\   nls97degreelevel[['degreelevel']], test_size=0.3, random_state=0) ohe = OneHotEncoder(drop_last=True, variables=['gender']) ohe.fit(X_train) X_train_enc, X_test_enc = \   ohe.transform(X_train), ohe.transform(X_test) scaler = StandardScaler() standcols = X_train_enc.iloc[:,:-1].columns scaler.fit(X_train_enc[standcols]) X_train_enc = \   pd.DataFrame(scaler.transform(X_train_enc[standcols]),   columns=standcols, index=X_train_enc.index).\   join(X_train_enc[['gender_Female']]) X_test_enc = \   pd.DataFrame(scaler.transform(X_test_enc[standcols]),   columns=standcols, index=X_test_enc.index).\   join(X_test_enc[['gender_Female']])
    ```

3.  现在，我们将运行一个 KNN 模型，并预测每个学位级别类别的值:

    ```
    knn = KNeighborsClassifier(n_neighbors = 5) knn.fit(X_train_enc, y_train.values.ravel()) pred = knn.predict(X_test_enc) pred_probs = knn.predict_proba(X_test_enc)[:, 1]
    ```

4.  我们可以使用这些预测来生成一个混淆矩阵:

    ```
    cm = skmet.confusion_matrix(y_test, pred) cmplot = skmet.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['High School', 'Bachelor','Post-Graduate']) cmplot.plot() cmplot.ax_.set(title='Confusion Matrix',    xlabel='Predicted Value', ylabel='Actual Value')
    ```

这会生成以下图:

![Figure 6.15 – Confusion matrix with a multiclass target

](img/B17978_06_015.jpg)

图 6.15-多类目标的混淆矩阵

可以手动计算评估指标。精度是我们的类内预测实际类内的百分比。所以，对于我们预测的高中，是 48 / (48 + 38 + 8) = 0.51。高中班级的敏感度——即我们的模型预测的高中实际值的百分比——为 48 / (48 + 19 +5) = 0.67。然而，这相当繁琐。幸运的是，scikit-learn 可以为我们做到这一点。

1.  我们可以调用`classification_report`方法来获得这些统计数据，传递实际值和预测值(记住，召回和敏感度是相同的度量):

    ```
    print(skmet.classification_report(y_test, pred,   target_names=['High School', 'Bachelor', 'Post-Graduate']))                precision    recall  f1-score   support   High School       0.51      0.67      0.58        72      Bachelor       0.51      0.49      0.50        92 Post-Graduate       0.42      0.24      0.30        42      accuracy                           0.50       206     macro avg       0.48      0.46      0.46       206  weighted avg       0.49      0.50      0.49       206
    ```

除了按类别划分的精度和灵敏度比率之外，我们还获得了一些其他统计数据。F1 分数是精确度和灵敏度的调和平均值。

![](img/B17978_06_0091.jpg)

这里， *p* 是精度， *s* 是灵敏度。

要获得所有类别的平均精度、敏感度和 F1 值，我们可以使用简单平均值(宏观平均值)或根据类别大小调整的加权平均值。使用加权平均值，我们得到的精确度、灵敏度和 F1 值分别为 0.49、0.50 和 0.49。(由于这里班级相对均衡，所以宏观平均和加权平均没有太大区别。)

这演示了如何将我们讨论的二元分类模型的评估方法扩展到多类评估。同样的概念和技术也适用，尽管它们更难实现。

到目前为止，我们已经关注了度量和可视化来帮助我们评估分类模型。我们还没有检查评估回归模型的度量标准。这些指标可能比分类指标更直接。我们将在下一节讨论它们。

# 评估回归模型

回归评估的指标通常基于目标变量的实际值和模型预测值之间的距离。最常见的衡量标准——均方误差、均方根误差、平均绝对误差和 R 平方——都是跟踪我们的预测如何成功地捕捉目标中的变化。

实际值和我们的预测之间的距离被称为残差，或误差。**均方误差** ( **MSE** )是残差平方的平均值:

![](img/B17978_06_0101.jpg)

这里，![](img/B17978_06_011.png)是第 I 次观察时的实际目标变量值，![](img/B17978_06_012.png)是我们对目标的预测。残差被平方以处理负值，其中预测值高于实际值。为了让我们的测量回到一个更有意义的范围，我们经常使用 MSE 的平方根。那就是被称为**均方根误差** ( **RMSE** )。

由于平方，MSE 对较大残差的惩罚要比较小残差大得多。例如，如果我们有五个观测值的预测，其中一个具有 25 的残差，而其他四个具有 0 的残差，我们将得到 *(0+0+0+0+625)/5 = 125* 。然而，如果所有五个观测值的残差都为 5，则 MSE 将为 *(25+25+25+25+25)/5 = 25* 。

对残差求平方的一个好的替代方法是取它们的绝对值。这给出了平均绝对误差:

![](img/B17978_06_0131.jpg)

r 平方，也称为决定系数，是我们的模型捕获的目标变量的变化比例的估计值。我们对残差求平方，就像计算 MSE 时所做的那样，然后除以每个实际目标值与其样本均值的偏差。这给了我们仍然无法解释的变化，我们减去 1 得到解释的变化:

![](img/B17978_06_0141.jpg)![](img/B17978_06_0151.jpg)

幸运的是，scikit-learn 使得生成这些统计数据变得很容易。在本节中，我们将构建一个土地温度的线性回归模型，并使用这些统计数据对其进行评估。我们将在 2019 年使用美国国家海洋和大气管理局关于气象站年平均温度、海拔和纬度的数据。

注意

陆地温度数据集包含 2019 年全球 12，000 多个站点的平均温度读数(摄氏度)，尽管大多数站点位于美国。原始数据来自全球历史气候学网络综合数据库。美国国家海洋和大气管理局已在[网站 https://www . ncdc . NOAA . gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4)上公开使用。

让我们开始建立一个线性回归模型:

1.  We will start by loading the libraries we need and the land temperatures data. We will also create training and testing DataFrames:

    ```
    import pandas as pd
    import numpy as np
    from sklearn.model_selection import train_test_split
    from sklearn.linear_model import LinearRegression
    import sklearn.metrics as skmet
    import matplotlib.pyplot as plt
    landtemps = pd.read_csv("data/landtemps2019avgs.csv")
    feature_cols = ['latabs','elevation']
    X_train, X_test, y_train, y_test =  \
      train_test_split(landtemps[feature_cols],\
      landtemps[['avgtemp']], test_size=0.3, random_state=0)
    ```

    注意

    `latabs`特征是没有南北指示器的纬度值；因此，位于北纬 30 度的埃及开罗和南纬 30 度的巴西阿雷格里港具有相同的数值。

2.  现在，我们扩展我们的数据:

    ```
    scaler = StandardScaler() scaler.fit(X_train) X_train = \   pd.DataFrame(scaler.transform(X_train),   columns=feature_cols, index=X_train.index) X_test = \   pd.DataFrame(scaler.transform(X_test),   columns=feature_cols, index=X_test.index) scaler.fit(y_train) y_train, y_test = \   pd.DataFrame(scaler.transform(y_train),   columns=['avgtemp'], index=y_train.index),\   pd.DataFrame(scaler.transform(y_test),   columns=['avgtemp'], index=y_test.index)
    ```

3.  接下来，我们实例化一个 scikit-learn `LinearRegression`对象，并在训练数据上拟合一个模型。我们的目标是年平均温度(`avgtemp`)，而特征是纬度(`latabs`)和`elevation`。`coef_`属性给出了每个特性的系数:

    ```
    lr = LinearRegression() lr.fit(X_train, y_train) np.column_stack((lr.coef_.ravel(),   X_test.columns.values)) array([[-0.8538957537748768, 'latabs'],        [-0.3058979822791853, 'elevation']], dtype=object)
    ```

`latabs`系数的解释是纬度每增加一个标准差，标准化年平均温度将下降 0.85。(`LinearRegression`模块不返回 p 值，p 值是系数估计值的统计显著性的度量。您可以使用`statsmodels`来查看普通最小二乘模型的完整摘要。)

1.  现在，我们可以得到预测值。让我们将返回的 NumPy 数组与测试数据中的特性和目标连接起来。然后，我们可以通过从实际值中减去预测值来计算残差(`avgtemp`)。残差看起来并不差，尽管有一点负偏斜和过度峰度:

    ```
    pred = lr.predict(X_test) preddf = pd.DataFrame(pred, columns=['prediction'],   index=X_test.index).join(X_test).join(y_test) preddf['resid'] = preddf.avgtemp-preddf.prediction preddf.resid.agg(['mean','median','skew','kurtosis']) mean             -0.021 median           0.032 skew              -0.641 kurtosis        6.816 Name: resid, dtype: float64
    ```

值得注意的是，在本书中，我们在使用回归模型的大部分时间里都会以这种方式生成预测和计算残差。如果您对我们刚刚在前面的代码块中所做的事情有一点不清楚，那么最好再看一遍。

1.  我们应该绘制残差图，以便更好地了解它们是如何分布的。

    ```
    Plt.hist(preddf.resid, color="blue") plt.axvline(preddf.resid.mean(), color='red', linestyle='dashed', linewidth=1) plt.title("Histogram of Residuals for Temperature Model") plt.xlabel("Residuals") plt.ylabel("Frequency")
    ```

这会产生以下情节:

![Figure 6.16 – Histogram of residuals for the linear regression model

](img/B17978_06_016.jpg)

图 6.16–线性回归模型的残差直方图

这看起来并不太糟糕，但是我们有更多的正残差，我们在测试数据中预测的温度比实际温度低，而不是负残差。

1.  用残差来绘制我们的预测可能会让我们更好地理解正在发生的事情:

    ```
    plt.scatter(preddf.prediction, preddf.resid, color="blue") plt.axhline(0, color='red', linestyle='dashed', linewidth=1) plt.title("Scatterplot of Predictions and Residuals") plt.xlabel("Predicted Temperature") plt.ylabel("Residuals")
    ```

这会产生以下情节:

![Figure 6.17 – Scatterplot of predictions by residuals for the linear regression model

](img/B17978_06_017.jpg)

图 6.17–线性回归模型残差预测散点图

这看起来并不可怕。残差在 0 附近随机浮动。但是，1 到 2 个标准差之间的预测值更有可能过低(没有正残差)而不是过高。高于 2，预测总是太高(它们有负残差)。这个模型的线性假设可能不合理。我们应该探索一下我们在第四章*中讨论过的几个变换，编码、变换和缩放特性*，或者尝试一个非参数模型，比如 KNN 回归。

极值也有可能将我们的系数拉得相当大。一个好的下一步可能是移除异常值，正如我们在第 1 章[](B17978_01_ePub.xhtml#_idTextAnchor014)*、*检查特性和目标的分布*的*识别极值和异常值*部分中所讨论的。然而，我们不会在这里这样做。*

 *1.  再来看一些评价措施。这可以通过 scikit-learn 的`metrics`库轻松完成。我们可以调用相同的函数来获得 RMSE 作为 MSE。我们只需要将平方参数设置为`False` :

    ```
    mse = skmet.mean_squared_error(y_test, pred) mse 0.18906346144036693 rmse = skmet.mean_squared_error(y_test, pred, squared=False) rmse 0.4348142838504353 mae = skmet.mean_absolute_error(y_test, pred) mae 0.318307379728143 r2 = skmet.r2_score(y_test, pred) r2 0.8162525715296725
    ```

小于标准偏差 0.2 的 MSE 和小于 0 的 MAE。3 的标准差看起来相当不错，尤其是对于这样一个稀疏的模型。超过 80%的 R 平方也相当有希望。

1.  让我们看看如果我们使用 KNN 模型，我们会得到什么:

    ```
    knn = KNeighborsRegressor(n_neighbors=5) knn.fit(X_train, y_train) pred = knn.predict(X_test) mae = skmet.mean_absolute_error(y_test, pred) mae 0.2501829988751876 r2 = skmet.r2_score(y_test, pred) r2 0.8631113217183314
    ```

这个模型实际上是对 MAE 和 R 平方的改进。

1.  我们还应该再看一看残差:

    ```
    preddf = pd.DataFrame(pred, columns=['prediction'],   index=X_test.index).join(X_test).join(y_test) preddf['resid'] = preddf.avgtemp-preddf.prediction plt.scatter(preddf.prediction, preddf.resid, color="blue") plt.axhline(0, color='red', linestyle='dashed', linewidth=1) plt.title("Scatterplot of Predictions and Residuals with KNN Model") plt.xlabel("Predicted Temperature") plt.ylabel("Residuals") plt.show()
    ```

这产生了下面的情节:

![Figure 6.18 – Scatterplot of predictions by residuals for the KNN model

](img/B17978_06_018.jpg)

图 6.18–KNN 模型残差预测散点图

这张残差图看起来也更好。在目标的分布中，没有我们更容易高估或低估的部分。

本节介绍了评估回归模型的关键方法，以及如何解释它们。它还展示了可视化，尤其是模型残差，如何能够改善这种解释。

然而，到目前为止，我们在使用回归和分类方法时，受到了我们如何构建训练和测试数据框架的限制。如果出于某种原因，测试数据在某些方面不寻常，该怎么办？更一般地说，我们得出我们的评估方法是准确的结论的依据是什么？如果我们使用 K-fold 交叉验证，我们会对这些方法更有信心，这将在下一节中介绍。

# 使用 K 倍交叉验证

到目前为止，我们已经保留了 30%的数据进行验证。这是一个不错的策略。它阻止我们在训练模型时提前查看测试数据。然而，这种方法没有充分利用所有可用的数据，无论是用于训练还是用于测试。如果我们使用 K-fold 交叉验证，我们可以使用我们所有的数据，同时也避免数据泄漏。也许这看起来好得不像是真的。但这并不是因为一个巧妙的小技巧。

**K 折叠交叉验证**训练我们的模型，除了一个 K 折叠或部分，留下一个用于测试。这被重复 *k* 次，每次排除不同的折叠进行测试。然后，性能指标基于 K 倍的平均分数。

不过，在开始之前，我们需要再次考虑数据泄露的可能性。如果我们将用于训练模型的所有数据进行缩放，然后将其拆分成多个折叠，我们将在训练中使用来自所有折叠的信息。为了避免这种情况，我们需要对每次迭代的训练折叠进行缩放以及任何其他预处理。虽然我们可以手动完成这项工作，但 scikit-learn 的`pipeline`库可以为我们完成大部分工作。在这一节中，我们将讨论如何使用管道进行交叉验证。

让我们尝试使用 K-fold 交叉验证来评估我们在上一节中指定的两个模型。当我们这样做的时候，让我们看看随机森林回归器的工作效果如何:

1.  除了我们到目前为止使用过的库，我们还需要 scikit-learn 的*`make_pipeline``cross_validate`和`Kfold`库:

    ```
    import pandas as pd from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from sklearn.linear_model import LinearRegression from sklearn.neighbors import KNeighborsRegressor from sklearn.ensemble import RandomForestRegressor from sklearn.pipeline import make_pipeline from sklearn.model_selection import cross_validate from sklearn.model_selection import KFold
    ``` 
**   我们再次加载陆地温度数据，并创建训练和测试数据框架。我们仍然想留下一些数据进行最终验证，但是这一次，我们将只留下 10%。我们将用剩下的 90%进行培训和测试:

    ```
    landtemps = pd.read_csv("data/landtemps2019avgs.csv") feature_cols = ['latabs','elevation'] X_train, X_test, y_train, y_test =  \   train_test_split(landtemps[feature_cols],\   landtemps[['avgtemp']],test_size=0.1,random_state=0)
    ```

    *   现在，我们创建一个`KFold`对象，并指出我们想要五个折叠，并对数据进行洗牌(如果数据还没有被随机排序，洗牌是一个好主意):

    ```
    kf = Kfold(n_splits=5, shuffle=True, random_state=0)
    ```

    *   接下来，我们定义一个函数来创建管道。然后，该函数运行`cross_validate`，它接受管道和我们之前创建的`KFold`对象:

    ```
    def getscores(model):   pipeline = make_pipeline(StandardScaler(), model)   scores = cross_validate(pipeline, X=X_train,      y=y_train, cv=kf, scoring=['r2'], n_jobs=1)   scorelist.append(dict(model=str(model),     fit_time=scores['fit_time'].mean(),     r2=scores['test_r2'].mean()))
    ```

    *   现在，我们准备好为线性回归、随机森林回归和 KNN 回归模型调用`getscores`函数:

    ```
    scorelist = [] getscores(LinearRegression()) getscores(RandomForestRegressor(max_depth=2)) getscores(KNeighborsRegressor(n_neighbors=5))
    ```

    *   我们可以打印`scorelist`列表来查看我们的结果:

    ```
    scorelist [{'model': 'LinearRegression()',   'fit_time': 0.004968833923339844,   'r2': 0.8181125031214872},  {'model': 'RandomForestRegressor(max_depth=2)',   'fit_time': 0.28124608993530276,   'r2': 0.7122492698889024},  {'model': 'KNeighborsRegressor()',   'fit_time': 0.006945991516113281,   'r2': 0.8686733636724104}]
    ``` 

 *基于 R 平方，KNN 回归模型比线性回归或随机森林回归模型表现更好。随机森林回归器也有一个明显的缺点，即它的拟合时间要长得多。

# 用管道预处理数据

在上一节中，我们仅仅触及了 scikit-learn 管道的皮毛。我们经常需要将所有的预处理和特征工程整合到一个管道中，包括缩放、编码和处理异常值和缺失值。这可能很复杂，因为不同的功能可能需要不同的处理方式。我们可能需要估算带有数字特征的缺失值的中值和分类特征的最常见值。我们可能还需要转换我们的目标变量。我们将在本节中探讨如何做到这一点。

请遵循以下步骤:

1.  我们将从载入本章中已经使用过的库开始。然后，我们将添加`ColumnTransformer`和`TransformedTargetRegressor`类。我们将分别使用这些类来转换我们的特性和目标:

    ```
    import pandas as pd import numpy as np from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from sklearn.linear_model import LinearRegression from sklearn.impute import SimpleImputer from sklearn.pipeline import make_pipeline from feature_engine.encoding import OneHotEncoder from sklearn.impute import KNNImputer from sklearn.model_selection import cross_validate, KFold import sklearn.metrics as skmet from sklearn.compose import ColumnTransformer from sklearn.compose import TransformedTargetRegressor
    ```

2.  列转换器非常灵活。我们甚至可以将它与我们自己定义的预处理函数一起使用。下面的代码块从`helperfunctions`子文件夹中的`preprocfunc`模块导入类`OutlierTrans`
3.  `OutlierTrans`类通过与四分位数范围的距离识别极值。这是我们在 [*第 3 章*](B17978_03_ePub.xhtml#_idTextAnchor034) 、*中演示的识别和修复缺失值*的技术。

为了在 scikit-learn 管道中工作，我们的类必须有 fit 和 transform 方法。我们还需要继承`BaseEstimator`和`TransformerMixin`类。

在这个类中，几乎所有的动作都发生在`transform`方法中。任何大于第三个四分位数以上或第一个四分位数以下的四分位数范围的 1.5 倍的值都被指定为缺失值:

```
class OutlierTrans(BaseEstimator,TransformerMixin):
  def __init__(self,threshold=1.5):
    self.threshold = threshold

  def fit(self,X,y=None):
    return self

  def transform(self,X,y=None):
    Xnew = X.copy()
    for col in Xnew.columns:
      thirdq, firstq = Xnew[col].quantile(0.75),\
        Xnew[col].quantile(0.25)
      inlierrange = self.threshold*(thirdq-firstq)
      outlierhigh, outlierlow = inlierrange+thirdq,\
        firstq-inlierrange
      Xnew.loc[(Xnew[col]>outlierhigh) | \
        (Xnew[col]<outlierlow),col] = np.nan
    return Xnew.values                                 
```

我们的`OutlierTrans`类稍后可以在我们的管道中使用，就像我们在上一节中使用`StandardScaler`一样。我们以后再做。

1.  现在，我们准备加载需要处理的数据。在这一部分，我们将使用 NLS 每周工资数据。周薪将是我们的目标，我们将使用高中 GPA、母亲和父亲完成的最高年级、父母收入、性别以及个人是否完成学士学位作为特征。

我们将在这里创建以不同方式处理的特性列表。稍后，当我们指示管道对数字、分类和二元特征执行不同的操作时，这将很有帮助:

```
nls97wages = pd.read_csv("data/nls97wagesb.csv")
nls97wages.set_index("personid", inplace=True)
nls97wages.dropna(subset=['wageincome'], inplace=True)
nls97wages.loc[nls97wages.motherhighgrade==95,
  'motherhighgrade'] = np.nan
nls97wages.loc[nls97wages.fatherhighgrade==95,
  'fatherhighgrade'] = np.nan
num_cols = ['gpascience','gpaenglish','gpamath','gpaoverall',
  'motherhighgrade','fatherhighgrade','parentincome']
cat_cols = ['gender']
bin_cols = ['completedba']
target = nls97wages[['wageincome']]
features = nls97wages[num_cols + cat_cols + bin_cols]
X_train, X_test, y_train, y_test =  \
  train_test_split(features,\
  target, test_size=0.2, random_state=0)
```

1.  让我们看看一些描述性的统计数据。一些变量有一千多个缺失值(`gpascience`、`gpaenglish`、`gpamath`、`gpaoverall`和`parentincome` ):

    ```
    nls97wages[['wageincome'] + num_cols].agg(['count','min','median','max']).T                  count    min      median    max wageincome       5,091    0        40,000    235,884 gpascience       3,521    0        284       424 gpaenglish       3,558    0        288       418 gpamath          3,549    0        280       419 gpaoverall       3,653    42       292       411 motherhighgrade  4,734    1        12        20 fatherhighgrade  4,173    1        12        29 parentincome     3,803   -48,100   40,045    246,474
    ```

2.  现在，我们可以设置一个列转换器。首先，我们将创建处理数字数据(`standtrans`)、分类数据和二进制数据的管道。

对于数值数据，我们希望将异常值指定为缺失值。这里，我们将把一个值`2`传递给阈值参数`OutlierTrans`，表示我们希望高于或低于四分位数范围两倍的值被设置为缺失。回想一下，默认值是 1.5，所以我们稍微保守一些。

然后，我们将创建一个`ColumnTransformer`对象，将我们刚刚创建的三个管道传递给它，并指示哪个管道使用哪个特性:

```
standtrans = make_pipeline(OutlierTrans(2),
  StandardScaler())
cattrans = make_pipeline(SimpleImputer(strategy="most_frequent"),
  OneHotEncoder(drop_last=True))
bintrans = make_pipeline(SimpleImputer(strategy="most_frequent"))
coltrans = ColumnTransformer(
  transformers=[
    ("stand", standtrans, num_cols),
    ("cat", cattrans, ['gender']),
    ("bin", bintrans, ['completedba'])
  ]
)
```

1.  现在，我们可以将 column transformer 添加到一个管道中，该管道也包含我们想要运行的线性模型。我们将在管道中添加 KNN 插补，以处理缺失值。

我们还需要扩展目标，这在我们的管道中是做不到的。为此，我们将使用 scikit-learn 的`TransformedTargetRegressor`。我们将把刚刚创建的管道传递给目标回归器的`regressor`参数:

```
lr = LinearRegression()
pipe1 = make_pipeline(coltrans,
  KNNImputer(n_neighbors=5), lr)
ttr=TransformedTargetRegressor(regressor=pipe1,
  transformer=StandardScaler())
```

1.  让我们使用这个管道进行 K-fold 交叉验证。我们可以通过目标回归器`ttr`将我们的管道传递给`cross_validate`函数:

    ```
    kf = KFold(n_splits=10, shuffle=True, random_state=0) scores = cross_validate(ttr, X=X_train, y=y_train,   cv=kf, scoring=('r2', 'neg_mean_absolute_error'),   n_jobs=1) print("Mean Absolute Error: %.2f, R-squared: %.2f" %    (scores['test_neg_mean_absolute_error'].mean(),   scores['test_r2'].mean())) Mean Absolute Error: -23781.32, R-squared: 0.20
    ```

这些分数不是很好，尽管这并不是这次练习的重点。这里关键的一点是，我们通常希望将我们要做的大部分预处理放在一个管道中。这是避免数据泄露的最佳方式。列转换器是一个非常灵活的工具，允许我们对不同的特性应用不同的转换。

# 总结

本章介绍了关键的模型评估方法和技术，这样当我们在本书的剩余章节中广泛使用和扩展它们时，它们就会变得熟悉。我们研究了分类和回归模型的非常不同的评估方法。我们还探索了如何使用可视化来改善我们的预测分析。最后，我们使用管道和交叉验证来获得模型性能的可靠估计。

我希望这一章也给了你一个机会去习惯这本书前进的一般方法。尽管大量的算法将在后面的章节中讨论，我们将继续讨论前几章中讨论过的预处理问题。当然，我们将讨论每个算法的核心概念。但是，在真正的*动手*方式中，我们也将处理现实世界数据的混乱。每章将从相对原始的数据到特征工程，再到模型规范和模型评估，严重依赖 scikit-learn 的管道将所有内容整合在一起。

我们将在接下来的几章中讨论回归算法——那些允许我们对连续目标建模的算法。我们将探讨一些最流行的回归算法——线性回归、支持向量回归、K 近邻回归和决策树回归。我们还将考虑对回归模型进行修改，解决欠拟合和过拟合问题，包括非线性变换和正则化。*****