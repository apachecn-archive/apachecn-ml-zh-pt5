<html><head/><body>









<title>Section 5 – Clustering and Dimensionality Reduction with Unsupervised Learning</title>







<div><div><div/>

</div>

<div><h1 id="_idParaDest-167"><a id="_idTextAnchor169"/>第 5 节–利用无监督学习进行聚类和降维</h1>

<p>这本书的最后两章考察了无监督学习模型。这些都是没有预测目标的模型。即使没有目标，也可以从我们的数据中收集到许多见解。主成分分析(PCA)的降维允许我们用比原始数量的特征更少的成分来捕获我们的特征的方差。</p>

<p>用 PCA 创建的组件可用于可视化，或识别重要的但不能被每个特性很好地捕获的过程。当我们需要在监督学习模型中减少特征空间时，也可以使用 PCA。我们将在下一章演示如何创建和评估 PCA。</p>

<p>聚类有助于我们将实例按彼此之间比任何其他组中有更多共同点的实例进行分组。这通常揭示了原本不明显的关系。在这一章中，我们来看看两种流行的聚类算法，K-means 和 DBSCAN。当我们能够为我们的模型找到正确的超参数值时，集群工作得很好——k-means 的集群数量(k ),以及 DBSCAN 的 epsilon 值，它决定了集群中核心实例周围的半径大小。在本书的最后一章，我们将讨论如何为这些聚类算法选择最佳的超参数值。</p>

<p>本节包括以下章节:</p>

<ul>

<li><a href="B17978_15_ePub.xhtml#_idTextAnchor170"> <em class="italic">第十五章</em> </a>，<em class="italic">主成分分析</em></li>

<li><a href="B17978_16_ePub.xhtml#_idTextAnchor177"> <em class="italic">第十六章</em> </a>，<em class="italic"> K-Means 和 DBSCAN 聚类</em></li>

</ul>

</div>

<div><div/>

</div>

</div>



</body></html>