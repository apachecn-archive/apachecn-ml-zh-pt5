

# 零、前言

研究人员为分析准备数据所做的工作——提取、转换、清理和探索——并没有随着机器学习工具的日益普及而发生根本变化。30 年前，当我们为多变量分析准备数据时，我们非常关心缺失值、异常值、变量的分布形状以及变量之间的相关性，就像我们现在使用机器学习算法一样。虽然对机器学习(scikit-learn、TensorFlow、PyTorch 等)的相同库的广泛使用确实鼓励了方法的更大一致性，但是良好的数据清理和探索实践在很大程度上没有改变。

我们谈论机器学习的方式仍然非常侧重于算法；只要选择正确的模式，改变组织的洞察力就会随之而来。但是我们必须为我们在过去几十年中从数据中进行的同类学习腾出空间，我们从数据中做出的预测，我们对数据中关系的建模，以及我们对数据的清理和探索都是对话的重要部分。让我们的模型变得正确，既要从直方图或混淆矩阵中收集尽可能多的信息，也要仔细调整超参数。

类似地，数据分析师和科学家所做的工作从清理、探索、预处理、建模到评估并没有整齐地进行。在这个过程的每一步，我们都有潜在的模型，定期更新我们以前的模型。例如，我们最初可能会认为我们将使用逻辑回归来模拟一个特定的二元目标，但当我们看到特征的分布时，就会意识到我们可能至少需要尝试使用随机森林分类。我们将在本文中讨论建模的含义，即使是在解释相对常规的数据清理任务时。我们还将探索在过程的早期使用机器学习工具来帮助我们识别异常、估算值和选择特征。

这指出了过去十年数据分析师和科学家工作流程的另一个变化——不那么强调“一个模型”,更接受将模型构建作为一个迭代过程。一个项目可能需要多种机器学习算法——例如，主成分分析来降低维度(特征的数量)，然后逻辑回归进行分类。

尽管如此，随着机器学习工具指导我们更多的工作，我们在数据清理、探索和建模方面的方法有一个关键差异——更加强调预测，而不是理解底层数据。我们更关心我们的特征(也称为自变量、输入或预测值)对我们的目标(因变量、输出、响应)的预测程度，而不是特征和数据的底层结构之间的关系。我在本书的前两个部分指出了这是如何在某种程度上改变我们的焦点的，即使是在我们清理和探索数据的时候。

# 这本书是给谁的

在我写这本书的时候，我想到了很多读者，但我最常想到的是我的一个好朋友，她在 30 年前买了一本 Transact-SQL 书，并立即对她的数据库工作产生了极大的信心，最终围绕这些技能建立了职业生涯。如果有人刚开始作为数据科学家或分析师的职业生涯，就读过这本书，并有和我朋友相似的经历，我会很高兴。最重要的是，我想让你对阅读这本书的结果感到高兴和兴奋。

我也希望这本书对那些已经做了一段时间这类工作的人来说是一个有用的参考。在这里，我想象有人打开书，问自己，*在我的逻辑回归模型的网格搜索中，有什么好的值可以使用？*

为了与本书的实践性质保持一致，本书中的每一点输出都可以用代码再现。我也始终坚持一条规则，即使它很有挑战性。除了概念部分之外，每一部分都从原始数据开始，基本上与原始下载文件相同。在每一部分中，您都要从数据文件到模型。如果你忘记了一个特定的对象是如何被创建的，你只需要向后翻一两页就可以了。

对 pandas 和 NumPy 有所了解的读者会更容易理解一些代码块，对 Python 和 scikit-learn 有所了解的人也是如此。不过，这些都不是必需的。只是有些部分你可能想暂停更长时间。如果你需要额外的使用 Python 做数据工作的指导，我的 *Python 数据清理食谱*是一本我认为很好的伴侣书。

# 这本书涵盖了什么

[*第 1 章*](B17978_01_ePub.xhtml#_idTextAnchor014) ，*检查特性和目标的分布*，探索使用常见的 NumPy 和 pandas 技术来更好地理解我们的数据的属性。我们将生成汇总统计数据，如`mean`、`min`、`max`，以及标准差，并统计缺失数。我们还将创建关键特性的可视化，包括直方图和箱线图，以便让我们更好地了解每个特性的分布情况，而不仅仅是查看汇总统计数据。我们将暗示特征分布对数据转换、编码和缩放的影响，以及我们将在后续章节中使用相同数据进行的建模。

[*第二章*](B17978_02_ePub.xhtml#_idTextAnchor025) ，*考察特征与目标之间的二元和多元关系*，重点在于可能的特征与目标变量之间的相关性。我们将使用 pandas 方法进行双变量分析，使用 Matplotlib 进行可视化。我们将讨论我们的发现对特征工程和建模的影响。在本章中，我们还使用多元技术来理解特征之间的关系。

[*第 3 章*](B17978_03_ePub.xhtml#_idTextAnchor034) ，*识别和修复缺失值*，介绍了识别每个特性或目标的缺失值的技术，以及识别大量特性值缺失的观察值的技术。我们将探索估算值的策略，例如将值设置为总体平均值、给定类别的平均值或向前填充。我们也将检验多变量技术来估算缺失值，并讨论它们何时是合适的。

[*第四章*](B17978_04_ePub.xhtml#_idTextAnchor043) 、*编码、变换和缩放特征*，涵盖了一系列特征工程技术。我们将使用工具删除冗余或高度相关的功能。我们将探索最常见的编码方式——一键编码、顺序编码和散列编码。我们还将使用变换来改善我们的特征的分布。最后，我们将使用常见的宁滨和缩放方法来处理偏斜、峰度和异常值，并调整范围差异很大的特征。

[*第 5 章*](B17978_05_ePub.xhtml#_idTextAnchor058) ，*特性选择*将介绍许多特性选择方法，从过滤器、包装器到嵌入式方法。我们将探索它们如何与明确的和连续的目标一起工作。对于包装器和嵌入式方法，我们考虑它们在不同算法中的表现。

[*第 6 章*](B17978_06_ePub.xhtml#_idTextAnchor078) ，*准备模型评估*，将看到我们构建第一个成熟的管道，将我们的数据分成测试和训练数据集，并学习如何在不泄漏数据的情况下进行预处理。我们将使用 k-fold 实现交叉验证，并更仔细地评估我们模型的性能。

[*第 7 章*](B17978_07_ePub.xhtml#_idTextAnchor091) ，*线性回归模型*，是构建回归模型的几个章节中的第一章，这是许多数据科学家的老最爱，线性回归。我们将运行一个经典的线性模型，同时也检查使其成为线性模型的良好候选的特征空间的质量。我们将探索如何在必要时通过正则化和变换来改进线性模型。我们将研究随机梯度下降作为普通最小二乘优化的替代方法。我们还将学习如何使用网格搜索进行超参数调整。

[*第 8 章*](B17978_08_ePub.xhtml#_idTextAnchor106) ，*支持向量回归*，讨论关键的支持向量机概念，以及它们如何应用于回归问题。具体而言，我们将考察 epsilon 不敏感管和软余量等概念如何给我们带来灵活性，以获得可能的最佳拟合，从而应对我们的数据和领域相关挑战。我们还将探索，第一次，但肯定不是最后一次，非常方便的内核技巧，它允许我们在没有转换或增加特征数量的情况下建模非线性关系。

[*第九章*](B17978_09_ePub.xhtml#_idTextAnchor113) 、 *K 近邻、决策树、随机森林、梯度提升回归*，探讨了一些最流行的非参数回归算法。我们将讨论每种算法的优点，当您可能想要选择一种而不是另一种时，以及可能的建模挑战。这些挑战包括如何通过仔细调整超参数来避免欠拟合和过拟合。

[*第 10 章*](B17978_10_ePub.xhtml#_idTextAnchor126) ，*逻辑回归*，是关于用逻辑回归建立分类模型的几章中的第一章，逻辑回归是一种低偏差的高效算法。我们将仔细检查逻辑回归的假设，并讨论使逻辑回归成为一个好选择的数据集属性和建模问题。我们将使用正则化来处理高方差或当我们有许多高度相关的预测值时。我们将用多项式逻辑回归将算法扩展到多类问题。我们也将讨论如何处理第一次，而不是最后一次的阶级不平衡。

[*第十一章*](B17978_11_ePub.xhtml#_idTextAnchor135) 、*决策树和随机森林分类*，返回到 [*第九章*](B17978_09_ePub.xhtml#_idTextAnchor113) 、*K-最近邻、决策树、随机森林和梯度提升回归*中介绍的决策树和随机森林算法，这次处理分类问题。这给了我们另一个学习如何构造和解释决策树的机会。我们将调整关键的超参数，包括树的深度，以避免过度拟合。然后，我们将探索随机森林和梯度提升决策树作为决策树的良好、较低方差的替代方案。

[*第十二章*](B17978_12_ePub.xhtml#_idTextAnchor144) ， *K 近邻分类*，返回 **k 近邻** ( **KNNs** )处理二元和多类建模问题。我们将讨论并展示 KNN 的优势——构建一个简单的模型是多么容易，以及需要调整的超参数数量是多么有限。到本章结束时，我们将知道这两个——如何做 KNN，以及什么时候我们应该考虑它为我们的建模。

[*第十三章*](B17978_13_ePub.xhtml#_idTextAnchor152) ，*支持向量机分类*，探讨实现**支持向量分类** ( **SVC** )的不同策略。我们将使用线性 SVC，当我们的类是线性可分的时，它可以很好地执行。然后我们将研究如何使用内核技巧将 SVC 扩展到类不是线性可分的情况。最后，我们将使用一对一和一对多分类来处理具有两个以上值的目标。

[*第 14 章*](B17978_14_ePub.xhtml#_idTextAnchor162) ，*朴素贝叶斯分类*，在本章中讨论了朴素贝叶斯的基本假设，以及如何使用该算法来解决我们已经探索过的一些建模挑战，以及一些新的挑战，如文本分类。我们将考虑什么时候朴素贝叶斯是一个好的选择，什么时候不是。我们也将检验朴素贝叶斯模型的解释。

[*第十五章*](B17978_15_ePub.xhtml#_idTextAnchor170) ，*主成分分析*，考察**主成分分析** ( **PCA** )，包括它是如何工作的，以及我们什么时候可能要用到它。我们将学习如何解释 PCA 产生的成分，包括每个特征对每个成分的贡献以及解释了多少差异。我们将学习如何可视化组件，以及如何在后续分析中使用组件。我们还将研究如何使用内核进行 PCA，以及什么时候这可能会给我们带来更好的结果。

[*第 16 章*](B17978_16_ePub.xhtml#_idTextAnchor177) ， *K-Means 和 DBSCAN 聚类*，探讨了两种流行的聚类技术，K-Means 和**基于密度的空间聚类应用与噪声** ( **DBSCAN** )。我们将讨论每种方法的优势，并了解何时选择一种聚类算法。我们还将学习如何评估我们的聚类，以及如何改变超参数来改进我们的模型。

# 为了充分利用这本书

要运行本书中的代码，您需要安装 Python 的科学发行版，比如 Anaconda。所有代码都用 scikit-learn 版本 0.24.2 和 1.0.2 进行了测试。

# 下载示例代码文件

你可以从 GitHub 的 https://GitHub . com/packt publishing/Data-Cleaning-and-Exploration-with-Machine-Learning 下载本书的示例代码文件。如果代码有更新，它会在 GitHub 库中更新。

我们在[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)也有来自我们丰富的书籍和视频目录的其他代码包。看看他们！

# 下载彩色图像

我们还提供了一个 PDF 文件，其中有本书中使用的截图和图表的彩色图像。你可以在这里下载:[https://packt.link/aLE6J](https://packt.link/aLE6J)。

# 使用的约定

本书通篇使用了许多文本约定。

`Code in text`:表示文本中的码字、数据库表名、文件夹名、文件名、文件扩展名、路径名、伪 URL、用户输入和 Twitter 句柄。这里有一个例子:“出于学习目的，我们在 GitHub 存储库中的`chapter08`文件夹下提供了两个示例`mlruns`工件和`huggingface`缓存文件夹。”

代码块设置如下:

```
client = boto3.client('sagemaker-runtime') 
```

```
response = client.invoke_endpoint(
```

```
        EndpointName=app_name, 
```

```
        ContentType=content_type,
```

```
        Accept=accept,
```

```
        Body=payload
```

```
        )
```

当我们希望将您的注意力吸引到代码块的特定部分时，相关的行或项目以粗体显示:

```
loaded_model = mlflow.pyfunc.spark_udf(
```

```
    spark,
```

```
    model_uri=logged_model, 
```

```
    result_type=StringType())
```

任何命令行输入或输出都按如下方式编写:

```
mlflow models serve -m models:/inference_pipeline_model/6
```

**粗体**:表示新术语、重要单词或您在屏幕上看到的单词。例如，菜单或对话框中的单词以**粗体**显示。下面是一个例子:“要执行该单元格中的代码，您只需点击右上角下拉菜单中的**运行单元格**。”

提示或重要注意事项

像这样出现。

# 取得联系

我们随时欢迎读者的反馈。

`customercare@packtpub.com`并在邮件主题中提及书名。

**勘误表**:虽然我们已经尽力确保内容的准确性，但错误还是会发生。如果你在这本书里发现了一个错误，请告诉我们，我们将不胜感激。请参观 www.packtpub.com/support/errata 并填写表格。

`copyright@packt.com`用链接指向素材。

如果你有兴趣成为一名作家:如果有一个你擅长的主题，并且你有兴趣写一本书或者为一本书投稿，请访问 authors.packtpub.com。

# 分享你的想法

一旦您阅读了*使用机器学习进行数据清理和探索*，我们很想听听您的想法！请点击此处，直接进入该书的亚马逊评论页面，并分享您的反馈。

您的评论对我们和技术社区非常重要，将有助于我们确保提供高质量的内容。