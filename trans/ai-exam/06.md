

# 六、使用谷歌翻译创新人工智能

在这一章中，我们将说明如何通过谷歌翻译来创新现有的人工智能。首先，我们将从理解发明、创新、颠覆、高价产品和革命之间的区别开始，以及我们如何才能对人工智能创新产生影响。

有时，开发人员会将发明与创新混淆，导致关键人工智能项目的重大失败。一些人工智能设计师认为革命意味着颠覆，导致早期销售，然后一无所有。

一旦我们定义了创新的关键概念，我们将使用谷歌翻译来理解围绕**自然语言处理** ( **NLP** )的语言学原则。

谷歌翻译于 2006 年进入市场，并于 2016 年通过神经网络进行了增强，但尽管如此，它仍然经常产生糟糕的答案。这是好消息还是坏消息？我们将在一个 Python 程序中实现 Google 的 API，以找出如何发现从一种语言到另一种语言的错误翻译。

一旦我们发现了谷歌翻译的局限性，我们将最终发现如何通过自己的适应来超越这些局限性，方法是在一个 Python 程序中探索谷歌的 API，添加一个**k-nearest neighbors**(**KNN**)算法，并统计测量结果。

与媒体炒作相反，人工智能刚刚开始创新人类流程。还有大量的工作要做。要取得进步，每个人都必须参与进来，这一点我们将在本章讨论。即使 Google、Amazon、Microsoft、IBM 和其他公司提供了一个解决方案，这并不意味着它不能由第三方作为现有解决方案的附件或新的独立产品来改进。毕竟，一旦福特在一百多年前发明了 T 型车，这并不妨碍开发更好的汽车。相反，看看你的周围！

为了利用人工智能的冒险，我们将从理解人工智能的中断到谷歌翻译，然后创新。

本章将涵盖以下主题:

*   在开始实施谷歌翻译之前，理解人工智能创新的关键概念
*   发明和创新的区别
*   革命性和颠覆性人工智能的区别
*   用 Python 实现 Google 翻译 API
*   引入语言学作为构建任何自然语言处理算法的先决条件
*   KNN 算法
*   如何用 Python 中的 KNN 定制谷歌翻译

我们将从探索人工智能创新和颠覆的关键概念开始。

本章中所有的 Python 程序和文件都可以在[https://github . com/packt publishing/Artificial-Intelligence-By-Example-Second-Edition/tree/master/CH06](https://github.com/PacktPublishing/Artificial-Intelligence-By-Example-Second-Edition/tree/master/CH0)中找到。

还有一个名为`COLAB_Translate.ipynb`的 Jupyter 笔记本，它包含了一次运行中的所有 Python 程序。你可以使用你的谷歌账户:[https://colab.research.google.com/](https://colab.research.google.com/)直接上传到谷歌合作实验室。

# 理解人工智能中的创新和颠覆

开始一个项目时，我们必须问自己的第一个问题，比如一个翻译解决方案是找到我们的定位。我们要做的是发明还是创新？我们的工作是颠覆性的还是革命性的？我们将在本章中探讨这些概念，以便在进一步深入之前理解广泛的实用主义图景。

## AI 具有颠覆性吗？

“颠覆性”这个词更多的是而不是不与人工智能联系在一起。媒体炒作告诉我们，人工智能机器人将很快在世界各地取代人类。尽管媒体的大肆宣传使得获得人工智能预算变得更加容易，但如果我们想要实现人工智能解决方案，我们需要知道我们的立场。如果我们想创新，我们需要找到前沿，并从那里建立新的想法。

为什么不直接使用工具，看看会发生什么？这是一个好主意还是一个冒险的主意？与拥有巨额预算的公司不同，一个人的资源是有限的。如果你花时间在错误的方向上学习，你将需要几个月的时间在另一个更好的方向上积累足够的经验来达到你的目标。例如，假设您在对大量数据进行分类时遇到困难，正如我们在第 4 章、*中探讨的那样，使用 K 均值聚类*优化您的解决方案。你会在你公司的一个项目上花上几个月，然后失败。这可能会让你丢掉工作。相反，如果你找到了正确的模型，并了解了关键概念，你的项目可以在几天内起飞。

在开始一个项目之前，先找出我们在创新和颠覆方面的位置。这在项目开始时似乎并不重要，但在生产和销售阶段却意义重大。本节将阐明这些概念。

天底下没有什么是新的——即使是在考虑人工智能的时候。大多数人工智能理论和数学工具已经存在了几十年，如果不是几百年的话。我们常常倾向于认为，既然某样东西对我们来说是新的，那它就是刚刚被发明或发现的。这个错误在许多项目中可能是致命的。如果你知道一个理论或功能已经存在了几十年或几个世纪，你可以做一些深入的研究，并使用 100 多年前发现的解决方案来解决你现在的问题。如果你这样做了，你将会使用已经被证明是可靠的方程式来节省大量的时间。如果你不这样做，你可能会浪费宝贵的时间去重新发明现有的方程式。

找出哪些是新的，哪些不是，将对你的个人或专业人工智能项目产生重大影响。

### 人工智能基于数学理论，这并不新鲜

人工智能理论目前严重依赖应用数学。在*第 1 章*、*通过强化学习*开始下一代人工智能、**马尔可夫决策过程** ( **MDP** )、一种**强化学习** ( **RL** )方法中进行了描述。Google 已经在 AlphaGo Zero 中成功将 RL 与神经网络结合。

安德烈·马尔科夫是出生于 1856 年的俄罗斯数学家，他发明了 MDP。例如，他成功地将该算法应用于给定语言的单词序列中的字母预测。理查德·贝尔曼在 1957 年出版了 MDP 的增强版。

贝尔曼还创造了表达式“维数灾难”，并出版了关于今天在人工智能中广泛使用的数学工具的书籍。现在众所周知，可以执行维度减少以避免在算法中面对成千上万的维度(例如，特征)。

逻辑函数(参见*第 2 章*、*构建奖励矩阵——设计你的数据集*)可以追溯到比利时数学家皮埃尔·弗朗索瓦·维赫斯特(Pierre Franç ois Verhulst，1844-1845)。逻辑函数使用自然对数底数 *e* ，也称为欧拉数。莱昂哈德·欧拉(1707-1783)是瑞士数学家，从事自然对数的研究。

托马斯·贝叶斯(1701-1761)发明了以他的名字命名的定理:贝叶斯定理。在 AI 中应用广泛。我们将在第 7 章、*用朴素贝叶斯优化区块链*中用到它。

人工智能、机器学习、深度学习中几乎所有应用的数学都可以追溯到 17 世纪到 20 世纪的数学家。我们必须到别处寻找 21 世纪的人工智能创新。我们需要找到人工智能中真正新的东西，这也是帮助它在 21 世纪初如此迅速扩张的原因。

### 神经网络并不新鲜

当代专家描述的神经网络可以追溯到 20 世纪 40 年代和 50 年代。甚至**卷积神经网络**(**CNN**)都可以追溯到 20 世纪。法国计算机科学家 Yann LeCun 在 20 世纪 80 年代奠定了 CNN 的基础(参见*第 9 章*、*卷积神经网络(CNN)*的抽象图像分类)；他在 20 世纪 90 年代成功地应用了我们今天所知道的这些方法。

我们必须再次在别处寻找 21 世纪的人工智能创新。

如果神经网络也不是新的，我们必须在我们的环境中找到真正的新因素，这些因素产生了当今人工智能的成功。

## 关注颠覆——使人工智能具有颠覆性的因素

虽然人工智能的基础早在计算机存在或普及之前就已经存在，但只是在最近，我们才看到人工智能真正开始在我们的社会中引起波澜。在接下来的章节中，我们将看看近年来让人工智能成为强大颠覆力量的因素。

### 21 世纪初的云服务器能力、数据量和网络共享

理解是什么推动了近年来人工智能的出现是很重要的。

数据量推动了 21 世纪人工智能的出现。如果没有人工智能推动整个计算机科学市场，处理数据、分类数据以及做出预测和决策将是不可能的。

如果你把围绕人工智能的幻想抛在脑后，并记住人工智能的这一关键必要性，你将完全理解为什么人工智能会出现并留在这里。

人工智能创新性破坏的第一个迹象出现在 2000 年到 2010 年之间。在那之前，互联网存在，服务器也存在。但是，从 2005 年左右开始，云服务器被广泛使用。有了这种计算能力，世界各地的开发人员可以尝试使用机器学习和深度学习所需的高度贪婪的资源。他们最终可以使用人工智能解决否则不可能解决的大数据问题。

与此同时，随着功能强大的服务器的出现，互联网提供了人类历史上最大的知识库。

最重要的是，社交网络变得广泛使用。分享发现和源代码变得很平常。万维网(WWW)鼓励开源软件，促进了当地的研究和开发。

从 21 世纪第一个十年中期开始，人工智能时代对当地专家来说成为可能。

今天，使人工智能作为一种创新出现的是更强大的机器和智力资源的可用性的结合。

### 公众意识

在 1995 年到 2005 年的云架构革命之后的几年里，公众对人工智能的认识仍然很模糊。

到 2015 年左右，当我们都意识到人工智能可以大规模取代人类并以人类历史上从未见过的水平创造就业机会时，人工智能给我们带来了沉重的打击。

更糟糕的是，我们意识到机器可以在我们引以为豪的领域打败我们，比如国际象棋(*第三章*、*机器智能——评估函数和数值收敛*)、围棋和视频游戏。我们看到越来越多的制造业工作由机器人完成，办公室工作由机器人完成，以及每天都在出现的更多领域。

人类历史上第一次，人类物种可以被一个新的“物种”超越:智能机器人。作为开发人员，我们认为我们是安全的，直到谷歌提出了 AutoML，这是一个可以比人类更好地创建机器学习解决方案的解决方案。与此同时，现成的机器学习平台已经普及，可以减少甚至取代人工智能软件开发。

人工智能既让人敬畏又让人害怕。机器会走多远？我们会简单地经历工作置换，还是会发展到物种更替？

这对许多人来说是一个机会吗？谁知道呢？无论如何，这一章提供了一些指导，帮助你以一种驱动你不断创新和有用的方式思考。在大数据时代，我们经常面对庞大的数据集，人工智能将会一直存在；没有它我们将无法应付。让我们充分利用它吧！

在我们开始研究人工智能提供的令人难以置信的机会之前，让我们在脑海中澄清一下到底有什么区别，首先是*发明*和*创新*，然后是*革命*与*颠覆*。理解我们正在开发和实施的东西将对人工智能市场产生的影响是很重要的。

## 发明与创新

一些人工智能程序，特别是深度学习算法，仍然是发明而不是创新，直到谷歌和其他主要参与者大规模使用它们。

如果你在某些应用上发明了比谷歌更好的算法，它仍然是一项发明，直到它真正改变你的公司或网络上的某些东西。

假设你通过优化数量的神经元和新的激活函数找到了一种更快的识别图像的方法。如果没有人使用它，那么无论它看起来有多好，这项发明仍然是个人的理论发现。

当别人开始使用这种新算法的时候，那么它就变成了一种创新。只有当一项发明改变了公司内部的流程或被足够多的私人用户使用时，它才成为创新。

## 革命性与颠覆性解决方案

假设一种新的图像识别算法成为一家重要公司的创新。这个新算法已经从一个**发明**(没有被使用)变成了一个**创新**(一个有所作为的解决方案)。

该公司现在广泛使用这种算法。每个子公司都可以使用它。对于这家公司来说，新的图像识别算法已经取得了革命性的地位。公司销售额上升了，利润率也上升了。

但也许这家公司并没有主导市场，也没有人效仿它。这项创新仍然是革命性的，但还没有成为颠覆性的。

那么，假设创造算法的人决定离职，带着算法创业。它作为开源程序出现在 GitHub 上。每个人都想要它，并且下载的数量每天都在增加，直到 100 多万用户开始实施它。公司网站上提供一些价格非常低廉的附加产品。一年之内，它成为一种新的识别图像的方式。所有公司都必须效仿，否则就会落后。这个解决方案已经变得具有破坏性，因为它在全球范围内改变了市场。

## 从哪里开始？

我们现在已经探索了创造人工智能的基本概念。使用谷歌翻译的翻译项目的第一步是尽可能使用谷歌的 API 来实现算法。正如我们将在下一节看到的，我们将探索谷歌翻译的局限性。一旦找到了极限，当我们使用人工智能定制谷歌翻译时，创造力就会爆发。

我们会发现，即使解决方案存在，它也有局限性，可以改进、定制、打包和出售。*有限制就有行情*。

永远不要批评你在一个人工智能解决方案中发现的缺陷；它们是金矿！

*哪里有限制，哪里就有机会*。

让我们用谷歌翻译来说明这一点，让我们走到前沿，然后越过边界进入未知的领域。

# 使用谷歌翻译发现充满机遇的世界

从开始，Google Translate 探索 NLP 是准备在 web 解决方案中使用 NLP 的好方法。任何颠覆性的基于网络的解决方案都必须能够运行在至少几种语言中。你需要掌握几种语言的 NLP 来实现聊天机器人、翻译解决方案和在线信息网站，如维基百科。

谷歌提供了许多资源来使用、探索或改进谷歌翻译。让 Python 代码运行起来，然后评估结果的质量，这在公司实施重要的翻译之前是至关重要的。让我们运行谷歌翻译。

## 入门指南

Google 的开发者 API 客户端库页面如下:[https://developers.google.com/api-client-library/](https://developers.google.com/api-client-library/)。在这个页面上，你会看到许多语言的库:Java、PHP、.NET，JavaScript，Objective-C，Dart，Ruby 等等。

然后，转到 Python 参考资料，按照说明注册，在 Google API 控制台中创建一个项目，并安装这个库。

如果你在做这个部分的时候遇到问题或者还不想安装任何东西，本章是独立的。本章介绍了源代码。

不管您是否安装了工具，现在都可以开始了。

## 该计划

本节的目标是实现谷歌翻译功能。您可以实现并运行程序，或者先简单地阅读自包含部分。

### 标题

Google 提供的标准 Google header 应该足以让 API 工作，如下面的代码所示:

```
from googleapiclient.discovery import build 
```

考虑到谷歌管理的多种语言，特殊字符是一个需要处理的主要问题。当使用谷歌翻译时，网络上的许多论坛和示例程序都在与`UTF-8`标题作斗争。建议了很多解决方案，比如下面的源代码头。

```
# -*- coding: utf-8 -*- 
```

然后当 Google Translate 返回结果的时候，更多的问题出现了，很多自己开发功能。它们工作得很好，但是我在寻找一个简单的单行解决方案。这里的目标不是有很多行代码，而是专注于谷歌翻译的限制，以发现人工智能中最前沿的解释语言。

所以，我没有使用`UTF-8`头，而是使用 HTML 库实现了它。

```
import html 
```

当遇到结果时，下面的一行 HTML 解析器代码完成了任务。

```
print("result:", html.unescape(result)) 
```

它工作得很好，因为 Google 将根据您实现的选项返回 HTML 字符串或文本字符串。这意味着 HTML 模块可以完成这项工作。

### 实现谷歌的翻译服务

谷歌的翻译服务需要至少三个值来返回一个结果:

*   `developerKey`:这是在前面描述的入门过程结束时获得的 API 密钥。
*   `q="text to translate"`:在我的代码中，我使用了`source`。
*   `target="abbreviation of the translated text"` : `en`为英语，`fr`为法语，以此类推。

更多选项可用，如以下部分所述。

考虑到这一点，翻译功能将按如下方式工作:

```
def g_translate(source,targetl):

    service = build('translate', 'v2',developerKey='your Key')

    request = service.translations().list(q=source,

        target=targetl)

    response = request.execute()

    return response['translations'][0]['translatedText'] 
```

在`Google_translate.py`程序中，`q`和`target`将被发送给函数以获得一个解析结果:

```
source="your text"

targetl="abbreviation of the target language"

result = g_translate(source,targetl)

print(result) 
```

总结一下程序，让我们把 Google Translate 翻译成法语，其中包含 HTML 解析器解析的重音符号:

```
from googleapiclient.discovery import build

import html

def g_translate(source,targetl):

    service = build('translate', 'v2',developerKey='your key')

    request = service.translations().list(q=source,

        target=targetl)

    response = request.execute()

    return response['translations'][0]['translatedText']

source='Google Translate is great!'

targetl="fr"

result = g_translate(source,targetl)

print("result:", html.unescape(result)) 
```

`Google_Translate.py`工作正常。结果将显示正确的答案和经过分析的重音:

```
Google Translate est génial! 
```

在这一点上，谷歌翻译满足了一个黑盒探索的方法。它具有颠覆性，改变了世界，可以取代许多公司的翻译来满足所有的公司需求。

事实上，我们可以在这里结束这一章，进入我们最喜欢的社交网络，为我们的翻译项目造势。

大团圆结局？

嗯，还没有！

我们需要从语言学家的角度来探索谷歌翻译。

## 从语言学家角度看谷歌翻译

语言学家对程序的研究将涉及更深入的、白盒式的探索。该方法将揭示许多需要改进的地方。

到这本书出版的时候，也许谷歌已经改进了本章中的例子。但是不用担心；在这种情况下，你会很快发现数百个其他不正确的例子。旅程才刚刚开始！

### 摆弄工具

用随机的例子来玩工具会导致令人惊讶的结果。这个探索性的源代码被保存为`Google_translate_a_few_test_expressions.py`。

该程序模拟了一个名为 Usty 的人创建的对话框，如下所示:

```
source='Hello. My name is Usty!'

 >>>result:Bonjour. Je m'appelle Usty!

source='The weather is nice today'

 >>>result: Le temps est beau aujourd'hui

source='Ce professor me chercher des poux.'

 >>>result: This professor is looking for lice! 
```

前两个例子用法语看起来不错，虽然第二个翻译有点奇怪。但是在第三个测试中，表达 *chercher des poux* 在英语中的意思是*找麻烦*，翻译成法语就是不找虱子。

现在将对谷歌翻译进行语言评估。

### 谷歌翻译的语言学评估

正确评估谷歌翻译将直接导致其局限性。

极限是研究人员渴望的边界！我们是拓荒者！

专家级评估将带领项目团队走向前沿甚至更远。为此，我们将首先探讨一些语言学方法。

#### 词汇场理论

词汇域描述单词域。一个词只有在上下文中才能理解它的全部含义。这个语境往往超越了其他几个词甚至一句话。

*Chercher des poux* 翻译过来就是*寻找虱子*。但是在法语中，它可以表示*找麻烦*或者字面意思*找虱子*。谷歌翻译得出的结果包含三个基本问题。

```
source='chercher des poux'

>>result: look for lice 
```

**问题 1——词汇域**:没有上下文，就无法知道这是在找虱子还是在找麻烦。

**问题 2——隐喻或习惯表达**:假设你必须翻译*这让你很头疼*。没有办法知道这是一个物理问题还是一个隐喻的意思*这让你发疯*。当翻译成法语时，这两个习惯用语恰好有相同的隐喻。但是法语中的虱子在英语中毫无意义。

**问题 3** : *chercher* 在法语中是不定式，结果应该是*在英语中找*虱子。但是输入*chercher des limites est intéressant*提供了正确的动词形式，即*在寻找*:

```
source='Chercher des limites est intéressant.'

>>>result:Looking for boundaries is interesting. 
```

答案是正确的，因为*是*将句子分成两部分，这使得谷歌翻译更容易将 *chercher* 识别为句子的第一部分，从而使用英语中的 *looking* 。

词汇领域因语言而异，行话也是如此。

#### 行话

行话产生于领域专业化。在 AI 中，*隐藏神经元*的表述是行话。例如，这个表达对律师来说毫无意义。律师可能会认为你在某个地方隐藏了这方面的情报，或者把钱藏在一种叫做隐藏神经元的加密货币里。

同样，如果有人要求人工智能专家解释*提交动议*的确切含义，那将被证明是困难的。

在企业法律环境中，除了将谷歌翻译用作字典，如果只有随机数量的结果被证明是正确的，翻译句子可能会有风险。

如果我们将行话变体添加到从一种语言到另一种语言的词汇变体中，我们可以看到当单词在上下文中时，单词到单词的翻译不起作用。因此，翻译不仅仅是在我们要翻译的语言中找到最相似的单词。

#### 翻译不仅仅是翻译，而是解释

有时，翻译需要口译，如以下摘自法国商法标准描述的句子所示:

```
source='Une SAS ne dispense pas de suivre les recommandations en vigueur autour des pratiques commerciales.'

>>>result:An SAS does not exempt from following the recommendations in force around commercial practices. 
```

法语句子指的是一种类型的公司；SAS 类似于股份有限公司等公司类型。在英语中，SAS 的意思是特殊航空服务。然后是语法，听起来不太对。

一个翻译可以写出更好的英语，并详细说明什么是 SAS:

*SAS(法国的一种公司)必须遵循涵盖商业惯例的建议。*

翻译往往意味着口译，而不仅仅是翻译单词。

在这种情况下，法律翻译可以解释合同中的文本，甚至写作:

*公司必须尊重公平对待所有客户的法律义务。*

法律翻译会建议在合同开头定义*公司*以避免混淆，比如 Google Translate 刚刚做的那个。

当阅读 NLP、聊天机器人和翻译时，一切似乎都很容易。然而，在谷歌翻译上工作很容易变成一场噩梦！

让我们举最后一个例子:

```
The project team is all ears 
```

谷歌翻译提供法语输出:

```
source:"The project team is all ears".

>>>result: L'équipe de projet est tout ouïe. 
```

法语和英语一样，最好说*项目团队*，不要用的*说项目*的*团队。在法语中，我们有 *équipe projet* (équipe(团队)出现在项目之前)。*

从我们到目前为止的例子中，我们可以看到谷歌翻译是:

*   有时是正确的
*   有时是错的
*   有时部分正确，部分错误

现在的问题是如何知道一个翻译属于哪一类。

#### 如何知道一个翻译是否正确

如果你不懂这种语言，你如何检查翻译？

小心点。如果谷歌翻译提供另一种语言的随机正确答案，那么你没有办法知道翻译是否可靠。

如果你不能确信谷歌翻译是正确的，你可能会发现自己陷入困境；甚至向对你来说很重要的人发送相反的信息。你可能会误解你试图理解的一句话。

例如，在一家运输公司，你可以写一封电子邮件，说明长途汽车停下来了，人们在抱怨:

```
source='The coach stopped and everybody was complaining.' 
```

Google Translate 因为词汇领域的原因，把 *coach* 翻译成法语的运动教练，会给这句话一个完全不同的意思:

```
result: L'entraîneur s'est arrêté et tout le monde se plaignait.. 
```

现在，情况可能会变得更糟。为了帮助谷歌翻译，让我们添加一些背景。

```
source='The coach broke down and stopped and everybody was complaining.' 
```

这个回答更差。谷歌翻译用法语表达 *en panne* 正确地翻译了*抛锚*，但仍然在法语中将*教练*翻译为*夹带者*(教练)，意思是*教练*抛锚，而不是*教练*(大巴)。

```
result: L'entraîneur est tombé en panne et s'est arrêté et tout le monde se plaignait. 
```

毫无疑问，谷歌将继续改进该程序，就像它自 2006 年以来所做的那样。然而，就目前而言，人工翻译将会发现数百种谷歌翻译还无法处理的表达方式。

当一个词或一个表达有几个意思时，用你的母语理解一个句子可能会很困难。在这个问题上增加一个翻译功能使得提供一个可靠的答案更加困难。

这就是我们到达前沿的地方，就在前沿之外，因为我们已经确立了谷歌翻译的极限。

在下一节中，我们将看看我们可以改善标准谷歌翻译结果的一些方法。尽管没有检验翻译的灵丹妙药，但我们将探索改进这一过程的方法。我们会找到一种方法来改善谷歌翻译和实现它。

# 人工智能作为一个新的前沿

谷歌有一个伟大但有限的翻译程序。利用缺陷来创新！人工智能的研发仅仅触及了未来创新的皮毛。

首先，实现一个 AI 解决方案。然后，用它本来的样子。但是不要接受它的限制。不要对此持否定态度。创新！想象想法或倾听你喜欢的其他想法，并在团队中构建解决方案！谷歌甚至可能会公布你的解决方案！

为任何翻译改进谷歌翻译是不可能的。一种现实的方法是专注于为给定的领域定制 Google Translate，比如本例中的运输公司。在下一节中，我们将重点关注定制谷歌翻译的方法。

## 词汇场与一词多义

将提供如何在特定领域改进谷歌翻译的想法。这一节重点介绍谷歌翻译的交通词汇错误。再次，谷歌可能会迅速纠正这个错误，但该方法可以应用于许多剩余的错误。

一个**词汇域**包含构成集合和子集的单词。它们因语言而异。语言本身形成一个集合，包含词汇域的子集。

较冷的国家比几乎不下雪的热带国家有更多的词来描述水的冰冻状态。cold 的词汇域可以是 *C* 的子集:

*C* = { *冰*，*冰雹*，*雪花*，*雪人*，*雪泥*，*粉*，*雪花*，*雪球*，*暴风雪*，*融化*，*嘎吱* … *n*

维度的诅咒在这里适用。单词包含了难以置信的维度和定义。为了翻译某些表达式，Google Translate 会抑制它们的维度并减少它们。

Google Translate 经常使用 n-grams 进行翻译。n 元语法是固定长度的标记序列。记号可以是一个单词、一个字符，甚至是单词和字符的数字表示。

给定前一个/后一个*n*–*x*或 *n* + *x* 记号，计算记号 *n* 表示某事物的概率。 *x* 是一个变量，取决于所应用的算法。

例如， *slushy* 在表达 *slushy snow* 中有特殊的含义。雪正在部分融化，很潮湿，当我们走过时会发出哗哗的声音。融化只是*雪泥*含义的一个组成部分。

谷歌翻译，在这一点上，只会将翻译成法语 *slushy snow* :

*内格*(雪)*方丹*(融)

谷歌翻译也将翻译*融化的雪*通过:

*内格*(雪)*方丹*(融)

要将 *slushy* 翻译成法语，你必须使用一个短语。要找到那个短语，你需要一些想象力或者有一些解析过的(搜索过的)小说或者其他形式的言语表达。这需要时间和资源。谷歌翻译很可能需要几年时间才能在所有公开的语言中达到可接受的本土水平。

另一个要考虑的方面是多义性。

一词多义意味着一个词在一种语言中可以有几种非常不同的意思。另一种语言中的对等词可能只是有一种意思，或者其他非常不同的意思。

英语中的“Go + over”可以指*过桥*或*复习一些笔记*。在这一点上(希望在你读这本书的时候它会有所改进)，这两个例子都是由 aller sur 翻译成法语的。意思是继续(不是结束)，这两种情况都不正确。英语中的介词本身就构成了一个领域，同一个词可以产生许多意思。动词 *go* 可以有很多种含义:*向上*(楼上)*向上*(股市)*向下*(楼下)*向下*(散架)，除此之外还有很多可能性。

原型定制程序从定义`X`开始。翻译一个小数据集就足够了:

```
X=['Eating fatty food can be unhealthy.',

   'This was a catch-22 situation.',

   'She would not lend me her tote bag',

   'He had a chip on his shoulder',

   'The market was bearish yesterday',

   'That was definitely wrong',

   'The project was compromised but he pulled a rabit out of his hat',

   'So just let the chips fall where they may',

   'She went the extra mile to satisfy the customer',

   'She bailed out when it became unbearable',

   'The term person includes one or more individuals, labor unions, partnerships, associations, corporations, legal representatives, mutual companies, joint-stock companies, trusts, unincorporated organizations, trustees, trustees in bankruptcy, or receivers.',

   'The coach broke down, stopped and everybody was complaining'] 
```

如果您发现拼写错误或小错误，不要在培训阶段纠正它们。需要一定量的噪声来重现人为和机器错误，以避免过度拟合。

Google Translate 会自动翻译这些句子。

`X1`，在下面的代码中实现，定义了一些与句子统计相关的关键字；它应用前面描述的 n 元语法概率理论。

```
X1=['grasse',

    'insoluble',

    'sac',

    'aggressif',

    'marché',

    'certainement',

    'chapeau',

    'advienne',

    'supplémentaire',

    'parti',

    'personne',

    'bus'] 
```

`X1`中的每条线都与`X`中的相应线相联。如前所述，这只是一种可能性，可能并不正确。

在这一点上，我们不求完美，只求改进。

让我们来探索如何通过在 Python 程序中实现 KNN 来定制翻译，从而改进谷歌翻译。

## 探索前沿——用 Python 程序定制谷歌翻译

现在是时候添加一些定制的新奇东西了。本节中向量的用法将在下一节中解释，同样是通过使用它们的源代码。

触发向量将迫使程序尝试一种替代方法来翻译一个误译的句子。当句子被识别后，如果它在`X2`中的值等于`1`，它将触发一个更深层次的翻译功能，如下所示:

```
X2=[0,0,0,1,0,0,0,0,0,0,0,1] 
```

`0`和`1`是旗帜。每个值代表`X`中的一行。

**开发人员注意事项**:要正确使用该方法，该向量的所有值都应设置为`1`。这将自动触发几个替代方法来翻译谷歌翻译错误。这里还有很多工作要做！

这个例子取自一家运输公司。应该建立一个交通短语词典。在这种情况下，一个通用的`phrase_translation`字典已经用一个表达式实现了，如下面的数组所示。

```
phrase_translation=['','','','Il est agressif','','','','','','','',''] 
```

为了填满这本词典，还需要做些什么？

*   扫描公司的所有文件——电子邮件、信件、合同和各种形式的书面文件。
*   存储嵌入的单词和句子。
*   当系统返回错误答案时，通过在学习界面中提供反馈(正确答案),培训团队使用程序来改进程序。

Google Translate 在全球范围内做不到的事情，你可以在本地范围内实现，以显著改善系统。

既然我们已经定义了一个方法，我们将深入研究 KNN 算法。

## k-最近邻算法

无论你如何解决一个语言问题，它总会归结为语境的概念。当有人不理解别人时，他们会说:“你断章取义了，”或者“我不是这个意思；我来解释一下。”

如前所述，在许多情况下，如果没有词汇字段，就无法翻译单词或表达式。程序将会显示，难度与多义性成正比。

使用 KNN 算法作为分类方法可以证明是非常有用的。任何语言解释(翻译或聊天机器人)都必须使用面向上下文的算法。

通过寻找彼此最接近的单词(邻居)，KNN 将创建解释语言所需的词汇域。更好的是，当提供适当的数据集时，它将解决一词多义的问题，如下面几节所示。

### 实现 KNN 算法

一般来说，一个单词需要一个上下文来表达某种意思。寻找附近的“邻居”提供了一种有效的方法来确定单词的归属。

KNN 受到监督，因为它使用提供的数据标签来训练其算法。在这种情况下，KNN 用于分类目的。对于给定点 *p* ，KNN 将计算到所有其他点的距离。然后， *k* 表示要考虑的 k 个最近邻居。

让我们通过一个例子来澄清这一点。在英语中，“教练”一词可以指足球场、公共汽车或铁路客车上的教练。在运输公司中，“教练”通常是一辆公共汽车，不应与教练混淆:

*   **步骤 1** :解析(以详细的方式检查)以“coach”为总线，以“coach”为培训师的文本。因此，程序正在搜索三个目标词:教练、公共汽车和教练。
*   **第二步**:找到一些和我们要搜索的目标词出现的比较接近的词。按照建议，执行以下操作:
    *   解析标准程序可以使用的所有公司文档。
    *   使用 Python 函数，如`if(n-gram in the source)`，然后存储数据。

在这种情况下，源代码提供的以下输出摘录中显示的`V1.csv`文件包含这种解析函数的结果:

```
broke,road,stopped,shouted,class

1,3.5,6.4,9,trainer

1,3.0,5.4,9,trainer

1,3.2,6.3,9,trainer

...

6.4,6.2,9.5,1.5,bus

2,3.2,9,1,bus

6.4,6.2,9.5,1.5,bus

...

3.3,7.3,3.0,2.5,coach

4.7,5.7,3.1,3.7,coach

2.0,6.0,2.7,3.1,coach 
```

生成文件如`V1.csv`不在本章或本书的讨论范围之内。但是，除了其他网站，您还可以通过以下链接探索 scikit-learn 的文本文档功能:

[https://sci kit-learn . org/stable/tutorial/text _ analytics/working _ with _ text _ data . html](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)

该程序解析电子邮件、文件和合同。每行代表解析一个文档的结果。数字代表出现的次数(单词出现的次数)。这些数字已经被“压缩”(一次又一次地分割)，以保持较小且易于管理。有关如何处理文本数据的更多信息，请单击上一段中的 scikit-learn 链接。

渐渐地，与“教练”一起出现的单词是“喊”多于“停”对一辆公共汽车来说，“抛锚”(如在抛锚中的“抛锚”)、“路”和“停”出现的次数比“喊”多。

“蔻驰”平均出现在“喊”、“停”、“路”和“断”中，因为它可能是一辆教练或公共汽车，因此我们在翻译这个词时面临的问题。“coach”的多义性(几个意思)会导致糟糕的翻译。

KNN 算法加载了包含待训练数据的`V1.csv`文件，结果如下:

![https://packt-type-cloud.s3.amazonaws.com/uploads/sites/2134/2018/05/B09946_08_01-1.png](img/B15438_06_01.png)

图 6.1:KNN 算法的结果

`knn_polysemy.py`程序确定了以下内容:

*   蓝色的动词“broke”更有可能应用于公共汽车( *x* 轴值> 6)，而不是教练( *x* 轴值< 4)。然而，“教练”仍然高于“教练”，低于“公共汽车”，因为它可以兼而有之。
*   “路”这个词跟蓝图遵循的逻辑一样。
*   动词“stopped”适用于教练，更适用于公共汽车。“蔻驰”仍然没有决定。
*   动词“大喊”显然更适用于教练，而不是公共汽车。“蔻驰”仍然没有决定。

请注意，这些图表中每个点的坐标如下:

*   **y 轴**:总线= 1，教练= 2，教练= 3。
*   **x 轴**:该值代表“压扁”出现次数(单词出现的次数)值。

这是在许多来源中搜索这些词的结果。

当一个新的点，一个名为*P*n 的数据点被引入系统时，它将根据 *k* 的值找到它的最近邻居。

KNN 算法将使用欧几里德距离公式计算 *P* [n] 和从 *P* [1] 到*P*[n][–1]的所有其他点之间的欧几里德距离。KNN 的 *k* 表示该算法出于分类目的将考虑的“最近邻居”的数量。两个给定点之间的欧氏距离( *d* [1] ，例如，*P*[n](*x*[1]，*y*[1*P*[(*x*[2]]]

![](img/B15438_06_001.png)

考虑到要计算的距离数量，像`sklearn.neighbors`提供的函数证明是必要的。

### knn_polysemy.py 程序

程序导入前面描述的`V1.csv`文件，打印几行，并在各自的 *x* 轴和 *y* 轴的正确数组中准备标签，如源代码示例所示:

```
import pandas as pd

from matplotlib import pyplot as plt

from sklearn.neighbors import KNeighborsClassifier

# Import data

df = pd.read_csv('V1.csv')

print (df.head())

# KNN Classification labels

X = df.loc[:,'broke':'shouted']

Y = df.loc[:,'class'] 
```

然后对模型进行定型，如下面的代码所示:

```
# Trains the model

knn = KNeighborsClassifier()

knn.fit(X,Y) 
```

一旦模型定型，就会请求预测，并由以下代码提供:

```
# Requesting a prediction

#broke and stopped are

#activated to see the best choice of words to fit these features.

# brock and stopped were found in the sentence to be interpreted.

# In X_DL as in X, the labels are : broke, road, stopped,shouted.

X_DL = [[9,0,9,0]]

prediction = knn.predict(X_DL)

print ("The prediction is:",str(prediction).strip('[]')) 
```

这是显示的结果:

```
The prediction is: 'bus' 
```

绘制初始数据是为了可视化，如以下代码所示:

```
#Uses the same V1.csv because the parsing has

# been checked and is reliable as "dataset lexical rule base".

df = pd.read_csv('V1.csv')

# Plotting the relation of each feature with each class

figure,(sub1,sub2,sub3,sub4) = plt.subplots(

    4,sharex=True,sharey=True)

plt.suptitle('k-nearest neighbors')

plt.xlabel('Feature')

plt.ylabel('Class')

X = df.loc[:,'broke']

Y = df.loc[:,'class']

sub1.scatter(X, Y,color='blue',label='broke')

sub1.legend(loc=4, prop={'size': 5})

sub1.set_title('Polysemy')

X = df.loc[:,'road']

Y = df.loc[:,'class']

sub2.scatter(X, Y,color='green',label='road')

sub2.legend(loc=4, prop={'size': 5})

X = df.loc[:,'stopped']

Y = df.loc[:,'class']

sub3.scatter(X, Y,color='red',label='stopped')

sub3.legend(loc=4, prop={'size': 5})

X = df.loc[:,'shouted']

Y = df.loc[:,'class']

sub4.scatter(X, Y,color='black',label='shouted')

sub4.legend(loc=4, prop={'size': 5})

figure.subplots_adjust(hspace=0)

plt.show() 
```

这个程序的压缩版本已经在`Google_Translate_Customized.py`推出，如下图所示:

```
def knn(polysemy,vpolysemy,begin,end):

    df = pd.read_csv(polysemy+'.csv')

    X = df.loc[:,'broke':'shouted']

    Y = df.loc[:,'class']

    knn = KNeighborsClassifier()

    knn.fit(X,Y)

    prediction = knn.predict(vpolysemy)

    return prediction 
```

描述如下:

*   `polysemy`是要读取的文件的名称，因为它可以是任何文件。
*   `vpolysemy`是需要预测的向量。
*   将来，在待办事项列表中，`begin`应该替换`broke`，而`end`应该替换`shouted`，这样函数就可以预测任何向量的值。
*   调用 KNN 分类器并返回预测。

既然我们已经准备好了 KNN 分类器函数，我们就可以定制谷歌翻译了。

### 在 Google_Translate_Customized.py 中实现 KNN 函数

因为涉及到语言学的概念，这个项目需要更多的时间和研究。掌握算法的最好方法是按顺序运行它。

谷歌翻译提供各种翻译方法。我们将在下面的代码中重点介绍其中的两个:

```
#print('Phrase-Based Machine Translation(PBMT)model:base'): #m='base'

print('Neural Machine Translation model:nmt') 
```

这些解释如下:

*   **基于短语的机器翻译(PBMT)** :翻译整个单词序列。短语，或者更确切地说是 phraseme(多词表达)，并不总是一个完整的句子。
*   **神经机器翻译(NMT)** :这使用了神经网络，如**递归神经网络** ( **RNN** )，这将在本书后面详细介绍。这种方法超出了短语的范围，考虑了整个句子。就本章介绍的数据集而言，这种神经网络方法提供了稍好的结果。

这两种方法和谷歌的其他方法都很有趣，但谷歌翻译在许多情况下仍然需要额外的定制算法来达到可接受的质量水平。在这一章中，我们将探索一种使用 KNN 的方法，但是你也可以使用其他方法，只要它们有效。

正如您到目前为止所看到的，如果您考虑到许多语言的词汇领域和结构、它们的地区差异和行话，这个主题是极其复杂的。

#### 步骤 1–逐行将 X 数据集从英语翻译成法语

下面的代码调用翻译函数:

```
for xi in range(len(X)):

    source=X[xi]

    targetl="fr";m='nmt'

    result = g_translate(source,targetl,m) 
```

该代码解释如下:

*   `xi`是`X`中的行号。
*   `source`是`X`的`xi`线。
*   `targetl`是目标语言，在本例中是`fr`(法语)。
*   `m`是方法(PBMT 或 NMT)，如前所述。在这种情况下，应用`nmt`。
*   然后，调用谷歌翻译功能，如本章前面所述。结果存储在`result`变量中。

#### 步骤 2–回译

如果 *L* [1] 是一个人的母语，而*L*2 是一种这个人根本不懂的语言，那么谁能知道从语言 *L* [1] 翻译成语言 *L* [2] 的正确性呢？

这是译者经常使用回译来检查翻译的原因之一:

*平移* = *初始平移从 L* [1] *到 L* [2]

*回平移* = *从 L* [回平移 2] *到 L* [1]

如果没有获得初始文本，那么很可能有问题。在这种情况下，起始句 *L* [1] 的长度可以与翻译回 *L* [1] 的相同句子的长度进行比较。以下代码调用回译:

```
 back_translate=result

    back_translate = g_translate(back_translate,targetl,m)

    print("source:",source,":",len(source))

    print("result:",result)

    print("target:",back_translate,":",len(back_translate)) 
```

长度比较可用于改进算法:

*初始 n-gram 的长度* = *回译的长度*

如果相等，那么翻译可能是正确的。如果不是，它可能是不正确的。当然，在每次翻译过程中必须运用更多的方法。然而，导致改进的方法已经是好的一步。在这种情况下，将源(初始句子)与以下代码中的回译进行比较:

```
 if(source == back_translate):

        print("true")

        if((term not in words)and (xi!=4)):

            t+=1

    else:

    f+=1;print("false") 
```

*   `t`是一个`True`计数器。
*   `f`是一个`False`计数器。

`X`的第一行如下:

```
source: Eating fatty food can be unhealthy. : 35

result: Manger de la nourriture grasse peut être malsain.

target: Eating fat food can be unhealthy. : 33

false 
```

*吃油腻食物*反译为*吃油腻食物*，略有不妥。可能出问题了。

法语句子听起来也不对。高脂肪食物不能这样翻译。通常常见的句子是*马槽草*，意思是*吃*(马槽)*胖子*(草)，不能照此翻译成英文。

本节提到的`X`数组从第 8 行开始:

```
X=['Eating fatty food can be unhealthy.',

   'This was a catch-22 situation.',

   'She would not lend me her tote bag',

   'He had a chip on his shoulder',

....] 
```

几个短语带着错误的翻译回来，例如，`X[4]`，`'He had a chip on his shoulder'`。我在下面的代码中使用`False`条件中的触发器编写了一个基于短语的翻译。

```
 else:

        f+=1;print("false")

    if(X2[xi]>0):

        DT=deeper_translate(source,xi)

        dt+=1 
```

由于我没有为这本书写一个完整的应用，只是一些将来可以扩展的例子，所以我用`X2`作为触发器。如果`X2[x1]>0`，则`deeper_translate`功能被激活。

#### 步骤 3–使用基于短语的翻译进行更深入的翻译

`deeper_translate`有两个论点:

*   `source`:要翻译的第一个句子
*   `x1`:目标句

在这种情况下，要解决的问题是一个在英语中存在但在法语中不存在的习惯表达:

```
source: He had a chip on his shoulder : 29

result: Il avait une puce sur son épaule

target: He had a chip on his shoulder : 29

false 
```

意思是对某事或某人有意见。它表达了某种形式的紧张。

Google 将*芯片*翻译成假设电脑芯片，或者法语中的 *puce* ，意思是*电脑芯片*和*跳蚤*。这个翻译毫无意义。

*芯片*分为三类，应标注如下:

*   成语性词语
*   行话
*   一词多义

此时，我创建的以下函数模拟了基于短语的解决方案，以实现更深入的翻译。

```
def deeper_translate(source,index):

    dt=source

    deeper_response=phrase_translation[index]

    if(len(deeper_response)<=0):

        print("deeper translation program result:",

            deeper_response,":Now true") 
```

`deeper_translate`函数在下面的`phrase_translation`数组(list、vector 或任何需要的东西)中寻找包含 *chip* 的翻译句子。

```
phrase_translation=['','','','Il est agressif','','','','','','','',''] 
```

最终结果是翻译、回译、术语搜索和短语翻译。以下是生成的结果，每行前都添加了注释:

```
Initial sentence:

source: He had a chip on his shoulder : 29

Wrong answer:

result: Il avait une puce sur son épaule

The back-translation works:

target: He had a chip on his shoulder : 29

term: aggressif

false

deeper translation program result: Il est agressif 
```

问题是，`term`从何而来？

`term`来自`X1`，应该在翻译中的关键词列表。`X1`已被手动输入，但它应该是对被视为类别的句子中的单词进行自动搜索而得到的可能性列表。这意味着要翻译的句子应该有几个层次的意思，而不仅仅是正在计算的字面意思。

实际的`True` / `False`条件包含以下要检查的更深层次的翻译级单词:

```
 if(source == back_translate):

        print("true")

        if((term not in words) and (xi!=4)):

            t+=1

    else:

        f+=1;print("false")

        if(X2[xi]>0):

            DT=deeper_translate(source,xi)

            dt+=1 
```

在原型的当前状态下，只有示例 4 激活了基于短语的翻译。否则，`True`被接受。如果`False`是这种情况，则在该示例代码中，仅在两种情况下激活更深层次的翻译。标志在`X2` ( `0`或`1`)。

`deeper_translate`用于基于短语的翻译(如前所述)或 KNN 例程，如果基于短语的翻译不起作用，则激活该例程。

如果转换不起作用，则为 KNN 算法准备一个 n 元语法，如以下代码所示:

```
 if(len(deeper_response)<=0):

        v1=0

        for i in range(4):

            ngram=V1[i]

            if(ngram in source):

                vpolysemy[0][i]=9

                v1=1 
```

`V1[i]`包含在前面的 KNN 算法中描述的用于传输词汇字段的关键字(n-grams ),如下面的代码所示:

```
V1=['broke','road','stopped','shouted','coach','bus','car',

    'truck','break','broke','roads','stop'] 
```

为每个 n 元语法解析源(要翻译的句子)。如果找到了 n-gram，则为该 n-gram 激活多义向量。初始值设置为`0`，如以下代码所示:

```
vpolysemy=[[0,0,0,0]] 
```

变量`v1`被激活，通知程序在这种情况下必须读取`V1.csv`。应该会自动创建无限数量的 KNN 引用，如前面 KNN 部分所述。

在这种情况下，只有`v1`被激活。但是在为公司定制他们本地需求的项目工作了几个月之后，应该会创建许多其他文件。

在这种情况下，当`v1`被激活时，它填写如下变量。

```
 if(v1>0):

        polysemy='V1'

        begin=str(V1[0]).strip('[]');end=str(V1[3]).strip('[]')

        sememe=knn(polysemy,vpolysemy,begin,end) 
```

*   `polysemy`表示要打开的 KNN 文件。
*   `begin`是`V1`向量的第一个标签，`end`是`V1`向量的最后一个标签。
*   `sememe`是我们期待的预测。

现在，如前面对`knn_polysemy.py`所述，在下面的代码中调用 KNN 算法的压缩版本:

```
def knn(polysemy,vpolysemy,begin,end):

    df = pd.read_csv(polysemy+'.csv')

    X = df.loc[:,begin:end]

    Y = df.loc[:,'class']

    knn = KNeighborsClassifier()

    knn.fit(X,Y)

    prediction = knn.predict(vpolysemy)

    return prediction 
```

在这种情况下，例子是教练的多义性特征，如 KNN 部分所解释的。将产生如下输出:

```
Source: The coach broke down, stopped and everybody was complaining : 59

result: L'entraîneur est tombé en panne, s'est arrêté et tout le monde se plaignait

target: The coach broke down, stopped, and everyone was complaining : 59

term: bus

false 
```

翻译是假的，因为谷歌翻译返回的是*培训师*而不是*公交车*。

术语 *bus* 在英语和法语中是相同的。

KNN 例程返回英文的 *bus* 作为找到*故障*和*停止*时使用的正确单词，如 KNN 部分所示。

`deeper_translate`函数中其余源代码的目标是将*coach*——增加要翻译的多义性的单词——替换为更好的要翻译的单词(有限多义性):`sememe`。

`sememe`变量由 KNN 函数在以下代码中初始化:

```
 sememe=knn(polysemy,vpolysemy,begin,end)

            for i in range(2):

                if(V1_class[i] in source):

                    replace=str(V1_class[i]).strip('[]')

                    sememe=str(sememe).strip('[]')

                    dtsource = source.replace(replace,sememe)

                    targetl="fr";m='base'

                    result = g_translate(dtsource,targetl,m)

                    print('polysemy narrowed result:',result,

                        ":Now true") 
```

该函数用 KNN 算法在英语句子中找到的*总线*替换*教练*，然后要求谷歌翻译再试一次。返回正确答案。

`deeper_translate`函数不是试图翻译一个有太多意思(多义性)的单词，而是先用一个更好的单词(多义性更少)替换这个单词。通常会获得更好的结果。

##### 步骤 3.1–添加一个频率误差概率函数

添加了一个 frequentist 错误概率函数来测量性能，如以下代码所示:

```
def frequency_p(tnumber,cnumber):

    ff=cnumber/tnumber #frequentist interpretation and probability

    return ff 
```

*   `cnumber`是 Google Translate 返回的错误答案数。
*   `tnumber`是翻译的句子数量。
*   给出了一个简单的错误(翻译)概率，ETP。

当翻译为 false 或`f>0`时，调用该函数，如以下代码所示:

```
 if(f>0):

        B1=frequency_p(xi+1,f) #error detection probability before deep translation

        B2=frequency_p(xi+1,f-dt) #error detection probability after deep translation

    if(f>0):

        print("ETP before DT",round(B1,2),

            "ETP with DT",round(B2,2))

    else:

        print('Insufficient data in probability distribution') 
```

*   `B1`是调用`deeper_translate`函数之前的错误(翻译)概率(ETP)。
*   `B2`是调用`deeper_translate`函数后的 ETP。

程序结束时，会显示一个摘要，如以下输出所示:

```
print("------Summary------")

print('Neural Machine Translation model:nmt')

print('Google Translate:',"True:",t,"False:",f,'ETP',round(f/len(X),2))

print('Customized Google Translate:',"True:",t,"False:",f-dt,'ETP',round((f-dt)/len(X),2))

a=2.5;at=t+a;af=f-a #subjective acceptance of an approximate result

print('Google Translate acceptable:',"True:",at,"False:",af,'ETP',round(af/len(X),2))

#The error rate should decrease and be stabilized as the KNN knowledge base increases

print('Customized Google Translate acceptable:',"True:",at,"False:",af-dt,'ETP',round((af-dt)/len(X),2)) 
```

*   增加了对近似结果的主观接受，以增加真实概率。
*   随着 KNN 知识库质量的提高，错误率应该会降低。在频繁概率理论中，这意味着应该达到稳定的预测率。

我们改进谷歌翻译的努力已经到了最后阶段。让我们考虑一下实验后的一些结论。

### 谷歌翻译定制实验的结论

产生的最终错误(翻译)概率很有趣，如以下输出所示:

```
>>------Summary------

>>Neural Machine Translation model:nmt

>>Google Translate: True: 2 False: 8 ETP 0.67

>>Customized Google Translate: True: 2 False: 7 ETP 0.58

>>Google Translate acceptable: True: 4.5 False: 5.5 ETP 0.46

>>Customized Google Translate acceptable: True: 4.5 False: 4.5 ETP 0.38 
```

即使有了 NMT 模式，谷歌翻译仍然举步维艰。

这为人工智能语言学家提供了巨大的机会，正如所展示的一些在本地水平上改进谷歌翻译的方法可以走得更远。

谷歌翻译的这个实验表明，谷歌只是触及了现实生活中的翻译的表面，而这些翻译对接收这些翻译的母语人士来说听起来是正确的。在消耗资源之前，需要一个真正的公司项目，通过对其盈利能力的财务分析来使其步入正轨。

### 破坏性的革命循环

正如你现在看到的，谷歌翻译，像所有的人工智能解决方案一样，有其局限性。一旦达到这个极限，你就处于最前沿。

越界进入 AI 边疆；独自或与团队一起创新。

如果你为一家公司工作，你可以为数百名用户创建一个革命性的定制解决方案。它不一定要上市。它仍然是您公司的一项重要资产。

在某个时候，这个革命性的附加软件将超越公司，其他人将会使用它。它将变得具有破坏性。

最后，其他人将会达到您现在具有破坏性的解决方案的极限。然后，他们将在自己的公司中进行创新和定制，作为一种革命性的解决方案。这就是我所说的破坏性革命循环。这是具有挑战性和令人兴奋的，因为这意味着人工智能开发人员在不久的将来不会全部被 AutoAI 机器人取代！

设计一个解决方案并不意味着它将是一项发明、创新、革命或颠覆性的。但这并不重要。只要有利可图，公司通过解决方案获得的收益就不仅仅是销售的新奇产品。这是第一条规则。也就是说，如果不在市场上进行创新，该公司将无法生存多年。

如果一个产品出于安全原因需要质量，只要有必要，它就应该保持其发明状态。如果一个产品在完全完成之前可以在低端市场产生销售，那么公司应该出售它。该公司将获得创新的声誉，获得更多资金进行投资，并接管竞争对手的领地。

# 摘要

谷歌翻译是颠覆性营销的一个很好的例子。如图所示，理论、模型甚至云架构都已经超过 10 年了。但每当数亿用户中的一个偶然发现它，它就会通过将用户与谷歌解决方案挂钩来制造更多的破坏。用户会一次又一次地回来查看更多的广告，大家都很开心！

人工智能才刚刚开始。谷歌翻译从 2006 年就开始了。然而，这些结果仍然给开发者、语言学家和数学家留下了改进的空间。谷歌增加了一个神经网络，并提供其他模型，通过分析整个句子来改善翻译。要多久才算真正靠谱？与此同时，国际社会正在将人工智能从尖端领域推向前沿。

在这一章中，我们首先仔细探讨了发明和创新之间的区别。一项创新会对市场的其他部分产生影响。一项发明只是一项创新的起点。我们看到一个革命性的解决方案可能是一个技术突破。但是，这种革命性的解决方案只有在推广到市场的其他部分时才会变得具有破坏性。

然后，我们学习了一些基本的语言学原则，这些原则可以帮助我们理解谷歌翻译，它的局限性，以及如何改善翻译错误。

我们最终实现了一个定制的翻译工具，使用 KNN 来解决谷歌翻译错误。

在下一章，*第 7 章*，*用朴素贝叶斯*优化区块链，我们将通过使用区块链在企业环境中进行预测，进一步探索人工智能的新前沿。

# 问题

1.  是不是最好等到有了顶级产品再投放市场？(是|否)
2.  考虑到所做的投资，一个新产品应该总是定价高，以达到市场的顶端部分。(是|否)
3.  发明一个新的解决方案会使它本身为人所知。(是|否)
4.  AI 可以在不使用标准非学习算法的情况下解决大多数问题。(是|否)
5.  谷歌翻译可以令人满意地翻译所有语言。(是|否)
6.  如果你没有创造力，尝试创新是没有用的。(是|否)
7.  如果你不是语言学家，尝试改进谷歌翻译是没有用的。(是|否)
8.  翻译太复杂，难以理解。(是|否)
9.  人工智能已经达到了极限。(是|否)

# 进一步阅读

*   关于颠覆性创新的哈佛商业评论可以在这里找到:【https://hbr.org/2015/12/what-is-disruptive-innovation 
*   谷歌翻译文档可以在这里找到:[https://cloud.google.com/translate/docs/](https://cloud.google.com/translate/docs/ )
*   谷歌 alpha go Zero:[https://deep mind . com/blog/article/alpha go-Zero-starting-scratch](https://deepmind.com/blog/article/alphago-zero-starting-scratch)
*   KNN 文档:[http://sci kit-learn . org/stable/modules/neighbors . html # neighbors](http://scikit-learn.org/stable/modules/neighbors.html#neighbors)
*   关于翻译 ann 的见解:[https://research . Google blog . com/2016/09/a-neural-network-for-machine . html](https://research.googleblog.com/2016/09/a-neural-network-for-machine.html)
*   关于英法翻译的见解:[http://www . onesky app . com/blog/French-translation-challenges/](http://www.oneskyapp.com/blog/french-translation-challenges/)
*   有关如何使用文本数据为算法构建数据集的更多信息:[https://sci kit-learn . org/stable/tutorial/text _ analytics/working _ with _ text _ data . html](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)