<html><head/><body>
<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Object Detection – CIFAR-10 Example</title>
    <meta content="urn:uuid:b6d6a510-8f2b-40e4-8a30-e199afd87745" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">物体检测–CIFAR-10 示例</h1>
                
            
            
                
<p class="calibre2">在介绍了基础知识和<strong class="calibre13">卷积神经网络</strong>(<strong class="calibre13">CNN</strong>)背后的直觉/动机之后，我们将在可用于对象检测的最流行的数据集之一上演示这一点。我们还将看到 CNN 的初始层如何获得关于我们对象的非常基本的特征，但最终的卷积层将获得更多的语义级特征，这些特征是从第一层中的那些基本特征建立起来的。</p>
<p class="calibre2">本章将涵盖以下主题:</p>
<ul class="calibre7">
<li class="calibre8">目标检测</li>
<li class="calibre8">CIFAR-10 mages 中的物体探测—模型建立和训练</li>
</ul>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Object detection</title>
    <meta content="urn:uuid:b6d6a510-8f2b-40e4-8a30-e199afd87745" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">目标检测</h1>
                
            
            
                
<p class="calibre2">维基百科称:</p>
<p>“对象检测——计算机视觉领域中用于在图像或视频序列中寻找和识别对象的技术。尽管物体的图像在不同的观察点、许多不同的尺寸和比例或者甚至当它们被平移或旋转时会有所不同，但是人类可以毫不费力地识别图像中的大量物体。当物体被部分遮挡时，它们甚至可以被识别。这项任务对于计算机视觉系统来说仍然是一个挑战。几十年来，已经实施了许多方法来完成这项任务。”</p>
<p class="calibre2">图像分析是深度学习中最突出的领域之一。图像很容易生成和处理，它们正是机器学习的正确数据类型:对人类来说容易理解，但对计算机来说很难。毫不奇怪，图像分析在深度神经网络的历史中发挥了关键作用。</p>
<div><img src="img/0d82c9b0-e87a-4f16-a94c-805efcf6f9f5.jpg" class="calibre31"/></div>
<p>图 11.1:探测物体的例子。资料来源:B. C. Russell，A. Torralba，C. Liu，R. Fergus，W. T. Freeman，场景对齐的物体检测，神经信息处理系统进展，2007，网址:http://Bryan Russell . org/papers/nipsdetectionbyscenealignment 07 . pdf</p>
<p class="calibre2">随着自动驾驶汽车、面部检测、智能视频监控和人数统计解决方案的兴起，快速准确的物体检测系统需求很大。这些系统不仅包括图像中的对象识别和分类，还可以通过在它们周围画出适当的方框来定位它们中的每一个。这使得物体检测比其传统的计算机视觉前身图像分类更难。</p>
<p class="calibre2">在这一章中，我们将研究对象检测——找出图像中的对象。举个例子，想象一下一辆自动驾驶汽车需要像<em class="calibre19">图 11.1 </em>中那样检测路上的其他汽车。目标检测有很多复杂的算法。它们通常需要庞大的数据集、非常深的卷积网络和很长的训练时间。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>CIFAR-10 – modeling, building, and training</title>
    <meta content="urn:uuid:b6d6a510-8f2b-40e4-8a30-e199afd87745" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">CIFAR-10–建模、建造和培训</h1>
                
            
            
                
<p class="calibre2">这个例子展示了如何创建一个 CNN 来对 CIFAR-10 数据集中的图像进行分类。我们将使用一个简单的卷积神经网络实现几个卷积和完全连接的层。</p>
<p class="calibre2">尽管网络架构非常简单，但您将会看到它在尝试检测 CIFAR-10 图像中的对象时表现如何。</p>
<p class="calibre2">所以，让我们从这个实现开始。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Used packages</title>
    <meta content="urn:uuid:b6d6a510-8f2b-40e4-8a30-e199afd87745" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">用过的包装</h1>
                
            
            
                
<p class="calibre2">我们为此实施导入了所有必需的包:</p>
<pre class="calibre21">%matplotlib inline<br class="title-page-name"/>%config InlineBackend.figure_format = 'retina'<br class="title-page-name"/><br class="title-page-name"/>from urllib.request import urlretrieve<br class="title-page-name"/>from os.path import isfile, isdir<br class="title-page-name"/>from tqdm import tqdm<br class="title-page-name"/>import tarfile<br class="title-page-name"/>import numpy as np<br class="title-page-name"/>import random<br class="title-page-name"/>import matplotlib.pyplot as plt<br class="title-page-name"/>from sklearn.preprocessing import LabelBinarizer<br class="title-page-name"/>from sklearn.preprocessing import OneHotEncoder<br class="title-page-name"/><br class="title-page-name"/>import pickle<br class="title-page-name"/>import tensorflow as tf</pre>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Loading the CIFAR-10 dataset</title>
    <meta content="urn:uuid:b6d6a510-8f2b-40e4-8a30-e199afd87745" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">加载 CIFAR-10 数据集</h1>
                
            
            
                
<p class="calibre2">在这个实现中，我们将使用 CIFAR-10，它是用于对象检测的最广泛使用的数据集之一。因此，让我们首先定义一个助手类来下载和提取 CIFAR-10 数据集(如果尚未下载的话):</p>
<pre class="calibre21">cifar10_batches_dir_path = 'cifar-10-batches-py'<br class="title-page-name"/><br class="title-page-name"/>tar_gz_filename = 'cifar-10-python.tar.gz'<br class="title-page-name"/><br class="title-page-name"/>class DLProgress(tqdm):<br class="title-page-name"/>    last_block = 0<br class="title-page-name"/><br class="title-page-name"/>    def hook(self, block_num=1, block_size=1, total_size=None):<br class="title-page-name"/>        self.total = total_size<br class="title-page-name"/>        self.update((block_num - self.last_block) * block_size)<br class="title-page-name"/>        self.last_block = block_num<br class="title-page-name"/><br class="title-page-name"/>if not isfile(tar_gz_filename):<br class="title-page-name"/>    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Python Images Batches') as pbar:<br class="title-page-name"/>        urlretrieve(<br class="title-page-name"/>            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',<br class="title-page-name"/>            tar_gz_filename,<br class="title-page-name"/>            pbar.hook)<br class="title-page-name"/><br class="title-page-name"/>if not isdir(cifar10_batches_dir_path):<br class="title-page-name"/>    with tarfile.open(tar_gz_filename) as tar:<br class="title-page-name"/>        tar.extractall()<br class="title-page-name"/>        tar.close()</pre>
<p class="calibre2">下载并提取 CIFAR-10 数据集后，您会发现它已经被分成了五批。CIFAR-10 包含 10 个类别的图像:</p>
<ul class="calibre7">
<li class="calibre8"><kbd class="calibre12">airplane</kbd></li>
<li class="calibre8"><kbd class="calibre12">automobile</kbd></li>
<li class="calibre8"><kbd class="calibre12">bird</kbd></li>
<li class="calibre8"><kbd class="calibre12">cat</kbd></li>
<li class="calibre8"><kbd class="calibre12">deer</kbd></li>
<li class="calibre8"><kbd class="calibre12">dog</kbd></li>
<li class="calibre8"><kbd class="calibre12">frog</kbd></li>
<li class="calibre8"><kbd class="calibre12">horse</kbd></li>
<li class="calibre8"><kbd class="calibre12">ship</kbd></li>
<li class="calibre8"><kbd class="calibre12">truck</kbd></li>
</ul>
<p class="calibre2">在我们深入构建网络核心之前，让我们做一些数据分析和预处理。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Data analysis and preprocessing</title>
    <meta content="urn:uuid:b6d6a510-8f2b-40e4-8a30-e199afd87745" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">数据分析和预处理</h1>
                
            
            
                
<p class="calibre2">我们需要分析数据集并做一些基本的预处理。因此，让我们从定义一些帮助函数开始，这些函数将使我们能够从我们拥有的五个批次中加载一个特定的批次，并打印关于该批次及其样本的一些分析:</p>
<pre class="calibre21"># Defining a helper function for loading a batch of images<br class="title-page-name"/>def load_batch(cifar10_dataset_dir_path, batch_num):<br class="title-page-name"/>    <br class="title-page-name"/>    with open(cifar10_dataset_dir_path + '/data_batch_' + str(batch_num), mode='rb') as file:<br class="title-page-name"/>        batch = pickle.load(file, encoding='latin1')<br class="title-page-name"/><br class="title-page-name"/>    input_features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)<br class="title-page-name"/>    target_labels = batch['labels']<br class="title-page-name"/><br class="title-page-name"/>    return input_features, target_labels</pre>
<p class="calibre2">然后，我们定义一个函数，它可以帮助我们显示特定批次中特定样本的统计数据:</p>
<pre class="calibre21">#Defining a function to show the stats for batch ans specific sample<br class="title-page-name"/>def batch_image_stats(cifar10_dataset_dir_path, batch_num, sample_num):<br class="title-page-name"/><br class="title-page-name"/>    batch_nums = list(range(1, 6))<br class="title-page-name"/><br class="title-page-name"/>    #checking if the batch_num is a valid batch number<br class="title-page-name"/>    if batch_num not in batch_nums:<br class="title-page-name"/>        print('Batch Num is out of Range. You can choose from these Batch nums: {}'.format(batch_nums))<br class="title-page-name"/>        return None<br class="title-page-name"/><br class="title-page-name"/>    input_features, target_labels = load_batch(cifar10_dataset_dir_path, batch_num)<br class="title-page-name"/><br class="title-page-name"/>    #checking if the sample_num is a valid sample number<br class="title-page-name"/>    if not (0 &lt;= sample_num &lt; len(input_features)):<br class="title-page-name"/>        print('{} samples in batch {}. {} is not a valid sample number.'.format(len(input_features), batch_num, sample_num))<br class="title-page-name"/>        return None<br class="title-page-name"/><br class="title-page-name"/>    print('\nStatistics of batch number {}:'.format(batch_num))<br class="title-page-name"/>    print('Number of samples in this batch: {}'.format(len(input_features)))<br class="title-page-name"/>    print('Per class counts of each Label: {}'.format(dict(zip(*np.unique(target_labels, return_counts=True)))))<br class="title-page-name"/><br class="title-page-name"/>    image = input_features[sample_num]<br class="title-page-name"/>    label = target_labels[sample_num]<br class="title-page-name"/>    cifar10_class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']<br class="title-page-name"/><br class="title-page-name"/>    print('\nSample Image Number {}:'.format(sample_num))<br class="title-page-name"/>    print('Sample image - Minimum pixel value: {} Maximum pixel value: {}'.format(image.min(), image.max()))<br class="title-page-name"/>    print('Sample image - Shape: {}'.format(image.shape))<br class="title-page-name"/>    print('Sample Label - Label Id: {} Name: {}'.format(label, cifar10_class_names[label]))<br class="title-page-name"/>    plt.axis('off')<br class="title-page-name"/>    plt.imshow(image)</pre>
<p class="calibre2">现在，我们可以使用该函数来处理数据集并可视化特定图像:</p>
<pre class="calibre21"># Explore a specific batch and sample from the dataset<br class="title-page-name"/>batch_num = 3<br class="title-page-name"/>sample_num = 6<br class="title-page-name"/>batch_image_stats(cifar10_batches_dir_path, batch_num, sample_num)</pre>
<p class="calibre2">输出如下所示:</p>
<pre class="calibre21"><br class="title-page-name"/>Statistics of batch number 3:<br class="title-page-name"/>Number of samples in this batch: 10000<br class="title-page-name"/>Per class counts of each Label: {0: 994, 1: 1042, 2: 965, 3: 997, 4: 990, 5: 1029, 6: 978, 7: 1015, 8: 961, 9: 1029}<br class="title-page-name"/><br class="title-page-name"/>Sample Image Number 6:<br class="title-page-name"/>Sample image - Minimum pixel value: 30 Maximum pixel value: 242<br class="title-page-name"/>Sample image - Shape: (32, 32, 3)<br class="title-page-name"/>Sample Label - Label Id: 8 Name: ship</pre>
<div><img src="img/ae827baa-2394-4eaf-93cd-018a7ae7b8a1.png" class="calibre109"/></div>
<p>图 11.2:来自批次 3 的样本图像 6</p>
<p class="calibre2">在将我们的数据集输入模型之前，我们需要将其归一化到 0 到 1 的范围内。</p>
<p class="calibre2">批量归一化优化网络训练。已经证明它有几个好处:</p>
<ul class="calibre7">
<li class="calibre8"><strong class="calibre1">更快的训练</strong>:由于网络前向传递过程中的额外计算和网络后向传递过程中要训练的额外超参数，每个训练步骤都会更慢。然而，它应该收敛得更快，所以训练应该更快。</li>
<li class="calibre8"><strong class="calibre1">更高的学习速率</strong>:梯度下降算法主要要求网络以较小的学习速率收敛到损失函数的最小值。随着神经网络越来越深，它们的梯度值在反向传播过程中变得越来越小，因此它们通常需要更多的迭代。使用批量标准化的思想允许我们使用更高的学习率，这进一步提高了网络训练的速度。</li>
<li class="calibre8"><strong class="calibre1">易于初始化权重</strong>:权重初始化可能会比较困难，如果我们使用深度神经网络的话会更加困难。批量标准化似乎允许我们在选择初始权重时不那么小心。</li>
</ul>
<p class="calibre2">因此，让我们通过定义一个函数来对输入图像列表进行归一化，使这些图像的所有像素值都在 0 和 1 之间:</p>
<div><div><div><pre class="calibre21">#Normalize CIFAR-10 images to be in the range of [0,1]<br class="title-page-name"/><br class="title-page-name"/>def normalize_images(images):<br class="title-page-name"/>    <br class="title-page-name"/>    # initial zero ndarray<br class="title-page-name"/>    normalized_images = np.zeros_like(images.astype(float))<br class="title-page-name"/>    <br class="title-page-name"/>    # The first images index is number of images where the other indices indicates<br class="title-page-name"/>    # hieight, width and depth of the image<br class="title-page-name"/>    num_images = images.shape[0]<br class="title-page-name"/>    <br class="title-page-name"/>    # Computing the minimum and maximum value of the input image to do the normalization based on them<br class="title-page-name"/>    maximum_value, minimum_value = images.max(), images.min()<br class="title-page-name"/>    <br class="title-page-name"/>    # Normalize all the pixel values of the images to be from 0 to 1<br class="title-page-name"/>    for img in range(num_images):<br class="title-page-name"/>        normalized_images[img,...] = (images[img, ...] - float(minimum_value)) / float(maximum_value - minimum_value)<br class="title-page-name"/><br class="title-page-name"/>    return normalized_images</pre></div>
</div>
</div>
<p class="calibre2">接下来，我们需要实现另一个助手函数来编码输入图像的标签。在这个函数中，我们将使用 sklearn 的一键编码，其中每个图像标签由一个零向量表示，除了这个向量所表示的图像的类索引。</p>
<p class="calibre2">输出向量的大小将取决于我们在数据集中拥有的类的数量，在 CIFAR-10 数据的情况下是 10 个类:</p>
<pre class="calibre21">#encoding the input images. Each image will be represented by a vector of zeros except for the class index of the image <br class="title-page-name"/># that this vector represents. The length of this vector depends on number of classes that we have<br class="title-page-name"/># the dataset which is 10 in CIFAR-10<br class="title-page-name"/><br class="title-page-name"/>def one_hot_encode(images):<br class="title-page-name"/>    <br class="title-page-name"/>    num_classes = 10<br class="title-page-name"/>    <br class="title-page-name"/>    #use sklearn helper function of OneHotEncoder() to do that<br class="title-page-name"/>    encoder = OneHotEncoder(num_classes)<br class="title-page-name"/>    <br class="title-page-name"/>    #resize the input images to be 2D<br class="title-page-name"/>    input_images_resized_to_2d = np.array(images).reshape(-1,1)<br class="title-page-name"/>    one_hot_encoded_targets = encoder.fit_transform(input_images_resized_to_2d)<br class="title-page-name"/>    <br class="title-page-name"/>    return one_hot_encoded_targets.toarray()</pre>
<p class="calibre2">现在，是时候调用前面的帮助器函数来进行预处理并持久化数据集，以便我们以后可以使用它:</p>
<pre class="calibre21">def preprocess_persist_data(cifar10_batches_dir_path, normalize_images, one_hot_encode):<br class="title-page-name"/>    <br class="title-page-name"/>    <br class="title-page-name"/>    num_batches = 5<br class="title-page-name"/>    valid_input_features = []<br class="title-page-name"/>    valid_target_labels = []<br class="title-page-name"/><br class="title-page-name"/>    for batch_ind in range(1, num_batches + 1):<br class="title-page-name"/>        <br class="title-page-name"/>        #Loading batch<br class="title-page-name"/>        input_features, target_labels = load_batch(cifar10_batches_dir_path, batch_ind)<br class="title-page-name"/>        num_validation_images = int(len(input_features) * 0.1)<br class="title-page-name"/><br class="title-page-name"/>        # Preprocess the current batch and perisist it for future use<br class="title-page-name"/>        input_features = normalize_images(input_features[:-num_validation_images])<br class="title-page-name"/>        target_labels = one_hot_encode( target_labels[:-num_validation_images])<br class="title-page-name"/>        <br class="title-page-name"/>        #Persisting the preprocessed batch<br class="title-page-name"/>        pickle.dump((input_features, target_labels), open('preprocess_train_batch_' + str(batch_ind) + '.p', 'wb'))<br class="title-page-name"/>        <br class="title-page-name"/><br class="title-page-name"/>        # Define a subset of the training images to be used for validating our model<br class="title-page-name"/>        valid_input_features.extend(input_features[-num_validation_images:])<br class="title-page-name"/>        valid_target_labels.extend(target_labels[-num_validation_images:])<br class="title-page-name"/><br class="title-page-name"/>    # Preprocessing and persisting the validationi subset<br class="title-page-name"/>    input_features = normalize_images( np.array(valid_input_features))<br class="title-page-name"/>    target_labels = one_hot_encode(np.array(valid_target_labels))<br class="title-page-name"/>    <br class="title-page-name"/>    pickle.dump((input_features, target_labels), open('preprocess_valid.p', 'wb'))<br class="title-page-name"/>    <br class="title-page-name"/><br class="title-page-name"/>    #Now it's time to preporcess and persist the test batche<br class="title-page-name"/>    with open(cifar10_batches_dir_path + '/test_batch', mode='rb') as file:<br class="title-page-name"/>        test_batch = pickle.load(file, encoding='latin1')<br class="title-page-name"/><br class="title-page-name"/><br class="title-page-name"/>    test_input_features = test_batch['data'].reshape((len(test_batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)<br class="title-page-name"/>    test_input_labels = test_batch['labels']<br class="title-page-name"/><br class="title-page-name"/>    # Normalizing and encoding the test batch<br class="title-page-name"/>    input_features = normalize_images( np.array(test_input_features))<br class="title-page-name"/>    target_labels = one_hot_encode(np.array(test_input_labels))<br class="title-page-name"/>    <br class="title-page-name"/>    pickle.dump((input_features, target_labels), open('preprocess_test.p', 'wb'))<br class="title-page-name"/>    <br class="title-page-name"/># Calling the helper function above to preprocess and persist the training, validation, and testing set<br class="title-page-name"/>preprocess_persist_data(cifar10_batches_dir_path, normalize_images, one_hot_encode)</pre>
<p class="calibre2">因此，我们将预处理后的数据保存到磁盘上。</p>
<p class="calibre2">我们还需要加载验证集，以便在训练过程的不同时期在其上运行训练模型:</p>
<pre class="calibre21"># Load the Preprocessed Validation data<br class="title-page-name"/>valid_input_features, valid_input_labels = pickle.load(open('preprocess_valid.p', mode='rb'))</pre>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Building the network</title>
    <meta content="urn:uuid:b6d6a510-8f2b-40e4-8a30-e199afd87745" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">构建网络</h1>
                
            
            
                
<p class="calibre2">现在是时候构建我们的分类应用程序的核心了，这是这个 CNN 架构的计算图，但是为了最大化这个实现的好处，我们不打算使用 TensorFlow layers API。相反，我们将使用它的张量流神经网络版本。</p>
<p class="calibre2">因此，让我们从定义模型输入占位符开始，这些占位符将输入图像、目标类和丢弃层的保持概率参数(这有助于我们通过丢弃一些连接来降低架构的复杂性，从而减少过度拟合的机会):</p>
<pre class="calibre21"><br class="title-page-name"/># Defining the model inputs<br class="title-page-name"/>def images_input(img_shape):<br class="title-page-name"/> return tf.placeholder(tf.float32, (None, ) + img_shape, name="input_images")<br class="title-page-name"/><br class="title-page-name"/>def target_input(num_classes):<br class="title-page-name"/> <br class="title-page-name"/> target_input = tf.placeholder(tf.int32, (None, num_classes), name="input_images_target")<br class="title-page-name"/> return target_input<br class="title-page-name"/><br class="title-page-name"/>#define a function for the dropout layer keep probability<br class="title-page-name"/>def keep_prob_input():<br class="title-page-name"/> return tf.placeholder(tf.float32, name="keep_prob")</pre>
<p class="calibre2">接下来，我们需要使用 TensorFlow 神经网络实现版本来构建具有最大池的卷积层:</p>
<pre class="calibre21"># Applying a convolution operation to the input tensor followed by max pooling<br class="title-page-name"/>def conv2d_layer(input_tensor, conv_layer_num_outputs, conv_kernel_size, conv_layer_strides, pool_kernel_size, pool_layer_strides):<br class="title-page-name"/><br class="title-page-name"/><br class="title-page-name"/> input_depth = input_tensor.get_shape()[3].value<br class="title-page-name"/> weight_shape = conv_kernel_size + (input_depth, conv_layer_num_outputs,)<br class="title-page-name"/> <br class="title-page-name"/> <br class="title-page-name"/> #Defining layer weights and biases<br class="title-page-name"/> weights = tf.Variable(tf.random_normal(weight_shape))<br class="title-page-name"/> biases = tf.Variable(tf.random_normal((conv_layer_num_outputs,)))<br class="title-page-name"/> <br class="title-page-name"/> #Considering the biase variable<br class="title-page-name"/> conv_strides = (1,) + conv_layer_strides + (1,)<br class="title-page-name"/><br class="title-page-name"/><br class="title-page-name"/> conv_layer = tf.nn.conv2d(input_tensor, weights, strides=conv_strides, padding='SAME')<br class="title-page-name"/> conv_layer = tf.nn.bias_add(conv_layer, biases)<br class="title-page-name"/><br class="title-page-name"/> conv_kernel_size = (1,) + conv_kernel_size + (1,)<br class="title-page-name"/><br class="title-page-name"/> pool_strides = (1,) + pool_layer_strides + (1,)<br class="title-page-name"/> pool_layer = tf.nn.max_pool(conv_layer, ksize=conv_kernel_size, strides=pool_strides, padding='SAME')<br class="title-page-name"/> return pool_layer</pre>
<p class="calibre2">正如您可能在前一章中看到的，最大池化操作的输出是一个 4D 张量，它与完全连接的层所需的输入格式不兼容。因此，我们需要实现一个展平图层，将 max pooling 图层的输出从 4D 张量转换为 2D 张量:</p>
<pre class="calibre21">#Flatten the output of max pooling layer to be fing to the fully connected layer which only accepts the output<br class="title-page-name"/># to be in 2D<br class="title-page-name"/>def flatten_layer(input_tensor):<br class="title-page-name"/>return tf.contrib.layers.flatten(input_tensor)</pre>
<p class="calibre2">接下来，我们需要定义一个助手函数，使我们能够将一个完全连接的层添加到我们的架构中:</p>
<pre class="calibre21">#Define the fully connected layer that will use the flattened output of the stacked convolution layers<br class="title-page-name"/>#to do the actuall classification<br class="title-page-name"/>def fully_connected_layer(input_tensor, num_outputs):<br class="title-page-name"/> return tf.layers.dense(input_tensor, num_outputs)</pre>
<p class="calibre2">最后，在使用这些辅助函数创建整个架构之前，我们需要创建另一个辅助函数，该辅助函数将获取完全连接层的输出，并根据数据集中的类数量生成 10 个实数值:</p>
<pre class="calibre21">#Defining the output function<br class="title-page-name"/>def output_layer(input_tensor, num_outputs):<br class="title-page-name"/>    return  tf.layers.dense(input_tensor, num_outputs)</pre>
<p class="calibre2">因此，让我们继续定义函数，将所有这些零碎信息放在一起，创建一个具有三个卷积层的 CNN。每个操作之后都有最大池操作。我们还将有两个完全连接的层，其中每一层后面都有一个下降层，以降低模型的复杂性并防止过度拟合。最后，我们将让输出层产生 10 个实值向量，其中每个值代表每个正确类的分数:</p>
<pre class="calibre21">def build_convolution_net(image_data, keep_prob):<br class="title-page-name"/> <br class="title-page-name"/> # Applying 3 convolution layers followed by max pooling layers<br class="title-page-name"/> conv_layer_1 = conv2d_layer(image_data, 32, (3,3), (1,1), (3,3), (3,3)) <br class="title-page-name"/> conv_layer_2 = conv2d_layer(conv_layer_1, 64, (3,3), (1,1), (3,3), (3,3))<br class="title-page-name"/> conv_layer_3 = conv2d_layer(conv_layer_2, 128, (3,3), (1,1), (3,3), (3,3))<br class="title-page-name"/><br class="title-page-name"/># Flatten the output from 4D to 2D to be fed to the fully connected layer<br class="title-page-name"/> flatten_output = flatten_layer(conv_layer_3)<br class="title-page-name"/><br class="title-page-name"/># Applying 2 fully connected layers with drop out<br class="title-page-name"/> fully_connected_layer_1 = fully_connected_layer(flatten_output, 64)<br class="title-page-name"/> fully_connected_layer_1 = tf.nn.dropout(fully_connected_layer_1, keep_prob)<br class="title-page-name"/> fully_connected_layer_2 = fully_connected_layer(fully_connected_layer_1, 32)<br class="title-page-name"/> fully_connected_layer_2 = tf.nn.dropout(fully_connected_layer_2, keep_prob)<br class="title-page-name"/> <br class="title-page-name"/> #Applying the output layer while the output size will be the number of categories that we have<br class="title-page-name"/> #in CIFAR-10 dataset<br class="title-page-name"/> output_logits = output_layer(fully_connected_layer_2, 10)<br class="title-page-name"/> <br class="title-page-name"/> #returning output<br class="title-page-name"/> return output_logits</pre>
<p class="calibre2">让我们调用前面的帮助函数来构建网络，并定义其损耗和优化标准:</p>
<pre class="calibre21">#Using the helper function above to build the network<br class="title-page-name"/><br class="title-page-name"/>#First off, let's remove all the previous inputs, weights, biases form the previous runs<br class="title-page-name"/>tf.reset_default_graph()<br class="title-page-name"/><br class="title-page-name"/># Defining the input placeholders to the convolution neural network<br class="title-page-name"/>input_images = images_input((32, 32, 3))<br class="title-page-name"/>input_images_target = target_input(10)<br class="title-page-name"/>keep_prob = keep_prob_input()<br class="title-page-name"/><br class="title-page-name"/># Building the models<br class="title-page-name"/>logits_values = build_convolution_net(input_images, keep_prob)<br class="title-page-name"/><br class="title-page-name"/># Name logits Tensor, so that is can be loaded from disk after training<br class="title-page-name"/>logits_values = tf.identity(logits_values, name='logits')<br class="title-page-name"/><br class="title-page-name"/># defining the model loss<br class="title-page-name"/>model_cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits_values, labels=input_images_target))<br class="title-page-name"/><br class="title-page-name"/># Defining the model optimizer<br class="title-page-name"/>model_optimizer = tf.train.AdamOptimizer().minimize(model_cost)<br class="title-page-name"/><br class="title-page-name"/># Calculating and averaging the model accuracy<br class="title-page-name"/>correct_prediction = tf.equal(tf.argmax(logits_values, 1), tf.argmax(input_images_target, 1))<br class="title-page-name"/>accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='model_accuracy')<br class="title-page-name"/>tests.test_conv_net(build_convolution_net)</pre>
<p class="calibre2">现在我们已经建立了这个网络的计算架构，是时候开始训练过程并看到一些结果了。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Model training</title>
    <meta content="urn:uuid:b6d6a510-8f2b-40e4-8a30-e199afd87745" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">模特培训</h1>
                
            
            
                
<p class="calibre2">因此，让我们定义一个助手函数，它将使我们能够开始训练过程。该函数将输入图像、目标类的一键编码和保持概率值作为输入。然后，它会将这些值提供给计算图形，并调用模型优化器:</p>
<pre class="calibre21">#Define a helper function for kicking off the training process<br class="title-page-name"/>def train(session, model_optimizer, keep_probability, in_feature_batch, target_batch):<br class="title-page-name"/>session.run(model_optimizer, feed_dict={input_images: in_feature_batch, input_images_target: target_batch, keep_prob: keep_probability})</pre>
<p class="calibre2">我们将需要在训练过程的不同时间步骤中验证我们的模型，因此我们将定义一个助手函数，它将在验证集上打印出模型的准确性:</p>
<pre class="calibre21">#Defining a helper funcitno for print information about the model accuracy and it's validation accuracy as well<br class="title-page-name"/>def print_model_stats(session, input_feature_batch, target_label_batch, model_cost, model_accuracy):<br class="title-page-name"/>    <br class="title-page-name"/>    validation_loss = session.run(model_cost, feed_dict={input_images: input_feature_batch, input_images_target: target_label_batch, keep_prob: 1.0})<br class="title-page-name"/>    validation_accuracy = session.run(model_accuracy, feed_dict={input_images: input_feature_batch, input_images_target: target_label_batch, keep_prob: 1.0})<br class="title-page-name"/>    <br class="title-page-name"/>    print("Valid Loss: %f" %(validation_loss))<br class="title-page-name"/>    print("Valid accuracy: %f" % (validation_accuracy))</pre>
<p class="calibre2">让我们也定义模型超参数，我们可以用它来调整模型以获得更好的性能:</p>
<pre class="calibre21"># Model Hyperparameters<br class="title-page-name"/>num_epochs = 100<br class="title-page-name"/>batch_size = 128<br class="title-page-name"/>keep_probability = 0.5</pre>
<p class="calibre2">现在，让我们开始训练过程，但只针对一批 CIFAR-10 数据集，看看基于这一批的模型精度如何。</p>
<p class="calibre2">但是，在此之前，我们将定义一个助手函数，该函数将加载一个批处理训练，并将输入图像与目标类分开:</p>
<pre class="calibre21"># Splitting the dataset features and labels to batches<br class="title-page-name"/>def batch_split_features_labels(input_features, target_labels, train_batch_size):<br class="title-page-name"/>    for start in range(0, len(input_features), train_batch_size):<br class="title-page-name"/>        end = min(start + train_batch_size, len(input_features))<br class="title-page-name"/>        yield input_features[start:end], target_labels[start:end]<br class="title-page-name"/><br class="title-page-name"/>#Loading the persisted preprocessed training batches<br class="title-page-name"/>def load_preprocess_training_batch(batch_id, batch_size):<br class="title-page-name"/>    filename = 'preprocess_train_batch_' + str(batch_id) + '.p'<br class="title-page-name"/>    input_features, target_labels = pickle.load(open(filename, mode='rb'))<br class="title-page-name"/><br class="title-page-name"/>    # Returning the training images in batches according to the batch size defined above<br class="title-page-name"/>    return batch_split_features_labels(input_features, target_labels, train_batch_size)</pre>
<p class="calibre2">现在，让我们开始一批的训练过程:</p>
<pre class="calibre21">print('Training on only a Single Batch from the CIFAR-10 Dataset...')<br class="title-page-name"/>with tf.Session() as sess:<br class="title-page-name"/> <br class="title-page-name"/> # Initializing the variables<br class="title-page-name"/> sess.run(tf.global_variables_initializer())<br class="title-page-name"/> <br class="title-page-name"/> # Training cycle<br class="title-page-name"/> for epoch in range(num_epochs):<br class="title-page-name"/> batch_ind = 1<br class="title-page-name"/> <br class="title-page-name"/> for batch_features, batch_labels in load_preprocess_training_batch(batch_ind, batch_size):<br class="title-page-name"/> train(sess, model_optimizer, keep_probability, batch_features, batch_labels)<br class="title-page-name"/> <br class="title-page-name"/> print('Epoch number {:&gt;2}, CIFAR-10 Batch Number {}: '.format(epoch + 1, batch_ind), end='')<br class="title-page-name"/> print_model_stats(sess, batch_features, batch_labels, model_cost, accuracy)<br class="title-page-name"/><br class="title-page-name"/>Output:<br class="title-page-name"/>.<br class="title-page-name"/>.<br class="title-page-name"/>.<br class="title-page-name"/>Epoch number 85, CIFAR-10 Batch Number 1: Valid Loss: 1.490792<br class="title-page-name"/>Valid accuracy: 0.550000<br class="title-page-name"/>Epoch number 86, CIFAR-10 Batch Number 1: Valid Loss: 1.487118<br class="title-page-name"/>Valid accuracy: 0.525000<br class="title-page-name"/>Epoch number 87, CIFAR-10 Batch Number 1: Valid Loss: 1.309082<br class="title-page-name"/>Valid accuracy: 0.575000<br class="title-page-name"/>Epoch number 88, CIFAR-10 Batch Number 1: Valid Loss: 1.446488<br class="title-page-name"/>Valid accuracy: 0.475000<br class="title-page-name"/>Epoch number 89, CIFAR-10 Batch Number 1: Valid Loss: 1.430939<br class="title-page-name"/>Valid accuracy: 0.550000<br class="title-page-name"/>Epoch number 90, CIFAR-10 Batch Number 1: Valid Loss: 1.484480<br class="title-page-name"/>Valid accuracy: 0.525000<br class="title-page-name"/>Epoch number 91, CIFAR-10 Batch Number 1: Valid Loss: 1.345774<br class="title-page-name"/>Valid accuracy: 0.575000<br class="title-page-name"/>Epoch number 92, CIFAR-10 Batch Number 1: Valid Loss: 1.425942<br class="title-page-name"/>Valid accuracy: 0.575000<br class="title-page-name"/><br class="title-page-name"/>Epoch number 93, CIFAR-10 Batch Number 1: Valid Loss: 1.451115<br class="title-page-name"/>Valid accuracy: 0.550000<br class="title-page-name"/>Epoch number 94, CIFAR-10 Batch Number 1: Valid Loss: 1.368719<br class="title-page-name"/>Valid accuracy: 0.600000<br class="title-page-name"/>Epoch number 95, CIFAR-10 Batch Number 1: Valid Loss: 1.336483<br class="title-page-name"/>Valid accuracy: 0.600000<br class="title-page-name"/>Epoch number 96, CIFAR-10 Batch Number 1: Valid Loss: 1.383425<br class="title-page-name"/>Valid accuracy: 0.575000<br class="title-page-name"/>Epoch number 97, CIFAR-10 Batch Number 1: Valid Loss: 1.378877<br class="title-page-name"/>Valid accuracy: 0.625000<br class="title-page-name"/>Epoch number 98, CIFAR-10 Batch Number 1: Valid Loss: 1.343391<br class="title-page-name"/>Valid accuracy: 0.600000<br class="title-page-name"/>Epoch number 99, CIFAR-10 Batch Number 1: Valid Loss: 1.319342<br class="title-page-name"/>Valid accuracy: 0.625000<br class="title-page-name"/>Epoch number 100, CIFAR-10 Batch Number 1: Valid Loss: 1.340849<br class="title-page-name"/>Valid accuracy: 0.525000</pre>
<p class="calibre2">如您所见，仅在单个批次上训练时，验证准确性并不是很好。让我们看看仅基于模型的完整训练过程，验证准确性将如何变化:</p>
<pre class="calibre21">model_save_path = './cifar-10_classification'<br class="title-page-name"/><br class="title-page-name"/>with tf.Session() as sess:<br class="title-page-name"/> # Initializing the variables<br class="title-page-name"/> sess.run(tf.global_variables_initializer())<br class="title-page-name"/> <br class="title-page-name"/> # Training cycle<br class="title-page-name"/> for epoch in range(num_epochs):<br class="title-page-name"/> <br class="title-page-name"/> # iterate through the batches<br class="title-page-name"/> num_batches = 5<br class="title-page-name"/> <br class="title-page-name"/> for batch_ind in range(1, num_batches + 1):<br class="title-page-name"/> for batch_features, batch_labels in load_preprocess_training_batch(batch_ind, batch_size):<br class="title-page-name"/> train(sess, model_optimizer, keep_probability, batch_features, batch_labels)<br class="title-page-name"/> <br class="title-page-name"/> print('Epoch number{:&gt;2}, CIFAR-10 Batch Number {}: '.format(epoch + 1, batch_ind), end='')<br class="title-page-name"/> print_model_stats(sess, batch_features, batch_labels, model_cost, accuracy)<br class="title-page-name"/> <br class="title-page-name"/> # Save the trained Model<br class="title-page-name"/> saver = tf.train.Saver()<br class="title-page-name"/> save_path = saver.save(sess, model_save_path)<br class="title-page-name"/><br class="title-page-name"/>Output:<br class="title-page-name"/>.<br class="title-page-name"/>.<br class="title-page-name"/>.<br class="title-page-name"/>Epoch number94, CIFAR-10 Batch Number 5: Valid Loss: 0.316593<br class="title-page-name"/>Valid accuracy: 0.925000<br class="title-page-name"/>Epoch number95, CIFAR-10 Batch Number 1: Valid Loss: 0.285429<br class="title-page-name"/>Valid accuracy: 0.925000<br class="title-page-name"/>Epoch number95, CIFAR-10 Batch Number 2: Valid Loss: 0.347411<br class="title-page-name"/>Valid accuracy: 0.825000<br class="title-page-name"/>Epoch number95, CIFAR-10 Batch Number 3: Valid Loss: 0.232483<br class="title-page-name"/>Valid accuracy: 0.950000<br class="title-page-name"/>Epoch number95, CIFAR-10 Batch Number 4: Valid Loss: 0.294707<br class="title-page-name"/>Valid accuracy: 0.900000<br class="title-page-name"/>Epoch number95, CIFAR-10 Batch Number 5: Valid Loss: 0.299490<br class="title-page-name"/>Valid accuracy: 0.975000<br class="title-page-name"/>Epoch number96, CIFAR-10 Batch Number 1: Valid Loss: 0.302191<br class="title-page-name"/>Valid accuracy: 0.950000<br class="title-page-name"/>Epoch number96, CIFAR-10 Batch Number 2: Valid Loss: 0.347043<br class="title-page-name"/>Valid accuracy: 0.750000<br class="title-page-name"/>Epoch number96, CIFAR-10 Batch Number 3: Valid Loss: 0.252851<br class="title-page-name"/>Valid accuracy: 0.875000<br class="title-page-name"/>Epoch number96, CIFAR-10 Batch Number 4: Valid Loss: 0.291433<br class="title-page-name"/>Valid accuracy: 0.950000<br class="title-page-name"/>Epoch number96, CIFAR-10 Batch Number 5: Valid Loss: 0.286192<br class="title-page-name"/>Valid accuracy: 0.950000<br class="title-page-name"/>Epoch number97, CIFAR-10 Batch Number 1: Valid Loss: 0.277105<br class="title-page-name"/>Valid accuracy: 0.950000<br class="title-page-name"/>Epoch number97, CIFAR-10 Batch Number 2: Valid Loss: 0.305842<br class="title-page-name"/>Valid accuracy: 0.850000<br class="title-page-name"/>Epoch number97, CIFAR-10 Batch Number 3: Valid Loss: 0.215272<br class="title-page-name"/>Valid accuracy: 0.950000<br class="title-page-name"/>Epoch number97, CIFAR-10 Batch Number 4: Valid Loss: 0.313761<br class="title-page-name"/>Valid accuracy: 0.925000<br class="title-page-name"/>Epoch number97, CIFAR-10 Batch Number 5: Valid Loss: 0.313503<br class="title-page-name"/>Valid accuracy: 0.925000<br class="title-page-name"/>Epoch number98, CIFAR-10 Batch Number 1: Valid Loss: 0.265828<br class="title-page-name"/>Valid accuracy: 0.925000<br class="title-page-name"/>Epoch number98, CIFAR-10 Batch Number 2: Valid Loss: 0.308948<br class="title-page-name"/>Valid accuracy: 0.800000<br class="title-page-name"/>Epoch number98, CIFAR-10 Batch Number 3: Valid Loss: 0.232083<br class="title-page-name"/>Valid accuracy: 0.950000<br class="title-page-name"/>Epoch number98, CIFAR-10 Batch Number 4: Valid Loss: 0.298826<br class="title-page-name"/>Valid accuracy: 0.925000<br class="title-page-name"/>Epoch number98, CIFAR-10 Batch Number 5: Valid Loss: 0.297230<br class="title-page-name"/>Valid accuracy: 0.950000<br class="title-page-name"/>Epoch number99, CIFAR-10 Batch Number 1: Valid Loss: 0.304203<br class="title-page-name"/>Valid accuracy: 0.900000<br class="title-page-name"/>Epoch number99, CIFAR-10 Batch Number 2: Valid Loss: 0.308775<br class="title-page-name"/>Valid accuracy: 0.825000<br class="title-page-name"/>Epoch number99, CIFAR-10 Batch Number 3: Valid Loss: 0.225072<br class="title-page-name"/>Valid accuracy: 0.925000<br class="title-page-name"/>Epoch number99, CIFAR-10 Batch Number 4: Valid Loss: 0.263737<br class="title-page-name"/>Valid accuracy: 0.925000<br class="title-page-name"/>Epoch number99, CIFAR-10 Batch Number 5: Valid Loss: 0.278601<br class="title-page-name"/>Valid accuracy: 0.950000<br class="title-page-name"/>Epoch number100, CIFAR-10 Batch Number 1: Valid Loss: 0.293509<br class="title-page-name"/>Valid accuracy: 0.950000<br class="title-page-name"/>Epoch number100, CIFAR-10 Batch Number 2: Valid Loss: 0.303817<br class="title-page-name"/>Valid accuracy: 0.875000<br class="title-page-name"/>Epoch number100, CIFAR-10 Batch Number 3: Valid Loss: 0.244428<br class="title-page-name"/>Valid accuracy: 0.900000<br class="title-page-name"/>Epoch number100, CIFAR-10 Batch Number 4: Valid Loss: 0.280712<br class="title-page-name"/>Valid accuracy: 0.925000<br class="title-page-name"/>Epoch number100, CIFAR-10 Batch Number 5: Valid Loss: 0.278625<br class="title-page-name"/>Valid accuracy: 0.950000</pre>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Testing the model</title>
    <meta content="urn:uuid:b6d6a510-8f2b-40e4-8a30-e199afd87745" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">测试模型</h1>
                
            
            
                
<p class="calibre2">让我们针对 CIFAR-10 数据集的测试集部分来测试训练好的模型。首先，我们将定义一个辅助函数，它将帮助我们可视化一些样本图像的预测及其对应的真实标签:</p>
<pre class="calibre21">#A helper function to visualize some samples and their corresponding predictions<br class="title-page-name"/>def display_samples_predictions(input_features, target_labels, samples_predictions):<br class="title-page-name"/> <br class="title-page-name"/> num_classes = 10<br class="title-page-name"/> <br class="title-page-name"/> cifar10_class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']<br class="title-page-name"/><br class="title-page-name"/>label_binarizer = LabelBinarizer()<br class="title-page-name"/> label_binarizer.fit(range(num_classes))<br class="title-page-name"/> label_inds = label_binarizer.inverse_transform(np.array(target_labels))<br class="title-page-name"/><br class="title-page-name"/>fig, axies = plt.subplots(nrows=4, ncols=2)<br class="title-page-name"/> fig.tight_layout()<br class="title-page-name"/> fig.suptitle('Softmax Predictions', fontsize=20, y=1.1)<br class="title-page-name"/><br class="title-page-name"/>num_predictions = 4<br class="title-page-name"/> margin = 0.05<br class="title-page-name"/> ind = np.arange(num_predictions)<br class="title-page-name"/> width = (1. - 2. * margin) / num_predictions<br class="title-page-name"/><br class="title-page-name"/>for image_ind, (feature, label_ind, prediction_indicies, prediction_values) in enumerate(zip(input_features, label_inds, samples_predictions.indices, samples_predictions.values)):<br class="title-page-name"/> prediction_names = [cifar10_class_names[pred_i] for pred_i in prediction_indicies]<br class="title-page-name"/> correct_name = cifar10_class_names[label_ind]<br class="title-page-name"/><br class="title-page-name"/>axies[image_ind][0].imshow(feature)<br class="title-page-name"/> axies[image_ind][0].set_title(correct_name)<br class="title-page-name"/> axies[image_ind][0].set_axis_off()<br class="title-page-name"/><br class="title-page-name"/>axies[image_ind][1].barh(ind + margin, prediction_values[::-1], width)<br class="title-page-name"/> axies[image_ind][1].set_yticks(ind + margin)<br class="title-page-name"/> axies[image_ind][1].set_yticklabels(prediction_names[::-1])<br class="title-page-name"/> axies[image_ind][1].set_xticks([0, 0.5, 1.0])</pre>
<p class="calibre2">现在，让我们恢复训练好的模型，并根据测试集对其进行测试:</p>
<pre class="calibre21">test_batch_size = 64<br class="title-page-name"/>save_model_path = './cifar-10_classification'<br class="title-page-name"/>#Number of images to visualize<br class="title-page-name"/>num_samples = 4<br class="title-page-name"/><br class="title-page-name"/>#Number of top predictions<br class="title-page-name"/>top_n_predictions = 4<br class="title-page-name"/><br class="title-page-name"/>#Defining a helper function for testing the trained model<br class="title-page-name"/>def test_classification_model():<br class="title-page-name"/><br class="title-page-name"/> input_test_features, target_test_labels = pickle.load(open('preprocess_test.p', mode='rb'))<br class="title-page-name"/> loaded_graph = tf.Graph()<br class="title-page-name"/>with tf.Session(graph=loaded_graph) as sess:<br class="title-page-name"/> <br class="title-page-name"/> # loading the trained model<br class="title-page-name"/> model = tf.train.import_meta_graph(save_model_path + '.meta')<br class="title-page-name"/> model.restore(sess, save_model_path)<br class="title-page-name"/><br class="title-page-name"/># Getting some input and output Tensors from loaded model<br class="title-page-name"/> model_input_values = loaded_graph.get_tensor_by_name('input_images:0')<br class="title-page-name"/> model_target = loaded_graph.get_tensor_by_name('input_images_target:0')<br class="title-page-name"/> model_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')<br class="title-page-name"/> model_logits = loaded_graph.get_tensor_by_name('logits:0')<br class="title-page-name"/> model_accuracy = loaded_graph.get_tensor_by_name('model_accuracy:0')<br class="title-page-name"/> <br class="title-page-name"/> # Testing the trained model on the test set batches<br class="title-page-name"/> test_batch_accuracy_total = 0<br class="title-page-name"/> test_batch_count = 0<br class="title-page-name"/> <br class="title-page-name"/> for input_test_feature_batch, input_test_label_batch in batch_split_features_labels(input_test_features, target_test_labels, test_batch_size):<br class="title-page-name"/> test_batch_accuracy_total += sess.run(<br class="title-page-name"/> model_accuracy,<br class="title-page-name"/> feed_dict={model_input_values: input_test_feature_batch, model_target: input_test_label_batch, model_keep_prob: 1.0})<br class="title-page-name"/> test_batch_count += 1<br class="title-page-name"/><br class="title-page-name"/>print('Test set accuracy: {}\n'.format(test_batch_accuracy_total/test_batch_count))<br class="title-page-name"/><br class="title-page-name"/># print some random images and their corresponding predictions from the test set results<br class="title-page-name"/> random_input_test_features, random_test_target_labels = tuple(zip(*random.sample(list(zip(input_test_features, target_test_labels)), num_samples)))<br class="title-page-name"/> <br class="title-page-name"/> random_test_predictions = sess.run(<br class="title-page-name"/> tf.nn.top_k(tf.nn.softmax(model_logits), top_n_predictions),<br class="title-page-name"/> feed_dict={model_input_values: random_input_test_features, model_target: random_test_target_labels, model_keep_prob: 1.0})<br class="title-page-name"/> <br class="title-page-name"/> display_samples_predictions(random_input_test_features, random_test_target_labels, random_test_predictions)<br class="title-page-name"/><br class="title-page-name"/>#Calling the function<br class="title-page-name"/>test_classification_model()<br class="title-page-name"/><br class="title-page-name"/>Output:<br class="title-page-name"/>INFO:tensorflow:Restoring parameters from ./cifar-10_classification<br class="title-page-name"/>Test set accuracy: 0.7540007961783439</pre>
<div><img src="img/fc105794-646e-4a0a-8fe0-c7c432a1ccca.png" class="calibre110"/></div>
<p class="calibre2">让我们想象另一个例子来看看一些错误:</p>
<div><img src="img/ee5f68c7-4a4e-40f9-9009-a78465f6559e.png" class="calibre111"/></div>
<p class="calibre2">现在，我们有一个大约 75%的测试准确率，这对于一个简单的 CNN 来说已经不错了。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Summary</title>
    <meta content="urn:uuid:b6d6a510-8f2b-40e4-8a30-e199afd87745" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">摘要</h1>
                
            
            
                
<p class="calibre2">本章向我们展示了如何创建一个 CNN 来对 CIFAR-10 数据集中的图像进行分类。在测试集上，分类准确率约为 79% - 80%。卷积层的输出也被绘制出来，但是很难看出神经网络如何识别和分类输入图像。需要更好的可视化技术。</p>
<p class="calibre2">接下来，我们将使用深度学习的现代和令人兴奋的实践之一，即迁移学习。迁移学习允许你在小数据集上使用深度学习的数据贪婪架构。</p>


            

            
        
    </body>

</html>
</body></html>